
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    [{"authors":null,"categories":null,"content":"Phân Tích về Kiến Trúc API Hiện Đại\nGiới thiệu Trong thế giới phát triển phần mềm, việc lựa chọn kiến trúc API không đơn thuần là một quyết định kỹ thuật, đó là một lựa chọn chiến lược định hình cách các hệ thống tương tác, phát triển và mở rộng. Cuộc tranh luận giữa REST và gRPC không phải là câu hỏi “cái nào tốt hơn”, mà là việc lựa chọn giữa hai triết lý thiết kế mạnh mẽ nhưng khác biệt cơ bản. REST, với tư cách là một kiểu kiến trúc, đã định hình nên các API web trong hơn hai thập kỷ, trở thành tiêu chuẩn de facto nhờ tính linh hoạt và khả năng tiếp cận phổ quát. Mặt khác, gRPC, một framework mã nguồn mở hiệu suất cao do Google phát triển, nổi lên như một giải pháp được thiết kế đặc biệt cho kỷ nguyên microservice, nơi hiệu suất, độ trễ thấp và các hợp đồng dịch vụ nghiêm ngặt là tối quan trọng.\nSự trỗi dậy của gRPC không phải là một nỗ lực nhằm thay thế hoàn toàn REST. Thay vào đó, nó phản ánh một xu hướng rộng lớn hơn trong kiến trúc phần mềm: sự chuyên môn hóa của các công cụ cho các bối cảnh cụ thể. Sự phát triển của kiến trúc microservices đã tạo ra một loạt các thách thức mới - chẳng hạn như giao tiếp đa ngôn ngữ, độ trễ cực thấp giữa các dịch vụ nội bộ và nhu cầu về các hợp đồng API chặt chẽ - mà REST không được thiết kế rõ ràng để giải quyết. Khoảng trống này đã tạo ra một “thị trường ngách” để gRPC phát triển mạnh mẽ, cung cấp một bộ giải pháp được tối ưu hóa cho những thách thức này.\nMô Hình REST Để hiểu rõ về REST, điều quan trọng là phải nhận ra rằng nó không phải là một giao thức hay một tiêu chuẩn, mà là một kiểu kiến trúc (architectural style) được định nghĩa bởi Roy Fielding vào năm 2000. Một hệ thống được coi là “RESTful” khi nó tuân thủ một tập hợp các ràng buộc kiến trúc được thiết kế để tối ưu hóa cho một hệ thống phân tán quy mô lớn như World Wide Web.\np/s: Nếu bất ngờ vì trước giờ nghĩ REST là một giao thức thì để lại 1 comment nhé =))\nKiến Trúc Cốt Lõi của REST Sức mạnh và sự phổ biến của REST bắt nguồn từ sáu ràng buộc sau:\nTách Biệt Client-Server (Client-Server Decoupling): Ràng buộc này yêu cầu sự tách biệt rõ ràng về mối quan tâm giữa client và server. Server và client chỉ tương tác thông qua một giao diện chuẩn hóa. Sự tách biệt này cho phép chúng phát triển độc lập - client không cần biết về logic nghiệp vụ của server, và server không cần biết về giao diện cuar client miễn là hợp đồng giao diện không thay đổi.\nVô Trạng Thái (Statelessness): Trong kiến trúc REST, mỗi yêu cầu từ client đến server phải chứa tất cả thông tin cần thiết để server hiểu và xử lý nó. Server không lưu trữ bất kỳ trạng thái phiên nào của client giữa các yêu cầu. Điều này giúp cải thiện đáng kể khả năng mở rộng, độ tin cậy và khả năng hiển thị của hệ thống, vì mỗi yêu cầu có thể được xử lý độc lập mà không cần ngữ cảnh từ các yêu cầu trước đó.\nGiao Diện Đồng Nhất (Uniform Interface): Đây là ràng buộc trung tâm và mang tính định danh nhất của REST, được thiết kế để đơn giản hóa và tách rời kiến trúc. Nó bao gồm 4 ràng buộc con:\nĐịnh danh tài nguyên (Identification of resources): Mọi tài nguyên đều được định danh duy nhất thông qua một URI (Uniform Resource Identifier). Ví dụ: https://…/osers/123 thì 123 là ID duy nhất của order đó.\nThao tác tài nguyên thông qua các biểu diễn (Manipulation of resources through representations): Client tương tác với tài nguyên thông qua các biểu diễn của chúng (ví dụ: một tài liệu JSON hoặc XML). Biểu diễn này chứa đủ thông tin để client có thể sửa đổi hoặc xóa tài nguyên trên server.\nThông điệp tự mô tả (Self-descriptive messages): Mỗi thông điệp chứa đủ thông tin để mô tả cách xử lý nó. Ví dụ, một header Content-Type cho biết định dạng media của thông điệp.\nHypermedia as the Engine of Application State (HATEOAS): Client chỉ cần biết URI khởi đầu. Sau đó, tất cả các hành động và tài nguyên trong tương lai mà client có thể truy cập đều được khám phá thông qua các siêu liên kết có trong các phản hồi từ server.\nKhả Năng Lưu Cache (Cacheability): Các phản hồi từ server phải được đánh dấu rõ ràng là có thể lưu cache hay không. Điều này cho phép client hoặc các máy chủ trung gian lưu trữ các phản hồi, giúp giảm độ trễ và tải cho server, một tính năng quan trọng để cải thiện hiệu suất trên web.\nHệ Thống Phân Lớp (Layered System): Client không thể biết liệu nó đang kết nối trực tiếp đến server cuối cùng hay một máy chủ trung gian (microservices ấy). Kiến trúc phân lớp này cho phép triển khai các thành phần trung gian như proxy, gateway để cân bằng tải, bảo mật hoặc lưu cache mà không ảnh hưởng đến client hoặc server.\nMã Lệnh Theo Yêu Cầu (Code on Demand - Tùy chọn): Đây là ràng buộc duy nhất không bắt buộc. Nó cho phép server tạm thời mở rộng hoặc tùy chỉnh chức năng của client bằng cách truyền mã thực thi (ví dụ: JavaScript).\nTrong thực tế, nguyên tắc “Giao Diện Đồng Nhất”, đặc biệt là HATEOAS, là khía cạnh mạnh mẽ nhất nhưng lại thường bị bỏ qua nhất của REST. Mục đích thực sự của HATEOAS là cho phép sự kết hợp cực kỳ lỏng lẻo, cho phép server phát triển cấu trúc API của mình …","date":1756339200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"95eb8e8bbcae05f5456438c25b02556c","permalink":"https://blog.nagih.io.vn/post/architechture/rest-v%C3%A0-grpc/","publishdate":"2025-08-28T00:00:00Z","relpermalink":"/post/architechture/rest-v%C3%A0-grpc/","section":"post","summary":"Phân Tích về Kiến Trúc API Hiện Đại\n","tags":["architechture","microservices"],"title":"REST và gRPC","type":"post"},{"authors":null,"categories":null,"content":"Architecture Overview Domain-Driven Design(DDD)\nPhần I: Các Nguyên tắc Cốt lõi của DDD Thiết kế Chiến lược: Lập bản đồ Context Nghiệp vụ Context Giới hạn (Bounded Contexts) Các hệ thống lớn hiếm khi có một mô hình duy nhất, thống nhất. Thuật ngữ “Người dùng” có thể có ý nghĩa khác nhau trong layer “Xác thực” so với context “Hỗ trợ Kỹ thuật”. Bounded Context là một ranh giới rõ ràng mà trong đó một mô hình miền cụ thể và Ngôn ngữ Phổ biến của nó là nhất quán và hợp lệ. Chiến lược “chia để trị” này là câu trả lời của DDD để quản lý sự phức tạp trong các tổ chức lớn. Việc xác định các context này là mục tiêu chính của Thiết kế Chiến lược và rất quan trọng để xác định ranh giới của các microservice.\nToàn bộ cấu trúc của một hệ thống phức tạp bắt nguồn trực tiếp từ những sự mơ hồ về ngôn ngữ được phát hiện trong quá trình thiết kế chiến lược. Quá trình này diễn ra như sau: đầu tiên, các chuyên gia lĩnh vực và nhà phát triển nhận ra rằng một thuật ngữ duy nhất (ví dụ: “Khách hàng”) có nhiều ý nghĩa mâu thuẫn giữa các phòng ban (hiện tượng đa nghĩa). Xung đột ngôn ngữ này làm cho việc xây dựng một mô hình miền thống nhất duy nhất trở nên bất khả thi nếu không muốn tạo ra sự nhầm lẫn và lỗi. Để giải quyết vấn đề này, họ áp dụng mẫu Bounded Context, vẽ ra các ranh giới rõ ràng xung quanh các khu vực mà ngôn ngữ là nhất quán. Ví dụ, một “Context Bán hàng” và một “Context Hỗ trợ” được xác định. Các Bounded Context này sau đó trở thành những ứng cử viên tự nhiên cho các service hoặc module riêng biệt trong kiến trúc phần mềm. Do đó, kiến trúc ở cấp độ cao (ví dụ: việc phân chia thành các microservice) là một hệ quả trực tiếp của việc giải quyết các vấn đề giao tiếp và định nghĩa một Ngôn ngữ Phổ biến rõ ràng. Kiến trúc không phải là một quyết định kỹ thuật tùy tiện; nó là một giải pháp cho một vấn đề giao tiếp nghiệp vụ.\nThiết kế Chiến thuật: Các Khối Xây dựng Miền Thiết kế Chiến thuật cung cấp các mẫu để xây dựng một mô hình miền phong phú, biểu cảm bên trong một Bounded Context duy nhất.\nEntities (Thực thể): Các đối tượng được xác định không phải bởi các thuộc tính của chúng, mà bởi định danh duy nhất và sự tồn tại liên tục theo thời gian (ví dụ: một Customer với một ID duy nhất). Chúng có thể thay đổi, nhưng các thay đổi trạng thái nên được mô hình hóa như các hoạt động nghiệp vụ rõ ràng (ví dụ:\ncustomer.ChangeAddress(), không phải customer.setAddress().\nValue Objects (Đối tượng Giá trị): Các đối tượng đại diện cho một khía cạnh mô tả của miền và không có định danh khái niệm (ví dụ: Money, Address, Color). Được định nghĩa bởi các thuộc tính của chúng, là bất biến, và sự bằng nhau của chúng dựa trên giá trị, không phải định danh.\nAggregates (Tập hợp): Một cụm các đối tượng liên quan (Entities và Value Objects) được coi là một đơn vị duy nhất cho các thay đổi dữ liệu. Mỗi Aggregate có một Entity gốc, được gọi là Aggregate Root. Aggregate Root là thành viên duy nhất của Aggregate mà các đối tượng bên ngoài được phép giữ tham chiếu đến. Nó chịu trách nhiệm thực thi các quy tắc nghiệp vụ (bất biến) cho toàn bộ cụm. Mẫu này xác định các ranh giới nhất quán giao dịch.\nDomain Services (Dịch vụ Miền): Khi một logic miền nào đó không tự nhiên thuộc về một Entity hoặc Value Object (ví dụ: một quy trình liên quan đến nhiều Aggregate), nó có thể được mô hình hóa trong một Domain Service không trạng thái.\nDomain Events (Sự kiện Miền): Một cơ chế để ghi lại các sự kiện quan trọng xảy ra trong miền (ví dụ: OrderShipped, DeliveryCanceled). Chúng rất quan trọng cho việc giao tiếp giữa các Aggregate và đặc biệt là giữa các Bounded Context khác nhau trong kiến trúc microservices.\nRepositories (Kho chứa) và Factories (Nhà máy): Repositories cung cấp ảo giác về một bộ sưu tập các Aggregate trong bộ nhớ, trừu tượng hóa cơ chế lưu trữ. Factories đóng gói logic để tạo ra các đối tượng hoặc Aggregate phức tạp.\nTên Mẫu Mục đích Đặc điểm Chính Ví dụ Entity Đại diện cho một đối tượng có định danh và vòng đời. Có ID duy nhất, khả biến (mutable), sự bằng nhau dựa trên ID. Customer, Product, Order Value Object Mô tả một thuộc tính của miền. Không có ID, bất biến (immutable), sự bằng nhau dựa trên giá trị. Address, Money, DateRange Aggregate Một cụm các đối tượng được coi là một đơn vị nhất quán. Có một Aggregate Root, định nghĩa ranh giới giao dịch. Một Order cùng với các OrderLineItem của nó. Domain Service Đóng gói logic miền không thuộc về một Entity duy nhất. Không trạng thái, thường liên quan đến nhiều Aggregate. Dịch vụ tính toán phí vận chuyển dựa trên nhiều đơn hàng. Domain Event Ghi lại một sự kiện nghiệp vụ đã xảy ra. Bất biến, mô tả một điều gì đó trong quá khứ. OrderPlaced, PaymentReceived Repository Trừu tượng hóa việc truy cập và lưu trữ các Aggregate. Cung cấp giao diện giống như bộ sưu tập, ẩn chi tiết cơ sở dữ liệu. CustomerRepository, OrderRepository Factory Đóng gói logic tạo đối tượng phức tạp. Đảm bảo các đối tượng được tạo ra ở trạng thái hợp lệ. OrderFactory tạo một Order từ các thông tin đầu vào. Phần II: Clean và Hexagonal …","date":1756252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"97296ffd4c5a83ec54d2cc5d5b9b75c4","permalink":"https://blog.nagih.io.vn/post/architechture/ddd-domain-driven-design/","publishdate":"2025-08-27T00:00:00Z","relpermalink":"/post/architechture/ddd-domain-driven-design/","section":"post","summary":"Architecture Overview Domain-Driven Design(DDD)\n","tags":["architechture","go","microservices"],"title":"DDD (Domain-Driven Design)","type":"post"},{"authors":null,"categories":null,"content":"1 Số Labs từ Cơ bản tới Nâng cao về Operating\nTại sao Hệ Điều Hành Vẫn Quan Trọng trong Thế Giới Cloud-Native Trong lĩnh vực DevOps hiện đại, tồn tại một nghịch lý: trong khi các công cụ cấp cao như Kubernetes, Docker và Ansible trừu tượng hóa hệ điều hành bên dưới, việc hiểu sâu về Linux lại trở nên quan trọng hơn bao giờ hết. Hầu hết các công cụ DevOps cốt lõi đều được xây dựng để chạy tốt nhất trên Linux, biến nó thành nền tảng phổ biến cho cơ sở hạ tầng đám mây và tự động hóa.\nHướng dẫn này được thiết kế để nâng tầm kỹ sư từ một người dùng đơn thuần các công cụ này trở thành một kiến trúc sư hiểu rõ hoạt động bên trong của chúng. Hệ điều hành Linux không nên được xem như một hệ thống cũ kỹ, mà là “API” nền tảng, phổ quát cho mọi hoạt động tự động hóa cơ sở hạ tầng. Tám bài lab dưới đây được cấu trúc như một hành trình có phương pháp, phản ánh quy trình xử lý sự cố trong thực tế, bắt đầu từ các kiểm tra hệ thống cơ bản, đi sâu dần vào phân tích hiệu năng, gỡ lỗi nâng cao và cuối cùng là các nguyên tắc cốt lõi của container hóa. Đây không chỉ là một bộ sưu tập các lệnh; nó là một mô hình tư duy về hệ thống.\nLab 1: Điều Hướng và Quản Lý Hệ Thống Tệp Mục tiêu: Xây dựng “trí nhớ cơ bắp” để điều hướng hệ thống tệp Linux và thực hiện các thao tác tệp thiết yếu. Đây là nền tảng để tìm kiếm log, quản lý tệp cấu hình và chuẩn bị các tạo phẩm ứng dụng cho việc triển khai.\nCác Khái Niệm Cốt Lõi Triết lý “Mọi thứ đều là tệp”: Trong Linux, một nguyên tắc cốt lõi là mọi thứ, từ thiết bị phần cứng, socket mạng đến các thư mục, đều được biểu diễn dưới dạng tệp. Điều này cung cấp một giao diện thống nhất để tương tác với toàn bộ hệ thống.\nTiêu chuẩn Phân cấp Hệ thống tệp (FHS): Cấu trúc thư mục trong Linux tuân theo một tiêu chuẩn, mang lại sự dễ đoán trong quản trị hệ thống. Các thư mục chính bao gồm /etc cho các tệp cấu hình, /var/log cho các tệp nhật ký, /home cho thư mục người dùng và /usr cho các tiện ích và ứng dụng hệ thống.\nThực Hành (Từng bước) Bước 1: Xác định vị trí: Sử dụng lệnh pwd để in ra thư mục làm việc hiện tại và whoami để xác định người dùng hiện tại.\nBước 2: Khám phá xung quanh: Sử dụng ls với các cờ phổ biến (-l, -a, -h) để liệt kê nội dung thư mục và hiểu định dạng đầu ra (quyền, chủ sở hữu, kích thước, ngày).\nBước 3: Di chuyển: Thực hành điều hướng bằng cd, sử dụng cả đường dẫn tuyệt đối (ví dụ: cd /var/log) và tương đối (ví dụ: cd../..).\nBước 4: Tạo và Xóa: Sử dụng touch để tạo các tệp trống, mkdir để tạo thư mục (và -p để tạo các thư mục cha), và rm để xóa tệp và thư mục (-r để xóa đệ quy).\nBước 5: Thao tác với tệp: Sử dụng cp để sao chép, mv để di chuyển/đổi tên, và cat để hiển thị nội dung tệp.\nLệnh Trường Hợp Sử Dụng Phổ Biến ls Liệt kê nội dung của một thư mục. cd Thay đổi thư mục làm việc hiện tại. pwd In ra đường dẫn đầy đủ của thư mục hiện tại. mkdir Tạo một thư mục mới. rm Xóa tệp hoặc thư mục. cp Sao chép tệp hoặc thư mục. mv Di chuyển hoặc đổi tên tệp hoặc thư mục. touch Tạo một tệp trống hoặc cập nhật dấu thời gian của tệp. cat Hiển thị nội dung của một tệp. head / tail Hiển thị phần đầu hoặc phần cuối của một tệp. Lab 2: Quản Lý Người Dùng, Nhóm và Quyền Truy Cập Mục tiêu: Bảo mật tài nguyên hệ thống bằng cách làm chủ quyền sở hữu tệp và các danh sách kiểm soát truy cập. Kỹ năng này có thể áp dụng trực tiếp vào việc bảo mật môi trường tác tử CI/CD, thiết lập quyền cho các tạo phẩm triển khai và cấu hình quyền truy cập của người dùng trên máy chủ.\nCác Khái Niệm Cốt Lõi Bộ ba Bảo mật: Mô hình quyền trong Linux dựa trên ba thực thể: user (người dùng, chủ sở hữu), group (nhóm), và other (những người khác).\nGiải mã Quyền: Mỗi thực thể có thể được cấp ba loại quyền cơ bản: read (r) (đọc), write (w) (ghi), và execute (x) (thực thi). Ý nghĩa của các quyền này khác nhau giữa tệp và thư mục. Ví dụ, quyền execute trên một thư mục cho phép người dùng cd vào thư mục đó, trong khi trên một tệp, nó cho phép chạy tệp đó như một chương trình.\nThực Hành (Từng bước) Bước 1: Quản trị Người dùng và Nhóm: Tạo một người dùng mới với useradd, đặt mật khẩu với passwd, và tạo một nhóm mới với groupadd. Thêm người dùng vào nhóm vừa tạo.\nBước 2: Thay đổi Quyền sở hữu: Sử dụng chown để thay đổi chủ sở hữu của một tệp và chgrp (hoặc chown user:group) để thay đổi nhóm sở hữu. Luôn sử dụng\nsudo cho các hoạt động này khi cần thiết.\nBước 3: Sửa đổi Quyền bằng Ký hiệu Tượng trưng: Sử dụng chmod với ký hiệu tượng trưng (u+x, g-w, o=r) để thay đổi quyền một cách chi tiết và dễ đọc.\nBước 4: Sửa đổi Quyền bằng Ký hiệu Bát phân (Số): Giới thiệu các giá trị số (r=4, w=2, x=1) và trình bày cách thiết lập các quyền phổ biến như chmod 755 cho các tập lệnh và chmod 644 cho các tệp web.\nGiá trị Bát phân Ký hiệu Tượng trưng Trường Hợp Sử Dụng Phổ Biến 777 rwxrwxrwx Không an toàn, chỉ dùng cho mục đích tạm thời hoặc trong môi trường được kiểm soát chặt chẽ. 755 rwxr-xr-x Các tập lệnh thực thi, các thư mục cần người khác truy cập. 644 rw-r--r-- Các tệp nội dung web, tệp cấu hình chỉ đọc cho người khác. 600 rw------- Các tệp nhạy …","date":1755907200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"08d9a8e1b661f7b6464343c1a4aae6a8","permalink":"https://blog.nagih.io.vn/post/system/labs-operating/","publishdate":"2025-08-23T00:00:00Z","relpermalink":"/post/system/labs-operating/","section":"post","summary":"1 Số Labs từ Cơ bản tới Nâng cao về Operating\n","tags":["system","network"],"title":"Labs Operating","type":"post"},{"authors":null,"categories":null,"content":"Hướng dẫn thiết kế kiến trúc Microservices\nKiến trúc Microservices Toàn tập: Từ Quy chuẩn Đặt tên đến Các Mẫu Thiết kế Nâng cao Phần 1: Các Quy ước Thiết kế Cơ bản: Đặt tên và API Quy ước đặt tên Service Việc đặt tên là một khía cạnh quan trọng nhưng thường bị bỏ qua trong kiến trúc. Một cái tên tốt sẽ tự nó trở thành tài liệu và giúp hệ thống thống nhất với lĩnh vực kinh doanh. Đây không phải là một nhiệm vụ kỹ thuật đơn thuần, mà là một hoạt động kiến trúc chiến lược. Việc đặt tên đòi hỏi sự hợp tác với các bên liên quan trong kinh doanh để thiết lập một “ngôn ngữ phổ biến”. Nếu không, sẽ dẫn đến sự mất kết nối giữa mô hình phần mềm và thực tế kinh doanh, gây ra sự nhầm lẫn, chi phí bảo trì cao và khó khăn cho các thành viên mới trong việc tiếp cận dự án. Do đó, một tài liệu “quy ước đặt tên” và một “danh mục dịch vụ” (service catalog) là những tạo tác quan trọng của một kiến trúc microservices trưởng thành.\nÁp dụng Thiết kế Hướng Tên miền (Domain-Driven Design - DDD): Chiến lược hiệu quả nhất là đặt tên dịch vụ theo các tên miền và năng lực kinh doanh, sử dụng “ngôn ngữ phổ biến” (ubiquitous language) của doanh nghiệp. Ví dụ, thay vì một tên chung chung như\nProcessingService, hãy sử dụng một cái tên cụ thể như LoanApprovalWorkflow hoặc FraudDetectionEngine.\nThiết lập Quy ước Đặt tên Nhất quán:\nSử dụng một mẫu rõ ràng và nhất quán. Một định dạng được đề xuất là domain-capability-service (ví dụ: payments-refund-service) hoặc sử dụng tiền tố không gian tên (Cart-CheckoutService) để chỉ rõ quyền sở hữu và chức năng.\nNếu dịch vụ liên quan đến một thực thể (danh từ), hãy sử dụng dạng số nhiều + -service (ví dụ: ingredients-service). Nếu nó liên quan đến một hành động (động từ), hãy sử dụng động từ + -service (ví dụ: auth-service).\nNhững điều cần tránh khi đặt tên dịch vụ:\nTên đội ngũ/Tổ chức: Các đội ngũ có thể thay đổi, nhưng chức năng kinh doanh của dịch vụ thì thường không. Tránh các tên như kingpins-user-frontend.\nPhiên bản và Trạng thái: Tránh các hậu tố như -v2, -new, hoặc -legacy. Thông tin này nên được xử lý thông qua việc phiên bản hóa API hoặc cờ tính năng (feature flags), không phải trong tên dịch vụ.\nCác thuật ngữ Mơ hồ hoặc Quá chung chung: Tránh các tên như CoreService hoặc DataAggregator. Một bài kiểm tra tốt là “Quy tắc 5 giây”: một kỹ sư mới có thể đoán được mục đích của dịch vụ trong vòng 5 giây.\nCác tên Gây khó chịu hoặc “Thông minh”: Duy trì sự chuyên nghiệp và rõ ràng. Tránh đùa cợt, tham chiếu văn hóa hoặc các thuật ngữ có thể gây khó chịu.\nThiết kế API có Khả năng mở rộng và Trực quan API là hợp đồng giao tiếp giữa các dịch vụ. Một hệ sinh thái microservices trưởng thành có khả năng sẽ là một hệ thống lai, sử dụng REST cho lưu lượng “bắc-nam” (từ client đến backend) và gRPC cho lưu lượng “đông-tây” (giữa các dịch vụ). Sự lựa chọn này phản ánh sự đánh đổi giữa khả năng con người đọc được và hiệu quả máy móc. REST sử dụng JSON, dễ đọc và được hỗ trợ rộng rãi, lý tưởng cho các API công khai và client trình duyệt. gRPC sử dụng Protocol Buffers dạng nhị phân, không thể đọc được bởi con người nhưng nhỏ gọn hơn và phân tích nhanh hơn nhiều. Điều này làm cho gRPC vượt trội hơn trong giao tiếp nội bộ có thông lượng cao và độ trễ thấp, nơi hiệu suất là yếu tố quan trọng.\nCác Thực hành Tốt nhất cho API RESTful (cho API bên ngoài/công khai):\nTài nguyên thay vì Hành động (Sử dụng Danh từ): Các endpoint nên đại diện cho tài nguyên (danh từ), không phải hành động (động từ). Sử dụng /vendors, không phải /getVendors. Phương thức HTTP (GET, POST, PUT, DELETE) sẽ xác định hành động.\nSử dụng Số nhiều Nhất quán: Luôn sử dụng danh từ số nhiều cho các bộ sưu tập (ví dụ: /products, /orders) để duy trì tính nhất quán.\nURI phân cấp cho các Mối quan hệ: Biểu diễn các tài nguyên lồng nhau một cách logic. Ví dụ, để lấy đơn hàng của một khách hàng cụ thể, sử dụng /customers/{customerId}/orders. Giữ hệ thống phân cấp này nông (không quá\ncollection/item/collection) để tránh phức tạp.\nSử dụng Tham số Truy vấn để Lọc/Sắp xếp: Không đặt logic lọc trong đường dẫn URI. Thay vào đó, hãy sử dụng tham số truy vấn: /vendors/{id}/ledgers?status=paid\u0026amp;sort=date_desc.\nGiới thiệu về gRPC (cho giao tiếp nội bộ/giữa các dịch vụ):\ngRPC là một giải pháp thay thế hiệu suất cao cho REST trong giao tiếp nội bộ. Nó sử dụng HTTP/2 và Protocol Buffers (protobufs) để tuần tự hóa (serialization).\nLợi ích: Hiệu suất nhanh hơn do tuần tự hóa nhị phân và ghép kênh (multiplexing) trên một kết nối TCP duy nhất, kiểu dữ liệu mạnh mẽ thông qua định nghĩa lược đồ .proto, và hỗ trợ tạo mã nguồn gốc bằng nhiều ngôn ngữ.\nHướng dẫn Thiết kế API của Google (AIPs): Hướng dẫn thiết kế chính thức của Google là một thực hành tốt nhất để cấu trúc các dịch vụ gRPC, bao gồm các phương thức tiêu chuẩn như Get, List, Create, Update, Delete.\nPhần 2: Các Mẫu Giao tiếp Nâng cao Lựa chọn Phong cách Giao tiếp Phù hợp: Đồng bộ và Bất đồng bộ Sự lựa chọn cơ bản về cách các dịch vụ tương tác có ảnh hưởng sâu sắc đến khả năng phục hồi và khả năng mở rộng của hệ thống. Một hệ …","date":1755475200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"244d5f94e425d1c73b6cfd944f85fc9b","permalink":"https://blog.nagih.io.vn/post/system/desgin-microservices/","publishdate":"2025-08-18T00:00:00Z","relpermalink":"/post/system/desgin-microservices/","section":"post","summary":"Hướng dẫn thiết kế kiến trúc Microservices\n","tags":["system","microservices"],"title":"Desgin Microservices","type":"post"},{"authors":null,"categories":null,"content":"6 Cấp Độ Trưởng Thành Từ Deploy Thủ Công Đến Vận Hành Tinh Gọn\nHành Trình Trưởng Thành DevOps Trong thế giới phát triển phần mềm hiện đại, DevOps không chỉ là một chức danh công việc mà là một triết lý văn hóa và một tập hợp các phương pháp kỹ thuật. Mục tiêu cốt lõi của DevOps là rút ngắn vòng đời phát triển phần mềm và cung cấp sản phẩm một cách liên tục với chất lượng cao, thông qua việc phá vỡ các rào cản giữa đội ngũ Phát triển (Development - Dev) và Vận hành (Operations - Ops), thúc đẩy sự hợp tác, chia sẻ trách nhiệm và giao tiếp hiệu quả\nTrước khi bắt đầu, cần phải làm rõ một sự khác biệt nền tảng nhưng thường bị nhầm lẫn: “Deployment” (Triển khai) và “Release” (Phát hành).\nDeployment là một hoạt động kỹ thuật, bao gồm việc di chuyển mã nguồn từ môi trường này sang môi trường khác, ví dụ từ staging lên production. Đây là một quy trình vận hành thuần túy, tập trung vào việc đảm bảo mã nguồn chạy đúng trong môi trường mới.\nRelease là một quyết định kinh doanh, liên quan đến việc cung cấp các tính năng mới cho người dùng. Quá trình này có thể bao gồm các hoạt động marketing, đào tạo người dùng, hoặc tung ra theo từng giai đoạn. Một tính năng có thể được “deploy” lên production nhiều lần nhưng ẩn sau một “feature flag” (cờ tính năng) và chỉ được “release” khi có quyết định từ phía kinh doanh.\nHiểu rõ sự khác biệt này là chìa khóa để nhận ra rằng toàn bộ hành trình trưởng thành của DevOps về cơ bản là một cuộc tìm kiếm không ngừng nhằm quản lý và giảm thiểu rủi ro, đồng thời tăng tốc độ cung cấp giá trị cho người dùng. Mỗi cấp độ đại diện cho một chiến lược quản lý rủi ro ngày càng tinh vi hơn. Ở cấp độ thấp nhất, rủi ro cực kỳ cao, một phương pháp kém hiệu quả. Các cấp độ tiếp theo lần lượt giảm thiểu rủi ro từ lỗi con người, lỗi tích hợp, sự không nhất quán của môi trường, cho đến các lỗi vận hành hệ thống phân tán.\nCấp độ 0: Deploy Thủ Công Đây là vạch xuất phát, điểm khởi đầu hỗn loạn của nhiều tổ chức. Các quy trình ở cấp độ này chủ yếu là thủ công, bị động và không có tài liệu rõ ràng.\nThực tiễn, Công cụ và Quy trình Quy trình thủ công: Việc triển khai được thực hiện bằng cách kết nối thủ công đến máy chủ thông qua các giao thức như FTP, SCP, hoặc SSH, sau đó sao chép từng tệp. Hoàn toàn không có tự động hóa.\nQuản lý mã nguồn hỗn loạn: Nếu có sử dụng Git, quy trình làm việc thường là “Centralized Workflow”, nơi mọi người đều đẩy (push) mã nguồn trực tiếp lên nhánh chính (main hoặc master), gây ra sự bất ổn định và khó theo dõi.\n“Deployment Checklist” - Tia hy vọng đầu tiên: Nỗ lực đầu tiên để tạo ra trật tự thường là một danh sách kiểm tra (checklist) thủ công. Đây là một tài liệu liệt kê các bước cần tuân theo, từ việc sao lưu cơ sở dữ liệu đến việc khởi động lại dịch vụ. Dù thô sơ, đây là bước quan trọng đầu tiên hướng tới việc chuẩn hóa quy trình.\nRủi ro và Nỗi đau Rủi ro bảo mật thảm khốc: Giao thức FTP truyền thông tin đăng nhập (username, password) dưới dạng văn bản thuần (plain text), khiến chúng dễ dàng bị “bắt” bởi bất kỳ ai trên mạng. Dữ liệu truyền đi cũng không được mã hóa, có nguy cơ bị tấn công xen giữa (man-in-the-middle), nơi kẻ tấn công có thể chèn mã độc vào các tệp đang được triển khai mà không bị phát hiện.\nHệ thống cực kỳ mong manh: Quy trình này rất dễ xảy ra lỗi. Chỉ cần quên một tệp, sao chép sai thư mục, hoặc một tệp truyền bị lỗi cũng có thể làm sập toàn bộ hệ thống.\nKhông có cơ chế Rollback đáng tin cậy: Khi một lần triển khai thất bại, không có cách nào dễ dàng và tự động để quay trở lại phiên bản ổn định trước đó. “Rollback” lại là một quy trình thủ công điên cuồng khác, cố gắng khôi phục phiên bản cũ dưới áp lực cực lớn.\nCái giá phải trả của con người: Cấp độ này gây ra căng thẳng cực độ, kiệt sức và một nền văn hóa sợ hãi xung quanh việc triển khai. Các bản phát hành trở nên hiếm hoi, đồ sộ và đầy rủi ro.\nCấp độ 1: Tự Động Hóa Bằng Script và Quản Lý Mã Nguồn Có Cấu Trúc Khi nỗi đau của Cấp độ 0 trở nên không thể chịu đựng được, tổ chức buộc phải thực hiện bước tiến thực sự đầu tiên hướng tới tự động hóa. Trọng tâm lúc này là làm cho quy trình thủ công hiện có trở nên lặp lại được và ít bị lỗi hơn bằng cách viết script cho nó.\nThực tiễn, Công cụ và Quy trình Sự ra đời của Script triển khai: “Deployment checklist” từ Cấp độ 0 được mã hóa thành một kịch bản (script) triển khai đơn giản, thường sử dụng Bash. Script này tự động hóa các bước kết nối đến máy chủ, lấy mã nguồn mới nhất từ kho chứa, và khởi động lại các dịch vụ.\nQuy trình Git có cấu trúc: Nhóm nhận ra rằng việc đẩy trực tiếp lên nhánh main là không bền vững. Họ áp dụng một chiến lược phân nhánh chính thức, phổ biến nhất là Feature Branch Workflow.\nNhánh main giờ đây được coi là “bất khả xâm phạm” và luôn ở trạng thái sẵn sàng để triển khai.\nTất cả công việc mới (tính năng, sửa lỗi) được thực hiện trên các nhánh riêng biệt.\nCác thay đổi được tích hợp trở lại vào main thông qua Pull Request (hoặc Merge Request), cho phép thực hiện quy trình đánh giá mã nguồn (code review).\nLợi ích và Những Vấn đề Còn Tồn Tại Lợi …","date":1755388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"70ee9929061eb48991f6a0ff82f4a9ef","permalink":"https://blog.nagih.io.vn/post/deploy/6-level-deploy/","publishdate":"2025-08-17T00:00:00Z","relpermalink":"/post/deploy/6-level-deploy/","section":"post","summary":"6 Cấp Độ Trưởng Thành Từ Deploy Thủ Công Đến Vận Hành Tinh Gọn\n","tags":["deploy"],"title":"6 Level Deploy","type":"post"},{"authors":null,"categories":null,"content":"Nginx - Từ C10k Đến Containers\nPhần 1: Nền Tảng Hiệu Năng: “Tại Sao” và “Cái Gì” của Nginx Phần này thiết lập bối cảnh cơ bản về sự tồn tại và triết lý thiết kế cốt lõi của Nginx. Khám phá vấn đề lịch sử mà Nginx được thiết kế để giải quyết và phân tích các lựa chọn kiến trúc đã biến nó thành một nền tảng của cơ sở hạ tầng web hiện đại.\n1.1. Nguồn Gốc của Nginx: Giải Quyết Vấn Đề 10,000 Kết Nối Nginx ra đời không phải là một sự cải tiến gia tăng, mà là một sự thay đổi mô hình trong kiến trúc máy chủ web, một phản ứng trực tiếp trước những hạn chế kiến trúc cơ bản của các máy chủ tiền nhiệm, vốn không còn phù hợp với sự phát triển bùng nổ của Internet.\nVào đầu những năm 2000, khi Internet phát triển với tốc độ chóng mặt, một thách thức kỹ thuật mới đã xuất hiện, được gọi là vấn đề C10k. Thuật ngữ này, do kỹ sư Dan Kegel đặt ra vào năm 1999, mô tả bài toán xử lý 10,000 kết nối đồng thời trên một máy chủ duy nhất.1 Vấn đề này không chỉ đơn thuần là về tốc độ xử lý yêu cầu (throughput), mà là về khả năng quản lý hiệu quả một số lượng lớn các kết nối đang mở cùng một lúc. Các máy chủ web phổ biến thời bấy giờ, như Apache, với mô hình xử lý một tiến trình hoặc một luồng cho mỗi kết nối, đã gặp phải giới hạn nghiêm trọng. Mỗi kết nối tiêu tốn một lượng tài nguyên CPU và bộ nhớ đáng kể, tạo ra một rào cản về khả năng mở rộng khi số lượng người dùng tăng vọt.\nTrong bối cảnh đó, Igor Sysoev, một kỹ sư hệ thống người Nga làm việc tại Rambler, đã bắt đầu phát triển Nginx vào năm 2002. Ban đầu, ông đã cố gắng cải thiện hiệu suất của Apache thông qua các module như\nmod_accel, nhưng nhanh chóng nhận ra rằng cần một cách tiếp cận hoàn toàn mới. Nginx không được tạo ra để trở thành “một Apache nhanh hơn”, mà là để định nghĩa lại cách một máy chủ web xử lý I/O và quản lý kết nối. Phần mềm được phát hành công khai vào năm 2004 dưới dạng mã nguồn mở miễn phí, theo giấy phép BSD 2 điều khoản.\nThành công của kiến trúc mới này đã được chứng minh nhanh chóng. Đến tháng 9 năm 2008, Nginx đã phục vụ 500 triệu yêu cầu mỗi ngày cho cổng thông tin và công cụ tìm kiếm Rambler. Năm 2011, Nginx, Inc. được thành lập để cung cấp các sản phẩm thương mại và hỗ trợ (NGINX Plus), và sau đó được F5 Networks mua lại vào năm 2019.\n1.2. Kiến Trúc của Tốc Độ: Hướng Sự Kiện, I/O Bất Đồng Bộ Không Chặn Chìa khóa cho hiệu suất và khả năng mở rộng vượt trội của Nginx nằm ở kiến trúc bất đồng bộ, hướng sự kiện và I/O không chặn (asynchronous, event-driven, non-blocking I/O). Đây là yếu tố cốt lõi giúp Nginx giải quyết vấn đề C10k.\nNginx hoạt động theo mô hình master-worker. Một tiến trình\nmaster duy nhất chịu trách nhiệm cho các tác vụ quản trị: đọc và xác thực cấu hình, liên kết với các cổng mạng, và tạo ra một số lượng tiến trình worker (thường là một worker cho mỗi lõi CPU). Các tiến trình\nworker này mới là nơi xử lý các yêu cầu của client.\nMỗi tiến trình worker là đơn luồng (single-threaded) và chạy một vòng lặp sự kiện (event loop). Vòng lặp này sử dụng các cơ chế hiệu quả của hệ điều hành như epoll (trên Linux) hoặc kqueue (trên FreeBSD) để giám sát hàng ngàn kết nối cùng lúc cho các sự kiện (ví dụ: có dữ liệu mới để đọc, bộ đệm sẵn sàng để ghi). Khi một sự kiện xảy ra, một hàm gọi lại (callback) được kích hoạt để xử lý nó. Vì tất cả các hoạt động I/O đều là\nkhông chặn (non-blocking), tiến trình worker không bao giờ phải chờ đợi các hoạt động chậm chạp như đọc/ghi đĩa hoặc mạng. Thay vào đó, nó khởi tạo hoạt động và ngay lập tức chuyển sang xử lý các sự kiện khác. Khi hoạt động I/O hoàn tất, hệ điều hành sẽ thông báo cho vòng lặp sự kiện, và kết quả sẽ được xử lý.\nMô hình này mang lại hai lợi ích to lớn. Thứ nhất, nó loại bỏ hoàn toàn chi phí tạo ra một tiến trình hoặc luồng mới cho mỗi kết nối. Thứ hai, nó tránh được việc chuyển đổi ngữ cảnh (context switching) tốn kém, một vấn đề lớn của các mô hình truyền thống khi tải cao. Kết quả là Nginx có thể xử lý hàng ngàn kết nối với chi phí bộ nhớ cực thấp (chỉ khoảng 100KB đến 1MB mỗi kết nối) và đạt được thông lượng rất cao, có thể lên tới 100,000 yêu cầu mỗi giây cho mỗi worker.\nKiến trúc master-worker không chỉ mang lại hiệu suất mà còn là nền tảng cho sự ổn định vận hành và các tính năng quan trọng như cập nhật cấu hình không gián đoạn (zero-downtime reloads). Khi cần thay đổi cấu hình, một tín hiệu reload được gửi đến tiến trình master. Master sẽ xác thực cấu hình mới và tạo ra một bộ worker mới với cấu hình cập nhật. Các worker cũ sẽ được tắt một cách nhẹ nhàng: chúng ngừng chấp nhận kết nối mới nhưng tiếp tục xử lý các kết nối hiện có cho đến khi hoàn tất. Khi tất cả các kết nối cũ đã đóng, các worker cũ sẽ tự kết thúc. Toàn bộ quá trình này diễn ra mà không làm mất bất kỳ kết nối nào của client, cho phép cập nhật không thời gian chết, một yêu cầu tối quan trọng trong các hoạt động DevOps hiện đại.\nPhần 2: “Con Dao Đa Năng” của Thụy Sĩ - Các Trường Hợp Sử Dụng Cốt Lõi của Nginx Từ lý thuyết đến thực tiễn, phần này sẽ trình bày sự linh hoạt của Nginx thông qua các vai trò phổ biến nhất của nó. …","date":1755302400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"bb06f6e0d7caa25ce589fe6ca739a940","permalink":"https://blog.nagih.io.vn/post/deploy/nginx/","publishdate":"2025-08-16T00:00:00Z","relpermalink":"/post/deploy/nginx/","section":"post","summary":"Nginx - Từ C10k Đến Containers\n","tags":["deploy"],"title":"Nginx Overview","type":"post"},{"authors":null,"categories":null,"content":"Các Thực tiễn Tốt nhất cho Môi trường Production\nPhần 1: Docker Principle\nPhần 2: Docker CLI\nPhần 3: Docker Dockerfile\nPhần 4: Docker Compose\nPhần 5: Docker Practical Guide\nPhần 6: Docker Fullstack Example\nPhần 6: Các Thực tiễn Tốt nhất cho Môi trường Production Việc đưa các ứng dụng container hóa vào môi trường production đòi hỏi một mức độ cẩn trọng và tối ưu hóa cao hơn so với môi trường phát triển. Phần này sẽ cung cấp các thực tiễn tốt nhất, giúp bạn xây dựng các image nhỏ gọn, an toàn và các tệp Compose có khả năng bảo trì cao, sẵn sàng cho việc triển khai thực tế.\n6.1 Tối ưu hóa Kích thước và Tốc độ: Multi-Stage Builds Một trong những vấn đề phổ biến nhất với các Docker image là chúng trở nên cồng kềnh. Một image lớn không chỉ chiếm nhiều dung lượng lưu trữ mà còn làm tăng thời gian tải về và triển khai. Tệ hơn nữa, nó thường chứa các công cụ xây dựng (như JDK, Go toolchain, build-essentials) và các dependencies chỉ cần thiết cho quá trình biên dịch, không cần thiết cho việc chạy ứng dụng. Những thành phần thừa này làm tăng bề mặt tấn công của image một cách không cần thiết.\nMulti-stage builds là một tính năng mạnh mẽ của Docker để giải quyết vấn đề này. Kỹ thuật này cho phép bạn sử dụng nhiều lệnh\nFROM trong cùng một Dockerfile. Mỗi lệnh FROM bắt đầu một “stage” (giai đoạn) xây dựng mới.\nCách hoạt động rất đơn giản và hiệu quả:\nStage 1 (Build Stage): Bạn sử dụng một image cơ sở đầy đủ (ví dụ: golang:1.21) có tất cả các công cụ cần thiết để biên dịch, kiểm thử và đóng gói ứng dụng của bạn. Giai đoạn này được đặt tên (ví dụ: AS builder).\nStage 2 (Final Stage): Bạn bắt đầu một giai đoạn mới với một image cơ sở tối giản (ví dụ: alpine:latest hoặc thậm chí scratch—một image trống).\nCopy Artifacts: Bạn sử dụng lệnh COPY --from=builder để sao chép chỉ những tạo tác (artifacts) cần thiết—chẳng hạn như tệp nhị phân đã biên dịch hoặc các tệp đã được thu nhỏ—từ giai đoạn xây dựng vào giai đoạn cuối cùng.\nVí dụ với ứng dụng Go từ Phần 4 đã minh họa hoàn hảo điều này. Image cuối cùng chỉ chứa tệp nhị phân thực thi và image Alpine cơ sở, giảm kích thước từ hàng trăm MB xuống chỉ còn vài MB.\n6.2 Tăng cường Bảo mật Bảo mật là yếu tố không thể bỏ qua khi triển khai. Dockerfile của bạn là tuyến phòng thủ đầu tiên.\nChạy với người dùng không phải root: Mặc định, các container chạy với người dùng root, điều này tạo ra một rủi ro bảo mật nghiêm trọng. Nếu một kẻ tấn công khai thác được một lỗ hổng trong ứng dụng của bạn và thoát ra khỏi container, chúng có thể có quyền root trên máy chủ. Hãy luôn tạo một người dùng và nhóm không có đặc quyền bên trong Dockerfile và sử dụng lệnh USER để chuyển sang người dùng đó trước khi chạy ứng dụng.\nDockerfile\n# Create a non-root user RUN addgroup -S appgroup \u0026amp;\u0026amp; adduser -S appuser -G appgroup #... copy files and set permissions... RUN chown -R appuser:appgroup /app # Switch to the non-root user USER appuser CMD [\u0026#34;/app/my-binary\u0026#34;] Chọn base image tối giản: Nguyên tắc là “càng ít càng tốt”. Một image cơ sở tối giản như alpine, distroless, hoặc scratch chứa ít thành phần hơn, đồng nghĩa với việc có ít lỗ hổng tiềm tàng hơn và bề mặt tấn công nhỏ hơn.\nSử dụng .dockerignore: Tương tự như .gitignore, tệp .dockerignore ngăn chặn các tệp và thư mục không cần thiết (như .git, node_modules, các tệp log cục bộ, tệp bí mật) được gửi đến Docker daemon trong quá trình xây dựng. Điều này không chỉ giúp image nhỏ hơn mà còn ngăn chặn việc vô tình rò rỉ thông tin nhạy cảm vào image.\n6.3 Quản lý các file Compose có thể bảo trì Khi dự án phát triển, việc quản lý cấu hình cho các môi trường khác nhau (phát triển, kiểm thử, sản xuất) trở nên quan trọng.\nSử dụng biến môi trường và tệp .env: Không bao giờ ghi cứng các giá trị nhạy cảm như mật khẩu, khóa API, hoặc thông tin đăng nhập cơ sở dữ liệu trực tiếp vào tệp docker-compose.yml. Thay vào đó, hãy tham chiếu chúng dưới dạng biến môi trường. Docker Compose sẽ tự động tải các biến từ một tệp .env trong cùng thư mục. Tệp .env này nên được thêm vào .gitignore để đảm bảo nó không được đưa vào hệ thống quản lý phiên bản.\nTrong docker-compose.yml:\nYAML\nenvironment: - DB_PASSWORD=${POSTGRES_PASSWORD} Trong tệp .env:\nCode snippet\nPOSTGRES_PASSWORD=supersecret Quản lý các môi trường khác nhau (Dev vs. Prod): Thay vì duy trì nhiều tệp Compose gần như giống hệt nhau, hãy sử dụng một tệp docker-compose.yml cơ sở cho các cấu hình chung và một tệp docker-compose.override.yml cho các cấu hình dành riêng cho môi trường phát triển. Docker Compose tự động đọc và hợp nhất cả hai tệp này.\ndocker-compose.yml (cơ sở, cho production):\nYAML\nservices: web: image: my-app:latest ports: [\u0026#34;80:8000\u0026#34;] docker-compose.override.yml (cho development, không commit vào Git):\nYAML\nservices: web: build:. volumes: -.:/app # Mount source code for live reload ports: - \u0026#34;8000:8000\u0026#34; command: npm run dev Khi bạn chạy docker compose up, Compose sẽ hợp nhất hai tệp này, tạo ra một cấu hình phát triển hoàn chỉnh. Trong môi trường production, bạn chỉ cần triển khai tệp docker-compose.yml cơ sở.\nNếu thấy …","date":1755216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"c2325093af1745359a57900b9ecfaa9e","permalink":"https://blog.nagih.io.vn/post/docker/docker-best-practice-for-production/","publishdate":"2025-08-15T00:00:00Z","relpermalink":"/post/docker/docker-best-practice-for-production/","section":"post","summary":"Các Thực tiễn Tốt nhất cho Môi trường Production\n","tags":["docker"],"title":"Docker Best Practice for Production","type":"post"},{"authors":null,"categories":null,"content":"Triển khai Full-Stack: WordPress với PostgreSQL bằng Docker Compose\nPhần 1: Docker Principle\nPhần 2: Docker CLI\nPhần 3: Docker Dockerfile\nPhần 4: Docker Compose\nPhần 5: Docker Practical Guide\nPhần 6: Triển khai Full-Stack: WordPress với PostgreSQL bằng Docker Compose Đây là phần tổng hợp, nơi chúng ta sẽ áp dụng tất cả các kiến thức đã học để triển khai một ứng dụng web hoàn chỉnh và thực tế: một trang web WordPress được hỗ trợ bởi cơ sở dữ liệu PostgreSQL. Ví dụ này thể hiện sức mạnh thực sự của Docker Compose trong việc điều phối nhiều dịch vụ phụ thuộc lẫn nhau. Đáng chú ý, chúng ta sẽ sử dụng PostgreSQL theo yêu cầu cụ thể, một lựa chọn ít phổ biến hơn so với MySQL/MariaDB trong các hướng dẫn WordPress thông thường, nhưng hoàn toàn khả thi và mạnh mẽ.\n5.1 Kiến trúc ứng dụng Hệ thống của chúng ta sẽ bao gồm các thành phần sau, tất cả được định nghĩa và kết nối trong một tệp docker-compose.yml duy nhất:\nDịch vụ 1 (db): Một container chạy PostgreSQL, sử dụng image chính thức postgres:15-alpine. Đây sẽ là nơi lưu trữ tất cả nội dung của trang WordPress (bài viết, trang, người dùng, v.v.).\nDịch vụ 2 (wordpress): Một container chạy WordPress, sử dụng image chính thức wordpress:latest. Dịch vụ này sẽ chứa máy chủ web (Apache) và PHP để chạy ứng dụng WordPress.\nVolume 1 (db_data): Một named volume để lưu trữ dữ liệu của PostgreSQL. Điều này đảm bảo rằng cơ sở dữ liệu của bạn sẽ tồn tại ngay cả khi container db bị xóa và tạo lại.\nVolume 2 (wp_content): Một named volume để lưu trữ các tệp của WordPress, bao gồm themes, plugins và các tệp được tải lên. Điều này cho phép bạn cập nhật phiên bản WordPress mà không làm mất các tùy chỉnh và nội dung của mình.\nNetwork (app_net): Một mạng bridge tùy chỉnh để hai dịch vụ có thể giao tiếp với nhau một cách an toàn và đáng tin cậy, tách biệt với các container khác có thể đang chạy trên cùng một máy chủ.\nViệc sử dụng một tệp docker-compose.yml để định nghĩa toàn bộ kiến trúc này biến nó thành một dạng “cơ sở hạ tầng dưới dạng mã” (Infrastructure as Code). Tệp này trở thành nguồn chân lý duy nhất cho toàn bộ ứng dụng, có thể được quản lý phiên bản trong Git, chia sẻ với các thành viên trong nhóm và đảm bảo rằng mọi người đều có thể khởi tạo một môi trường giống hệt nhau chỉ bằng một lệnh duy nhất, giúp cải thiện đáng kể quá trình giới thiệu thành viên mới và tính nhất quán.\n5.2 Phân tích chi tiết docker-compose.yml Tạo một thư mục cho dự án của bạn, ví dụ my-wordpress-site. Bên trong thư mục đó, tạo một tệp có tên docker-compose.yml với nội dung sau:\nYAML\nversion: \u0026#39;3.8\u0026#39; services: db: image: postgres:15-alpine container_name: wordpress_db volumes: - db_data:/var/lib/postgresql/data environment: POSTGRES_DB: ${POSTGRES_DB} POSTGRES_USER: ${POSTGRES_USER} POSTGRES_PASSWORD: ${POSTGRES_PASSWORD} restart: always networks: - app_net wordpress: depends_on: - db image: wordpress:latest container_name: wordpress_app ports: - \u0026#34;8000:80\u0026#34; volumes: - wp_content:/var/www/html environment: WORDPRESS_DB_HOST: db:5432 WORDPRESS_DB_USER: ${POSTGRES_USER} WORDPRESS_DB_PASSWORD: ${POSTGRES_PASSWORD} WORDPRESS_DB_NAME: ${POSTGRES_DB} restart: always networks: - app_net volumes: db_data: wp_content: networks: app_net: driver: bridge Giải thích chi tiết:\nservices:: Định nghĩa hai dịch vụ của chúng ta là db và wordpress.\ndb service:\nimage: postgres:15-alpine: Sử dụng phiên bản 15 của PostgreSQL trên nền Alpine Linux để có kích thước nhỏ.\nvolumes: - db_data:/var/lib/postgresql/data: Ánh xạ named volume db_data vào thư mục dữ liệu mặc định của PostgreSQL bên trong container.\nenvironment:: Cấu hình cơ sở dữ liệu. Các giá trị ${...} sẽ được Docker Compose thay thế bằng các biến môi trường từ một tệp .env hoặc từ shell, một thực tiễn tốt để giữ bí mật an toàn.\nrestart: always: Tự động khởi động lại container này nếu nó bị dừng.\nnetworks: - app_net: Kết nối dịch vụ này vào mạng app_net.\nwordpress service:\ndepends_on: - db: Yêu cầu Compose khởi động dịch vụ db trước dịch vụ wordpress.\nports: - \u0026#34;8000:80\u0026#34;: Ánh xạ cổng 8000 trên máy chủ của bạn tới cổng 80 (cổng web mặc định) bên trong container WordPress.\nvolumes: - wp_content:/var/www/html: Ánh xạ named volume wp_content vào thư mục gốc của WordPress.\nenvironment:: Cung cấp cho WordPress thông tin cần thiết để kết nối với cơ sở dữ liệu. Lưu ý WORDPRESS_DB_HOST: db:5432. Ở đây, db là tên của dịch vụ cơ sở dữ liệu, và Docker Compose sẽ đảm bảo rằng tên này được phân giải thành địa chỉ IP nội bộ của container db trên mạng app_net.\nvolumes: (cấp cao nhất): Khai báo hai named volumes db_data và wp_content để Docker quản lý.\nnetworks: (cấp cao nhất): Khai báo mạng tùy chỉnh app_net sử dụng driver bridge mặc định.\n5.3 Triển khai và Quản lý Tạo tệp Biến môi trường (.env) Trong cùng thư mục với docker-compose.yml, tạo một tệp tên là .env. Tệp này sẽ chứa các thông tin nhạy cảm. Docker Compose sẽ tự động đọc tệp này.\nLưu ý: Hãy thêm .env vào tệp .gitignore của bạn để không vô tình đưa thông tin đăng nhập vào kho mã nguồn.\nCode snippet\n#.env file # PostgreSQL …","date":1755216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"54bb21a3dd1d5abc0650ca99c7c8f411","permalink":"https://blog.nagih.io.vn/post/docker/docker-fullstack-example/","publishdate":"2025-08-15T00:00:00Z","relpermalink":"/post/docker/docker-fullstack-example/","section":"post","summary":"Triển khai Full-Stack: WordPress với PostgreSQL bằng Docker Compose\n","tags":["docker"],"title":"Docker Fullstack Example","type":"post"},{"authors":null,"categories":null,"content":"Điều phối Ứng dụng với Docker Compose\nPhần 1: Docker Principle\nPhần 2: Docker CLI\nPhần 3: Docker Dockerfile\nPhần 4: Điều phối Ứng dụng với Docker Compose Khi các ứng dụng trở nên phức tạp hơn, chúng thường bao gồm nhiều thành phần phụ thuộc lẫn nhau—một máy chủ web, một API backend, một cơ sở dữ liệu, một hàng đợi tin nhắn, v.v. Việc quản lý từng container riêng lẻ bằng các lệnh docker run dài dòng và phức tạp trở nên không thực tế và dễ gây ra lỗi.\nĐây là lúc Docker Compose tỏa sáng. Docker Compose là một công cụ cho phép định nghĩa và chạy các ứng dụng Docker đa container một cách dễ dàng. Với Compose, bạn sử dụng một tệp YAML duy nhất (thường là\ndocker-compose.yml) để cấu hình tất cả các dịch vụ, mạng và volume của ứng dụng. Sau đó, chỉ với một lệnh duy nhất, bạn có thể khởi động hoặc gỡ bỏ toàn bộ hệ thống.\n3.1 Cấu trúc của tệp docker-compose.yml File docker-compose.yml là trung tâm của việc quản lý ứng dụng với Compose. Nó có cấu trúc khai báo, nghĩa là bạn mô tả “trạng thái mong muốn” của hệ thống, và Compose sẽ thực hiện các bước cần thiết để đạt được trạng thái đó. Các thành phần chính bao gồm:\nservices: Đây là khối chính, nơi bạn định nghĩa mỗi thành phần của ứng dụng như một “dịch vụ”. Mỗi dịch vụ tương ứng với một hoặc nhiều container chạy cùng một image.\nimage: \u0026lt;image_name\u0026gt;:\u0026lt;tag\u0026gt;: Chỉ định image Docker sẽ được sử dụng để tạo container cho dịch vụ này. Compose sẽ tìm image này trên máy cục bộ hoặc tải về từ Docker Hub.\nbuild: \u0026lt;path_to_context\u0026gt;: Thay vì sử dụng một image có sẵn, bạn có thể yêu cầu Compose xây dựng một image tại chỗ từ một Dockerfile. Giá trị này là đường dẫn đến thư mục chứa Dockerfile (ví dụ: build:.).\nports: - \u0026#34;\u0026lt;host_port\u0026gt;:\u0026lt;container_port\u0026gt;\u0026#34;: Ánh xạ cổng giữa máy chủ và container, tương tự cờ -p trong docker run.\nvolumes: - \u0026lt;volume_name_or_host_path\u0026gt;:\u0026lt;container_path\u0026gt;: Gắn một volume hoặc một thư mục từ máy chủ vào container. Đây là cách để lưu trữ dữ liệu bền bỉ hoặc chia sẻ tệp giữa máy chủ và container.\nenvironment: - \u0026lt;VAR_NAME\u0026gt;=\u0026lt;value\u0026gt;: Thiết lập các biến môi trường bên trong container. Đây là cách phổ biến để truyền các thông tin cấu hình như thông tin đăng nhập cơ sở dữ liệu, khóa API, v.v..\nnetworks: - \u0026lt;network_name\u0026gt;: Kết nối dịch vụ vào một hoặc nhiều mạng được định nghĩa. Compose tự động tạo một mạng mặc định cho tất cả các dịch vụ trong tệp, nhưng việc định nghĩa mạng tùy chỉnh mang lại sự kiểm soát tốt hơn.\ndepends_on: - \u0026lt;service_name\u0026gt;: Xác định sự phụ thuộc giữa các dịch vụ. Ví dụ, bạn có thể yêu cầu dịch vụ web chỉ khởi động sau khi dịch vụ cơ sở dữ liệu đã khởi động.\nvolumes (cấp cao nhất): Nơi bạn định nghĩa các “named volumes”. Việc khai báo chúng ở đây cho phép chúng được tái sử dụng và quản lý dễ dàng bởi Compose.\nnetworks (cấp cao nhất): Nơi bạn định nghĩa các mạng tùy chỉnh. Điều này cho phép bạn tạo ra các cấu trúc liên kết mạng phức tạp hơn và cô lập các nhóm dịch vụ.\n3.2 Từ docker run đến docker-compose.yml Để làm rõ mối liên hệ giữa CLI và Compose, bảng dưới đây sẽ ánh xạ các cờ phổ biến của lệnh docker run sang các khóa tương đương trong tệp docker-compose.yml. Việc hiểu rõ sự tương ứng này giúp quá trình chuyển đổi từ việc quản lý container đơn lẻ sang điều phối toàn bộ ứng dụng trở nên trực quan hơn. Nó cho thấy docker-compose.yml không phải là một ngôn ngữ hoàn toàn mới, mà là một cách khai báo, có cấu trúc để thể hiện những cấu hình tương tự.\nCờ docker run Khóa docker-compose.yml Ví dụ -d (Mặc định khi dùng up -d) docker compose up -d -p 8080:80 ports ports: [\u0026#34;8080:80\u0026#34;] -v my-data:/data volumes volumes: [\u0026#34;my-data:/data\u0026#34;] -e VAR=value environment environment: --name my-app container_name container_name: my-app --network my-net networks networks: [\u0026#34;my-net\u0026#34;] --restart=always restart restart: always 3.3 Các lệnh Docker Compose cốt lõi Sau khi đã định nghĩa ứng dụng trong tệp docker-compose.yml, bạn sử dụng một vài lệnh đơn giản để quản lý toàn bộ vòng đời của nó.\ndocker compose up: Lệnh này là trái tim của Compose. Nó đọc tệp docker-compose.yml, xây dựng các image cần thiết, tạo và khởi chạy tất cả các container dịch vụ, và tạo các network và volume tương ứng. Nếu không có cờ -d, nó sẽ chạy ở chế độ foreground và hiển thị log tổng hợp từ tất cả các container.\ndocker compose up -d: Chạy ứng dụng ở chế độ nền (detached). Đây là cách sử dụng phổ biến nhất trong môi trường phát triển và sản xuất. docker compose down: Lệnh này là đối nghịch của up. Nó sẽ dừng và xóa tất cả các container, cùng với các network được tạo bởi Compose.\ndocker compose down --volumes: Thêm cờ này để xóa cả các named volumes đã được định nghĩa trong tệp Compose. Hãy cẩn thận vì điều này sẽ xóa vĩnh viễn dữ liệu. docker compose build: Nếu bạn đã thay đổi Dockerfile của một dịch vụ, lệnh này sẽ buộc xây dựng lại image cho dịch vụ đó trước khi chạy up.\ndocker compose logs: Hiển thị log từ các container dịch vụ.\ndocker compose logs -f \u0026lt;service_name\u0026gt;: Theo dõi log của một dịch vụ cụ thể trong thời gian thực. docker compose exec \u0026lt;service_name\u0026gt; \u0026lt;command\u0026gt;: Thực thi một lệnh bên trong một …","date":1755129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"c6000203841f1b54e9643b75eaaf4401","permalink":"https://blog.nagih.io.vn/post/docker/docker-compose/","publishdate":"2025-08-14T00:00:00Z","relpermalink":"/post/docker/docker-compose/","section":"post","summary":"Điều phối Ứng dụng với Docker Compose\n","tags":["docker"],"title":"Docker Compose","type":"post"},{"authors":null,"categories":null,"content":"Nghệ Thuật Viết Dockerfile - Tối Ưu và Bảo Mật\nPhần 1: Docker Principle\nPhần 2: Docker CLI\nPhần 3: Nghệ Thuật Viết Dockerfile - Tối Ưu và Bảo Mật Dockerfile là một tệp văn bản chứa một loạt các chỉ thị, hướng dẫn Docker cách xây dựng một image. Viết một Dockerfile tốt không chỉ là làm cho nó hoạt động, mà còn là về việc tạo ra các image nhỏ gọn, an toàn và xây dựng nhanh chóng.\n3.1. Cấu trúc và các chỉ thị quan trọng Một Dockerfile điển hình bao gồm các chỉ thị sau 48:\nFROM: Luôn là chỉ thị đầu tiên. Nó xác định image cơ sở (base image) mà bạn sẽ xây dựng lên trên. Ví dụ: FROM python:3.9-slim.\nWORKDIR: Thiết lập thư mục làm việc cho các chỉ thị tiếp theo như RUN, COPY, CMD. Nếu thư mục không tồn tại, nó sẽ được tạo. Ví dụ: WORKDIR /app.\nCOPY: Sao chép tệp và thư mục từ bối cảnh xây dựng (thư mục chứa Dockerfile) vào hệ thống tệp của image. Ví dụ: COPY. /app.\nRUN: Thực thi các lệnh trong một lớp (layer) mới trên đỉnh của image hiện tại. Thường được sử dụng để cài đặt các gói phần mềm. Ví dụ: RUN pip install -r requirements.txt.\nEXPOSE: Thông báo cho Docker rằng container sẽ lắng nghe trên các cổng mạng được chỉ định khi chạy. Đây chỉ là một hình thức tài liệu; nó không thực sự public cổng. Ví dụ: EXPOSE 8000.\nENV: Thiết lập các biến môi trường. Các biến này có sẵn cho các chỉ thị tiếp theo trong Dockerfile và cho ứng dụng khi container chạy. Ví dụ: ENV APP_HOME /app.\nARG: Định nghĩa các biến chỉ tồn tại trong quá trình xây dựng image (build-time). Chúng có thể được truyền vào từ dòng lệnh docker build với cờ --build-arg. Ví dụ: ARG APP_VERSION=1.0.\n3.2. CMD vs. ENTRYPOINT Đây là hai chỉ thị thường gây nhầm lẫn nhưng có mục đích khác nhau rõ rệt.\nENTRYPOINT: Cấu hình một container sẽ chạy như một tệp thực thi. Nó xác định lệnh chính sẽ luôn được thực thi khi container khởi động.\nCMD: Cung cấp các đối số mặc định cho ENTRYPOINT. Nếu không có ENTRYPOINT, CMD sẽ được thực thi như lệnh chính.\nKhi chạy docker run my-image arg1 arg2, các đối số arg1 arg2 sẽ ghi đè hoàn toàn CMD, nhưng sẽ được nối vào sau ENTRYPOINT.\nCách sử dụng tốt nhất là kết hợp cả hai:\nSử dụng ENTRYPOINT để chỉ định tệp thực thi chính và CMD để cung cấp các đối số mặc định. Điều này tạo ra một image linh hoạt, cho phép người dùng dễ dàng truyền các đối số khác nhau mà không cần phải biết tên của tệp thực thi.\nVí dụ:\nDockerfile\nENTRYPOINT [\u0026#34;/usr/bin/python3\u0026#34;, \u0026#34;app.py\u0026#34;] CMD [\u0026#34;--mode\u0026#34;, \u0026#34;production\u0026#34;] docker run my-image: Sẽ chạy /usr/bin/python3 app.py --mode production.\ndocker run my-image --mode debug: Sẽ chạy /usr/bin/python3 app.py --mode debug (ghi đè CMD).\nCả hai chỉ thị nên được viết ở dạng “exec form” (mảng JSON) thay vì “shell form” (chuỗi lệnh) để tránh các vấn đề về phân tích cú pháp của shell và đảm bảo tín hiệu hệ thống được xử lý đúng cách.\n3.3. COPY vs. ADD Cả hai lệnh đều sao chép tệp vào image, nhưng có một sự khác biệt quan trọng.\nCOPY: Đơn giản và dễ đoán. Nó chỉ sao chép các tệp và thư mục cục bộ từ bối cảnh xây dựng vào container.\nADD: Có thêm hai tính năng “ma thuật”:\nNó có thể tải xuống tệp từ một URL.\nNó có thể tự động giải nén các tệp lưu trữ (như tar, gzip) nếu nguồn là một tệp cục bộ.\nCách sử dụng tốt nhất: Luôn ưu tiên COPY. Sự rõ ràng và dễ đoán của\nCOPY làm cho Dockerfile của bạn dễ bảo trì hơn. Các tính năng bổ sung của ADD có thể dẫn đến hành vi không mong muốn, làm tăng kích thước image một cách không cần thiết và tạo ra các rủi ro bảo mật (ví dụ: tải xuống tệp từ một URL không đáng tin cậy). Chỉ sử dụng ADD khi bạn thực sự cần tính năng tự động giải nén một tệp tar cục bộ. Để tải xuống từ URL, cách tốt hơn là sử dụng RUN curl... hoặc RUN wget... để bạn có thể kiểm tra và dọn dẹp tệp trong cùng một lớp.\n3.4. Tối ưu hóa kích thước Image với Multi-Stage Builds Đây là kỹ thuật quan trọng nhất để tạo ra các image sản xuất nhỏ gọn và an toàn. Ý tưởng là tách biệt môi trường xây dựng (build environment) và môi trường chạy (runtime environment) trong cùng một Dockerfile.\nCách hoạt động: Một Dockerfile đa giai đoạn (multi-stage) có nhiều chỉ thị FROM. Mỗi FROM bắt đầu một giai đoạn mới.\nGiai đoạn 1 (Build Stage): Bạn bắt đầu với một image lớn chứa tất cả các công cụ cần thiết để biên dịch ứng dụng của mình (ví dụ: golang:1.24 hoặc node:20). Giai đoạn này được đặt tên bằng cách sử dụng AS builder.\nGiai đoạn 2 (Final Stage): Bạn bắt đầu một giai đoạn mới với một image cơ sở tối giản, chỉ chứa những gì cần thiết để chạy ứng dụng (ví dụ: scratch - một image trống, hoặc alpine - một bản phân phối Linux siêu nhẹ).\nSao chép tạo phẩm: Bạn sử dụng chỉ thị COPY --from=builder \u0026lt;đường_dẫn_tạo_phẩm\u0026gt; \u0026lt;đích\u0026gt; để sao chép chỉ kết quả biên dịch (ví dụ: một tệp nhị phân duy nhất) từ giai đoạn xây dựng vào giai đoạn cuối cùng.\nLợi ích: Image cuối cùng chỉ chứa ứng dụng đã biên dịch và các phụ thuộc thời gian chạy tối thiểu, loại bỏ hoàn toàn SDK, công cụ xây dựng và các tệp trung gian. Điều này giúp giảm đáng kể kích thước image (có thể từ hàng trăm MB xuống chỉ còn vài MB) và giảm bề mặt tấn công bảo mật.\n3.5. Các phương pháp tốt nhất (Best …","date":1755129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"11fc4e7a224b0b2edbab65bdb01dd5b3","permalink":"https://blog.nagih.io.vn/post/docker/docker-dockerfile/","publishdate":"2025-08-14T00:00:00Z","relpermalink":"/post/docker/docker-dockerfile/","section":"post","summary":"Nghệ Thuật Viết Dockerfile - Tối Ưu và Bảo Mật\n","tags":["docker"],"title":"Docker Dockerfile","type":"post"},{"authors":null,"categories":null,"content":"Hướng dẫn Thực hành: Container hóa Ứng dụng Dịch vụ đơn\nPhần 1: Docker Principle\nPhần 2: Docker CLI\nPhần 3: Docker Dockerfile\nPhần 4: Docker Compose\nPhần 5: Hướng dẫn Thực hành: Container hóa Ứng dụng Dịch vụ đơn Lý thuyết là nền tảng, nhưng thực hành mới là cách tốt nhất để củng cố kiến thức. Phần này cung cấp các hướng dẫn từng bước để container hóa các ứng dụng đơn giản được viết bằng Go, Node.js và Python, ba trong số các ngôn ngữ phổ biến nhất trong phát triển web hiện đại.\n4.1 Ví dụ 1: Máy chủ Web Go nhẹ Go nổi tiếng với việc biên dịch ra các tệp nhị phân tĩnh, độc lập, rất phù hợp với container. Chúng ta sẽ tận dụng tính năng multi-stage build của Docker để tạo ra một image production siêu nhỏ.\nMã nguồn (main.go) Tạo một tệp main.go với nội dung sau. Đây là một máy chủ web đơn giản lắng nghe trên cổng 8080.\nGo\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func handler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello from Go in a Docker Container!\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, handler) log.Println(\u0026#34;Go web server starting on port 8080\u0026#34;) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) } Dockerfile Tạo một tệp tên là Dockerfile (không có phần mở rộng) với nội dung sau:\nDockerfile\n# Stage 1: Build the application FROM golang:1.21-alpine AS builder # Set the Current Working Directory inside the container WORKDIR /app # Copy go mod and sum files COPY go.mod go.sum./ # Download all dependencies. Dependencies will be cached if the go.mod and go.sum files are not changed RUN go mod download # Copy the source code COPY . . # Build the Go app # CGO_ENABLED=0 is for static builds # -o /go-app builds the executable to /go-app RUN CGO_ENABLED=0 GOOS=linux go build -o /go-app. # Stage 2: Create the final, lightweight image FROM alpine:latest # Copy the pre-built binary file from the previous stage COPY --from=builder /go-app /go-app # Expose port 8080 to the outside world EXPOSE 8080 # Command to run the executable CMD [\u0026#34;/go-app\u0026#34;] Giải thích Dockerfile:\nStage 1 (builder): Chúng ta bắt đầu với image golang:1.21-alpine, chứa tất cả các công cụ cần thiết để biên dịch mã Go. Chúng ta sao chép mã nguồn và biên dịch nó thành một tệp nhị phân tĩnh duy nhất tại /go-app.\nStage 2 (final): Chúng ta bắt đầu lại với một image alpine:latest siêu nhẹ. Sau đó, chúng ta chỉ sao chép tệp nhị phân đã được biên dịch từ stage builder vào image cuối cùng này. Kết quả là một image production chỉ chứa ứng dụng của bạn và không có bất kỳ công cụ build nào.\nXây dựng và Chạy Trước tiên, khởi tạo Go module:\nBash\ngo mod init go-webapp Bây giờ, xây dựng image và chạy container:\nBash\n# Build the Docker image docker build -t go-webapp. # Run the container, mapping port 8080 on the host to 8080 in the container docker run -p 8080:8080 go-webapp Mở trình duyệt và truy cập http://localhost:8080 để thấy thông điệp của bạn.\n4.2 Ví dụ 2: API Node.js \u0026amp; Express năng động Node.js là một lựa chọn phổ biến cho các API. Quy trình làm việc với Docker cho Node.js tập trung vào việc quản lý các dependencies npm một cách hiệu quả.\nMã nguồn và Dependencies Tạo một thư mục dự án và khởi tạo một dự án Node.js:\nBash\nmkdir node-api \u0026amp;\u0026amp; cd node-api npm init -y npm install express Tạo một tệp app.js:\nJavaScript\nconst express = require(\u0026#39;express\u0026#39;); const app = express(); const port = 3000; app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.send(\u0026#39;Hello from Node.js \u0026amp; Express in a Docker Container!\u0026#39;); }); app.listen(port, () =\u0026gt; { console.log(`Node.js API listening on port ${port}`); }); Dockerfile Tạo một tệp Dockerfile:\nDockerfile\n# Use an official Node.js runtime as a parent image FROM node:18-alpine # Set the working directory in the container WORKDIR /usr/src/app # Copy package.json and package-lock.json # This is done separately to take advantage of Docker\u0026#39;s layer caching. # The npm install step will only be re-run if these files change. COPY package*.json./ # Install app dependencies RUN npm install # Bundle app source COPY.. # Expose the port the app runs on EXPOSE 3000 # Define the command to run the app CMD [ \u0026#34;node\u0026#34;, \u0026#34;app.js\u0026#34; ] Giải thích Dockerfile:\nChúng ta sao chép package*.json và chạy npm install trước khi sao chép phần còn lại của mã nguồn. Đây là một kỹ thuật tối ưu hóa quan trọng. Vì các dependencies ít thay đổi hơn mã nguồn, Docker có thể tái sử dụng lớp (layer) đã được cache của npm install, giúp các lần build sau nhanh hơn đáng kể. 3. Xây dựng và Chạy\nBash\n# Build the Docker image docker build -t node-api. # Run the container, mapping port 3000 to 3000 docker run -p 3000:3000 node-api Truy cập http://localhost:3000 trên trình duyệt của bạn.\n4.3 Ví dụ 3: Ứng dụng Python \u0026amp; FastAPI hướng dữ liệu FastAPI là một framework Python hiện đại để xây dựng API. Tương tự như Node.js, việc quản lý dependencies là chìa khóa.\nMã nguồn và Dependencies Tạo một thư mục dự án. Bên trong, tạo tệp requirements.txt:\nfastapi uvicorn[standard] Tạo tệp main.py:\nPython\nfrom fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/\u0026#34;) def read_root(): return {\u0026#34;message\u0026#34;: \u0026#34;Hello from …","date":1755129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"2f80acd3179d607dd05a7568779e0aa4","permalink":"https://blog.nagih.io.vn/post/docker/docker-practical-guide/","publishdate":"2025-08-14T00:00:00Z","relpermalink":"/post/docker/docker-practical-guide/","section":"post","summary":"Hướng dẫn Thực hành: Container hóa Ứng dụng Dịch vụ đơn\n","tags":["docker"],"title":"Docker Practical Guide","type":"post"},{"authors":null,"categories":null,"content":"Sự Ra Đời và Các Nguyên Tắc Cốt Lõi của Docker\nPhần 1: Cuộc Cách Mạng Container 1.1 Giới thiệu về Docker: Tại sao lại là một cuộc cách mạng? Trong thế giới phát triển phần mềm hiện đại, Docker đã nổi lên như một công nghệ nền tảng, thay đổi cách các lập trình viên xây dựng, vận chuyển và chạy ứng dụng. Về cơ bản, Docker là một nền tảng mã nguồn mở được thiết kế để tự động hóa việc triển khai ứng dụng bên trong các môi trường biệt lập, nhẹ được gọi là container. Mỗi container đóng gói phần mềm cùng với tất cả những gì nó cần để hoạt động—bao gồm thư viện, công cụ hệ thống, mã nguồn và thời gian chạy (runtime)—thành một đơn vị tiêu chuẩn hóa.\nĐể hiểu rõ giá trị của Docker, điều quan trọng là phải phân biệt nó với công nghệ ảo hóa truyền thống: máy ảo (Virtual Machines - VMs).\nMáy ảo (VMs): Một máy ảo ảo hóa toàn bộ phần cứng vật lý, cho phép nhiều hệ điều hành khách (guest OS) chạy trên một máy chủ chủ (host server) duy nhất. Mỗi VM bao gồm một bản sao đầy đủ của một hệ điều hành, các tệp nhị phân và thư viện cần thiết, và chính ứng dụng. Điều này dẫn đến sự cô lập mạnh mẽ nhưng phải trả giá bằng việc tiêu tốn tài nguyên đáng kể, kích thước lớn (hàng gigabyte) và thời gian khởi động chậm.\nContainers: Ngược lại, container ảo hóa ở cấp độ hệ điều hành. Thay vì đóng gói cả một hệ điều hành khách, các container chia sẻ nhân (kernel) của hệ điều hành máy chủ. Chúng chỉ đóng gói ứng dụng và các dependencies của nó. Kết quả là các container cực kỳ nhẹ (thường chỉ vài chục megabyte), khởi động gần như tức thì và cho phép mật độ ứng dụng cao hơn nhiều trên cùng một phần cứng.\nSự thay đổi mô hình này mang lại những lợi ích to lớn, định hình lại toàn bộ vòng đời phát triển phần mềm:\nPhân phối ứng dụng nhanh chóng, nhất quán: Docker giải quyết triệt để vấn đề kinh điển “nó chạy trên máy tôi nhưng không chạy trên production”. Bằng cách đóng gói ứng dụng và môi trường của nó lại với nhau, Docker đảm bảo tính nhất quán trên các môi trường phát triển, kiểm thử và sản xuất.\nTính di động (Portability) vượt trội: Một container được xây dựng trên máy tính xách tay của lập trình viên có thể chạy không thay đổi trên bất kỳ hệ thống nào có cài đặt Docker, cho dù đó là máy chủ vật lý tại chỗ, máy ảo trên đám mây hay trong một môi trường lai.\nHiệu quả và Tiết kiệm chi phí: Vì các container nhẹ hơn nhiều so với VM, chúng cho phép chạy nhiều ứng dụng hơn trên cùng một cơ sở hạ tầng. Điều này cải thiện đáng kể việc sử dụng tài nguyên và giúp tiết kiệm chi phí phần cứng và cấp phép.\nTăng tốc quy trình phát triển (CI/CD): Docker tích hợp liền mạch vào các quy trình Tích hợp liên tục và Triển khai liên tục (CI/CD). Các image container có thể được xây dựng, kiểm thử và đẩy lên registry một cách tự động, giúp tăng tốc độ phát hành phần mềm một cách đáng kể.\nSự phổ biến của Docker không chỉ là một thành tựu kỹ thuật; nó là chất xúc tác trực tiếp cho văn hóa DevOps. Các lợi ích kỹ thuật như môi trường chuẩn hóa 1 và tính di động đã cung cấp cơ chế thực tế để thực hiện các nguyên lý cốt lõi của DevOps: phá vỡ các rào cản giữa phát triển (Dev) và vận hành (Ops), tự động hóa các quy trình, và tăng tần suất triển khai. Docker không chỉ tạo ra một công cụ mới; nó đã biến DevOps từ một triết lý thành một thực tiễn khả thi cho hàng triệu lập trình viên trên toàn thế giới.\n1.2 Hệ sinh thái Docker: Các Thành phần Cơ bản Để làm việc hiệu quả với Docker, việc nắm vững các khái niệm và thành phần cốt lõi của nó là điều bắt buộc.\nKiến trúc Docker\nDocker hoạt động theo kiến trúc client-server. Thành phần chính bao gồm:\nDocker Daemon (dockerd): Một dịch vụ nền chạy trên máy chủ, chịu trách nhiệm xây dựng, chạy và quản lý các đối tượng Docker như images, containers, networks và volumes.\nDocker Client (docker): Công cụ dòng lệnh (CLI) mà người dùng tương tác. Khi một lệnh như docker run được thực thi, client sẽ gửi yêu cầu đến daemon thông qua REST API qua socket UNIX hoặc giao diện mạng.\nImages và Containers: Bản thiết kế và Thực thể\nĐây là khái niệm cơ bản và quan trọng nhất trong Docker, thường gây nhầm lẫn cho người mới bắt đầu. Một phép ẩn dụ hữu ích là xem Image như một Class trong lập trình hướng đối tượng và Container như một Instance của class đó.\nImage: Một Docker image là một mẫu (template) chỉ đọc (read-only) và bất biến (immutable) chứa một tập hợp các chỉ dẫn để tạo ra một container. Nó giống như một bản thiết kế chi tiết, bao gồm mã nguồn ứng dụng, runtime, thư viện, biến môi trường và các tệp cấu hình. Images được xây dựng từ một\nDockerfile và bao gồm một loạt các lớp (layers) xếp chồng lên nhau. Mỗi chỉ thị trong Dockerfile tạo ra một lớp mới. Tính bất biến này chính là nguyên nhân trực tiếp tạo ra khả năng tái tạo và tính nhất quán mà Docker cung cấp; vì image không thể thay đổi, mọi container được khởi tạo từ nó đều được đảm bảo giống hệt nhau, loại bỏ hoàn toàn sự trôi dạt môi trường.\nContainer: Một Docker container là một thực thể đang chạy (a running instance) của một image. Khi Docker tạo một container từ một image, nó sẽ thêm một lớp có …","date":1755043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"9ee2d4aed02069512028d5365f982862","permalink":"https://blog.nagih.io.vn/post/docker/docker/","publishdate":"2025-08-13T00:00:00Z","relpermalink":"/post/docker/docker/","section":"post","summary":"Sự Ra Đời và Các Nguyên Tắc Cốt Lõi của Docker\n","tags":["docker"],"title":"Docker","type":"post"},{"authors":null,"categories":null,"content":"Làm chủ Docker Command Line (CLI)\nPhần 1: Docker Principle\nPhần 2: Làm Chủ Docker Command Line (CLI) Giao diện dòng lệnh (CLI) là công cụ chính để tương tác với Docker Daemon. Thay vì chỉ liệt kê các lệnh một cách khô khan, phần này sẽ tổ chức chúng theo các quy trình làm việc (workflow) mà một lập trình viên thường gặp phải hàng ngày, giúp hiểu rõ hơn về bối cảnh và mục đích sử dụng của từng lệnh.\n2.1 Quản lý Image Quản lý image là bước đầu tiên trong mọi quy trình làm việc với Docker. Đây là quá trình tạo, phân phối và duy trì các “bản thiết kế” cho ứng dụng của bạn.\ndocker build: Lệnh này xây dựng một Docker image từ một Dockerfile và một “bối cảnh” (context). Bối cảnh là tập hợp các tệp tại đường dẫn được chỉ định. Cờ -t (tag) được sử dụng để đặt tên và phiên bản cho image, giúp dễ dàng nhận dạng.\nVí dụ: docker build -t my-app:1.0. docker images (hoặc docker image ls): Liệt kê tất cả các image hiện có trên máy cục bộ của bạn, hiển thị thông tin như REPOSITORY, TAG, IMAGE ID, và SIZE.\ndocker pull: Tải một image hoặc một kho lưu trữ (repository) từ một registry, mặc định là Docker Hub.\nVí dụ: docker pull postgres:15-alpine docker push: Tải một image từ máy cục bộ của bạn lên một registry, cho phép chia sẻ với những người khác hoặc sử dụng trong môi trường production.\nVí dụ: docker push your-username/my-app:1.0 docker rmi (hoặc docker image rm): Xóa một hoặc nhiều image khỏi máy cục bộ để giải phóng dung lượng đĩa.\nVí dụ: docker rmi my-app:1.0 docker inspect \u0026lt;image\u0026gt;: Cung cấp thông tin chi tiết, ở cấp độ thấp về một image, bao gồm các lớp của nó và siêu dữ liệu (metadata).\n2.2 Vòng đời Container Sau khi có image, bước tiếp theo là tạo và quản lý các thực thể chạy của nó - các container.\ndocker run: Đây là lệnh trung tâm, kết hợp việc tạo và khởi chạy một container mới từ một image. Nó có nhiều cờ tùy chọn mạnh mẽ:\n-d hoặc --detach: Chạy container ở chế độ nền (detached mode) và in ra ID của container.\n-p \u0026lt;host_port\u0026gt;:\u0026lt;container_port\u0026gt;: Ánh xạ một cổng trên máy chủ (host) tới một cổng bên trong container, cho phép truy cập ứng dụng từ bên ngoài. Ví dụ: -p 8080:80.\n--name \u0026lt;container_name\u0026gt;: Gán một tên cụ thể cho container để dễ dàng tham chiếu thay vì sử dụng ID ngẫu nhiên.\n-v \u0026lt;host_path_or_volume_name\u0026gt;:\u0026lt;container_path\u0026gt;: Gắn một volume hoặc một thư mục từ máy chủ vào container.\n-e \u0026lt;VAR_NAME\u0026gt;=\u0026lt;value\u0026gt;: Thiết lập một biến môi trường bên trong container.\nVí dụ đầy đủ: docker run -d -p 8080:80 --name webserver -e APP_MODE=production nginx:latest\ndocker ps: Liệt kê tất cả các container đang chạy. Sử dụng cờ -a để hiển thị tất cả các container, bao gồm cả những container đã dừng.\ndocker stop \u0026lt;container_name_or_id\u0026gt;: Dừng một hoặc nhiều container đang chạy một cách nhẹ nhàng (gửi tín hiệu SIGTERM).\ndocker start \u0026lt;container_name_or_id\u0026gt;: Khởi động lại một hoặc nhiều container đã bị dừng.\ndocker restart \u0026lt;container_name_or_id\u0026gt;: Dừng và sau đó khởi động lại một container.\ndocker rm \u0026lt;container_name_or_id\u0026gt;: Xóa một hoặc nhiều container đã dừng. Sử dụng cờ -f để buộc xóa một container đang chạy.\n2.3 Tương tác và Gỡ lỗi Container Khi container đang chạy, bạn thường cần phải “nhìn vào bên trong” để gỡ lỗi hoặc thực hiện các tác vụ quản trị.\ndocker logs \u0026lt;container\u0026gt;: Lấy và hiển thị nhật ký (logs) được tạo ra bởi một container. Cờ -f (follow) rất hữu ích để theo dõi luồng log trong thời gian thực, tương tự như lệnh tail -f trong Linux.\ndocker exec -it \u0026lt;container\u0026gt; \u0026lt;command\u0026gt;: Thực thi một lệnh bên trong một container đang chạy. Cờ -it (-i cho interactive và -t cho TTY) cho phép bạn có một phiên làm việc tương tác. Đây là cách phổ biến nhất để “vào” một container.\nVí dụ: docker exec -it webserver bash sẽ mở một phiên shell Bash tương tác bên trong container tên là webserver. docker stats: Hiển thị một luồng trực tiếp về việc sử dụng tài nguyên (CPU, bộ nhớ, mạng I/O) của các container đang chạy, rất hữu ích để theo dõi hiệu suất.\n2.4 Dọn dẹp hệ thống Theo thời gian, Docker có thể tích tụ nhiều đối tượng không sử dụng (container đã dừng, image cũ, volume không được gắn), chiếm dụng không gian đĩa.\ndocker system prune: Một lệnh dọn dẹp mạnh mẽ, theo mặc định sẽ xóa tất cả các container đã dừng, các mạng không được sử dụng, các image lơ lửng (dangling images - những image không có tag và không được container nào sử dụng), và build cache.\ndocker system prune -a: Mở rộng việc dọn dẹp để xóa tất cả các image không được sử dụng (không chỉ là dangling).\ndocker system prune --volumes: Bao gồm cả việc xóa các volume không được sử dụng.\nBảng tra cứu nhanh các lệnh Docker CLI thiết yếu Bảng dưới đây tóm tắt các lệnh Docker CLI quan trọng nhất để tham khảo nhanh.\nLệnh Mô tả Ví dụ sử dụng docker build Xây dựng một image từ một Dockerfile. docker build -t my-app:latest. docker run Tạo và khởi chạy một container mới từ một image. docker run -d -p 80:80 --name web nginx docker ps Liệt kê các container đang chạy. Sử dụng -a để liệt kê tất cả. docker ps -a docker stop Dừng một container đang chạy. docker stop web docker rm Xóa một container đã dừng. …","date":1755043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"6a8221826b10004174228f9d3aa5f94b","permalink":"https://blog.nagih.io.vn/post/docker/docker-cli/","publishdate":"2025-08-13T00:00:00Z","relpermalink":"/post/docker/docker-cli/","section":"post","summary":"Làm chủ Docker Command Line (CLI)\n","tags":["docker"],"title":"Docker CLI","type":"post"},{"authors":null,"categories":null,"content":"Mastering Internet Protocol Addresses\nĐối với một người dùng Linux, dù bạn là nhà phát triển, quản trị viên hệ thống hay chỉ là một người đam mê công nghệ, việc hiểu sâu và làm chủ địa chỉ IP không chỉ là một kỹ năng hữu ích mà còn là một yêu cầu thiết yếu.\nBài viết này sẽ là kim chỉ nam của bạn, dẫn dắt bạn đi từ những khái niệm cơ bản nhất như “Địa chỉ IP là gì?” đến các kỹ thuật nâng cao như cấu hình mạng, quét tìm thiết bị và thiết lập kết nối từ xa an toàn. Chúng ta sẽ cùng nhau “mổ xẻ” các lệnh, khám phá các công cụ và áp dụng chúng vào những kịch bản thực tế, giúp bạn tự tin điều hướng trong không gian mạng rộng lớn bằng sức mạnh của dòng lệnh Linux.\nPhần 1: Giải Phẫu Địa Chỉ IP Trước khi đi sâu vào các câu lệnh và cấu hình, việc xây dựng một nền tảng kiến thức vững chắc về bản chất của địa chỉ IP là vô cùng quan trọng. Phần này sẽ giải mã các khái niệm cốt lõi, giúp bạn hiểu rõ “tại sao” và “như thế nào” trước khi học “làm gì”.\n1.1. Địa chỉ IP là gì? Hơn Cả những Con Số Vai trò Cốt lõi: “Địa chỉ Nhà Kỹ thuật số” của Thiết bị\nVề cơ bản, địa chỉ Giao thức Internet (Internet Protocol address), hay địa chỉ IP, là một định danh số duy nhất được gán cho mỗi thiết bị điện tử (như máy tính, điện thoại, máy chủ) khi tham gia vào một mạng máy tính sử dụng Giao thức Internet để giao tiếp. Hãy hình dung nó như một địa chỉ nhà trong thế giới thực; để một lá thư (dữ liệu) có thể được gửi đến đúng người nhận (thiết bị), nó cần một địa chỉ chính xác. Mục đích chính của địa chỉ IP là để nhận diện thiết bị và xác định vị trí của nó trên mạng, từ đó cho phép việc truyền và nhận dữ liệu diễn ra một cách chính xác.\nMọi dữ liệu di chuyển trên mạng đều được chia thành các đơn vị nhỏ hơn gọi là “gói tin” (packets). Mỗi gói tin này không chỉ chứa một phần dữ liệu mà còn mang theo một phần “tiêu đề” (header). Trong tiêu đề này, thông tin quan trọng nhất chính là địa chỉ IP của người gửi (nguồn) và địa chỉ IP của người nhận (đích). Cấu trúc này đảm bảo rằng dù các gói tin có thể đi theo những con đường khác nhau qua Internet, chúng vẫn sẽ đến được đúng đích và được tập hợp lại một cách chính xác.\nTuy nhiên, việc ví IP như một “địa chỉ nhà” chỉ là bước khởi đầu. Một sự tương đồng chính xác hơn cho người dùng kỹ thuật là: địa chỉ IP giống như địa chỉ của vị trí bạn đang kết nối mạng, trong khi địa chỉ MAC (Media Access Control) mới thực sự là số sê-ri định danh duy nhất của thiết bị đó. Địa chỉ MAC là một địa chỉ vật lý, được gán cứng vào card mạng của bạn bởi nhà sản xuất và không thay đổi. Ngược lại, địa chỉ IP của bạn có thể thay đổi. Khi bạn mang laptop từ nhà (kết nối vào mạng Wi-Fi gia đình) đến một quán cà phê (kết nối vào mạng Wi-Fi của quán), địa chỉ MAC của laptop vẫn giữ nguyên, nhưng nó sẽ được cấp một địa chỉ IP mới tương ứng với mạng của quán cà phê. Việc phân biệt rõ ràng giữa định danh thiết bị (MAC, Lớp 2) và định danh vị trí mạng (IP, Lớp 3) là chìa khóa để hiểu các khái niệm như DHCP, tính di động của mạng và cách các lớp khác nhau trong mô hình mạng tương tác với nhau.\nCỗ máy Vận hành: Giao thức IP và Vị trí trong Chồng Giao thức TCP/IP\nĐịa chỉ IP không tồn tại một mình; nó là một phần không thể tách rời của bộ giao thức TCP/IP, bộ khung xương sống của Internet hiện đại. TCP/IP là một mô hình phân tầng, trong đó Giao thức IP hoạt động ở Tầng Mạng (Network Layer), hay còn gọi là Tầng Internet, tương ứng với Lớp 3 trong mô hình tham chiếu OSI (Open Systems Interconnection).\nTrong bộ đôi này, mỗi giao thức có một nhiệm vụ riêng biệt:\nIP (Internet Protocol): Chịu trách nhiệm về việc định địa chỉ và định tuyến. Nó gắn địa chỉ IP vào các gói tin và quyết định con đường mà các gói tin đó sẽ đi qua mạng để đến đích. IP hoạt động theo nguyên tắc “nỗ lực tốt nhất” (best-effort), nghĩa là nó không đảm bảo các gói tin sẽ đến nơi, đến đúng thứ tự, hay không bị lỗi.\nTCP (Transmission Control Protocol): Hoạt động ở tầng trên (Tầng Giao vận - Transport Layer), TCP bổ sung cho sự thiếu tin cậy của IP. Nó thiết lập một kết nối ổn định, đảm bảo rằng tất cả các gói tin đều đến đích một cách toàn vẹn và theo đúng thứ tự. Nếu một gói tin bị mất, TCP sẽ yêu cầu gửi lại.\nSự kết hợp giữa một hệ thống địa chỉ và định tuyến toàn cầu (IP) và một cơ chế đảm bảo truyền tải đáng tin cậy (TCP) chính là thứ đã tạo nên một Internet mạnh mẽ và linh hoạt như ngày nay.\nHành trình của một Gói tin: Cách Dữ liệu Di chuyển trên Internet\nHãy xem xét một hành động quen thuộc: bạn gõ google.com vào trình duyệt. Đây là những gì xảy ra đằng sau hậu trường:\nPhân giải DNS: Máy tính của bạn không biết google.com ở đâu. Nó gửi một yêu cầu đến một Máy chủ Tên miền (DNS - Domain Name System) để hỏi: “Địa chỉ IP của google.com là gì?”. Máy chủ DNS sẽ trả lời bằng một địa chỉ IP, ví dụ 172.217.24.238.\nĐóng gói và Gửi đi: Trình duyệt của bạn tạo một yêu cầu (ví dụ: HTTP GET) và chuyển nó xuống các tầng thấp hơn của mô hình TCP/IP. Dữ liệu được chia thành các gói tin, mỗi gói được gắn tiêu đề chứa IP nguồn (máy của bạn) và IP đích (máy chủ Google).\nChặng đầu …","date":1755043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"ddf48f95c2ff19e1edbdf2879ae7dace","permalink":"https://blog.nagih.io.vn/post/network/ip/","publishdate":"2025-08-13T00:00:00Z","relpermalink":"/post/network/ip/","section":"post","summary":"Mastering Internet Protocol Addresses\n","tags":["network"],"title":"Internet Protocol (IP)","type":"post"},{"authors":null,"categories":null,"content":"SSH and GitHub Tutorial\nTrong hệ sinh thái phát triển phần mềm hiện đại, GitHub không chỉ là một kho lưu trữ mã nguồn mà còn là trung tâm cộng tác, quản lý dự án và triển khai ứng dụng. Việc tương tác hiệu quả và an toàn với nền tảng này là một kỹ năng cơ bản đối với mọi nhà phát triển. Mặc dù HTTPS cung cấp một phương thức kết nối ban đầu đơn giản, việc chuyển sang sử dụng giao thức SSH (Secure Shell) là một bước tiến quan trọng, không chỉ nâng cao đáng kể mức độ bảo mật mà còn tối ưu hóa quy trình làm việc hàng ngày.\nBlog này sẽ cung cấp một hướng dẫn chi tiết và toàn diện về việc thiết lập và sử dụng khóa SSH để kết nối với GitHub. Chúng ta sẽ đi từ những khái niệm cơ bản, lý do tại sao SSH là lựa chọn ưu việt, các bước cấu hình chi tiết, đến việc quản lý nhiều tài khoản phức tạp và xử lý các lỗi thường gặp. Mục tiêu là trang bị cho các nhà phát triển, từ người mới bắt đầu đến các chuyên gia dày dạn kinh nghiệm, kiến thức và công cụ cần thiết để làm chủ phương thức kết nối an toàn và hiệu quả này.\nPhần 1: Nâng Cấp Bảo Mật và Sự Tiện Lợi với SSH Trước khi đi sâu vào các bước kỹ thuật, điều quan trọng là phải hiểu rõ tại sao việc chuyển đổi từ HTTPS sang SSH lại là một nâng cấp đáng giá cho quy trình làm việc của một nhà phát triển chuyên nghiệp.\nNhững Hạn Chế của Xác thực qua HTTPS Khi bắt đầu với Git và GitHub, hầu hết người dùng đều chọn HTTPS vì sự đơn giản của nó. Tuy nhiên, phương thức này có những hạn chế cố hữu. Xác thực qua HTTPS yêu cầu sử dụng Personal Access Token (PAT), một chuỗi ký tự hoạt động tương tự như mật khẩu.\nMặc dù dễ thiết lập, quy trình này bộc lộ sự bất tiện trong quá trình sử dụng lâu dài. Git sẽ thường xuyên yêu cầu người dùng nhập thông tin xác thực, làm gián đoạn luồng công việc. Mặc dù các công cụ hỗ trợ quản lý thông tin đăng nhập (credential helpers) có thể lưu trữ token, nhưng chúng lại đặt ra một vấn đề khác về mức độ an toàn của việc lưu trữ này. Quan trọng hơn, một PAT bị rò rỉ có thể cấp cho kẻ tấn công quyền truy cập không chỉ vào các kho lưu trữ mà còn có thể vào toàn bộ tài khoản GitHub, tùy thuộc vào phạm vi quyền hạn được cấp cho token đó.\nSo Sánh Nhanh: HTTPS và SSH trên GitHub Để tóm tắt những khác biệt chính, bảng dưới đây cung cấp một cái nhìn tổng quan về hai phương thức xác thực.\nTiêu chí HTTPS (với Personal Access Token) SSH Cơ chế Xác thực Dựa trên token (hoạt động như mật khẩu) 1 Cặp khóa Public/Private (mật mã bất đối xứng) 1 Mức độ Bảo mật Dễ bị lộ nếu token không được bảo vệ cẩn thận 3 Rất cao; khóa riêng tư không bao giờ truyền qua mạng 4 Sự tiện lợi Yêu cầu nhập lại token hoặc phụ thuộc vào credential helper 3 Rất tiện lợi sau khi thiết lập, không cần nhập lại thông tin 8 Thiết lập ban đầu Đơn giản, chỉ cần tạo token 2 Phức tạp hơn một chút, yêu cầu tạo và quản lý cặp khóa 2 Quản lý Truy cập Phân quyền thông qua phạm vi của token trên GitHub 1 Có thể quản lý truy cập chi tiết qua từng khóa riêng lẻ 1 Phần 2: Hướng Dẫn Thiết Lập Khóa SSH Từ A đến Z Phần này sẽ hướng dẫn chi tiết từng bước để tạo và cấu hình khóa SSH cho tài khoản GitHub của bạn.\nBước 1: Tạo Cặp Khóa SSH với ssh-keygen Công cụ dòng lệnh ssh-keygen được sử dụng để tạo ra cặp khóa công khai và riêng tư, là nền tảng của việc xác thực bằng SSH.\nLựa chọn Thuật toán Mã hóa Việc lựa chọn thuật toán mã hóa là một quyết định quan trọng ảnh hưởng đến cả hiệu suất và bảo mật.\nEd25519 (Khuyến nghị): Đây là thuật toán hiện đại, được khuyến nghị sử dụng. Dựa trên Mật mã Đường cong Elliptic (Elliptic Curve Cryptography), Ed25519 cung cấp mức độ bảo mật rất cao với độ dài khóa ngắn hơn, giúp quá trình xác thực diễn ra nhanh hơn. Để tạo khóa Ed25519, hãy mở terminal và chạy lệnh sau, thay thế email bằng email liên kết với tài khoản GitHub của bạn:\nBash\n$ ssh-keygen -t ed25519 -C \u0026#34;your_email@example.com\u0026#34; RSA (Lựa chọn thay thế): RSA là một thuật toán cũ hơn nhưng vẫn rất phổ biến và tương thích rộng rãi. Nếu bạn cần hỗ trợ các hệ thống cũ không tương thích với Ed25519, RSA là một lựa chọn an toàn. Tuy nhiên, điều cực kỳ quan trọng là phải sử dụng độ dài khóa đủ lớn. Mức khuyến nghị tối thiểu hiện nay là 4096 bits để đảm bảo an toàn.9\nBash\n$ ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; Tầm quan trọng của Passphrase Trong quá trình tạo khóa, bạn sẽ được nhắc nhập một “passphrase”. Đây là một lớp bảo vệ cực kỳ quan trọng và rất nên được sử dụng. Passphrase này sẽ mã hóa file khóa riêng tư của bạn trên đĩa. Điều này có nghĩa là, ngay cả khi máy tính của bạn bị đánh cắp và kẻ tấn công có được file khóa riêng tư, họ cũng không thể sử dụng nó nếu không biết passphrase. Đây là tuyến phòng thủ cuối cùng để bảo vệ danh tính số của bạn.\nLưu khóa và Đặt tên file tùy chỉnh Theo mặc định, ssh-keygen sẽ lưu cặp khóa vào thư mục ~/.ssh/ với tên file là id_ed25519 và id_ed25519.pub (hoặc id_rsa cho RSA). Mặc dù bạn có thể chấp nhận giá trị mặc định, một thực hành tốt là đặt tên file tùy chỉnh, đặc biệt khi bạn dự định quản lý nhiều khóa cho các tài khoản khác nhau. Ví dụ, bạn có thể đặt tên là …","date":1755043200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"9c6e0e5f26e3be1972a03bcb49321a24","permalink":"https://blog.nagih.io.vn/post/git/ssh/","publishdate":"2025-08-13T00:00:00Z","relpermalink":"/post/git/ssh/","section":"post","summary":"SSH and GitHub Tutorial\n","tags":["ssh","git"],"title":"SSH - Github","type":"post"},{"authors":null,"categories":null,"content":"Principles and skills to extend MySQL table design\nTrong thế giới phát triển ứng dụng Backend, việc thiết kế cơ sở dữ liệu (database) không chỉ là một công việc kỹ thuật mà còn là một nghệ thuật đòi hỏi sự tỉ mỉ, hiểu biết sâu sắc về dữ liệu và tầm nhìn dài hạn về tính mở rộng của hệ thống. Đặc biệt, đối với các ứng dụng có nhiều kịch bản phức tạp như chat nhóm (chat group) với nhiều người dùng tham gia, việc lưu trữ dữ liệu đòi hỏi một phương pháp tiếp cận có nguyên tắc.\nDưới đây là 9 nguyên tắc cốt lõi và một số kỹ năng mở rộng mà mọi lập trình viên Backend cần nắm vững khi khởi tạo bảng trong MySQL, đảm bảo ứng dụng không chỉ chạy đúng mà còn hiệu quả và dễ bảo trì:\n1. Mọi Table Luôn Phải Có Các Column Mặc Định\nMột thiết kế table hoàn chỉnh cần có ít nhất 5 trường mặc định để theo dõi lịch sử và tính nhất quán của dữ liệu:\n• version: Ghi lại số lần chỉnh sửa của table, đồng thời liên quan đến các khái niệm khóa lạc quan (optimistic lock) và khóa bi quan (pessimistic lock)\n• creator_id: (Tùy chọn, tùy thuộc vào công ty) Ai là người tạo bản ghi này\n• modifier: Ai là người cuối cùng sửa đổi bản ghi, quan trọng để biết hành động cuối cùng trên table\n• create_at: Thời gian bản ghi được tạo\n• update_at: Thời gian bản ghi được cập nhật lần cuối\n2. Giải Thích Ngữ Nghĩa Các Column Bằng Comment\nKhi viết DDL (Data Definition Language) cho MySQL, PostgreSQL, hoặc bất kỳ hệ quản trị cơ sở dữ liệu nào, hãy luôn thêm comment giải thích ý nghĩa của từng column. Điều này đặc biệt quan trọng cho các trường kiểu liệt kê (enumeration) như status (ví dụ: 1 là private, 2 là public, 3 là friends, 4 là only me). Việc comment rõ ràng giúp các thành viên mới gia nhập team dễ dàng hiểu và làm quen với cấu trúc dữ liệu, tránh sự hiểu lầm về ngữ nghĩa của các trường\n3. Xóa Dữ Liệu Không Phải Xóa “Bay” (Xóa Logic)\nKhông bao giờ sử dụng lệnh DELETE để xóa vật lý dữ liệu trực tiếp trong môi trường sản phẩm. Thay vào đó, hãy sử dụng phương pháp xóa logic (soft delete) bằng cách thêm một trường để đánh dấu bản ghi đã bị xóa hay chưa, và thời gian xóa\n• Ban đầu có thể sử dụng hai trường: is_deleted (0: hoạt động, 1: đã xóa) và deleted_at (thời gian xóa)\n• Cách tối ưu hơn là chỉ sử dụng một trường deleted_at: Nếu giá trị là NULL nghĩa là bản ghi chưa bị xóa; nếu có giá trị thời gian, đó là thời gian bản ghi bị xóa\n• Lưu ý: Giá trị NULL có thể gây nhược điểm nghiêm trọng về hiệu suất index khi dữ liệu lớn, do đó cần cân nhắc kỹ hoặc tìm hiểu sâu hơn về NULL trong database\n4. Quy Ước Đặt Tên Với Prefix (Tiền Tố)\nCác trường (field) trong table nên có các tiền tố (prefix) để dễ dàng xác định nguồn gốc khi các bảng được join lại với nhau. Ví dụ, bảng account có thể có trường acc_number. Việc này cực kỳ quan trọng vì trong thực tế, chúng ta ít khi làm việc với dữ liệu độc lập mà thường phải join nhiều bảng (ít nhất 3 bảng là nguyên tắc làm việc). Nếu không có prefix, việc phân biệt ID hay create_at thuộc về bảng nào khi join sẽ gây ra sự hiểu nhầm và lỗi\n5. Tách Bảng Khi Có Quá Nhiều Trường (Vertical Partitioning)\nMột table không nên có quá nhiều trường (column), tối đa khoảng 20 trường. Nếu vượt quá, cần phải tách bảng dọc (vertical partition). Bảng có nhiều trường sẽ làm dữ liệu lưu trữ lớn, giảm hiệu suất truy vấn và tốn bộ nhớ\n• Tách bảng: Chia thành một bảng chính chứa các trường được truy cập thường xuyên và quan trọng (ví dụ: title, status, thumbnail của một bài post), và một bảng chi tiết chứa các trường ít quan trọng hơn hoặc chỉ hiển thị khi người dùng click vào (ví dụ: content, description)\n• Mối quan hệ giữa hai bảng này thường là 1-1, giúp việc join đơn giản và hiệu quả, không ảnh hưởng đến hiệu suất\n6. Chọn Kiểu Dữ Liệu và Độ Dài Thích Hợp\nMột hệ thống tốt không chỉ chạy đúng mà còn phải chạy hiệu quả. Việc chọn kiểu dữ liệu và độ dài phù hợp giúp:\n• Tiết kiệm bộ nhớ (memory) và dung lượng đĩa (disk)\n• Tối ưu tốc độ query\n• Giảm tỷ lệ Input/Output (I/O). Ví dụ:\nTrường title không nên để VARCHAR(255) nếu độ dài thực tế chỉ khoảng 100 ký tự (như tiêu đề video YouTube/TikTok)\nTrường language chỉ cần CHAR(2) (ví dụ: “en”, “vi”) thay vì VARCHAR dài\nTrường status chỉ nên dùng TINYINT (kích thước 1 byte, lưu trữ 0-255) thay vì INT (kích thước 4 byte, lưu trữ 0-4 tỷ ID) nếu các giá trị chỉ là 1, 2, 3\n7. Nguyên Tắc Not NULL\nKhông nên cho phép giá trị NULL bừa bãi. NULL không phải là một số, một chuỗi hay một biến boolean; nó là một vùng không xác định. NULL có thể:\n• Làm hỏng logic nghiệp vụ nếu quên xử lý\n• Gây lỗi index khi so sánh bằng NULL (ví dụ WHERE column IS NULL thường không sử dụng index hiệu quả). Các trường bắt buộc phải có giá trị (như title, status, create_at) nên được khai báo là NOT NULL. Khi không có giá trị, hãy sử dụng DEFAULT đi kèm với NOT NULL\n8. Chiến Lược Đánh Index\nIndex là chìa khóa để tối ưu hiệu suất truy vấn\n• Nên đánh index cho các trường ít trùng lặp và thường xuyên được sử dụng trong truy vấn, ví dụ: creator_id và create_at (quan trọng khi truy vấn theo thời gian). Luôn có prefix idx_ cho các index\n• Trường …","date":1754956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"c744e8cb4d13e977402088a198cccaf9","permalink":"https://blog.nagih.io.vn/post/database/9-mysql-table-design-rules--skills/","publishdate":"2025-08-12T00:00:00Z","relpermalink":"/post/database/9-mysql-table-design-rules--skills/","section":"post","summary":"Principles and skills to extend MySQL table design\n","tags":["database","sql"],"title":"9 MySQL Table Design Rules \u0026 Skills","type":"post"},{"authors":null,"categories":null,"content":"Tổng hợp các kiến thức cần biết về Docker\nPhần 1: Cuộc Cách Mạng Container - Thấu Hiểu Các Nguyên Tắc Cốt Lõi của Docker 1.1 Giới thiệu về Docker: Tại sao lại là một cuộc cách mạng? Trong thế giới phát triển phần mềm hiện đại, Docker đã nổi lên như một công nghệ nền tảng, thay đổi cách các lập trình viên xây dựng, vận chuyển và chạy ứng dụng. Về cơ bản, Docker là một nền tảng mã nguồn mở được thiết kế để tự động hóa việc triển khai ứng dụng bên trong các môi trường biệt lập, nhẹ được gọi là container.1 Mỗi container đóng gói phần mềm cùng với tất cả những gì nó cần để hoạt động—bao gồm thư viện, công cụ hệ thống, mã nguồn và thời gian chạy (runtime)—thành một đơn vị tiêu chuẩn hóa.3\nĐể hiểu rõ giá trị của Docker, điều quan trọng là phải phân biệt nó với công nghệ ảo hóa truyền thống: máy ảo (Virtual Machines - VMs).\nMáy ảo (VMs): Một máy ảo ảo hóa toàn bộ phần cứng vật lý, cho phép nhiều hệ điều hành khách (guest OS) chạy trên một máy chủ chủ (host server) duy nhất. Mỗi VM bao gồm một bản sao đầy đủ của một hệ điều hành, các tệp nhị phân và thư viện cần thiết, và chính ứng dụng. Điều này dẫn đến sự cô lập mạnh mẽ nhưng phải trả giá bằng việc tiêu tốn tài nguyên đáng kể, kích thước lớn (hàng gigabyte) và thời gian khởi động chậm.4\nContainers: Ngược lại, container ảo hóa ở cấp độ hệ điều hành. Thay vì đóng gói cả một hệ điều hành khách, các container chia sẻ nhân (kernel) của hệ điều hành máy chủ.6 Chúng chỉ đóng gói ứng dụng và các dependencies của nó. Kết quả là các container cực kỳ nhẹ (thường chỉ vài chục megabyte), khởi động gần như tức thì và cho phép mật độ ứng dụng cao hơn nhiều trên cùng một phần cứng.5\nSự thay đổi mô hình này mang lại những lợi ích to lớn, định hình lại toàn bộ vòng đời phát triển phần mềm:\nPhân phối ứng dụng nhanh chóng, nhất quán: Docker giải quyết triệt để vấn đề kinh điển “nó chạy trên máy tôi nhưng không chạy trên production”. Bằng cách đóng gói ứng dụng và môi trường của nó lại với nhau, Docker đảm bảo tính nhất quán trên các môi trường phát triển, kiểm thử và sản xuất.8\nTính di động (Portability) vượt trội: Một container được xây dựng trên máy tính xách tay của lập trình viên có thể chạy không thay đổi trên bất kỳ hệ thống nào có cài đặt Docker, cho dù đó là máy chủ vật lý tại chỗ, máy ảo trên đám mây hay trong một môi trường lai.1\nHiệu quả và Tiết kiệm chi phí: Vì các container nhẹ hơn nhiều so với VM, chúng cho phép chạy nhiều ứng dụng hơn trên cùng một cơ sở hạ tầng. Điều này cải thiện đáng kể việc sử dụng tài nguyên và giúp tiết kiệm chi phí phần cứng và cấp phép.3\nTăng tốc quy trình phát triển (CI/CD): Docker tích hợp liền mạch vào các quy trình Tích hợp liên tục và Triển khai liên tục (CI/CD). Các image container có thể được xây dựng, kiểm thử và đẩy lên registry một cách tự động, giúp tăng tốc độ phát hành phần mềm một cách đáng kể.1\nSự phổ biến của Docker không chỉ là một thành tựu kỹ thuật; nó là chất xúc tác trực tiếp cho văn hóa DevOps. Các lợi ích kỹ thuật như môi trường chuẩn hóa 1 và tính di động 8 đã cung cấp cơ chế thực tế để thực hiện các nguyên lý cốt lõi của DevOps: phá vỡ các rào cản giữa phát triển (Dev) và vận hành (Ops), tự động hóa các quy trình, và tăng tần suất triển khai. Docker không chỉ tạo ra một công cụ mới; nó đã biến DevOps từ một triết lý thành một thực tiễn khả thi cho hàng triệu lập trình viên trên toàn thế giới.7\n1.2 Hệ sinh thái Docker: Các Thành phần Cơ bản Để làm việc hiệu quả với Docker, việc nắm vững các khái niệm và thành phần cốt lõi của nó là điều bắt buộc.\nKiến trúc Docker\nDocker hoạt động theo kiến trúc client-server. Thành phần chính bao gồm:\nDocker Daemon (dockerd): Một dịch vụ nền chạy trên máy chủ, chịu trách nhiệm xây dựng, chạy và quản lý các đối tượng Docker như images, containers, networks và volumes.\nDocker Client (docker): Công cụ dòng lệnh (CLI) mà người dùng tương tác. Khi một lệnh như docker run được thực thi, client sẽ gửi yêu cầu đến daemon thông qua REST API qua socket UNIX hoặc giao diện mạng.1\nImages và Containers: Bản thiết kế và Thực thể\nĐây là khái niệm cơ bản và quan trọng nhất trong Docker, thường gây nhầm lẫn cho người mới bắt đầu. Một phép ẩn dụ hữu ích là xem Image như một Class trong lập trình hướng đối tượng và Container như một Instance của class đó.10\nImage: Một Docker image là một mẫu (template) chỉ đọc (read-only) và bất biến (immutable) chứa một tập hợp các chỉ dẫn để tạo ra một container.11 Nó giống như một bản thiết kế chi tiết, bao gồm mã nguồn ứng dụng, runtime, thư viện, biến môi trường và các tệp cấu hình. Images được xây dựng từ một\nDockerfile và bao gồm một loạt các lớp (layers) xếp chồng lên nhau. Mỗi chỉ thị trong Dockerfile tạo ra một lớp mới. Tính bất biến này chính là nguyên nhân trực tiếp tạo ra khả năng tái tạo và tính nhất quán mà Docker cung cấp; vì image không thể thay đổi, mọi container được khởi tạo từ nó đều được đảm bảo giống hệt nhau, loại bỏ hoàn toàn sự trôi dạt môi trường.4\nContainer: Một Docker container là một thực thể đang chạy (a running instance) của một image.4 Khi …","date":1754956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"032fc96de27ce2f7696cb94bef38cf70","permalink":"https://blog.nagih.io.vn/post/docker/docker.sync-conflict-20250821-125726-izlhqhs/","publishdate":"2025-08-12T00:00:00Z","relpermalink":"/post/docker/docker.sync-conflict-20250821-125726-izlhqhs/","section":"post","summary":"Tổng hợp các kiến thức cần biết về Docker\n","tags":["database","sql","vi"],"title":"Docker Overview","type":"post"},{"authors":null,"categories":null,"content":"Từ Zero Đến Hero - Tổng Hợp Tất Cả Các Lệnh SQL Quan Trọng\nPhần 1: Giới Thiệu - SQL Là Gì và Tại Sao Bạn Cần Phải Học Nó? SQL là gì? SQL, viết tắt của Structured Query Language (Ngôn ngữ Truy vấn có Cấu trúc), là ngôn ngữ tiêu chuẩn được sử dụng để giao tiếp, quản lý và thao tác với các cơ sở dữ liệu quan hệ. Cần phải nhấn mạnh rằng SQL không phải là một ngôn ngữ lập trình đa năng như Python hay Java, mà là một ngôn ngữ chuyên dụng, được thiết kế riêng cho mục đích làm việc với dữ liệu. Một trong những ưu điểm lớn nhất của SQL là nó không đòi hỏi kỹ năng mã hóa phức tạp, thay vào đó, nó sử dụng các từ khóa tiếng Anh gần gũi và dễ hiểu như\nSELECT, INSERT, UPDATE, giúp người dùng dễ dàng tiếp cận và sử dụng.\nLịch sử hình thành SQL ra đời vào những năm 1970, được phát triển bởi hai kỹ sư của IBM là Donald D. Chamberlin và Raymond F. Boyce. Ngôn ngữ này được xây dựng dựa trên nền tảng lý thuyết của mô hình cơ sở dữ liệu quan hệ do Tiến sĩ Edgar F. Codd, cũng là một nhà khoa học của IBM, đề xuất vào năm 1970. Ban đầu, nó có tên là SEQUEL (Structured English Query Language), nhưng sau đó được rút gọn thành SQL do một tranh chấp về thương hiệu. Kể từ đó, SQL đã trở thành một tiêu chuẩn công nghiệp được công nhận toàn cầu.\nVai trò và ứng dụng thực tế Ngày nay, SQL là một kỹ năng không thể thiếu đối với nhiều vị trí trong ngành công nghệ, từ nhà phân tích dữ liệu, nhà khoa học dữ liệu, lập trình viên backend cho đến quản trị viên cơ sở dữ liệu. Sự phổ biến của nó đến từ khả năng ứng dụng trong vô số lĩnh vực:\nPhân tích kinh doanh (Business Intelligence): Các chuyên gia sử dụng SQL để trích xuất, tổng hợp và phân tích dữ liệu từ các hệ thống lớn, nhằm tìm ra các xu hướng (insights) kinh doanh, tạo báo cáo và hỗ trợ việc ra quyết định.\nPhát triển ứng dụng: Hầu hết các ứng dụng web và di động đều cần một nơi để lưu trữ dữ liệu người dùng, thông tin sản phẩm, đơn hàng, v.v. SQL đóng vai trò là cầu nối ở tầng backend, giúp ứng dụng quản lý và thao tác với các dữ liệu này.\nNgành Game: Các trò chơi điện tử sử dụng cơ sở dữ liệu để lưu trữ và quản lý một lượng lớn thông tin như hồ sơ người chơi, điểm số, vật phẩm và thành tích.\nHệ thống giáo dục: Các trường học và tổ chức giáo dục dùng SQL để quản lý hồ sơ sinh viên, thông tin khóa học, điểm số và các hoạt động hành chính khác.\nCác Hệ Quản trị Cơ sở dữ liệu Quan hệ (RDBMS) phổ biến Một điểm quan trọng cần làm rõ là sự khác biệt giữa SQL và các Hệ Quản trị Cơ sở dữ liệu Quan hệ (Relational Database Management System - RDBMS). SQL là ngôn ngữ, trong khi RDBMS là phần mềm, là hệ thống thực thi các câu lệnh SQL đó. Có thể hình dung SQL như “tiếng Anh”, còn RDBMS như một “nhà xuất bản” sử dụng tiếng Anh để tạo ra sách. Việc nhầm lẫn giữa SQL và MySQL là rất phổ biến; MySQL chỉ là một trong nhiều RDBMS sử dụng ngôn ngữ SQL.\nMột số RDBMS phổ biến hiện nay bao gồm:\nMySQL: Một hệ quản trị CSDL quan hệ mã nguồn mở rất phổ biến, đặc biệt trong các ứng dụng web.\nPostgreSQL: Một hệ quản trị CSDL quan hệ mã nguồn mở mạnh mẽ, nổi tiếng với sự tuân thủ chuẩn SQL và các tính năng nâng cao.\nMicrosoft SQL Server: Một sản phẩm thương mại của Microsoft, được sử dụng rộng rãi trong các môi trường doanh nghiệp, đặc biệt là các tổ chức sử dụng hệ sinh thái Windows.\nOracle Database: Một hệ quản trị CSDL thương mại hàng đầu, thường được các tập đoàn lớn sử dụng cho các ứng dụng quan trọng và yêu cầu hiệu suất cao.\nPhần 2: Nền Tảng Của SQL - Hiểu Về Cơ Sở Dữ Liệu Quan Hệ Trước khi viết những câu lệnh SQL đầu tiên, việc nắm vững các khái niệm nền tảng của cơ sở dữ liệu quan hệ là điều kiện tiên quyết. Đây chính là cấu trúc mà SQL được thiết kế để tương tác.\nCác khái niệm cốt lõi Cơ sở dữ liệu (Database): Là một tập hợp các thông tin có liên quan đến nhau, được tổ chức và lưu trữ một cách có hệ thống trên máy tính để có thể dễ dàng truy cập và quản lý.\nCơ sở dữ liệu quan hệ (Relational Database): Là một loại cơ sở dữ liệu mà trong đó dữ liệu được tổ chức thành các bảng (tables) có cấu trúc chặt chẽ. Mô hình này được E.F. Codd đề xuất vào năm 1970 và đã trở thành mô hình thống trị trong quản lý dữ liệu suốt nhiều thập kỷ.\nBảng (Table): Là thành phần cấu trúc cơ bản nhất trong CSDL quan hệ, bao gồm các hàng và cột. Mỗi bảng đại diện cho một loại thực thể, ví dụ như bảng SinhVien, bảng SanPham.\nHàng (Row) và Cột (Column):\nCột (Column/Field/Attribute): Đại diện cho một thuộc tính hoặc một mẩu thông tin mô tả thực thể. Ví dụ, trong bảng SinhVien, các cột có thể là MaSinhVien, HoTen, NgaySinh.\nHàng (Row/Record/Tuple): Đại diện cho một bản ghi dữ liệu cụ thể, một thực thể đơn lẻ trong bảng. Ví dụ, một hàng trong bảng SinhVien chứa thông tin đầy đủ của một sinh viên cụ thể.\nChìa khóa của sự toàn vẹn Để đảm bảo dữ liệu luôn chính xác và nhất quán, CSDL quan hệ sử dụng các loại “khóa”.\nKhóa chính (Primary Key): Là một hoặc nhiều cột được sử dụng để xác định duy nhất mỗi hàng trong một bảng. Giá trị trong cột khóa chính không được phép trống (NULL) và phải là duy nhất trong toàn bộ bảng. Đây là “chứng minh nhân …","date":1754956800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"3c5037f4a42201b4e10db134d0085b44","permalink":"https://blog.nagih.io.vn/post/database/sql/","publishdate":"2025-08-12T00:00:00Z","relpermalink":"/post/database/sql/","section":"post","summary":"Từ Zero Đến Hero - Tổng Hợp Tất Cả Các Lệnh SQL Quan Trọng\n","tags":["database","sql"],"title":"SQL","type":"post"},{"authors":null,"categories":null,"content":"Overview of Cache\nTrong thế giới phát triển phần mềm, chúng ta luôn bị ám ảnh bởi một từ khóa: hiệu năng. Làm thế nào để ứng dụng chạy nhanh hơn? Làm sao để trang web tải trong chớp mắt? Làm sao để hệ thống chịu được hàng triệu lượt truy cập mà không sụp đổ? Giữa vô vàn câu trả lời, có một khái niệm nền tảng, một kỹ thuật được áp dụng ở mọi quy mô, từ con chip nhỏ trong CPU đến các hệ thống phân tán toàn cầu. Đó chính là Cache.\nNhiều người đã nghe về cache, có thể là “xóa cache trình duyệt” hay “cache của CPU”. Nhưng cache thực sự là gì? Nó hoạt động ra sao và tại sao nó lại quan trọng đến vậy?\nBài viết này sẽ đưa bạn đi từ những khái niệm cơ bản nhất đến các chiến lược chuyên sâu trong thiết kế hệ thống. Hy vọng rằng sau khi đọc xong, bạn sẽ có một cái nhìn rõ ràng và sâu sắc về “vũ khí bí mật” mang tên cache.\nHãy cùng bắt đầu!\nCache Là Gì? Để hiểu về cache, hãy bắt đầu bằng một câu chuyện đơn giản.\nCâu chuyện về Thư viện và Chiếc bàn làm việc Hãy tưởng tượng bạn là một nhà nghiên cứu cần rất nhiều sách cho công việc của mình. Toàn bộ sách được lưu trữ trong một thư viện khổng lồ ở phía bên kia thành phố. Mỗi khi cần một thông tin, bạn phải mất công di chuyển đến thư viện, tìm đúng cuốn sách, đọc, rồi lại đi về. Quá trình này rất chậm chạp và tốn thời gian.\nBây giờ, bạn nghĩ ra một giải pháp thông minh hơn. Thay vì mỗi lần cần lại chạy đi, bạn sẽ mang những cuốn sách hay dùng nhất về đặt ngay trên chiếc bàn làm việc của mình. Chiếc bàn này tuy nhỏ, không thể chứa cả thư viện, nhưng nó ở ngay trước mặt bạn. Lần tới, khi cần thông tin từ những cuốn sách đó, bạn chỉ cần với tay là có ngay, nhanh hơn gấp trăm lần so với việc đi đến thư viện.\nTrong thế giới máy tính, câu chuyện này diễn ra liên tục.\nThư viện khổng lồ chính là nơi lưu trữ dữ liệu chính, ví dụ như ổ cứng (HDD/SSD) hoặc Database. Nơi này có dung lượng lớn nhưng tốc độ truy cập khá chậm.\nChiếc bàn làm việc của bạn chính là Cache.\nCache là một lớp lưu trữ dữ liệu tốc độ cao, có kích thước nhỏ, dùng để chứa một tập hợp con của dữ liệu gốc. Mục đích của nó là để các yêu cầu truy xuất dữ liệu trong tương lai được phục vụ nhanh hơn rất nhiều so với việc phải lấy dữ liệu từ database. Về cơ bản, cache cho phép chúng ta tái sử dụng một cách hiệu quả những dữ liệu đã được truy xuất hoặc tính toán trước đó.\nTại sao Cache lại quan trọng đến vậy? Sử dụng cache mang lại 3 lợi ích cốt lõi, biến nó trở thành một kỹ thuật không thể thiếu trong hầu hết mọi hệ thống máy tính hiện đại.\nTăng tốc độ một cách chóng mặt (Performance): Đây là mục đích chính. Cache thường được triển khai trên các phần cứng truy cập nhanh như RAM (Bộ nhớ truy cập ngẫu nhiên). Tốc độ truy cập RAM nhanh hơn hàng trăm, thậm chí hàng nghìn lần so với ổ đĩa. Việc phục vụ dữ liệu từ cache giúp giảm độ trễ (latency) và tăng số lượng thao tác I/O mỗi giây (IOPS) một cách đáng kể, làm cho ứng dụng trở nên mượt mà và phản hồi nhanh hơn.\nGiảm tải cho hệ thống Backend: Cache hoạt động như một tấm khiên, che chắn cho cơ sở dữ liệu hoặc các dịch vụ API. Thay vì mọi yêu cầu đều phải truy cập vào cơ sở dữ liệu, phần lớn các yêu cầu đọc sẽ được cache xử lý. Điều này giúp cơ sở dữ liệu không bị quá tải, đặc biệt là trong những thời điểm có lưu lượng truy cập tăng đột biến, và giữ cho toàn bộ hệ thống ổn định.\nTiết kiệm chi phí (Cost Efficiency): Ở quy mô lớn, việc phục vụ dữ liệu từ cache trong bộ nhớ (in-memory) có thể rẻ hơn đáng kể so với việc phải nâng cấp liên tục các máy chủ cơ sở dữ liệu hoặc trả chi phí cho lưu lượng mạng cao khi truy xuất dữ liệu từ các dịch vụ đám mây.\nCache Hit và Cache Miss Hoạt động của cache xoay quanh hai kịch bản chính: Cache Hit và Cache Miss. Khi một client (có thể là CPU, trình duyệt web, hoặc ứng dụng của bạn) cần dữ liệu, nó sẽ luôn hỏi cache trước tiên.\nCache Hit (Tìm thấy trong Cache): Đây là kịch bản lý tưởng. Dữ liệu được yêu cầu có tồn tại trong cache. Cache sẽ ngay lập tức trả về dữ liệu này cho client. Quá trình này cực kỳ nhanh chóng.\nCache Miss (Không tìm thấy trong Cache): Đây là kịch bản không mong muốn. Dữ liệu được yêu cầu không có trong cache. Khi đó, hệ thống buộc phải truy cập đến database để lấy dữ liệu. Sau khi lấy được, dữ liệu này sẽ được sao chép một bản vào cache để những lần yêu cầu sau sẽ trở thành cache hit, rồi mới được trả về cho client.\nMột điểm cực kỳ quan trọng cần nhận thức ở đây là sự tồn tại của “Cache Miss” cho thấy một sự thật nền tảng: cache không phải là một phép màu tăng tốc miễn phí. Nó đi kèm với sự đánh đổi và chi phí. Một cache miss vốn dĩ còn chậm hơn một hệ thống không có cache. Bởi vì trong một hệ thống không cache, thời gian truy xuất chỉ đơn giản là thời gian lấy dữ liệu từ nguồn chính. Còn trong một cache miss, tổng thời gian là Thời gian kiểm tra cache (và thất bại) + Thời gian lấy dữ liệu từ database.\nDo đó, mục tiêu của mọi chiến lược caching không chỉ đơn giản là “có cache”, mà là thiết kế một hệ thống nơi tổng thời gian tiết kiệm được từ vô số các cache hit phải lớn hơn rất nhiều so với tổng thời gian bị mất đi do các …","date":1754784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"46cfb344e391e02950fc6055b5a1d56e","permalink":"https://blog.nagih.io.vn/post/system/cache/","publishdate":"2025-08-10T00:00:00Z","relpermalink":"/post/system/cache/","section":"post","summary":"Overview of Cache\n","tags":["system"],"title":"Cache","type":"post"},{"authors":null,"categories":null,"content":"Giới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\nKAFKA ĐƯỢC DÙNG KHI NÀO ? Kiến trúc truyền thống - Lập trình nối tiếp Các function quá lệ thuộc vào nhau: Nếu 1 ngày nào đó, tính năng update cart của 1 nhân viên B bị lỗi thì khi user save order -\u0026gt; update cart nhưng bị lỗi ở đây và trả về lỗi, thực tế nếu hệ thống bỏ qua bước này và cho tới bước update inventory thì có được hay không ? Thực tế, mọi trang thương mại điện tử hiện nay đều có thể xử lý lỗi thành công, miễn là cho user có trải nghiệm tốt là được. Nếu xảy ra lỗi. Các hệ thống sẽ trả cho user phần bù đắp thiệt hại cho user (1 vourcher chẳng hạn) chứ không nên để cho user đặt hàng không thành công.\nTrong hình ảnh tiếp theo, tôi đã cung cấp thêm thời gian phản hồi, có thể thấy mỗi 1 request sẽ mất 150ms\nGiả sử nhân viên B phụ trách tính năng update cart nhưng code yếu thì làm sao ? Tức là tính năng update cart được tính toán nhiều quá, không hiệu quả, và kết quả là bị tắc đường ở đó. Và tất nhiên hệ thống phải đồng bộ. Chẳng hạn khi có 10.000 users bị tắc nghẽn ở đó thì phải làm như thế nào ?\nVà một ngày nào đó, lượng users tăng cao, và cần thêm tính năng mới - Thống kê. Tính năng này thống kê điểm tích lũy cho user để có thể tặng quà cho những người mua hàng nhiều nhất, tích điểm,… Thì khi thêm 1 tính năng bất kỳ, đồng nghĩa với việc sẽ tăng thêm thời gian phản hồi, nguy cơ tăng lỗi cũng sẽ cao hơn\nKiến trúc phân tán Có thể thấy, tất cả các order đều được đẩy vào Message Queue, và ngay lập tức trả về response cho user, không cần quan tâm tới những tác vụ còn lại. Và tất nhiên các tác vụ update cart, update inventory, save payment, save shopping vẫn được tiến hành và được tiến hành theo đúng trình tự.\nVà nhắc lại trường hợp khi nãy, giả sử tính năng update inventory bị lỗi thì chuyện gì sẽ xảy ra? Điều đầu tiên là sẽ không ảnh hưởng tới trải nghiệm người dùng, tiếp theo là message queue có cơ chế tự động sửa lỗi những message bị error, nếu cố gắng sửa đổi trong vòng (10) lần mà không thành công, khi đó sẽ đưa con người vào trực tiếp tham gia quá trình sửa đổi này\nTỉ lệ phản hồi thay vì 150ms như kiến trúc truyền thống thì sẽ chỉ mất 20ms + 5ms từ save order tới message queue, ngay lập tức phản hồi tới user\nTrong kiến trúc phân tán, ta có thể quy định hệ thống làm việc với cường độ 100 orders/time, đến khi nào order hết trong MQ, hay có thể nói là chỉ chỉ đưa cho 100 reqs để làm mà thôi, không được vội vàng, còn lại phải xếp hàng lần lượt, cứ như vậy cho đến hết.\nVà bây giờ, nếu lượng users tăng cao và cần thêm tính năng mới thì cũng không hề ảnh hưởng tới dây chuyền sản xuất\nNếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","date":1754697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"7fcca94ac047f7f8ceaeb1da94f747c7","permalink":"https://blog.nagih.io.vn/post/system/kafka/","publishdate":"2025-08-09T00:00:00Z","relpermalink":"/post/system/kafka/","section":"post","summary":"Giới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\n","tags":["system"],"title":"Kafka","type":"post"},{"authors":null,"categories":null,"content":"Tổng quan về kiến trúc microservices\n1. Kiến trúc Microservices là gì? Hãy tưởng tượng bạn đang xây một ngôi nhà.\nKiến trúc nguyên khối (Monolith): Bạn xây toàn bộ ngôi nhà bằng một khối bê tông khổng lồ duy nhất. Mọi thứ dính liền với nhau. Nếu bạn muốn sửa đường ống nước trong bếp, bạn có thể phải đục cả bức tường lớn, ảnh hưởng đến phòng khách bên cạnh.\nKiến trúc Microservices: Bạn xây ngôi nhà bằng những viên gạch LEGO. Mỗi phòng (phòng khách, phòng ngủ, nhà bếp) là một khối LEGO riêng. Nếu muốn sửa bếp, bạn chỉ cần nhấc khối LEGO “nhà bếp” ra, sửa nó, rồi đặt lại mà không ảnh hưởng gì đến các phòng khác.\nTrong phần mềm, kiến trúc microservices là phương pháp chia một ứng dụng lớn thành nhiều dịch vụ (service) nhỏ, độc lập. Mỗi service đảm nhiệm một chức năng cụ thể, có database riêng, và được phát triển, triển khai, nâng cấp độc lập với các service khác.\n2. Các Service giao tiếp với nhau ra sao? Có giống Frontend gọi tới Backend không? Đây là câu hỏi cốt lõi và quan trọng nhất. Các service (vốn là các backend) giao tiếp với nhau qua mạng. Có hai kiểu giao tiếp chính:\nGiao tiếp Đồng bộ (Synchronous) Giống như một cuộc gọi điện thoại. Service A gọi đến Service B và phải chờ Service B trả lời rồi mới làm việc tiếp.\nCách thức: Thường sử dụng các giao thức như REST API (qua HTTP/S) hoặc gRPC.\nVí dụ: Khi bạn đặt hàng, Service Đơn Hàng sẽ gọi trực tiếp đến Service Kho Hàng để hỏi “Sản phẩm X còn hàng không?”. Service Đơn Hàng sẽ phải đợi câu trả lời từ Service Kho Hàng rồi mới cho phép khách đặt hàng.\nGiống Frontend gọi Backend không? Về mặt kỹ thuật (dùng REST API) thì giống, nhưng bản chất là khác. Đây là giao tiếp giữa các backend với nhau (backend-to-backend), diễn ra bên trong hệ thống mà người dùng không nhìn thấy.\nGiao tiếp Bất đồng bộ (Asynchronous) Giống như gửi email hoặc tin nhắn. Service A gửi một “thông điệp” (message) cho Service B rồi tiếp tục công việc của mình ngay lập tức, không cần chờ B trả lời. Service B sẽ nhận và xử lý thông điệp đó khi nào sẵn sàng.\nCách thức: Sử dụng một hệ thống trung gian gọi là Message Broker (hoặc Message Queue) như RabbitMQ, Kafka.\nVí dụ: Sau khi bạn đặt hàng thành công, Service Đơn Hàng sẽ gửi một thông điệp có nội dung “Đơn hàng #123 đã được tạo” vào một hàng đợi (queue). Service Thông Báo sẽ lắng nghe hàng đợi này, thấy có thông điệp mới liền lấy ra và gửi email xác nhận cho bạn. Service Đơn Hàng không cần quan tâm Service Thông Báo đã gửi email hay chưa.\nƯu điểm: Giúp các service hoàn toàn độc lập (decoupled). Nếu Service Thông Báo bị lỗi, các đơn hàng vẫn được tạo bình thường, các thông điệp sẽ nằm chờ trong queue để được xử lý sau.\n3. Có phải Microservices là kiến trúc ở Backend? Frontend chỉ cần 1 service? Đúng vậy, Microservices chủ yếu là một kiến trúc cho phần backend. Tuy nhiên, việc có nhiều service backend nhỏ lẻ lại tạo ra một vấn đề cho frontend: “Frontend nên gọi đến service nào?”.\nKhông thể để frontend (ứng dụng web, mobile) gọi trực tiếp đến 10 service backend khác nhau. Điều này rất phức tạp, khó quản lý và không an toàn. Giải pháp phổ biến nhất là sử dụng một API Gateway.\nAPI Gateway là gì? Hãy coi API Gateway như một anh chàng lễ tân của toàn bộ hệ thống.\nFrontend chỉ cần nói chuyện với “anh lễ tân” này thôi.\n“Anh lễ tân” sẽ chịu trách nhiệm xác thực yêu cầu, sau đó xem xét yêu cầu này thuộc về phòng ban nào (service nào) và chuyển tiếp đến đúng nơi.\nNó cũng có thể tổng hợp thông tin từ nhiều service trước khi trả về cho frontend.\nVí dụ: Để hiển thị trang chi tiết sản phẩm, frontend chỉ cần gửi 1 yêu cầu duy nhất đến API Gateway. API Gateway sẽ tự động gọi đến Service Sản Phẩm để lấy thông tin sản phẩm và gọi đến Service Đánh Giá để lấy các bình luận, sau đó gộp hai kết quả này lại và trả về cho frontend.\nVậy câu trả lời là: Backend được chia thành nhiều microservices, và thường có một lớp API Gateway làm điểm vào duy nhất cho tất cả các client (web, mobile…).\n4. Vấn đề về Dữ liệu: Mỗi Service một Database? Đây là một trong những quy tắc vàng và cũng là thách thức lớn nhất của microservices: Mỗi microservice phải sở hữu và quản lý cơ sở dữ liệu (database) của riêng mình.\nTại sao? Để đảm bảo tính độc lập tuyệt đối. Nếu Service A và Service B dùng chung một database, khi Service A muốn thay đổi cấu trúc bảng, nó có thể làm sập Service B. Như vậy thì không còn gọi là độc lập nữa.\nThách thức: Làm sao để thực hiện một nghiệp vụ yêu cầu dữ liệu từ nhiều service? Ví dụ: làm sao để đảm bảo khi tạo đơn hàng (Service Đơn Hàng) thì số lượng tồn kho (Service Kho Hàng) cũng phải được trừ đi một cách nhất quán?\nGiải pháp: Cần sử dụng các pattern nâng cao như Saga Pattern để quản lý các giao dịch phân tán (distributed transactions). Đây là một chủ đề phức tạp, nhưng ý tưởng cơ bản là mỗi service sẽ thực hiện phần việc của mình và phát ra sự kiện để service tiếp theo thực hiện phần việc của nó.\nNếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","date":1754524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1756428712,"objectID":"99316e1c0281011c2b6a09a2e4c9ae6c","permalink":"https://blog.nagih.io.vn/post/system/microservices/","publishdate":"2025-08-07T00:00:00Z","relpermalink":"/post/system/microservices/","section":"post","summary":"Tổng quan về kiến trúc microservices\n","tags":["system","microservices"],"title":"Microservices","type":"post"}]