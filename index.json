[{"content":"Kỹ thuật backup database định kỳ là một kỹ năng cực kỳ quan trọng đối với bất kỳ ai làm DevOps. Một chiến lược backup tốt sẽ giúp bạn cứu sống cả hệ thống khi có sự cố.\nI. Các Nguyên Tắc Vàng 1. RPO \u0026amp; RTO RPO (Recovery Point Objective): Lượng dữ liệu tối đa chấp nhận mất. RTO là 1h có nghĩa là nếu hệ thống sập, bạn có thể khôi phục trạng thái của nó cách đây 1h. Hay có thể được gọi là Tần suất backup\nRTO (Recovery Time Objective): Thời gian tối đa để hệ thống hoạt động trở lại sau sự cố. Quyết định Tốc độ và Mức độ tự động hóa\n2. Backup Types Full Backup: Sao lưu toàn bộ database. Đơn giản để khôi phục nhưng tốn tài nguyên và thời gian\nDifferential Backup: Backup những gì thay đổi của lần Full Backup cuối cùng\nIncremential Backup: Backup những gì thay đổi từ lần backup gần nhất. Tốc độ nhất nhưng cũng phức tạp nhất\n3. Quy Tắc 3-2-1 3 Bản copies: Luôn có 3 bản backup dữ liệu\n2 Loại Media: Lưu trữ trên ít nhất 2 thiết bị lưu trữ khác nhau\n1 Bản off-site: Giữ ít nhất 1 bản sao ở địa điểm vật lý khác\n4. Bảo mật và Mã hóa Luôn mã hóa file backup, cả khi đang truyền đi (in-transit) và khi đã lưu trữ (at-rest).\nQuản lý chặt chẽ quyền truy cập vào các file backup.\n5. Quan trọng nhất: KIỂM TRA RESTORE! Một bản backup chưa được kiểm tra khôi phục thành công thì không được coi là một bản backup.\nHãy lên lịch kiểm tra restore định kỳ (ví dụ: hàng quý) trên một môi trường staging để đảm bảo các file backup của bạn thực sự hoạt động.\nII. Kỹ Thuật 1. Cron Job \u0026amp; Shell Script Bước 1: Viết Shell Script backup (backup.sh)\n#!/bin/bash # --- Cấu hình --- # Thông tin kết nối Database DB_USER=\u0026#34;your_db_user\u0026#34; DB_PASSWORD=\u0026#34;your_db_password\u0026#34; DB_HOST=\u0026#34;localhost\u0026#34; DB_NAME=\u0026#34;your_db_name\u0026#34; # Thư mục lưu trữ backup trên server BACKUP_DIR=\u0026#34;/path/to/your/backups\u0026#34; # --- Logic Backup --- # Tạo thư mục backup nếu chưa tồn tại mkdir -p ${BACKUP_DIR} # Tạo tên file backup với định dạng ngày-tháng-năm DATE=$(date +%Y-%m-%d_%H-%M-%S) FILE_NAME=\u0026#34;${DB_NAME}_${DATE}.sql.gz\u0026#34; BACKUP_FILE=\u0026#34;${BACKUP_DIR}/${FILE_NAME}\u0026#34; # Đặt biến môi trường để pg_dump không hỏi mật khẩu export PGPASSWORD=${DB_PASSWORD} # Thực hiện backup bằng pg_dump, nén bằng gzip và lưu vào file # -U: user, -h: host, -d: database name # | gzip \u0026gt; : pipe output của pg_dump vào gzip để nén echo \u0026#34;Dang bat dau backup database: ${DB_NAME}...\u0026#34; pg_dump -U ${DB_USER} -h ${DB_HOST} -d ${DB_NAME} | gzip \u0026gt; ${BACKUP_FILE} # Xóa biến môi trường PGPASSWORD để bảo mật unset PGPASSWORD # Kiểm tra xem backup có thành công không if [ $? -eq 0 ]; then echo \u0026#34;Backup thanh cong: ${BACKUP_FILE}\u0026#34; else echo \u0026#34;Backup that bai!\u0026#34; exit 1 fi # Xóa các file backup cũ hơn 7 ngày echo \u0026#34;Xoa cac file backup cu hon 7 ngay...\u0026#34; find ${BACKUP_DIR} -type f -name \u0026#34;*.sql.gz\u0026#34; -mtime +7 -delete echo \u0026#34;Hoan tat.\u0026#34; Bước 2: Cấp quyền thực thi cho script\nchmod +x backup.sh Bước 3: Lên lịch auto run với Cron\nMở crontab để chỉnh sửa\ncrontab -e Thêm dòng sau vào cuối file để chạy script vào lúc 2 giờ sáng mỗi ngày\n# Chạy backup vào 2:00 AM hàng ngày 0 2 * * * /path/to/your/backup.sh \u0026gt;\u0026gt; /path/to/your/logs/backup.log 2\u0026gt;\u0026amp;1 0 2 * * * : Cú pháp cron cho \u0026ldquo;0 phút, 2 giờ, mỗi ngày, mỗi tháng, mỗi ngày trong tuần\u0026rdquo;.\n\u0026raquo; /path/to/your/logs/backup.log 2\u0026gt;\u0026amp;1: Ghi lại output (cả standard output và error) vào một file log để bạn có thể kiểm tra lại.\n2. Backup Database trong Docker Giả sử bạn có một container PostgreSQL đang chạy tên là my_postgres_container\nCách 1: Dùng docker exec và Cron trên máy Host\nScript backup_docker.sh sẽ được sửa lại một chút:\n#!/bin/bash # --- Cấu hình --- CONTAINER_NAME=\u0026#34;my_postgres_container\u0026#34; DB_USER=\u0026#34;your_db_user\u0026#34; DB_NAME=\u0026#34;your_db_name\u0026#34; BACKUP_DIR=\u0026#34;/path/on/host/to/backups\u0026#34; # Thư mục trên máy host # --- Logic Backup --- mkdir -p ${BACKUP_DIR} DATE=$(date +%Y-%m-%d_%H-%M-%S) FILE_NAME=\u0026#34;${DB_NAME}_${DATE}.sql.gz\u0026#34; BACKUP_FILE=\u0026#34;${BACKUP_DIR}/${FILE_NAME}\u0026#34; echo \u0026#34;Dang bat dau backup database từ container: ${CONTAINER_NAME}...\u0026#34; # Dùng \u0026#39;docker exec\u0026#39; để chạy pg_dump BÊN TRONG container # Output sẽ được chuyển ra máy host và nén lại docker exec ${CONTAINER_NAME} pg_dump -U ${DB_USER} -d ${DB_NAME} | gzip \u0026gt; ${BACKUP_FILE} # ...(Phần kiểm tra và xóa file cũ tương tự như script trước) ... # Xóa biến môi trường PGPASSWORD để bảo mật unset PGPASSWORD # Kiểm tra xem backup có thành công không if [ $? -eq 0 ]; then echo \u0026#34;Backup thanh cong: ${BACKUP_FILE}\u0026#34; else echo \u0026#34;Backup that bai!\u0026#34; exit 1 fi # Xóa các file backup cũ hơn 7 ngày echo \u0026#34;Xoa cac file backup cu hon 7 ngay...\u0026#34; find ${BACKUP_DIR} -type f -name \u0026#34;*.sql.gz\u0026#34; -mtime +7 -delete echo \u0026#34;Hoan tat.\u0026#34; Sau đó, bạn cũng dùng cron trên máy host để chạy script backup_docker.sh này.\nCách 2: Dùng một Sidecar Container\nĐây là một pattern nâng cao và rất phổ biến trong Kubernetes. Ý tưởng là bạn sẽ chạy một container riêng biệt chỉ để làm nhiệm vụ backup.\nTrong docker-compose.yml có thể định nghĩa một service backup:\nservices: db: image: postgres:13 container_name: my_postgres_container environment: - POSTGRES_USER=your_db_user - POSTGRES_PASSWORD=your_db_password - POSTGRES_DB=your_db_name volumes: - postgres_data:/var/lib/postgresql/data # Service này không chạy liên tục, chỉ chạy khi được gọi backup: image: postgres:13 # Dùng cùng image để có sẵn pg_dump depends_on: - db volumes: - ./backups:/backups # Gắn thư mục backups của host vào container environment: - PGPASSWORD=your_db_password # Lệnh sẽ chạy khi container này được khởi động command: \u0026gt; bash -c \u0026#34; pg_dump -h db -U your_db_user -d your_db_name | gzip \u0026gt; /backups/backup_$(date +%Y-%m-%d_%H-%M-%S).sql.gz \u0026#34; volumes: postgres_data: Chạy backup\ndocker-compose run --rm backup Bạn có thể kết hợp lệnh này với cron trên máy host để tự động hóa.\nIII. Tích hợp với Cloud (DevOps Workflow hoàn chỉnh) Một quy trình DevOps thực thụ sẽ không dừng lại ở việc lưu file backup trên cùng một server.\nWorkflow nâng cao:\nTạo file backup: Sử dụng một trong các kỹ thuật trên để tạo file .sql.gz.\nTải lên Cloud Storage: Dùng các công cụ command-line của nhà cung cấp cloud để đẩy file backup lên một nơi an toàn.\nAWS S3: aws s3 cp /path/to/backup.sql.gz s3://your-backup-bucket/\nGoogle Cloud Storage: gsutil cp /path/to/backup.sql.gz gs://your-backup-bucket/\nAzure Blob Storage: az storage blob upload \u0026ndash;file /path/to/backup.sql.gz \u0026ndash;container-name your-container \u0026ndash;name backup.sql.gz\nXóa file backup local: Sau khi đã tải lên cloud thành công, bạn có thể xóa file trên server để tiết kiệm dung lượng.\nThiết lập Lifecycle Rules: Cấu hình trên Cloud Storage để tự động xóa các bản backup cũ (ví dụ: chuyển sang lớp lưu trữ rẻ hơn sau 30 ngày và xóa hẳn sau 90 ngày).\nGiám sát và Cảnh báo (Monitoring \u0026amp; Alerting):\nSử dụng các công cụ như Prometheus, Healthchecks.io, hoặc đơn giản là gửi email/thông báo Slack khi script backup chạy thành công hoặc thất bại. Tự động hóa việc Restore: Viết script để tự động tải về bản backup mới nhất từ cloud và restore vào một môi trường staging. Chạy script này định kỳ (ví dụ: hàng tuần) để đảm bảo 100% rằng backup của bạn hoạt động.\nVí dụ script tích hợp AWS S3:\n# ... (Phần tạo backup như trên) ... # Kiểm tra backup thành công if [ $? -eq 0 ]; then echo \u0026#34;Backup thanh cong: ${BACKUP_FILE}\u0026#34; # Tải lên S3 echo \u0026#34;Tai file backup len AWS S3...\u0026#34; aws s3 cp ${BACKUP_FILE} s3://your-s3-bucket/database/ if [ $? -eq 0 ]; then echo \u0026#34;Tai len S3 thanh cong. Xoa file local.\u0026#34; rm ${BACKUP_FILE} else echo \u0026#34;Tai len S3 that bai!\u0026#34; fi else echo \u0026#34;Backup failed!\u0026#34; # Gửi cảnh báo đến Slack/Email ở đây exit 1 fi # ... (Phần xóa backup cũ trên S3 có thể dùng lifecycle rules) ... ","permalink":"https://blog.nagih.io.vn/posts/backup-database/","summary":"\u003cp\u003eKỹ thuật backup database định kỳ là một kỹ năng cực kỳ quan trọng đối với bất kỳ ai làm DevOps. Một chiến lược backup tốt sẽ giúp bạn cứu sống cả hệ thống khi có sự cố.\u003c/p\u003e","title":"Kĩ thuật backup dữ liệu Database định kỳ"},{"content":" Phase 1: Server Initialization \u0026amp; Basic Configuration 1. First Connect ssh root@your_server_ip 2. Create new User # add user adduser your_username # sudo authorization usermod -aG sudo your_username 3. FW - Uncomplicated Firewall # Install ufw if not available sudo apt install ufw # Allow ssh connection sudo ufw allow OpenSSH # Activate firewall sudo ufw enable 4. Update System apt update \u0026amp; apt upgrade -y 5. Re-Login ssh your_username@your_server_ip Phase 2: Setup Environment Docker \u0026amp; Docker Compose # Install Docker curl -sSL https://get.docker.com | sh # Add user to docker group sudo usermod -aG docker $USER # Re-Login to Apply changes Cloudflared Tunnel Workflow ","permalink":"https://blog.nagih.io.vn/posts/raspberry-pi---basic-server-workflow/","summary":"","title":"Hướng dẫn setup môi trường server cơ bản chạy web và các dịch vụ nền cho Raspberry Pi (Debian)"},{"content":" TCP là gì? TCP, viết tắt của Transmission Control Protocol (Giao thức điều khiển truyền vận), là một giao thức cốt lõi trong bộ giao thức Internet (TCP/IP). Nó hoạt động ở tầng Giao vận (Transport Layer - Tầng 4 trong mô hình OSI ). Nhiệm vụ chính của TCP là đảm bảo dữ liệu được truyền đi một cách đáng tin cậy và đúng thứ tự giữa các ứng dụng trên các thiết bị mạng khác nhau.\nHãy tưởng tượng bạn gửi một bức thư dài qua đường bưu điện. Thay vì gửi cả tập giấy dày, bạn chia nhỏ nó thành nhiều trang, đánh số thứ tự mỗi trang và gửi từng trang riêng lẻ. TCP cũng làm điều tương tự với dữ liệu của bạn. Nó chia dòng dữ liệu lớn thành các gói tin nhỏ hơn gọi là segment (phân đoạn).\nTCP thường hoạt động cùng với Giao thức Internet (IP) . Trong khi IP chịu trách nhiệm tìm đường và gửi các gói tin đến đúng địa chỉ đích, TCP đảm bảo rằng tất cả các gói tin này đến nơi an toàn, không lỗi và được lắp ráp lại theo đúng thứ tự ban đầu. Sự kết hợp này được gọi là TCP/IP, là nền tảng cho hầu hết các hoạt động trên Internet ngày nay.\nCác đặc điểm chính của TCP TCP được biết đến là một giao thức \u0026ldquo;hướng kết nối\u0026rdquo; (connection-oriented) và đáng tin cậy. Điều này có nghĩa là trước khi bất kỳ dữ liệu nào được gửi đi, một kết nối ảo phải được thiết lập giữa máy gửi và máy nhận. Các đặc điểm nổi bật của TCP bao gồm:\nĐộ tin cậy cao: TCP đảm bảo dữ liệu đến đích một cách toàn vẹn. Nó sử dụng cơ chế kiểm tra lỗi (checksum), gửi lại các gói tin bị mất và loại bỏ các gói tin trùng lặp.\nĐảm bảo đúng thứ tự: Mỗi segment được gán một \u0026ldquo;số thứ tự\u0026rdquo; (sequence number). Bên nhận sẽ dựa vào số này để sắp xếp lại các segment theo đúng thứ tự ban đầu, đảm bảo dữ liệu không bị xáo trộn.\nKiểm soát luồng (Flow Control): TCP sử dụng một cơ chế gọi là \u0026ldquo;cửa sổ trượt\u0026rdquo; (sliding window) để điều chỉnh tốc độ truyền dữ liệu. Điều này giúp bên gửi không làm quá tải bên nhận bằng cách gửi dữ liệu nhanh hơn khả năng xử lý của nó.\nKiểm soát tắc nghẽn (Congestion Control): TCP có khả năng phát hiện tình trạng tắc nghẽn mạng và tự động giảm tốc độ truyền để tránh làm tình hình tệ hơn.\nTCP hoạt động như thế nào? Quy trình \u0026ldquo;Bắt tay ba bước\u0026rdquo; Hoạt động của TCP có thể được chia thành ba giai đoạn chính: thiết lập kết nối, truyền dữ liệu và kết thúc kết nối.\n1. Thiết lập kết nối: Bắt tay ba bước (Three-Way Handshake) Đây là quy trình bắt buộc để thiết lập một kết nối TCP đáng tin cậy. Quá trình này diễn ra như sau:\nBước 1 (SYN): Máy khách (Client) muốn bắt đầu kết nối sẽ gửi một gói tin có cờ SYN (Synchronize) đến máy chủ (Server). Gói tin này về cơ bản là một lời chào: \u0026ldquo;Chào Server, tôi muốn kết nối. Số thứ tự bắt đầu của tôi là X.\u0026rdquo;\nBước 2 (SYN-ACK): Server nhận được gói SYN, nếu đồng ý kết nối, nó sẽ gửi lại một gói tin có cả cờ SYN và ACK (Acknowledgement). Gói tin này có ý nghĩa: \u0026ldquo;Chào Client, tôi đã nhận được yêu cầu của bạn (ACK X+1). Tôi cũng sẵn sàng kết nối. Số thứ tự bắt đầu của tôi là Y.\u0026rdquo;\nBước 3 (ACK): Client nhận được gói SYN-ACK từ Server. Để hoàn tất quá trình, Client gửi lại một gói tin chỉ có cờ ACK. Gói tin này xác nhận: \u0026ldquo;Tôi đã nhận được gói tin của Server (ACK Y+1). Kết nối đã được thiết lập!\u0026rdquo;\nSau khi hoàn thành 3 bước này, một kết nối ổn định được tạo ra và quá trình truyền dữ liệu có thể bắt đầu.\n2. Truyền dữ liệu Khi kết nối đã được thiết lập, dữ liệu sẽ được chia thành các segment và gửi đi.\nBên gửi sẽ gửi một lượng dữ liệu (trong giới hạn của cửa sổ trượt).\nBên nhận sau khi nhận được dữ liệu sẽ gửi lại một gói tin ACK để xác nhận.\nNếu bên gửi không nhận được ACK trong một khoảng thời gian nhất định, nó sẽ tự động gửi lại segment đó.\n3. Kết thúc kết nối: Bắt tay bốn bước (Four-Way Handshake) Khi quá trình truyền dữ liệu hoàn tất, kết nối sẽ được đóng lại thông qua một quy trình \u0026ldquo;bắt tay bốn bước\u0026rdquo; để đảm bảo cả hai bên đều đồng ý chấm dứt.\nMột bên (ví dụ: Client) gửi một gói tin FIN (Finish) để thông báo muốn kết thúc.\nBên kia (Server) gửi lại một gói ACK để xác nhận đã nhận được yêu cầu.\nSau đó, Server cũng gửi một gói FIN của riêng mình.\nCuối cùng, Client gửi lại một gói ACK để xác nhận, và kết nối được đóng hoàn toàn.\nSo sánh TCP và UDP Trong tầng Giao vận, ngoài TCP còn có một giao thức quan trọng khác là UDP (User Datagram Protocol). Dưới đây là bảng so sánh nhanh giữa hai giao thức này:\nĐặc điểm TCP (Transmission Control Protocol) UDP (User Datagram Protocol) Kiểu kết nối Hướng kết nối (Connection-oriented) Không kết nối (Connectionless) Độ tin cậy Rất cao. Đảm bảo dữ liệu đến nơi, đúng thứ tự, không lỗi. Không đáng tin cậy. Không đảm bảo dữ liệu có đến đích hay không, không sắp xếp thứ tự. Tốc độ Chậm hơn do các cơ chế kiểm tra, xác nhận và thiết lập kết nối. Rất nhanh do không có các quy trình phức tạp. Kiểm soát luồng Có Không Header Lớn hơn (tối thiểu 20 bytes) do chứa nhiều thông tin điều khiển. Nhỏ hơn (8 bytes), giúp giảm thiểu dữ liệu thừa. Ứng dụng phổ biến Truy cập web (HTTP/HTTPS), gửi email (SMTP), truyền file (FTP). Streaming video/audio, game online, gọi VoIP, DNS. Khi nào nên sử dụng TCP? TCP là lựa chọn lý tưởng cho các ứng dụng đòi hỏi tính toàn vẹn và độ chính xác của dữ liệu là ưu tiên hàng đầu. Nếu việc mất một vài gói tin có thể gây ra lỗi nghiêm trọng (ví dụ như tải một tệp tin bị hỏng, email bị mất nội dung), thì TCP là giao thức bắt buộc phải sử dụng.\n","permalink":"https://blog.nagih.io.vn/posts/overview/","summary":"","title":"Tổng quan về TCP"},{"content":" OSI là gì? Mô hình Kết nối các hệ thống mở (Open Systems Interconnection - OSI) là một khung khái niệm chia các chức năng truyền thông mạng thành 7 lớp hay 7 tầng riêng biệt. Được phát triển bởi Tổ chức Tiêu chuẩn hóa Quốc tế (ISO), mô hình này không phải là một giao thức cụ thể mà là một mô hình tham chiếu lý thuyết để chuẩn hóa cách các hệ thống máy tính khác nhau giao tiếp với nhau.\nCấu trúc 7 tầng của mô hình OSI Quá trình truyền dữ liệu trong mô hình OSI diễn ra theo thứ tự từ tầng ứng dụng (tầng 7) đi xuống tầng vật lý (tầng 1) ở máy gửi, và ngược lại ở máy nhận. Mỗi tầng có những chức năng cụ thể và có thêm thêm header (thông tin điều khiển) của riêng mình vào dữ liệu trước khi chuyển xuống tầng tiếp theo. Quá trình này gọi là \u0026ldquo;đóng gói dữ liệu\u0026rdquo;.\nTầng 7: Application Layer Đây là tầng gần gũi nhất với người dùng. Nó cung cấp giao diện để các ứng dụng phần mềm có thể truy cập và sử dụng các dịch vụ mạng.\nChức năng chính:\nCung cấp các dịch vụ mạng cho ứng dụng của người dùng như truy cập web, gửi/nhận email, truyền file.\nXác định các giao thức mà ứng dụng sử dụng để trao đổi dữ liệu.\nVí dụ thực tế: Khi bạn sử dụng trình duyệt web, email hoặc một phần mềm chat, bạn đang tương tác với tầng ứng dụng. Các giao thức phổ biến ở tầng này bao gồm HTTP/HTTPS (truy cập web), FTP (truyền tệp), SMTP (gửi email), và DNS (hệ thống phân giải tên miền).\nTầng 6: Presentation Layer Tầng này hoạt động như một \u0026ldquo;người phiên dịch\u0026rdquo; của mạng, đảm bảo rằng dữ liệu được gửi từ tầng ứng dụng của một hệ thống có thể được đọc và hiểu bởi tầng ứng dụng của hệ thống khác.\nChức năng chính:\nĐịnh dạng dữ liệu: Chuyển đổi dữ liệu sang một định dạng chung mà mạng có thể hiểu.\nMã hóa và giải mã: Đảm bảo tính bảo mật và bí mật của dữ liệu trong quá trình truyền.\nNén và giải nén: Giảm kích thước dữ liệu để truyền đi nhanh hơn và tiết kiệm băng thông.\nVí dụ thực tế: Mã hóa HTTPS thông qua SSL/TLS thường được coi là hoạt động ở tầng này. Các định dạng tệp hình ảnh (JPEG, GIF) và video (MPEG) cũng là ví dụ về hoạt động của tầng trình bày.\nTầng 5: Session Layer Tầng này chịu trách nhiệm thiết lập, quản lý và kết thúc các phiên giao tiếp (kết nối) giữa hai máy tính.\nChức năng chính:\nThiết lập và quản lý phiên: Tạo, duy trì và đồng bộ hóa các phiên giao tiếp giữa các ứng dụng.\nĐiều khiển đối thoại: Xác định lượt truyền dữ liệu (ai gửi, ai nhận, và trong bao lâu).\nKhôi phục phiên: Nếu một phiên bị gián đoạn, tầng này có thể giúp khôi phục lại từ một điểm kiểm tra (checkpoint), tránh việc phải truyền lại toàn bộ dữ liệu.\nVí dụ thực tế: Khi bạn thực hiện một cuộc gọi video, tầng phiên sẽ duy trì kết nối ổn định trong suốt cuộc gọi. Các giao thức như NetBIOS, RPC cũng hoạt động ở tầng này.\nTầng 4: Transport Layer Tầng vận chuyển đảm bảo việc truyền dữ liệu hoàn chỉnh và đáng tin cậy từ một tiến trình trên máy gửi đến một tiến trình trên máy nhận.\nChức năng chính:\nPhân đoạn và tái lắp ráp: Chia nhỏ dữ liệu từ tầng phiên thành các đoạn (segment) nhỏ hơn để truyền đi và tập hợp chúng lại ở phía nhận.\nKiểm soát luồng: Điều chỉnh tốc độ truyền dữ liệu để tránh làm quá tải thiết bị nhận.\nKiểm soát lỗi: Đảm bảo dữ liệu đến nơi một cách chính xác, không bị lỗi, mất mát hay trùng lặp.\nCung cấp hai loại giao thức chính:\nTCP (Transmission Control Protocol): Hướng kết nối, đảm bảo độ tin cậy cao (dữ liệu được gửi đầy đủ và đúng thứ tự). Thích hợp cho việc tải tệp, gửi email.\nUDP (User Datagram Protocol): Không kết nối, truyền dữ liệu nhanh hơn nhưng không đảm bảo độ tin cậy. Thích hợp cho streaming video, game online.\nTầng 3: Network Layer Tầng mạng chịu trách nhiệm cho việc định địa chỉ logic và định tuyến các gói tin (packet) qua các mạng khác nhau để đến đúng đích.\nChức năng chính:\nĐịnh địa chỉ logic (Logical Addressing): Gán địa chỉ IP cho các thiết bị để xác định chúng trên mạng.\nĐịnh tuyến (Routing): Xác định con đường tốt nhất để các gói tin di chuyển từ nguồn đến đích qua nhiều mạng khác nhau. Các thiết bị định tuyến (router) hoạt động ở tầng này.\nVí dụ thực tế: Khi bạn truy cập một trang web, tầng mạng sẽ xác định đường đi cho dữ liệu của bạn qua Internet để đến được máy chủ của trang web đó. Giao thức IP (Internet Protocol) là giao thức chính ở tầng này.\nTầng 2: Data Link Layer Tầng này cung cấp phương tiện truyền dữ liệu đáng tin cậy qua một liên kết vật lý trực tiếp. Nó nhận các gói tin từ tầng mạng và đóng gói chúng thành các khung (frame).\nChức năng chính:\nĐịnh địa chỉ vật lý (Physical Addressing): Thêm địa chỉ MAC (Media Access Control) của thiết bị gửi và nhận vào mỗi khung. Địa chỉ MAC là duy nhất cho mỗi card mạng.\nKiểm soát lỗi: Phát hiện và sửa lỗi có thể xảy ra ở tầng vật lý.\nKiểm soát truy cập môi trường (Media Access Control - MAC): Điều khiển việc các thiết bị trên cùng một mạng chia sẻ truy cập vào môi trường truyền.\nVí dụ thực tế: Các thiết bị chuyển mạch (switch) hoạt động ở tầng này. Giao thức Ethernet là một ví dụ điển hình.\nTầng 1: Physical Layer Đây là tầng thấp nhất, chịu trách nhiệm truyền các bit dữ liệu (0 và 1) qua môi trường truyền vật lý.\nChức năng chính:\nĐịnh nghĩa các đặc tính vật lý: Quy định về các thiết bị phần cứng như cáp mạng, đầu nối, card mạng, cũng như các đặc tính về điện, cơ và quang.\nBiểu diễn bit: Chuyển đổi các bit 0 và 1 thành các tín hiệu điện, ánh sáng hoặc sóng vô tuyến để truyền đi.\nTốc độ dữ liệu: Xác định số bit được truyền đi mỗi giây.\nVí dụ thực tế: Cáp đồng, cáp quang, sóng Wi-Fi, hub, và repeater là những ví dụ về các thành phần hoạt động ở tầng vật lý.\nƯu và nhược điểm của mô hình OSI Ưu điểm:\nChuẩn hóa: Tạo ra một tiêu chuẩn chung, giúp các nhà sản xuất khác nhau tạo ra các sản phẩm tương thích.\nGiảm độ phức tạp: Chia nhỏ quá trình truyền thông phức tạp thành các phần đơn giản, dễ quản lý và dễ hiểu hơn.\nHỗ trợ kỹ thuật module: Cho phép thay đổi hoặc phát triển công nghệ ở một tầng mà không ảnh hưởng đến các tầng khác.\nDễ dàng khắc phục sự cố: Giúp các kỹ sư mạng xác định vấn đề xảy ra ở tầng nào một cách nhanh chóng.\nNhược điểm:\nTính lý thuyết: Mô hình OSI chỉ là một mô hình tham chiếu và không được triển khai rộng rãi trong thực tế như mô hình TCP/IP.\nPhức tạp: Một số người cho rằng mô hình 7 tầng là quá phức tạp và một số tầng có chức năng không thực sự cần thiết trong nhiều ứng dụng thực tế.\n","permalink":"https://blog.nagih.io.vn/posts/overview/","summary":"","title":"Tổng quan về mô hình OSI"},{"content":"Có một số cách để tạo USB boot Windows trên Linux. Đây là phương pháp phổ biến nhất:\nSử dụng WoeUSB-ng Cài đặt # Ubuntu/Debian sudo apt install git p7zip-full python3-pip python3-wxgtk4.0 sudo pip3 install WoeUSB-ng # Fedora sudo dnf install WoeUSB-ng Sử dụng sudo woeusb --device /đường/dẫn/tới/Windows.iso /dev/sdX (Thay /dev/sdX bằng USB của bạn, ví dụ /dev/sdb)\nCách nhận biết tên thiết bị USB trên Linux 1. Command lsblk lsblk Kết quả sẽ hiển thị dạng:\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 238.5G 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi └─sda2 8:2 0 238G 0 part / sdb 8:16 1 14.9G 0 disk \u0026lt;-- Đây là USB └─sdb1 8:17 1 14.9G 0 part /media/user/USB Nhận biết: USB thường có RM = 1 (removable), dung lượng nhỏ hơn ổ cứng chính.\n2. Command sudo fdisk -l sudo fdisk -l Tìm thiết bị có nhãn như \u0026ldquo;USB\u0026rdquo; hoặc dung lượng khớp với USB của bạn.\n","permalink":"https://blog.nagih.io.vn/posts/usb-boot-windows-on-linux/","summary":"\u003cp\u003eCó một số cách để tạo USB boot Windows trên Linux. Đây là phương pháp phổ biến nhất:\u003c/p\u003e","title":"Hướng dẫn tạo USB Boot Windows trên Linux"},{"content":"Hướng dẫn sửa lỗi authorized khi SSH vào raspberry pi\nSửa trực tiếp trên Thẻ nhớ Tắt Pi và tháo thẻ nhớ SD.\nCắm thẻ nhớ vào máy tính của bạn (bạn có thể cần một đầu đọc thẻ).\nTruy cập vào phân vùng có tên rootfs (hoặc phân vùng có dung lượng lớn hơn).\nĐi đến đường dẫn /home/nagih/.ssh/.\nKiểm tra file authorized_keys: Mở nó ra và đảm bảo nội dung của file ~/.ssh/id_ed25519.pub trên máy tính của bạn được chép chính xác vào đây, trên một dòng duy nhất.\nKiểm tra quyền (khó hơn): Việc kiểm tra và sửa quyền file trên thẻ SD từ một máy tính khác (như Windows) là không khả thi. Nếu bạn dùng Linux, bạn có thể mount thẻ nhớ và dùng chmod để sửa.\n","permalink":"https://blog.nagih.io.vn/posts/fix-authorized/","summary":"\u003cp\u003eHướng dẫn sửa lỗi authorized khi SSH vào raspberry pi\u003c/p\u003e","title":"Hướng dẫn sửa lỗi authorized khi SSH vào raspberry pi"},{"content":"Chia sẻ một số kĩ thuật chuẩn đoán lỗi khi kết nối (SSH) tới server (Mạng nội bộ)\nGIẢ SỬ SERVER LÀ RASPBERRY PI 1. Chế độ Verbose của SSH Đây là công cụ chẩn đoán mạnh mẽ và hữu ích nhất có sẵn. Nó yêu cầu client SSH in ra tất cả các bước và thông tin trao đổi trong quá trình kết nối.\nCách thực hiện: Thêm cờ -v (verbose) vào lệnh SSH của bạn. Sử dụng -vvv để có mức độ chi tiết cao nhất.\nssh -vvv nagih@192.168.0.102 Phân tích kết quả: Bạn sẽ thấy một loạt các dòng gỡ lỗi (debug). Hãy chú ý đến những dòng cuối cùng trước khi kết nối thất bại.\nDừng ở Connecting to 192.168.0.102 port 22: Máy tính của bạn không thể tìm thấy Pi trên mạng. Nguyên nhân có thể là sai địa chỉ IP, Pi chưa khởi động xong, hoặc bị tường lửa mạng chặn.\nDừng ở Connection established rồi báo lỗi: Kết nối mạng đã thành công, nhưng dịch vụ SSH trên Pi đã từ chối. Đây là dấu hiệu của lỗi cấu hình SSH trên Pi (như hosts.deny) hoặc dịch vụ SSH không chạy đúng. Lỗi \u0026ldquo;Connection closed by\u0026hellip;\u0026rdquo; thường xuất hiện ở giai đoạn này.\nDừng ở các bước xác thực (Authenticating): Vấn đề nằm ở mật khẩu hoặc khóa SSH.\n2. Kiểm tra Kết nối Mạng cơ bản (ping) 🌐 Lệnh ping giúp xác nhận xem Raspberry Pi có đang \u0026ldquo;sống\u0026rdquo; và phản hồi trên mạng hay không.\nCách thực hiện: ping 192.168.0.102 Cách phân tích kết quả: Nhận được phản hồi Reply from...: Tốt! Raspberry Pi đang hoạt động và có thể truy cập được từ máy của bạn. Vấn đề chắc chắn nằm ở dịch vụ SSH (chưa bật, bị treo, hoặc bị tường lửa chặn).\nNhận được Request timed out hoặc Destination host unreachable: Máy tính của bạn không thể \u0026ldquo;thấy\u0026rdquo; Pi. Nguyên nhân có thể là:\nSai địa chỉ IP.\nPi chưa được cắm nguồn hoặc chưa khởi động xong.\nPi không kết nối được vào mạng WiFi/LAN.\nBạn và Pi đang ở hai mạng khác nhau.\n3. Quét Cổng Mạng (nmap) 🔍 nmap là một công cụ quét mạng mạnh mẽ giúp bạn kiểm tra xem cổng 22 (cổng SSH mặc định) trên Raspberry Pi có đang mở và lắng nghe kết nối hay không.\nCách thực hiện: Đầu tiên, bạn có thể cần cài đặt nmap. Sau đó, chạy lệnh sau:\nnmap -p 22 192.168.0.102 Cách phân tích kết quả: PORT 22/tcp OPEN: Cổng 22 đang mở. Điều này khẳng định dịch vụ SSH đang chạy trên Pi. Nếu bạn vẫn không kết nối được, nguyên nhân gần như chắc chắn là do cấu hình bảo mật trên Pi (như hosts.deny hoặc AllowUsers).\nPORT 22/tcp CLOSED: Cổng 22 đang bị đóng. Điều này có nghĩa là Pi đang hoạt động, nhưng dịch vụ SSH không chạy hoặc chưa được khởi động.\nPORT 22/tcp FILTERED: Cổng 22 đang bị một thiết bị tường lửa (trên Pi hoặc trên router mạng) chặn. Kết nối từ máy bạn bị lọc và không thể đến được dịch vụ SSH.\n4. Kiểm tra Tệp known_hosts của Client Đôi khi, nếu bạn cài đặt lại hệ điều hành trên Pi hoặc Pi được cấp lại IP của một thiết bị cũ, \u0026ldquo;dấu vân tay\u0026rdquo; SSH của nó sẽ thay đổi, gây ra lỗi bảo mật trên máy client.\nCách phát hiện: Lỗi thường sẽ có thông báo rất rõ ràng, chứa cảnh báo \u0026ldquo;REMOTE HOST IDENTIFICATION HAS CHANGED!\u0026rdquo;.\nCách khắc phục: Chạy lệnh sau trên máy client để xóa thông tin cũ về địa chỉ IP đó:\nssh-keygen -R \u0026#34;192.168.0.102\u0026#34; Sau đó, hãy thử kết nối lại. Bạn sẽ được hỏi để xác nhận dấu vân tay mới.\nTóm tắt quy trình chẩn đoán từ Client Dùng ping để xác nhận Pi có trên mạng không.\nKhông thấy? Kiểm tra IP, dây mạng/WiFi, nguồn điện của Pi. Dùng nmap để kiểm tra cổng 22.\nCLOSED? Dịch vụ SSH trên Pi chưa chạy.\nFILTERED? Tường lửa đang chặn.\nDùng ssh -vvv để xem chi tiết quá trình kết nối.\nLỗi sẽ hiện ra trong các bước cuối cùng, giúp bạn biết vấn đề nằm ở mạng, cấu hình dịch vụ, hay xác thực. ","permalink":"https://blog.nagih.io.vn/posts/diagnostic-techniques---ssh/","summary":"\u003cp\u003eChia sẻ một số kĩ thuật chuẩn đoán lỗi khi kết nối (SSH) tới server (Mạng nội bộ)\u003c/p\u003e","title":"Kĩ thuật chuẩn đoán lỗi khi SSH tới server"},{"content":"Các vấn đề về kết nối Internet phổ biến và cách khắc phục chi tiết\nI. CHUẨN ĐOÁN VẤN ĐỀ Bước 1: Kiểm tra kết nối vật lý # Kiểm tra card mạng có được nhận diện không lspci | grep -i network lspci | grep -i ethernet lsusb | grep -i wireless # Kiểm tra interface có tồn tại không ip link show ifconfig -a Kết quả mong đợi: Thấy các interface như eth0, wlan0, enp0s3\nBước 2: Kiểm tra trạng thái Interface # Xem trạng thái chi tiết ip addr show nmcli device status # Kiểm tra interface có UP không ip link show eth0 # Thay eth0 bằng interface của bạn Phân tích kết quả\nUP: Interface đã bật\nDOWN: Interface bị tắt\nNO-CARRIER: Không có tín hiệu (Dây mạng rút, không có sóng Wifi)\nBước 3: Test kết nối từng lớp # Layer 1-2: Kiểm tra link local ping -c 3 127.0.0.1 # Layer 3: Kiểm tra gateway ip route show # Xem default gateway ping -c 3 \u0026lt;gateway-ip\u0026gt; # Ping gateway # Layer 3: Kiểm tra DNS server ping -c 3 1.1.1.1 # Ping IP trực tiếp (Cloudflared / Google) # Layer 4: Kiểm tra phân giải tên miền nslookup google.com ping -c 3 google.com Bước 4: Kiểm tra cấu hình mạng # Kiểm tra IP configuration ip addr show route -n # Kiểm tra DNS setting cat /etc/resolv.conf system-resolve --status # Kiểm tra DHCP sudo dhclient -v eth0 # Test DHCP renewal Bước 5: Kiểm tra service và process # Kiểm tra network services systemctl status NetworkManager systemctl status networking systemctl status systemd-networkd # Kiểm tra Firewall sudo ufw status sudo iptables -L -n # Kiểm tra process sử dụng network ss -tuln # Listening ports netstart -rn # Routing table Bước 6: Xem Logs và Error messages journalctl -u NetworkManager -f dmesg | grep -i network dmesg | grep -i eth dmesg | grep -i wlan # Kernal messages dmes | tail -20 tail -f var/log/syslog | grep -i network Ma trận chuẩn đoán nhanh Triệu chứng Lệnh kiểm tra Nguyên nhân có thể Không thấy interface ip link show Driver không có/sai Interface DOWN ip link show Interface bị disable Không có IP ip addr show DHCP fail, static config sai Ping localhost fail ping 127.0.0.1 Network stack broken Ping gateway fail ping \u0026lt;gateway\u0026gt; L2/L3 problem Ping IP OK, domain fail nslookup google.com DNS problem Kết nối chậm traceroute google.com Routing/bandwidth issue Scripts auto chuẩn đoán lỗi #!/bin/bash echo \u0026#34;=== NETWORK DIAGNOSTIC REPORT ===\u0026#34; echo \u0026#34;Date: $(date)\u0026#34; echo echo \u0026#34;1. NETWORK INTERFACES:\u0026#34; ip link show echo echo \u0026#34;2. IP ADDRESSES:\u0026#34; ip addr show echo echo \u0026#34;3. ROUTING TABLE:\u0026#34; ip route show echo echo \u0026#34;4. DNS CONFIGURATION:\u0026#34; cat /etc/resolv.conf echo echo \u0026#34;5. CONNECTIVITY TESTS:\u0026#34; echo -n \u0026#34;Localhost: \u0026#34; ping -c 1 -W 2 127.0.0.1 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; GATEWAY=$(ip route | grep default | awk \u0026#39;{print $3}\u0026#39; | head -1) if [ ! -z \u0026#34;$GATEWAY\u0026#34; ]; then echo -n \u0026#34;Gateway ($GATEWAY): \u0026#34; ping -c 1 -W 2 $GATEWAY \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; fi echo -n \u0026#34;External DNS (8.8.8.8): \u0026#34; ping -c 1 -W 2 8.8.8.8 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; echo -n \u0026#34;Domain resolution (google.com): \u0026#34; nslookup google.com \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; echo echo \u0026#34;6. ACTIVE SERVICES:\u0026#34; systemctl is-active NetworkManager 2\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;NetworkManager: Active\u0026#34; || echo \u0026#34;NetworkManager: Inactive\u0026#34; systemctl is-active networking 2\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;networking: Active\u0026#34; || echo \u0026#34;networking: Inactive\u0026#34; Chạy scripts\nchmod +x network-diagnostic.sh ./network-diagnostic.sh II. XỬ LÝ LỖI 1. Không kết nối được mạng Kiểm tra trạng thái mạng\nip link show ip addr show nmcli device status Khắc phục\n# Khởi động lại network manager sudo systemctl restart NetworkManager # Hoặc khởi động lại networking service sudo systemctl restart networking 2. Lỗi DNS không phân giải được Kiểm tra DNS\nnslookup google.com dig google.com cat /etc/resolv.conf Khắc phục\n# Thay đổi DNS server sudo nano /etc/resolv.conf # Thêm các dòng sau: # Cloudflared nameserver 1.1.1.1 nameserver 1.0.0.1 # Google nameserver 8.8.8.8 nameserver 8.8.4.4 3. Lỗi drive card mạng Kiểm tra drive\nlspci -nnk | grep -iA2 net lsusb # cho USB WiFi adapter dmesg | grep -i network Khắc phục\n# Cài đặt driver thiếu sudo apt update sudo apt install linux-firmware sudo apt install firmware-iwlwifi # cho Intel WiFi # Khởi động lại sudo modprobe -r iwlwifi \u0026amp;\u0026amp; sudo modprobe iwlwifi 4. Lỗi Wifi không kết nối được iwconfig nmcli dev wifi list rfkill list Khắc phục\n# Bật WiFi nếu bị tắt sudo rfkill unblock wifi # Kết nối WiFi nmcli dev wifi connect \u0026#34;TenWiFi\u0026#34; password \u0026#34;MatKhau\u0026#34; # Reset network settings sudo rm /var/lib/NetworkManager/NetworkManager.state sudo systemctl restart NetworkManager 5. Lỗi IP conflict hoặc không nhận được IP ip route show dhclient -v Khắc phục\n# Renew IP address sudo dhclient -r sudo dhclient # Hoặc reset network interface sudo ifdown eth0 \u0026amp;\u0026amp; sudo ifup eth0 6. Lỗi firewall chặn kết nối Kiểm tra firewall\nsudo ufw status sudo iptables -L Khắc phục\n# Tạm thời tắt firewall để test sudo ufw disable # Hoặc mở port cần thiết sudo ufw allow 80 sudo ufw allow 443 sudo ufw allow ssh 7. Lỗi proxy settings Kiểm tra proxy\necho $http_proxy echo $https_proxy cat /etc/environment Khắc phục\n# Xóa proxy settings unset http_proxy unset https_proxy unset HTTP_PROXY unset HTTPS_PROXY # Hoặc cấu hình đúng proxy export http_proxy=http://proxy-server:port export https_proxy=http://proxy-server:port 8. Lỗi MTU size Kiểm tra và fix MTU\n# Kiểm tra MTU hiện tại ip link show # Thay đổi MTU sudo ip link set dev eth0 mtu 1400 # Hoặc cấu hình vĩnh viễn trong /etc/network/interfaces III. RESET HOÀN TOÀN NETWORKING # Backup cấu hình cũ nếu cần sudo cp -r /etc/NetworkManager /etc/NetworkManager.backup # Reset NetworkManager sudo rm -rf /etc/NetworkManager/system-connections/* sudo systemctl stop NetworkManager sudo systemctl start NetworkManager # Hoặc reinstall network packages sudo apt remove --purge network-manager sudo apt install network-manager ","permalink":"https://blog.nagih.io.vn/posts/internet-errors/","summary":"\u003cp\u003eCác vấn đề về kết nối Internet phổ biến và cách khắc phục chi tiết\u003c/p\u003e","title":"Các vấn đề về Internet và cách khắc phục"},{"content":"Chia sẻ mẫu Documentation cho lập trình viên Backend\nE-Library Management System - Backend Documentation 📋 Table of Contents System Overview Architecture API Documentation Database Schema Authentication \u0026amp; Security Setup \u0026amp; Deployment Testing Monitoring \u0026amp; Logging 🎯 System Overview Project: E-Library Management System\nVersion: v2.1.0\nTech Stack: Node.js, Express.js, MongoDB, Redis, Docker\nPurpose: Backend API cho hệ thống quản lý thư viện sách điện tử\nCore Features User authentication \u0026amp; authorization\nBook catalog management\nBook borrowing/returning system\nSearch \u0026amp; filtering\nUser notifications\nAdmin dashboard APIs\n🏗️ Architecture High-Level Architecture ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ Client Apps │─ │ Load Balancer │──│ API Gateway │ └─────────────────┘ └─────────────────┘ └─────────────────┘ │ ┌─────────────────────────────┼─────────────────────────────┐ │ │ │ ┌───────▼───────┐ ┌───────▼───────┐ ┌───────▼───────┐ │ │ │ │ Auth Service │ │ Book Service │ │ User Service │ │ │ │ └───────────────┘ └───────────────┘ └────────────────┘ │ │ │ └─────────────────────────────┼─────────────────────────────┘ │ ┌─────────────────────────────┼─────────────────────────────┐ │ │ │ ┌───────▼───────┐ ┌───────▼───────┐ ┌───────▼───────┐ │ │ │ │ MongoDB │ │ Redis │ │ File Store │ │ │ │ │ (Primary) │ │ (Caching) │ │ (Images) │ │ │ │ └───────────────┘ └───────────────┘ └───────────────┘ Service Dependencies Auth Service: JWT token validation, user roles\nBook Service: Book CRUD operations, search, categorization\nUser Service: User profile management, borrowing history\nNotification Service: Email/SMS notifications\nFile Service: Book cover uploads, PDF handling\n📡 API Documentation Base URL Production: https://api.elibrary.com/v2 Staging: https://staging-api.elibrary.com/v2 Development: http://localhost:3000/v2 Authentication All protected endpoints require Bearer token:\nAuthorization: Bearer \u0026lt;jwt_token\u0026gt; Response Format { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Request processed successfully\u0026#34;, \u0026#34;data\u0026#34;: {}, \u0026#34;pagination\u0026#34;: { \u0026#34;page\u0026#34;: 1, \u0026#34;limit\u0026#34;: 20, \u0026#34;total\u0026#34;: 100, \u0026#34;totalPages\u0026#34;: 5 }, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } Error Response { \u0026#34;success\u0026#34;: false, \u0026#34;error\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;VALIDATION_ERROR\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Invalid request data\u0026#34;, \u0026#34;details\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Email format is invalid\u0026#34; } ] }, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } 🔐 Authentication Endpoints POST /auth/register Description: Đăng ký tài khoản mới\nRequest Body:\n{ \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;SecurePass123!\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;+84901234567\u0026#34; } Response (201):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;User registered successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;isVerified\u0026#34;: false }, \u0026#34;token\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34; } } POST /auth/login Description: Đăng nhập hệ thống\nRequest Body:\n{ \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;SecurePass123!\u0026#34; } Response (200):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Login successful\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; }, \u0026#34;token\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34;, \u0026#34;refreshToken\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34; } } 📚 Book Management Endpoints GET /books Description: Lấy danh sách sách với phân trang và filter\nQuery Parameters:\npage (integer, default: 1): Trang hiện tại limit (integer, default: 20): Số sách per page category (string): Filter theo danh mục author (string): Filter theo tác giả search (string): Tìm kiếm theo title/author available (boolean): Chỉ lấy sách còn available Example Request:\nGET /books?page=1\u0026amp;limit=10\u0026amp;category=fiction\u0026amp;available=true Response (200):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;data\u0026#34;: { \u0026#34;books\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;The Great Gatsby\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;F. Scott Fitzgerald\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-0743273565\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;fiction\u0026#34;, \u0026#34;publishYear\u0026#34;: 1925, \u0026#34;description\u0026#34;: \u0026#34;A classic American novel...\u0026#34;, \u0026#34;coverImage\u0026#34;: \u0026#34;https://cdn.elibrary.com/covers/great-gatsby.jpg\u0026#34;, \u0026#34;totalCopies\u0026#34;: 5, \u0026#34;availableCopies\u0026#34;: 3, \u0026#34;rating\u0026#34;: 4.5, \u0026#34;createdAt\u0026#34;: \u0026#34;2025-09-01T10:00:00.000Z\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2025-09-15T14:30:00.000Z\u0026#34; } ] }, \u0026#34;pagination\u0026#34;: { \u0026#34;page\u0026#34;: 1, \u0026#34;limit\u0026#34;: 10, \u0026#34;total\u0026#34;: 156, \u0026#34;totalPages\u0026#34;: 16 } } POST /books Description: Thêm sách mới (Admin only)\nAuthentication: Required (Admin role)\nRequest Body:\n{ \u0026#34;title\u0026#34;: \u0026#34;New Book Title\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Author Name\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-1234567890\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;science\u0026#34;, \u0026#34;publishYear\u0026#34;: 2024, \u0026#34;description\u0026#34;: \u0026#34;Book description here...\u0026#34;, \u0026#34;totalCopies\u0026#34;: 3, \u0026#34;coverImage\u0026#34;: \u0026#34;base64_encoded_image_or_url\u0026#34; } Response (201):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book created successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;book\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123457\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;New Book Title\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Author Name\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-1234567890\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;science\u0026#34;, \u0026#34;publishYear\u0026#34;: 2024, \u0026#34;description\u0026#34;: \u0026#34;Book description here...\u0026#34;, \u0026#34;totalCopies\u0026#34;: 3, \u0026#34;availableCopies\u0026#34;: 3, \u0026#34;rating\u0026#34;: 0, \u0026#34;createdAt\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } } } PUT /books/:bookId Description: Cập nhật thông tin sách (Admin only)\nAuthentication: Required (Admin role)\nDELETE /books/:bookId Description: Xóa sách (Admin only)\nAuthentication: Required (Admin role)\n📖 Borrowing System Endpoints POST /borrowings Description: Mượn sách\nAuthentication: Required\nRequest Body:\n{ \u0026#34;bookId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;borrowDuration\u0026#34;: 14 } Response (201):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book borrowed successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;borrowing\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123458\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;bookId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;borrowDate\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34;, \u0026#34;dueDate\u0026#34;: \u0026#34;2025-09-30T10:30:00.000Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;active\u0026#34;, \u0026#34;renewalCount\u0026#34;: 0 } } } PUT /borrowings/:borrowingId/return Description: Trả sách\nAuthentication: Required\nResponse (200):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book returned successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;borrowing\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123458\u0026#34;, \u0026#34;returnDate\u0026#34;: \u0026#34;2025-09-16T15:45:00.000Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;returned\u0026#34;, \u0026#34;lateFee\u0026#34;: 0 } } } GET /borrowings/my-books Description: Lấy danh sách sách đang mượn của user\nAuthentication: Required\n🗄️ Database Schema Users Collection { _id: ObjectId, email: String (unique, required), password: String (hashed, required), firstName: String (required), lastName: String (required), phoneNumber: String, role: String (enum: [\u0026#39;user\u0026#39;, \u0026#39;librarian\u0026#39;, \u0026#39;admin\u0026#39;], default: \u0026#39;user\u0026#39;), isVerified: Boolean (default: false), avatar: String, address: { street: String, city: String, zipCode: String }, preferences: { notifications: { email: Boolean (default: true), sms: Boolean (default: false) }, favoriteCategories: [String] }, createdAt: Date, updatedAt: Date } Books Collection { _id: ObjectId, title: String (required, indexed), author: String (required, indexed), isbn: String (unique, required), category: String (required, indexed), publishYear: Number, publisher: String, language: String (default: \u0026#39;vietnamese\u0026#39;), description: String, coverImage: String, pdfFile: String, totalCopies: Number (required, min: 1), availableCopies: Number (required), rating: Number (default: 0), reviewCount: Number (default: 0), tags: [String], createdAt: Date, updatedAt: Date, createdBy: ObjectId (ref: \u0026#39;User\u0026#39;) } Borrowings Collection { _id: ObjectId, userId: ObjectId (ref: \u0026#39;User\u0026#39;, required), bookId: ObjectId (ref: \u0026#39;Book\u0026#39;, required), borrowDate: Date (required), dueDate: Date (required), returnDate: Date, status: String (enum: [\u0026#39;active\u0026#39;, \u0026#39;returned\u0026#39;, \u0026#39;overdue\u0026#39;], required), renewalCount: Number (default: 0, max: 2), lateFee: Number (default: 0), notes: String, createdAt: Date, updatedAt: Date } Categories Collection { _id: ObjectId, name: String (required, unique), slug: String (required, unique), description: String, parentCategory: ObjectId (ref: \u0026#39;Category\u0026#39;), isActive: Boolean (default: true), sortOrder: Number (default: 0), createdAt: Date, updatedAt: Date } 🔒 Authentication \u0026amp; Security JWT Configuration { secret: process.env.JWT_SECRET, algorithm: \u0026#39;HS256\u0026#39;, expiresIn: \u0026#39;24h\u0026#39;, refreshTokenExpiresIn: \u0026#39;7d\u0026#39; } Password Requirements Minimum 8 characters At least 1 uppercase letter At least 1 lowercase letter At least 1 number At least 1 special character Rate Limiting { \u0026#34;/auth/login\u0026#34;: \u0026#34;5 requests per 15 minutes per IP\u0026#34;, \u0026#34;/auth/register\u0026#34;: \u0026#34;3 requests per hour per IP\u0026#34;, \u0026#34;/books\u0026#34;: \u0026#34;100 requests per 15 minutes per user\u0026#34;, \u0026#34;/borrowings\u0026#34;: \u0026#34;20 requests per hour per user\u0026#34; } CORS Configuration { origin: [ \u0026#39;https://elibrary.com\u0026#39;, \u0026#39;https://admin.elibrary.com\u0026#39;, \u0026#39;http://localhost:3000\u0026#39; // development only ], methods: [\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;, \u0026#39;PUT\u0026#39;, \u0026#39;DELETE\u0026#39;], allowedHeaders: [\u0026#39;Content-Type\u0026#39;, \u0026#39;Authorization\u0026#39;] } ⚙️ Setup \u0026amp; Deployment Environment Variables # Database MONGODB_URI=mongodb://localhost:27017/elibrary REDIS_URL=redis://localhost:6379 # Authentication JWT_SECRET=your-super-secret-jwt-key JWT_EXPIRES_IN=24h REFRESH_TOKEN_SECRET=your-refresh-token-secret # External Services EMAIL_SERVICE_API_KEY=your-email-service-key SMS_SERVICE_API_KEY=your-sms-service-key CLOUDINARY_URL=cloudinary://your-cloudinary-url # Server PORT=3000 NODE_ENV=production Development Setup # 1. Clone repository git clone https://github.com/company/elibrary-backend.git cd elibrary-backend # 2. Install dependencies npm install # 3. Copy environment file cp .env.example .env # 4. Start MongoDB and Redis docker-compose up -d mongo redis # 5. Run database migrations npm run migrate # 6. Start development server npm run dev Docker Deployment # docker-compose.prod.yml version: \u0026#39;3.8\u0026#39; services: app: build: . ports: - \u0026#34;3000:3000\u0026#34; environment: - NODE_ENV=production - MONGODB_URI=mongodb://mongo:27017/elibrary - REDIS_URL=redis://redis:6379 depends_on: - mongo - redis mongo: image: mongo:6.0 volumes: - mongo_data:/data/db environment: MONGO_INITDB_ROOT_USERNAME: admin MONGO_INITDB_ROOT_PASSWORD: password redis: image: redis:7-alpine volumes: - redis_data:/data volumes: mongo_data: redis_data: CI/CD Pipeline (GitHub Actions) name: Deploy to Production on: push: branches: [main] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-node@v3 with: node-version: \u0026#39;18\u0026#39; - run: npm ci - run: npm test deploy: needs: test runs-on: ubuntu-latest steps: - name: Deploy to server run: | ssh user@server \u0026#34;cd /app \u0026amp;\u0026amp; git pull \u0026amp;\u0026amp; docker-compose up -d --build\u0026#34; 🧪 Testing Test Structure tests/ ├── unit/ │ ├── controllers/ │ ├── services/ │ └── utils/ ├── integration/ │ ├── auth.test.js │ ├── books.test.js │ └── borrowings.test.js └── e2e/ └── api.test.js Running Tests # Unit tests npm run test:unit # Integration tests npm run test:integration # E2E tests npm run test:e2e # All tests with coverage npm run test:coverage Test Example // tests/integration/books.test.js describe(\u0026#39;Books API\u0026#39;, () =\u0026gt; { beforeEach(async () =\u0026gt; { await Book.deleteMany({}); await User.deleteMany({}); // Create test user and admin testUser = await User.create({ email: \u0026#39;test@example.com\u0026#39;, password: \u0026#39;hashedpassword\u0026#39;, firstName: \u0026#39;Test\u0026#39;, lastName: \u0026#39;User\u0026#39; }); userToken = jwt.sign({ userId: testUser._id }, process.env.JWT_SECRET); }); describe(\u0026#39;GET /books\u0026#39;, () =\u0026gt; { it(\u0026#39;should return paginated books\u0026#39;, async () =\u0026gt; { // Create test books await Book.create([ { title: \u0026#39;Book 1\u0026#39;, author: \u0026#39;Author 1\u0026#39;, isbn: \u0026#39;1111111111\u0026#39; }, { title: \u0026#39;Book 2\u0026#39;, author: \u0026#39;Author 2\u0026#39;, isbn: \u0026#39;2222222222\u0026#39; } ]); const response = await request(app) .get(\u0026#39;/v2/books?page=1\u0026amp;limit=10\u0026#39;) .expect(200); expect(response.body.success).toBe(true); expect(response.body.data.books).toHaveLength(2); expect(response.body.pagination.total).toBe(2); }); }); }); 📊 Monitoring \u0026amp; Logging Logging Configuration // config/logger.js const winston = require(\u0026#39;winston\u0026#39;); const logger = winston.createLogger({ level: process.env.LOG_LEVEL || \u0026#39;info\u0026#39;, format: winston.format.combine( winston.format.timestamp(), winston.format.errors({ stack: true }), winston.format.json() ), transports: [ new winston.transports.File({ filename: \u0026#39;logs/error.log\u0026#39;, level: \u0026#39;error\u0026#39; }), new winston.transports.File({ filename: \u0026#39;logs/combined.log\u0026#39; }), new winston.transports.Console({ format: winston.format.simple() }) ] }); Metrics Collection Response Time: Average API response time Request Rate: Requests per second Error Rate: 4xx/5xx error percentage Database Connection: MongoDB connection pool status Memory Usage: Node.js heap usage Active Users: Currently logged in users Health Check Endpoint // GET /health { \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34;, \u0026#34;services\u0026#34;: { \u0026#34;database\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;redis\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;external_apis\u0026#34;: \u0026#34;operational\u0026#34; }, \u0026#34;metrics\u0026#34;: { \u0026#34;uptime\u0026#34;: \u0026#34;72h 15m\u0026#34;, \u0026#34;memory_usage\u0026#34;: \u0026#34;245MB\u0026#34;, \u0026#34;cpu_usage\u0026#34;: \u0026#34;15%\u0026#34; } } Alerting Rules Response time \u0026gt; 2000ms for 5 minutes Error rate \u0026gt; 5% for 3 minutes Database connection lost Memory usage \u0026gt; 80% Disk space \u0026lt; 10% 📈 Error Codes Reference Code HTTP Status Description VALIDATION_ERROR 400 Request validation failed UNAUTHORIZED 401 Invalid or missing authentication FORBIDDEN 403 Insufficient permissions NOT_FOUND 404 Resource not found CONFLICT 409 Resource already exists RATE_LIMIT_EXCEEDED 429 Too many requests INTERNAL_ERROR 500 Server error SERVICE_UNAVAILABLE 503 External service unavailable 🔄 Changelog v2.1.0 (2025-09-16) Added\nBook rating and review system Advanced search with filters PDF file upload for digital books Notification system for due dates Changed\nImproved authentication with refresh tokens Enhanced error handling and logging Updated database schema for better performance Fixed\nMemory leaks in file upload Race condition in book borrowing Timezone issues in due date calculations v2.0.0 (2025-08-01) Added\nComplete API redesign Role-based access control Redis caching layer Docker containerization 📞 Support \u0026amp; Contact Development Team: backend-team@company.com DevOps Team: devops@company.com Documentation: https://docs.elibrary.com Issue Tracker: https://github.com/company/elibrary-backend/issues Last updated: September 16, 2025\n","permalink":"https://blog.nagih.io.vn/posts/backend-documentation/","summary":"\u003cp\u003eChia sẻ mẫu Documentation cho lập trình viên Backend\u003c/p\u003e","title":"Mẫu Documentation cho Backend"},{"content":"biến SSH từ một công cụ kết nối đơn thuần thành một hệ thống quản lý danh tính hiệu quả\nGiới thiệu ~/.ssh/config File ~/.ssh/config cho phép bạn tạo các bí danh (alias) và các quy tắc kết nối cụ thể cho từng máy chủ. Thay vì phải gõ các lệnh dài dòng với các tùy chọn phức tạp, bạn có thể định nghĩa tất cả trong file này. Cấu trúc của file bao gồm các khối Host, mỗi khối chứa các chỉ thị áp dụng cho host đó.\nKịch bản: Quản lý nhiều tài khoản GitHub (Cá nhân \u0026amp; Công việc) Đây là một kịch bản rất phổ biến. Mục tiêu là có thể làm việc trên các kho lưu trữ của cả hai tài khoản trên cùng một máy tính mà không cần phải thay đổi cấu hình thủ công mỗi lần chuyển đổi.\nTạo khóa SSH thứ hai:\nHãy chắc chắn rằng bạn đã tạo 1 cặp khóa mới dành cho công việc và đặt một tên file khác biệt, ví dụ: id_ed25519_work. Sau đó, thêm khóa công khai này vào tài khoản GitHub công việc.\nCấu hình ~/.ssh/config:\nMở file ~/.ssh/config (nếu chưa có, hãy tạo nó) và thêm vào nội dung sau:\n# Tài khoản GitHub cá nhân Host github.com-personal HostName github.com User git IdentityFile ~/.ssh/id_ed25519_personal IdentitiesOnly yes # Tài khoản GitHub công việc Host github.com-work HostName github.com User git IdentityFile ~/.ssh/id_ed25519_work IdentitiesOnly yes Phân tích Host github.com-personal: Đây là bí danh (alias) bạn sẽ sử dụng. Khi Git hoặc SSH thấy host này, nó sẽ áp dụng các quy tắc bên dưới.\nHostName github.com: Đây là tên máy chủ thực tế mà SSH sẽ kết nối đến.\nUser git: GitHub yêu cầu tất cả các kết nối SSH sử dụng user git.\nIdentityFile ~/.ssh/id_ed25519_personal: Yêu cầu SSH sử dụng file khóa riêng tư cụ thể này để xác thực.\nIdentitiesOnly yes: Cực kỳ quan trọng. Theo mặc định, SSH client có thể thử tất cả các khóa có sẵn trong ssh-agent hoặc các file mặc định. Khi kết nối đến GitHub, nếu gửi sai khóa, kết nối có thể bị từ chối sau vài lần thử. IdentitiesOnly yes buộc SSH client chỉ sử dụng duy nhất khóa được chỉ định trong IdentityFile cho host này, loại bỏ sự mơ hồ và ngăn ngừa lỗi xác thực.\nÁp dụng cấu hình vào Git Sau khi đã cấu hình ~/.ssh/config, bạn cần cập nhật URL của các kho lưu trữ Git để chúng sử dụng các bí danh mới.\nĐối với kho lưu trữ mới (khi git clone): Thay vì sử dụng URL SSH mặc định, hãy thay thế github.com bằng bí danh bạn đã tạo.\n# Clone kho lưu trữ công việc $ git clone git@github.com-work:work-organization/project.git Đối với kho lưu trữ đã có: Sử dụng lệnh git remote set-url để cập nhật URL của remote origin.\n# Điều hướng đến thư mục kho lưu trữ công việc của bạn $ cd path/to/work/project # Cập nhật URL của remote $ git remote set-url origin git@github.com-work:work-organization/project.git Bạn có thể kiểm tra lại bằng lệnh git remote -v.\nVới thiết lập này, quy trình làm việc của bạn sẽ trở nên hoàn toàn tự động. Khi bạn ở trong một thư mục dự án công việc, các lệnh Git sẽ tự động sử dụng khóa công việc. Khi ở trong dự án cá nhân, chúng sẽ sử dụng khóa cá nhân.\n","permalink":"https://blog.nagih.io.vn/posts/all-in-one/","summary":"\u003cp\u003ebiến SSH từ một công cụ kết nối đơn thuần thành một hệ thống quản lý danh tính hiệu quả\u003c/p\u003e","title":"Hướng dẫn quản lý nhiều khóa SSH trên 1 thiết bị"},{"content":"Hướng dẫn chi tiết từng bước để tạo và cấu hình khóa SSH cho tài khoản GitHub của bạn.\nBước 1: Tạo Cặp Khóa SSH với ssh-keygen Lựa chọn Thuật toán Mã hóa Việc lựa chọn thuật toán mã hóa là một quyết định quan trọng ảnh hưởng đến cả hiệu suất và bảo mật.\nEd25519 (Khuyến nghị): Đây là thuật toán hiện đại, được khuyến nghị sử dụng. Ed25519 cung cấp mức độ bảo mật rất cao với độ dài khóa ngắn hơn, giúp quá trình xác thực diễn ra nhanh hơn.\n$ ssh-keygen -t ed25519 -C \u0026#34;your_email@example.com\u0026#34; RSA (Lựa chọn thay thế): RSA là một thuật toán cũ. Nếu bạn cần hỗ trợ các hệ thống cũ không tương thích với Ed25519. Tuy nhiên, điều cực kỳ quan trọng là phải sử dụng độ dài khóa đủ lớn. Mức khuyến nghị tối thiểu hiện nay là 4096 bits để đảm bảo an toàn.\n$ ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; Trong quá trình tạo khóa, bạn sẽ được nhắc nhập một \u0026ldquo;passphrase\u0026rdquo;. Đây là một lớp bảo vệ cực kỳ quan trọng và rất nên được sử dụng. Passphrase này sẽ mã hóa file khóa riêng tư của bạn trên đĩa. Điều này có nghĩa là, ngay cả khi máy tính của bạn bị đánh cắp và kẻ tấn công có được file khóa riêng tư, họ cũng không thể sử dụng nó nếu không biết passphrase. Đây là tuyến phòng thủ cuối cùng để bảo vệ danh tính số của bạn.\nLưu khóa và Đặt tên file tùy chỉnh Theo mặc định, ssh-keygen sẽ lưu cặp khóa vào thư mục ~/.ssh/ với tên file là id_ed25519 và id_ed25519.pub (hoặc id_rsa cho RSA). Mặc dù bạn có thể chấp nhận giá trị mặc định. Đặc biệt khi bạn dự định quản lý nhiều khóa cho các tài khoản khác nhau. Ví dụ, bạn có thể đặt tên là ~/.ssh/id_ed25519_personal cho tài khoản cá nhân và ~/.ssh/id_ed25519_work cho tài khoản công việc. Điều này sẽ giúp việc quản lý trở nên dễ dàng hơn ở các bước nâng cao.\nBước 2: Quản Lý Khóa với ssh-agent Khởi động ssh-agent:\nChạy lệnh sau trong terminal để khởi động agent cho phiên làm việc hiện tại của bạn.\n$ eval \u0026#34;$(ssh-agent -s)\u0026#34; Thêm khóa riêng tư vào ssh-agent:\nSử dụng lệnh ssh-add để thêm khóa riêng tư của bạn vào agent. Bạn sẽ được yêu cầu nhập passphrase mà bạn đã tạo ở Bước 1.\n$ ssh-add ~/.ssh/your_private_key_filename Bước 3: Thêm Khóa Công Khai (Public Key) vào Tài Khoản GitHub Sao chép nội dung khóa công khai:\nmacOS:\n$ pbcopy \u0026lt; ~/.ssh/id_ed25519_personal.pub Windows (sử dụng Git Bash hoặc WSL):\n$ cat ~/.ssh/id_ed25519_personal.pub | clip Thêm khóa vào GitHub:\nTruy cập tài khoản GitHub của bạn trên trình duyệt.\nVào Settings (Cài đặt)\nTrong thanh bên trái, chọn SSH and GPG keys (Khóa SSH và GPG).\nNhấp vào nút New SSH key (Khóa SSH mới).\nTrong trường Title, đặt một cái tên mang tính mô tả cho khóa của bạn (ví dụ: \u0026ldquo;MacBook Pro Cá Nhân\u0026rdquo;).\nTrong trường Key, dán nội dung khóa công khai bạn đã sao chép.\nNhấp vào Add SSH key (Thêm khóa SSH) để hoàn tất.\nBước 4: Kiểm Tra Kết Nối Chạy lệnh kiểm tra:\n$ ssh -T git@github.com Xác thực máy chủ (lần đầu tiên):\nThe authenticity of host \u0026#39;github.com (IP_ADDRESS)\u0026#39; can\u0026#39;t be established. ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU. Are you sure you want to continue connecting (yes/no)? Đây là một tính năng bảo mật của SSH để chống lại các cuộc tấn công xen giữa (man-in-the-middle). Sau khi xác nhận, gõ yes và nhấn Enter.\nKết quả thành công:\nHi username! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. Điều này xác nhận rằng cặp khóa SSH của bạn đã được thiết lập chính xác và GitHub đã xác thực thành công danh tính của bạn.\n","permalink":"https://blog.nagih.io.vn/posts/setup-ssh/","summary":"\u003cp\u003eHướng dẫn chi tiết từng bước để tạo và cấu hình khóa SSH cho tài khoản GitHub của bạn.\u003c/p\u003e","title":"Hướng dẫn thiết lập khóa SSH cho github"},{"content":"Ngay cả với một thiết lập cẩn thận, các vấn đề vẫn có thể phát sinh. Việc hiểu rõ cách chẩn đoán và khắc phục các lỗi SSH phổ biến là một kỹ năng quan trọng.\nChế độ Verbose Trước khi thử bất kỳ giải pháp nào, bước đầu tiên luôn là thu thập thêm thông tin. Tùy chọn -v (verbose) của lệnh ssh sẽ in ra chi tiết quá trình kết nối, cho bạn biết file cấu hình nào đang được đọc, khóa nào đang được thử, và chính xác lỗi xảy ra ở đâu.\n$ ssh -vT git@github.com Error 1: Permission denied (publickey) Ý nghĩa: Đây là lỗi xác thực phổ biến nhất. Nó có nghĩa là máy chủ GitHub đã từ chối tất cả các khóa SSH mà client của bạn cung cấp.\nCác bước kiểm tra và khắc phục:\nKiểm tra khóa trên GitHub: Đảm bảo rằng khóa công khai của bạn đã được thêm chính xác vào tài khoản GitHub.\nKiểm tra ssh-agent: Chạy ssh-add -l để xem các khóa hiện có trong agent. Nếu danh sách trống hoặc không chứa khóa bạn cần, hãy chạy lại ssh-add ~/.ssh/your_private_key để thêm nó vào.\nKiểm tra quyền truy cập file: SSH yêu cầu quyền truy cập rất nghiêm ngặt. Thư mục ~/.ssh phải có quyền là 700 (drwx−−−−−−), và file khóa riêng tư của bạn phải có quyền là 600 (−rw−−−−−−−). Sử dụng các lệnh sau để sửa:\n$ chmod 700 ~/.ssh $ chmod 600 ~/.ssh/your_private_key Kiểm tra ~/.ssh/config: Nếu bạn đang sử dụng file cấu hình, hãy kiểm tra kỹ lưỡng xem Host alias có khớp với URL remote của Git không, và IdentityFile có trỏ đến đúng file khóa riêng tư không.\nError 2: Host key verification failed Ý nghĩa: Dấu vân tay của máy chủ GitHub đã thay đổi so với lần cuối bạn kết nối. Đây là một cơ chế bảo mật quan trọng để cảnh báo về khả năng có một cuộc tấn công Man-in-the-Middle.\nCách khắc phục an toàn:\nKhông bao giờ bỏ qua cảnh báo này một cách mù quáng.\nTruy cập trang tài liệu chính thức của GitHub để xác minh dấu vân tay máy chủ mới nhất của họ.\nNếu dấu vân tay khớp, bạn có thể an toàn xóa khóa cũ khỏi file ~/.ssh/known_hosts bằng lệnh:\n$ ssh-keygen -R github.com Error 3: Agent admitted failure to sign using the key Ý nghĩa: ssh-agent đang chạy nhưng không thể sử dụng khóa để tạo chữ ký số cần thiết cho việc xác thực. Lỗi này đôi khi xảy ra trên các hệ thống Linux.\nCách khắc phục: Giải pháp thường rất đơn giản là tải lại khóa vào agent. Chạy lệnh ssh-add thường sẽ giải quyết được vấn đề này.\nError 4: Key is already in use Ý nghĩa: Bạn đang cố gắng thêm một khóa công khai vào tài khoản GitHub, nhưng khóa đó đã được sử dụng ở một nơi khác - hoặc trên một tài khoản người dùng khác, hoặc trong một kho lưu trữ khác dưới dạng \u0026ldquo;deploy key\u0026rdquo;.\nNguyên tắc: Một khóa SSH phải là định danh duy nhất cho một người dùng trên toàn bộ nền tảng GitHub. Khi được sử dụng làm deploy key, nó cũng phải là duy nhất cho mỗi kho lưu trữ.\nCách khắc phục:\nSử dụng lệnh sau để xác định tài khoản nào đang sử dụng khóa đó:\n$ ssh -T -ai ~/.ssh/your_key git@github.com Gỡ khóa khỏi tài khoản hoặc kho lưu trữ cũ, hoặc đơn giản là tạo một cặp khóa hoàn toàn mới cho mục đích sử dụng mới.\nError 5: Các Phương Pháp Bảo Mật Tốt Nhất (Best Practices) và Tổng Kết Làm chủ SSH không chỉ dừng lại ở việc thiết lập thành công. Việc duy trì một tư thế bảo mật vững chắc đòi hỏi sự chú ý liên tục. Các phương pháp tốt nhất có thể được tóm gọn trong một vòng đời bảo mật của khóa SSH.\nVòng Đời Bảo Mật Của Khóa SSH Tạo (Creation):\nThuật toán mạnh: Luôn ưu tiên sử dụng Ed25519 vì hiệu suất và bảo mật vượt trội.\nPassphrase mạnh: Luôn đặt một passphrase mạnh và duy nhất cho mỗi khóa. Sử dụng trình quản lý mật khẩu để lưu trữ an toàn các passphrase này.\nBảo vệ (Protection):\nQuyền truy cập file: Duy trì quyền truy cập file chính xác là điều bắt buộc: chmod 700 ~/.ssh và chmod 600 ~/.ssh/private_key.\nBí mật tuyệt đối: Không bao giờ chia sẻ, gửi qua email, hoặc lưu trữ khóa riêng tư của bạn ở bất kỳ đâu ngoài máy tính cá nhân đã được bảo vệ. Chỉ có khóa công khai là an toàn để chia sẻ.\nSử dụng (Usage):\nSử dụng ssh-agent: Tận dụng ssh-agent để giảm thiểu số lần phải nhập passphrase, qua đó giảm nguy cơ bị keylogger ghi lại.\nCấu hình timeout cho agent: Để tăng cường bảo mật, hãy đặt thời gian tồn tại cho các khóa trong agent bằng tùy chọn -t. Lệnh ssh-add -t 3600 sẽ yêu cầu agent \u0026ldquo;quên\u0026rdquo; khóa sau một giờ (3600 giây) không hoạt động. Điều này cực kỳ hữu ích để bảo vệ chống lại việc truy cập trái phép nếu máy tính của bạn bị bỏ lại mà không được khóa.\nBảo trì (Maintenance):\nKiểm tra định kỳ (Audit): Lên lịch (ví dụ: hàng quý) để truy cập trang cài đặt SSH trên GitHub và xem lại danh sách các khóa đã được cấp quyền. Xóa ngay lập tức bất kỳ khóa nào bạn không nhận ra, không còn sử dụng, hoặc thuộc về các thiết bị đã mất.\nXoay vòng khóa (Rotation): Một thực hành bảo mật nâng cao là định kỳ tạo một cặp khóa mới và thay thế các khóa cũ. Việc này giới hạn \u0026ldquo;cửa sổ cơ hội\u0026rdquo; cho một kẻ tấn công nếu một khóa cũ bị xâm phạm mà bạn không hề hay biết.\n","permalink":"https://blog.nagih.io.vn/posts/error-handler/","summary":"\u003cp\u003eNgay cả với một thiết lập cẩn thận, các vấn đề vẫn có thể phát sinh. Việc hiểu rõ cách chẩn đoán và khắc phục các lỗi SSH phổ biến là một kỹ năng quan trọng.\u003c/p\u003e","title":"Hướng dẫn xử lý sự cố và các lỗi thường gặp khi thiết lập SSH"},{"content":"Những hạn chế của xác thực qua HTTPS và sự thay thế SSH\nTrong hệ sinh thái phát triển phần mềm hiện đại, GitHub không chỉ là một kho lưu trữ mã nguồn mà còn là trung tâm cộng tác, quản lý dự án và triển khai ứng dụng. Việc tương tác hiệu quả và an toàn với nền tảng này là một kỹ năng cơ bản đối với mọi nhà phát triển. Mặc dù HTTPS cung cấp một phương thức kết nối ban đầu đơn giản, việc chuyển sang sử dụng giao thức SSH (Secure Shell) là một bước tiến quan trọng, không chỉ nâng cao đáng kể mức độ bảo mật mà còn tối ưu hóa quy trình làm việc hàng ngày.\n1. Những Hạn Chế của Xác thực qua HTTPS Khi bắt đầu với Git và GitHub, hầu hết người dùng đều chọn HTTPS vì sự đơn giản của nó. Tuy nhiên, phương thức này có những hạn chế cố hữu. Xác thực qua HTTPS yêu cầu sử dụng Personal Access Token (PAT), một chuỗi ký tự hoạt động tương tự như mật khẩu.\nMặc dù dễ thiết lập, quy trình này bộc lộ sự bất tiện trong quá trình sử dụng lâu dài. Git sẽ thường xuyên yêu cầu người dùng nhập thông tin xác thực, làm gián đoạn luồng công việc. Mặc dù các công cụ hỗ trợ quản lý thông tin đăng nhập (credential helpers) có thể lưu trữ token, nhưng chúng lại đặt ra một vấn đề khác về mức độ an toàn của việc lưu trữ này. Quan trọng hơn, một PAT bị rò rỉ có thể cấp cho kẻ tấn công quyền truy cập không chỉ vào các kho lưu trữ mà còn có thể vào toàn bộ tài khoản GitHub, tùy thuộc vào phạm vi quyền hạn được cấp cho token đó.\nSo Sánh Nhanh: HTTPS và SSH trên GitHub Để tóm tắt những khác biệt chính, bảng dưới đây cung cấp một cái nhìn tổng quan về hai phương thức xác thực.\nTiêu chí HTTPS (với Personal Access Token) SSH Cơ chế Xác thực Dựa trên token (hoạt động như mật khẩu) Cặp khóa Public/Private (mật mã bất đối xứng) Mức độ Bảo mật Dễ bị lộ nếu token không được bảo vệ cẩn thận Rất cao; khóa riêng tư không bao giờ truyền qua mạng Sự tiện lợi Yêu cầu nhập lại token hoặc phụ thuộc vào credential helper Rất tiện lợi sau khi thiết lập, không cần nhập lại thông tin Thiết lập ban đầu Đơn giản, chỉ cần tạo token Phức tạp hơn một chút, yêu cầu tạo và quản lý cặp khóa Quản lý Truy cập Phân quyền thông qua phạm vi của token trên GitHub Có thể quản lý truy cập chi tiết qua từng khóa riêng lẻ ","permalink":"https://blog.nagih.io.vn/posts/https--ssh/","summary":"\u003cp\u003eNhững hạn chế của xác thực qua HTTPS và sự thay thế SSH\u003c/p\u003e","title":"SSH - Github"},{"content":"Sử dụng triết lý của Nix ứng dụng trong việc triển khai môi trường lập trình ứng dụng sao cho tối ưu và tốt nhất.\nTrong bài viết này, tôi sẽ hướng dẫn các bạn setup môi trường lập trình ứng dụng trên NixOS bằng IntelliJ IDEA và Nix Flakes thay vì sử dụng Android Studio. Đây là quy trình hiệu quả và phù hợp với triết lý của NixOS\nQuá trình này quản lý 2 nguyên tắc cốt lõi của NixOS\nQuản lý hệ thống bằng cách khai báo (Declarative System Management): Mọi package, phần mềm, cấu hình hệ thống được define trong file configuration.nix, giúp hệ thống luôn có thể tái tạo và có tính nhất quán\nMôi trường phát triển biệt lập (Isolated Development Environments): Sử dụng nix-shell để tạo ra môi trường chứa chính xác phiên bản của các công cụ đã được define cho từng project mà không làm ảnh hưởng tới hệ thống chính\nCác bước tiến hành Bước 1: Cài đặt các công cụ cơ bản trên hệ thống Điều đầu tiên, vì sử dụng IntelliJ IDEA nên bắt buộc rằng nó được cài trên hệ thống của bạn và đã bật tính năng Flakes của NixOS\nMở file cấu hình hệ thống NixOS của bạn\nThêm package jetbrains.idea-community hoặc idea-ultimate(nếu có premium) vào danh sách environment.systemPackages\nTrong bước này có thể thêm JDK mặc định nếu muốn, nhưng việc define JDK cho từng project sẽ tốt hơn nếu bạn không muốn cài trên hệ thống chính\n# .../configuration.nix { config, pkgs, ... }: { # Bật tính năng Flakes và nix-command mới nix.settings.experimental-features = [ \u0026#34;nix-command\u0026#34; \u0026#34;flakes\u0026#34; ]; environment.systemPackages = with pkgs; [ git # Git để quản lý mã nguồn jetbrains.idea-community # Thêm IntelliJ IDEA vào cấu hình ]; # ... các cấu hình khác } Rebuild NixOS để áp dụng thay đổi: sudo nixos-rebuild switch\nBước 2: Tạo môi trường phát triển riêng cho Project Đây là bước quan trọng nhất và là nơi sức mạnh của nix được thể hiện rõ nhất\nTạo thư mục chứa dự án\nmkdir my-app cd my-app Tạo file flake.nix. File này là trái tim của môi trường, nó sẽ define tất cả những công cụ cần thiết trong project: JDK, Maven, Gradle, \u0026hellip;\n{ description = \u0026#34;Môi trường phát triển Android trên NixOS (kênh Unstable)\u0026#34;; inputs = { nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-unstable\u0026#34;; flake-utils.url = \u0026#34;github:numtide/flake-utils\u0026#34;; }; outputs = { self, nixpkgs, flake-utils }: flake-utils.lib.eachDefaultSystem (system: let # Cấu hình để tự động chấp nhận giấy phép Android SDK pkgs = import nixpkgs { inherit system; config = { allowUnfree = true; android_sdk.accept_license = true; }; }; # \u0026#34;Lắp ráp\u0026#34; môi trường SDK bằng hàm và tham số tương thích android-sdk-env = pkgs.androidenv.composeAndroidPackages { platformVersions = [ \u0026#34;36\u0026#34; ]; buildToolsVersions = [ \u0026#34;36.0.0\u0026#34; ]; includeEmulator = true; platformToolsVersion = \u0026#34;36.0.0\u0026#34;; cmdLineToolsVersion = \u0026#34;11.0\u0026#34;; includeSystemImages = true; systemImageTypes = [ \u0026#34;google_apis\u0026#34; ]; abiVersions = [ \u0026#34;x86_64\u0026#34; ]; }; in { devShells.default = pkgs.mkShell { buildInputs = [ # Hàm cũ trả về một attribute set, cần truy cập .androidsdk android-sdk-env.androidsdk pkgs.jdk pkgs.qt6.qtwayland ]; shellHook = \u0026#39;\u0026#39; # Đường dẫn SDK cũng cần .androidsdk export ANDROID_SDK_ROOT=\u0026#34;${android-sdk-env.androidsdk}/libexec/android-sdk\u0026#34; export PATH=\u0026#34;$ANDROID_SDK_ROOT/cmdline-tools/latest/bin:$ANDROID_SDK_ROOT/platform-tools:$ANDROID_SDK_ROOT/emulator:$PATH\u0026#34; export QT_QPA_PLATFORM=xcb echo \u0026#34;✅ Môi trường Android cho API 36 (Unstable) đã sẵn sàng.\u0026#34; \u0026#39;\u0026#39;; }; }); } Lưu ý: Có thể thay đổi các version máy ảo Android cho phù hợp, tuy nhiên các công cần sử dụng đúng version để có thể hoạt động được với nhau (platformVersions, buildToolsVersions , platformToolsVersion)\nInstall và truy cập vào nix-shell\nnix develop ➜ nix develop ✅ Môi trường Android đã sẵn sàng. [nagih@nixos:~/Workspaces/noob/app/my-app]$ Bước 3: Cấu hình IntelliJ IDEA Bây giờ, ta sẽ khởi động IntelliJ IDEA bên trong môi trường Nix để có thể nhận diện được tất cả công cụ\nKhởi động IntelliJ: Từ terminal, gõ lệnh\nidea-community . Cài đặt Plugin Android mới: Nếu đây là lần đầu sử dụng IntelliJ cho Android, hãy vào Plugins -\u0026gt; Marketplace, Tìm kiếm Android và cài đặt\nTạo dự án mới\nTrong IntelliJ, vào Projects -\u0026gt; New Project\nChọn Android từ danh sách Generators bên trái\nChọn template, ví dụ Empty Views Activity và nhấn next\nĐiền thông tin project\nQuan trọng: Ở mục Build configuration language cần phù hợp với language đã được khai báo trong flake.nix (kotlin / groovy)\nSau khi tạo project, nếu thấy hiển thị lỗi này, hãy sửa theo hướng dẫn của phần Các lỗi phổ biến ở phía dưới\nBước 4: Tạo và khởi chạy máy ảo AVD (Android Virtual Device) Phương pháp 1: Tạo trong intelliJ (Recommand)\nTruy cập Device Manager\nNhấn + để thêm mới AVD\nChọn thiết bị mà bạn muốn sử dụng\nChọn System Image\nChọn tab x86 Images\nChọn System Image mà bạn đã cài đặt (Không chọn bất kỳ system image nào có nút Install)\nChọn lấy 1 System Image trong phần x86 Images (Không Install)\nThoát khỏi IntelliJ và nix-shell\nSửa file flake.nix theo System Image mà bạn đã chọn ở trên\nKích hoạt nix develop và tiếp tục\nKhởi chạy máy ảo\nSau khi tạo thành công máy ảo, có thể chưa hiện ngay trong phần Device Manager, lúc này hãy thoát IntelliJ và mở lại, bạn sẽ thấy nó. Sau đó chỉ cần nhấn nút Run.\nPhương pháp 2: Sử dụng CLI (Chạy máy ảo với cửa sổ riêng)\nClose hoàn toàn IntelliJ IDEA\nXác minh công cụ emulator và avdmanager có tồn tại trong môi trường hay không\nwhich emulator which avdmanager Nếu kết quả có các đường dẫn trỏ tới /nix/store/... cho cả 2 lệnh thì xin chúc mừng Nếu không thấy kết quả -\u0026gt; Điều này có nghĩa là flake.nix của bạn đang có vấn đề, hoặc có thể bạn chưa truy cập và nix develop Kiểm tra System Image\nsdkmanager --list_installed Tạo máy ảo (AVD) thông qua andmanager\navdmanager create avd --name \u0026#34;Pixel_API36\u0026#34; --package \u0026#34;system-images;android-36;google_apis;x86_64\u0026#34; --device \u0026#34;pixel_7_pro\u0026#34; name: Tên AVD\npackage: System image\ndevice: Loại thiết bị, nếu muốn kiểm tra có các thiết bị nào, hãy dùng lệnh avdmanager list device\nKhởi động IntelliJ\nKhởi động lại IntelliJ IDEA trong môi trường nix-shell\nidea-community . Open project mà khi nãy đã tạo (nếu đã bị thoát ra)\nMáy ảo AVD sẽ xuất hiện trong phần Device Manager. Bạn có thể thấy xuất hiện dấu !, điều này là bình thường vì chưa run AVD\nKhởi chạy máy ảo AVD\nOpen terminal bên trong IntelliJ IDEA\nemulator -avd [avd-name] \u0026amp; Các lỗi phổ biến 1. Lỗi khi tạo dự án Nguyên nhân\nLỗi này xảy ra do IntelliJ mặc định sử dụng template có sẵn (API 34) nhưng trong flake.nix difine API khác\nCố gắng tải API 34: Khi thấy công thức yêu cầu API 34 mà trong bếp không có, nó sẽ cố gắng tự đi \u0026ldquo;chợ\u0026rdquo; (tự tải về) và đặt vào kho (/nix/store). Bị NixOS chặn lại: NixOS thấy IntelliJ đang cố ghi vào \u0026ldquo;kho\u0026rdquo; chỉ đọc, nên đã chặn lại và báo lỗi Failed to read or create install properties file.34 Giải pháp\nTruy cập vào môi trường nix-shell\nCopy lấy đường dẫn của $ANDROID_SDK_ROOT\necho $ANDROID_SDK_ROOT Cấu hình cho IntelliJ\nTruy cập File -\u0026gt; Project Structure... Vào tab Platform Settings -\u0026gt; SDKs Nhấn + -\u0026gt; Add Android SDK\u0026hellip; và dán đường dẫn $ANDROID_SDK_ROOT (đường dẫn này đang trỏ đến SDK của bạn). Trong phần Build target sẽ xuất hiện SDK của bạn Cập nhật build.gradle\nMở file app/build.gradle.kts\nThay đổi compileSdk và targetSdk thành SDK mà bạn đã define (36)\nĐồng bộ Gradle:\nNhấn nút \u0026ldquo;Sync Now\u0026rdquo;. 2. \u0026ldquo;The skin directory, does not point to valid skin\u0026rdquo; Lỗi này có nghĩa là máy ảo (AVD) đang cố gắng sử dụng một \u0026ldquo;skin\u0026rdquo; (bộ giao diện mô phỏng viền cứng của điện thoại), nhưng không thể tìm thấy các file của skin đó ở đường dẫn được chỉ định.\nGiải pháp 1: Tắt Skin trong Cài đặt Máy ảo (Cách dễ nhất)\nCách đơn giản và hiệu quả nhất là yêu cầu máy ảo không cần tải skin nữa.\nMở Device Manager trong IntelliJ.\nTìm đến máy ảo đang bị lỗi của bạn và nhấn vào biểu tượng Edit (hình cây bút chì) ở cột Actions.\nCửa sổ \u0026ldquo;Virtual Device Configuration\u0026rdquo; sẽ hiện ra. Hãy tìm đến mục \u0026ldquo;Enable Device Frame\u0026rdquo; (Bật khung thiết bị).\nBỏ dấu tick ở ô này.\nNhấn Finish để lưu lại thay đổi.\nSau khi tắt skin, hãy thử khởi động lại máy ảo. Lỗi sẽ biến mất và máy ảo sẽ hiển thị dưới dạng một cửa sổ đơn giản chỉ có màn hình.\nGiải pháp 2: Sửa file cấu hình thủ công (Cách trực tiếp)\nNếu bạn không tìm thấy tùy chọn trong giao diện, bạn có thể chỉnh sửa file cấu hình trực tiếp.\nMở terminal và điều hướng đến thư mục cấu hình của máy ảo. Thay TenMayAo.avd bằng tên máy ảo của bạn (ví dụ: Pixel8Pro_API35.avd):\ncd ~/.android/avd/TenMayAo.avd/ Mở file config.ini bằng một trình soạn thảo văn bản (ví dụ: nano config.ini).\nTìm các dòng bắt đầu bằng skin.name và skin.path.\nThay đổi giá trị của chúng thành _no_skin hoặc xóa cả hai dòng đó đi.\nVí dụ, sửa từ:\nskin.name = pixel_8_pro skin.path = /some/invalid/nix/store/path Thành:\nskin.name = _no_skin skin.path = _no_skin Lưu file và thử khởi động lại máy ảo.\n","permalink":"https://blog.nagih.io.vn/posts/app-development/","summary":"\u003cp\u003eSử dụng triết lý của Nix ứng dụng trong việc triển khai môi trường lập trình ứng dụng sao cho tối ưu và tốt nhất.\u003c/p\u003e","title":"Hướng dẫn setup môi trường App Development trên nixos best practice"},{"content":"Thông thường khi cài windows, mặc định sẽ tự tạo phân vùng Boot EFI 512MB, bài viết này sẽ hướng dẫn bạn cách tùy biến size phân vùng EFI\nSử dụng Command Prompt trong quá trình cài đặt\nBước 1: Khởi động từ USB/DVD cài Windows\nKhi màn hình xuất hiện, nhấn Shift + F10 để mở Command Prompt Bước 2: Sử dụng DiskPart để tạo phân vùng\ndiskpart list disk select disk 0 (Chọn ổ đĩa cần cài) clean convert gpt Bước 3: Tạo phân vùng EFI với size tùy chỉnh\ncreate partition efi size=4096 format quick fs=fat32 label=\u0026#34;System\u0026#34; assign letter=S active Thay 4096 bằng size bạn muốn (MB)\nBước 4: Tạo phân vùng MSR\ncreate partition msr size=128 Bước 5: Tạo phân vùng chính cho Windows\ncreate partition primary format quick fs=ntfs label=\u0026#34;Windows\u0026#34; assign letter=C active exit Thông thường hay xảy ra trường hợp ổ C đang được định nghĩa là USB Boot, lúc này hãy cứ thao tác bằng giao diện như bình thường\n","permalink":"https://blog.nagih.io.vn/posts/custom-windows-efi/","summary":"\u003cp\u003eThông thường khi cài windows, mặc định sẽ tự tạo phân vùng Boot EFI 512MB, bài viết này sẽ hướng dẫn bạn cách tùy biến size phân vùng EFI\u003c/p\u003e","title":"Hướng dẫn tùy biến phân vùng EFI khi cài windows"},{"content":"Khối Quản lý Tiến trình (PCB) - \u0026ldquo;CMND\u0026rdquo; của Mọi Chương trình trong Máy tính\nGiới thiệu Hệ điều hành (Operating System - OS). Để quản lý từng mỗi chương trình đang chạy, hay còn gọi là process, process cần một bản thông tin chi tiết về từng thành viên. Bản thông tin này chính là Khối Quản lý Tiến trình (Process Control Block - PCB).\nĐể dễ hình dung nhất, hãy coi PCB chính là \u0026ldquo;Chứng minh nhân dân\u0026rdquo; (CMND) hay \u0026ldquo;Căn cước công dân\u0026rdquo; (CCCD) của một tiến trình. Đó là một tấm thẻ định danh chứa đựng mọi thông tin sống còn mà hệ điều hành cần để quản lý, giám sát và điều khiển tiến trình đó. Nếu không có \u0026ldquo;tấm thẻ\u0026rdquo; này, một tiến trình sẽ trở nên vô danh và không thể quản lý được đối với hệ điều hành.\n1. Khối Quản lý Tiến trình (PCB) chính xác là gì? Dấu vân tay Kỹ thuật số Về mặt hình thức, PCB là một cấu trúc dữ liệu cơ bản nằm trong nhân (kernel) của hệ điều hành. Nó còn được biết đến với các tên gọi khác như \u0026ldquo;Bộ mô tả Tiến trình\u0026rdquo; (Process Descriptor) hay \u0026ldquo;Khối điều khiển Tác vụ\u0026rdquo; (Task Control Block).5 Điều quan trọng cần nhấn mạnh là PCB không phải là một phần của chương trình người dùng viết ra; nó là một công cụ nội bộ, được tạo ra và sử dụng độc quyền bởi hệ điều hành để quản lý các tiến trình.\nVòng đời của một PCB Vòng đời của một PCB gắn liền với vòng đời của tiến trình mà nó đại diện:\nKhởi tạo: Ngay khi người dùng khởi chạy một ứng dụng (ví dụ, nhấp đúp vào biểu tượng Google Chrome), hệ điều hành sẽ tạo ra một tiến trình mới. Song song với đó, nó cấp phát bộ nhớ và khởi tạo một PCB tương ứng cho tiến trình này. Quản lý: Trong suốt thời gian tồn tại của tiến trình, hệ điều hành liên tục đọc và cập nhật thông tin trong PCB của nó khi trạng thái và việc sử dụng tài nguyên thay đổi. Kết thúc: Khi tiến trình hoàn thành nhiệm vụ hoặc bị chấm dứt, hệ điều hành sẽ thu hồi tất cả tài nguyên của nó và phá hủy PCB, giải phóng bộ nhớ đã cấp phát. Lưu trữ An toàn PCB chứa những thông tin cực kỳ quan trọng đối với sự ổn định của hệ thống. Do đó, nó được lưu trữ trong một vùng bộ nhớ được bảo vệ đặc biệt gọi là \u0026ldquo;không gian nhân\u0026rdquo; (kernel space). Cơ chế bảo vệ này ngăn chặn các chương trình người dùng truy cập và sửa đổi (dù vô tình hay cố ý) dữ liệu điều khiển của chính chúng hoặc của các tiến trình khác, một hành động có thể gây sập toàn bộ hệ thống.\nBảng Tiến trình (Process Table) Để theo dõi tất cả các tiến trình đang hoạt động, hệ điều hành duy trì một danh sách tổng thể, thường được gọi là Bảng Tiến trình (Process Table). Về cơ bản, đây là một mảng hoặc danh sách liên kết chứa các con trỏ trỏ đến từng PCB của mọi tiến trình đang hoạt động trong hệ thống. Bảng này giống như một cuốn danh bạ mà hệ điều hành dùng để tra cứu mọi tiến trình mà nó đang quản lý.\nTừ góc độ của nhân hệ điều hành, PCB không chỉ đơn thuần là một bản ghi thông tin; nó chính là hiện thân của tiến trình. Một chương trình trên đĩa cứng (ví dụ: chrome.exe) chỉ là một tập hợp các chỉ thị thụ động. Một tiến trình là sự thực thi\nchủ động của những chỉ thị đó. Và PCB chính là cấu trúc dữ liệu cụ thể hóa \u0026ldquo;sự chủ động\u0026rdquo; này. Nó là thực thể hữu hình, có thể quản lý được mà hệ điều hành tương tác. Tất cả các hành động quản lý của OS—lập lịch, cấp phát tài nguyên, chấm dứt—đều là các hoạt động được thực hiện trên hoặc dựa vào dữ liệu chứa trong PCB. Do đó, có thể nói rằng PCB là linh hồn kỹ thuật số, là bản chất của một tiến trình trong mắt hệ điều hành.\n2. Giải phẫu PCB - Nhìn vào bên trong \u0026ldquo;Tấm thẻ Căn cước\u0026rdquo; Mặc dù cấu trúc chính xác có thể khác nhau giữa các hệ điều hành (ví dụ, Linux và Windows), các loại thông tin cốt lõi về cơ bản là giống nhau. Chúng ta sẽ tiếp tục sử dụng phép ẩn dụ \u0026ldquo;Tấm thẻ Căn cước\u0026rdquo; để làm rõ mục đích của từng thành phần.\nPhân tích chi tiết các thành phần Thông tin Nhận dạng (Process Identification Data): Mã định danh Tiến trình (Process ID - PID): Một số nguyên duy nhất do hệ điều hành cấp để xác định tiến trình. Đây là trường thông tin quan trọng nhất, được sử dụng làm khóa trong hầu hết các bảng hệ thống khác. Ví von: Số CMND/CCCD duy nhất trên thẻ căn cước. Mã định danh Tiến trình Cha (Parent Process ID - PPID): PID của tiến trình đã tạo ra tiến trình này. Điều này thiết lập một cấu trúc phân cấp dạng cây cho các tiến trình. Mã định danh Người dùng (User ID - UID) \u0026amp; Nhóm (Group ID - GID): Xác định người dùng và nhóm sở hữu tiến trình, được sử dụng cho mục đích bảo mật và phân quyền. Trạng thái Tiến trình (Process State): Một trường ghi lại trạng thái hiện tại của tiến trình. Thông tin này rất quan trọng để bộ lập lịch biết được tiến trình nào đủ điều kiện để chạy. Mới (New): Tiến trình đang được tạo. Sẵn sàng (Ready): Tiến trình đã được nạp vào bộ nhớ và đang chờ đến lượt được cấp CPU. Đang chạy (Running): Các chỉ thị của tiến trình đang được thực thi bởi một lõi CPU. Đang chờ/Bị chặn (Waiting/Blocked): Tiến trình không thể tiếp tục cho đến khi một sự kiện nào đó xảy ra (ví dụ: chờ người dùng nhập liệu hoặc chờ đọc dữ liệu từ đĩa). Kết thúc (Terminated): Tiến trình đã hoàn thành và đang trong quá trình dọn dẹp. Ngữ cảnh Thực thi (Execution Context): Bộ đếm Chương trình (Program Counter - PC): Lưu địa chỉ bộ nhớ của chỉ thị tiếp theo sẽ được thực thi. Đây là yếu tố sống còn để có thể tiếp tục một tiến trình sau khi nó bị gián đoạn. Ví von: Một chiếc kẹp đánh dấu trang sách. Nó cho bạn biết chính xác cần bắt đầu đọc lại từ đâu. Các thanh ghi CPU (CPU Registers): Một bản sao lưu (snapshot) nội dung của các thanh ghi đa dụng, con trỏ ngăn xếp (stack pointer), v.v., của CPU tại thời điểm tiến trình bị ngắt. Các thanh ghi này chứa dữ liệu trung gian của các phép tính hiện tại. Ví von: Những dòng ghi chú trên giấy nháp khi đang giải một bài toán phức tạp. Bạn cần lưu chúng lại để có thể tiếp tục bài toán sau đó. Thông tin Quản lý Tài nguyên (Resource Management Information): Thông tin Lập lịch CPU (CPU Scheduling Information): Dữ liệu được bộ lập lịch của hệ điều hành sử dụng để quyết định tiến trình nào sẽ chạy tiếp theo. Bao gồm độ ưu tiên của tiến trình, con trỏ đến các hàng đợi lập lịch mà nó đang tham gia, và các tham số khác. Ví von: Nhóm lên máy bay hoặc hạng vé của hành khách (ví dụ: VIP, Thương gia, Phổ thông) quyết định thứ tự lên máy bay. Thông tin Quản lý Bộ nhớ (Memory Management Information): Thông tin về bộ nhớ được cấp phát cho tiến trình này, chẳng hạn như con trỏ đến bảng trang (page tables) hoặc bảng phân đoạn (segment tables) của nó. Điều này xác định không gian địa chỉ của tiến trình và ngăn nó truy cập vào bộ nhớ của các tiến trình khác. Ví von: Sổ đỏ hoặc giấy tờ nhà đất, xác định ranh giới của một mảnh đất. Thông tin Trạng thái I/O (I/O Status Information): Danh sách các thiết bị I/O được cấp phát cho tiến trình (ví dụ: một máy in cụ thể) và danh sách các tệp tin mà nó đang mở. Ví von: Một thẻ thư viện ghi lại những cuốn sách đang được mượn, hoặc danh sách các công cụ đã mượn từ một xưởng làm việc. Thông tin Kế toán (Accounting Information): Theo dõi việc sử dụng tài nguyên, chẳng hạn như lượng thời gian CPU mà tiến trình đã tiêu thụ, giới hạn thời gian, v.v. Thông tin này có thể được sử dụng để giám sát hệ thống hoặc tính phí trong môi trường doanh nghiệp. Ví von: Chi tiết sử dụng trên hóa đơn tiện ích (ví dụ: số kilowatt-giờ điện đã dùng). Bảng: Giải phẫu \u0026ldquo;Tấm thẻ Căn cước\u0026rdquo; của một Tiến trình Bảng dưới đây tóm tắt các thành phần chính của PCB và phép ví von tương ứng, giúp củng cố khái niệm một cách trực quan.\nComponent (Thành phần) Purpose (Mục đích) Analogy (Phép ví von) Process ID (PID) Một số duy nhất để nhận dạng tiến trình. Số CMND/CCCD Process State Hoạt động hiện tại của tiến trình (Đang chạy, Đang chờ, v.v.). Tình trạng hôn nhân (Độc thân, Đã kết hôn,\u0026hellip;) Program Counter (PC) Địa chỉ của lệnh tiếp theo sẽ thực thi. Dấu trang sách (Bookmark) CPU Registers Lưu trữ dữ liệu tạm thời cho phép tính hiện tại. Giấy nháp (Scratchpad) Memory Info Chi tiết về việc cấp phát bộ nhớ của tiến trình. Sổ đỏ / Giấy tờ nhà đất I/O Status Info Danh sách các tệp tin và thiết bị đang sử dụng. Thẻ thư viện và các vật dụng đã mượn Scheduling Info Độ ưu tiên để truy cập CPU. Mức độ ưu tiên / Vé VIP Accounting Info Ghi lại tài nguyên đã tiêu thụ (ví dụ: thời gian CPU). Hóa đơn tiền điện/nước 3. PCB trong Thực tiễn - Phép màu của Đa nhiệm (Chuyển đổi Ngữ cảnh) Vai trò quan trọng nhất của PCB là cho phép đa nhiệm (multitasking) thông qua một cơ chế gọi là \u0026ldquo;chuyển đổi ngữ cảnh\u0026rdquo; (context switch).1 Chuyển đổi ngữ cảnh là quá trình hệ điều hành dừng một tiến trình và bắt đầu một tiến trình khác.2 Điều này xảy ra hàng trăm, thậm chí hàng nghìn lần mỗi giây, tạo ra ảo giác về sự thực thi song song.\nTác nhân Kích hoạt Một cuộc chuyển đổi ngữ cảnh không xảy ra ngẫu nhiên. Nó được kích hoạt bởi các sự kiện cụ thể 20:\nĐa nhiệm: \u0026ldquo;Lát cắt thời gian\u0026rdquo; (time slice hoặc quantum) của một tiến trình đã hết, và bộ lập lịch quyết định đã đến lượt một tiến trình khác (đa nhiệm phủ đầu - preemptive multitasking). Chờ I/O: Tiến trình đang chạy yêu cầu một tác vụ tốn thời gian (như đọc một tệp từ đĩa) và chuyển sang trạng thái \u0026ldquo;Chờ\u0026rdquo;, giải phóng CPU cho một tiến trình khác. Ngắt (Interrupts): Một ngắt phần cứng xảy ra (ví dụ: người dùng nhấp chuột), yêu cầu hệ điều hành phải xử lý, và việc này có thể liên quan đến việc chuyển sang một tiến trình khác. Quy trình từng bước của một cuộc Chuyển đổi Ngữ cảnh Hãy tưởng tượng CPU đang chạy Tiến trình A (ví dụ: Microsoft Word) và cần chuyển sang Tiến trình B (ví dụ: Google Chrome).\nNgắt Xảy ra: Một sự kiện (như ngắt từ bộ đếm thời gian) báo hiệu cần phải chuyển đổi. Phần cứng CPU tự động chuyển quyền điều khiển cho nhân hệ điều hành. Lưu Ngữ cảnh của Tiến trình A: Hệ điều hành ngay lập tức tạm dừng Tiến trình A. Sau đó, nó sao chép một cách tỉ mỉ toàn bộ ngữ cảnh thực thi hiện tại từ phần cứng của CPU vào PCB của Tiến trình A. Ngữ cảnh này bao gồm Bộ đếm Chương trình, tất cả các thanh ghi CPU, và các thông tin trạng thái khác. Quá trình này giống như việc bạn cẩn thận lưu lại trò chơi trước khi thoát. Cập nhật Trạng thái: Hệ điều hành cập nhật trường \u0026ldquo;Trạng thái Tiến trình\u0026rdquo; trong PCB của Tiến trình A từ \u0026ldquo;Đang chạy\u0026rdquo; thành \u0026ldquo;Sẵn sàng\u0026rdquo; hoặc \u0026ldquo;Đang chờ\u0026rdquo;. Nó di chuyển PCB này vào hàng đợi thích hợp (ví dụ: hàng đợi sẵn sàng). Chọn Tiến trình Tiếp theo: Bộ lập lịch của hệ điều hành chạy thuật toán của mình, tham khảo các PCB trong hàng đợi sẵn sàng để chọn tiến trình tiếp theo sẽ chạy. Giả sử nó chọn Tiến trình B. Nạp Ngữ cảnh của Tiến trình B: Hệ điều hành lấy ngữ cảnh đã được lưu từ PCB của Tiến trình B và nạp nó vào phần cứng của CPU. Bộ đếm Chương trình được khôi phục, các thanh ghi được điền đầy bằng các giá trị đã lưu của Tiến trình B, và các con trỏ bộ nhớ được cập nhật. Tiếp tục Thực thi: Hệ điều hành chuyển quyền điều khiển từ nhân trở lại chương trình người dùng. Tiến trình B bắt đầu thực thi chỉ thị tiếp theo của nó, hoàn toàn không biết rằng nó đã từng bị tạm dừng. Nó tiếp tục chính xác từ nơi nó đã dừng lại. Phép ví von: Hai đầu bếp chia sẻ một khu vực làm việc Hãy tưởng tượng hai đầu bếp (Tiến trình A và B) phải chia sẻ chung một chiếc thớt và một con dao (CPU).\nĐầu bếp A đang thái rau. Người quản lý (Hệ điều hành) nói rằng thời gian của anh ta đã hết. Đầu bếp A ghi vào sổ tay của mình (PCB A): \u0026ldquo;Tôi đang thái cà rốt, con dao ở đây, còn lại 3 củ\u0026rdquo; (lưu PC, các thanh ghi, trạng thái). Sau đó, anh ta dọn dẹp khu vực làm việc và rời đi. Người quản lý gọi đầu bếp B. Đầu bếp B nhìn vào sổ tay của mình (PCB B), trong đó ghi: \u0026ldquo;Tôi đang thái hành tây, cần con dao nhỏ, đã thái được nửa củ thứ hai.\u0026rdquo; Đầu bếp B sắp xếp khu vực làm việc chính xác như trong ghi chú của mình (nạp ngữ cảnh) và ngay lập tức tiếp tục thái củ hành tây thứ hai. Quá trình chuyển đổi diễn ra liền mạch. Mặc dù quá trình chuyển đổi ngữ cảnh có vẻ kỳ diệu, nó không hề miễn phí. Nó là một chi phí hoạt động thuần túy (overhead); trong khoảng thời gian hệ điều hành đang lưu và nạp các PCB, không có công việc hữu ích nào của người dùng được thực hiện. Điều này tạo ra một sự đánh đổi cơ bản trong thiết kế hệ điều hành. Kích thước và độ phức tạp của PCB đóng góp trực tiếp vào chi phí này. Các nhà thiết kế hệ điều hành luôn phải đối mặt với một xung đột cốt lõi:\nChuyển đổi thường xuyên và nhanh chóng (lát cắt thời gian ngắn) làm cho hệ thống có cảm giác rất nhạy và tương tác tốt, nhưng một tỷ lệ lớn thời gian CPU bị lãng phí cho chi phí chuyển đổi. Chuyển đổi không thường xuyên và chậm hơn (lát cắt thời gian dài) hiệu quả hơn (ít thời gian lãng phí cho chi phí), nhưng hệ thống có thể cảm thấy ì ạch, vì một tiến trình duy nhất có thể độc chiếm CPU trong thời gian dài hơn. Do đó, thiết kế của PCB và thuật toán lập lịch có mối liên hệ mật thiết trong một bài toán cân bằng giữa việc cung cấp các tính năng nâng cao, đảm bảo khả năng phản hồi của hệ thống và tối đa hóa hiệu quả sử dụng CPU.\n4. Tại sao PCB là người hùng thầm lặng của Hệ điều hành Cấu trúc dữ liệu có vẻ đơn giản này lại là nền tảng cho máy tính hiện đại vì nhiều lý do.\nYếu tố cho phép Đa nhiệm: Như đã trình bày, nếu không có khả năng lưu và khôi phục trạng thái của PCB, việc chuyển đổi ngữ cảnh sẽ là không thể. Chúng ta sẽ bị mắc kẹt trong một thế giới đơn nhiệm. Nền tảng cho Lập lịch: Bộ lập lịch là \u0026ldquo;bộ não\u0026rdquo; quyết định tiến trình nào sẽ được sử dụng CPU, nhưng PCB là \u0026ldquo;hệ thần kinh\u0026rdquo; cung cấp tất cả các thông tin đầu vào (độ ưu tiên, trạng thái, việc sử dụng tài nguyên) để bộ não đó đưa ra quyết định thông minh. Người bảo vệ sự Ổn định của Hệ thống: Bằng cách lưu trữ ranh giới bộ nhớ và quyền sở hữu tài nguyên, PCB giúp hệ điều hành thực thi sự cô lập giữa các tiến trình, ngăn chặn một chương trình hoạt động sai cách làm hỏng các chương trình khác hoặc chính nhân hệ điều hành. Công cụ Quản lý Tài nguyên: Hệ điều hành sử dụng thông tin I/O và bộ nhớ trong các PCB để quản lý việc cấp phát tài nguyên, ngăn ngừa xung đột (ví dụ: hai tiến trình cố gắng ghi vào cùng một tệp tin đồng thời), và thậm chí giúp phát hiện tình trạng bế tắc (deadlock). Vượt ra ngoài Tiến trình đơn: Các khái niệm Nâng cao Một tiến trình có thể có nhiều luồng (thread), giống như các \u0026ldquo;tiến trình mini\u0026rdquo;. Trong trường hợp này, PCB chứa thông tin được chia sẻ chung (như không gian bộ nhớ), trong khi mỗi luồng sẽ có một Khối điều khiển Luồng (Thread Control Block - TCB) nhẹ hơn để lưu trữ ngữ cảnh thực thi riêng của nó (các thanh ghi, con trỏ ngăn xếp). Điều này cho phép đa nhiệm ở mức độ chi tiết hơn nữa ngay trong một ứng dụng duy nhất.\nCác trường thông tin và độ phức tạp cụ thể của cấu trúc PCB trong một hệ điều hành nhất định là sự phản ánh trực tiếp các mục tiêu và triết lý thiết kế của hệ điều hành đó. Một hệ điều hành thời gian thực (RTOS) cho hệ thống phanh của ô tô ưu tiên sự đoán trước và các thời hạn nghiêm ngặt. Do đó, PCB của nó có thể sẽ có các trường rất chi tiết và chặt chẽ liên quan đến các ràng buộc thời gian. Ngược lại, PCB của một máy chủ Linux (task_struct) nổi tiếng là phức tạp, chứa thông tin sâu rộng về quyền của người dùng/nhóm, giới hạn tài nguyên, và các tín hiệu giao tiếp liên tiến trình, phản ánh di sản đa người dùng và chú trọng bảo mật của nó. Điều này có nghĩa là PCB không chỉ là một triển khai kỹ thuật chung chung; nó là một tạo tác thể hiện triết lý kiến trúc và mục đích dự định của toàn bộ hệ điều hành.\n","permalink":"https://blog.nagih.io.vn/posts/process-control-block/","summary":"\u003cp\u003eKhối Quản lý Tiến trình (PCB) - \u0026ldquo;CMND\u0026rdquo; của Mọi Chương trình trong Máy tính\u003c/p\u003e","title":"Process Control Block"},{"content":"Phân Tích về Kiến Trúc API Hiện Đại | Rest \u0026amp; gRPC\nGiới thiệu REST, với tư cách là một kiểu kiến trúc, đã định hình nên các API web trong hơn hai thập kỷ, trở thành tiêu chuẩn de facto nhờ tính linh hoạt và khả năng tiếp cận phổ quát. Mặt khác, gRPC, một framework mã nguồn mở hiệu suất cao do Google phát triển, nổi lên như một giải pháp được thiết kế đặc biệt cho kỷ nguyên microservice, nơi hiệu suất, độ trễ thấp và các hợp đồng dịch vụ nghiêm ngặt là tối quan trọng.\nREST REST không phải là một giao thức hay một tiêu chuẩn, mà là một kiểu kiến trúc (architectural style) được định nghĩa bởi Roy Fielding vào năm 2000. Một hệ thống được coi là \u0026ldquo;RESTful\u0026rdquo; khi nó tuân thủ một tập hợp các ràng buộc kiến trúc được thiết kế để tối ưu hóa cho một hệ thống phân tán quy mô lớn như World Wide Web.\nKiến trúc cốt lõi của REST Sức mạnh và sự phổ biến của REST bắt nguồn từ sáu ràng buộc sau:\nTách Biệt Client-Server (Client-Server Decoupling): Server và client chỉ tương tác thông qua một giao diện chuẩn hóa. Sự tách biệt này cho phép chúng phát triển độc lập - client không cần biết về logic nghiệp vụ của server, và server không cần biết về giao diện của client miễn là hợp đồng giao diện không thay đổi.\nVô Trạng Thái (Statelessness): Trong kiến trúc REST, mỗi yêu cầu từ client đến server phải chứa tất cả thông tin cần thiết để server hiểu và xử lý nó. Server không lưu trữ bất kỳ trạng thái phiên nào của client giữa các yêu cầu.\nGiao Diện Đồng Nhất (Uniform Interface): Được thiết kế để đơn giản hóa và tách rời kiến trúc. Nó bao gồm 4 ràng buộc con:Đ\nIdentification of resources: Mọi tài nguyên đều được định danh duy nhất thông qua một URI (Uniform Resource Identifier).\nVí dụ: https://.../osers/123 thì 123 là ID duy nhất của order đó. Manipulation of resources through representations: Client tương tác với tài nguyên thông qua các biểu diễn của chúng (ví dụ: một tài liệu JSON hoặc XML). Biểu diễn này chứa đủ thông tin để client có thể sửa đổi hoặc xóa tài nguyên trên server.\nSelf-descriptive: Mỗi thông điệp chứa đủ thông tin để mô tả cách xử lý nó. Ví dụ, một header Content-Type cho biết định dạng media của thông điệp.\nHATEOAS: Client chỉ cần biết URI khởi đầu. Sau đó, tất cả các hành động và tài nguyên trong tương lai mà client có thể truy cập đều được khám phá thông qua các siêu liên kết có trong các phản hồi từ server.\nCacheability: Cho phép client hoặc các máy chủ trung gian lưu trữ các phản hồi, giúp giảm độ trễ và tải cho server.\nLayered System: Client không thể biết liệu nó đang kết nối trực tiếp đến server cuối cùng hay một máy chủ trung gian (microservices).\nCode on Demand: Đây là ràng buộc duy nhất không bắt buộc. Nó cho phép server tạm thời mở rộng hoặc tùy chỉnh chức năng của client bằng cách truyền mã thực thi (ví dụ: JavaScript).\nTriển khai đển hình Thông thường, REST được triển khai trên HTTP/1.1. Các tài nguyên được thao tác bằng HTTP tiêu chuẩn (GET, POST, PUT, DELETE), và dữ liệu thường được trao đổi bằng định dạng JSON.\nFramework gRPC - Hiệu Suất và Gọi Thủ Tục Từ Xa gRPC (gRPC Remote Procedure Call) là một framework RPC hiện đại, được xây dựng trên nền tảng các công nghệ hiệu suất cao. Thay vì tập trung vào tài nguyên, gRPC tập trung vào các dịch vụ và các thủ tục (hàm) mà client có thể gọi từ xa. Kiến trúc của nó được xây dựng trên ba trụ cột chính: Protocol Buffers, HTTP/2, và các mô hình streaming tiên tiến.\nMô Hình RPC Cốt lõi của gRPC là mô hình Gọi Thủ Tục Từ Xa (Remote Procedure Call). Ý tưởng là cho phép một client gọi một hàm trên một server từ xa một cách minh bạch, như thể nó là một lời gọi hàm cục bộ. Framework sẽ trừu tượng hóa toàn bộ quá trình giao tiếp mạng phức tạp, bao gồm tuần tự hóa dữ liệu, kết nối và xử lý lỗi.\n1. Protocol Buffers (Protobuf) Protobuf là Ngôn ngữ Định nghĩa Giao diện (Interface Definition Language - IDL) mặc định của gRPC. Nó đóng vai trò là bản thiết kế cho cả dịch vụ và cấu trúc dữ liệu.\nDesign-first: Với gRPC, bắt đầu bằng cách định nghĩa các dịch vụ cấu trúc dữ liệu trong một tệp .proto. Tệp này hoạt động như một hợp đồng chính thức giữa client và server.\nTạo mã tự động: Trình biên dịch protoc của Protobuf sau đó sẽ đọc tệp .proto này và tự động tạo ra các client stub (phía client) và server skeleton (phía server) với kiểu dữ liệu mạnh (strongly-typed).\n2. Giao thức HTTP/2 gRPC được xây dựng nguyên bản trên HTTP/2, một bản nâng cấp lớn so với HTTP/1.1, và tận dụng triệt để các tính năng của nó để đạt được hiệu suất vượt trội.\nBinary Framing: HTTP/2 truyền dữ liệu dưới dạng các khung nhị phân, hiệu quả hơn so với định dạng văn bản của HTTP/1.1.\nFull Multiplexing: Đây là tính năng đột phá nhất. HTTP/2 cho phép gửi và nhận nhiều yêu cầu và phản hồi đồng thời trên một kết nối TCP duy nhất, loại bỏ hoàn toàn vấn đề \u0026ldquo;chặn đầu hàng\u0026rdquo; (head-of-line blocking) của HTTP/1.1.\nHeader Compression: Sử dụng thuật toán HPACK, HTTP/2 nén các header của yêu cầu và phản hồi, giảm đáng kể dữ liệu dư thừa và chi phí mạng.\nHỗ trợ streaming nguyên bản: HTTP/2 được thiết kế để hỗ trợ streaming dữ liệu, một nền tảng cơ bản cho các mô hình giao tiếp tiên tiến của gRPC.\n3. Các mô hình Streaming tiên tiến Nhờ vào nền tảng HTTP/2, gRPC hỗ trợ bốn mô hình giao tiếp, mang lại sự linh hoạt vượt trội so với mô hình yêu cầu-phản hồi đơn lẻ của REST:\nUnary RPC: Mô hình yêu cầu-phản hồi cổ điển, tương tự như một lời gọi REST. Client gửi một yêu cầu duy nhất và nhận lại một phản hồi duy nhất.\nServer Streaming RPC: Client gửi một yêu cầu và nhận lại một luồng (stream) các phản hồi từ server. Rất hữu ích cho các trường hợp như đăng ký nhận thông báo hoặc cập nhật dữ liệu trực tiếp.\nClient Streaming RPC: Client gửi một luồng các thông điệp đến server, và server sẽ phản hồi bằng một thông điệp duy nhất sau khi đã nhận tất cả. Thích hợp cho việc tải lên các tệp lớn hoặc gửi dữ liệu đo lường từ xa.\nBidirectional Streaming RPC: Cả client và server đều có thể gửi các luồng thông điệp cho nhau một cách độc lập trên cùng một kết nối. Mô hình này lý tưởng cho các ứng dụng tương tác thời gian thực như chat hoặc game nhiều người chơi.\nBảng So Sánh Tổng Quan Tiêu Chí REST gRPC Mô hình Dựa trên tài nguyên (Resource-based) Gọi thủ tục từ xa (RPC) Tiêu chuẩn hóa Không có tiêu chuẩn chính thức, là một tập hợp các nguyên tắc Được định nghĩa rõ ràng và chi tiết Giao thức vận chuyển Thường là HTTP/1.1 (có thể dùng HTTP/2) HTTP/2 Định dạng dữ liệu mặc định JSON (cũng hỗ trợ XML, text, v.v.) Protocol Buffers (Protobuf) Các chế độ dịch vụ Chỉ Unary (yêu cầu-phản hồi đơn lẻ) Unary, Client streaming, Server streaming, Bidirectional streaming Thiết kế API Thường là Code-first (mã trước) Design-first (thiết kế trước) Mức độ ghép nối Ghép nối lỏng (Loosely coupled) Ghép nối chặt (Tightly coupled) Tạo mã Yêu cầu công cụ bên thứ ba (ví dụ: OpenAPI Generator) Tích hợp sẵn (thông qua trình biên dịch protoc) Hỗ trợ trình duyệt Hỗ trợ nguyên bản và phổ quát Yêu cầu lớp proxy (gRPC-Web) Lưu cache Hỗ trợ tốt thông qua các cơ chế HTTP tiêu chuẩn Không hỗ trợ mặc định, cần tự triển khai Triết Lý và Thiết Kế Sự khác biệt cơ bản nhất giữa REST và gRPC nằm ở triết lý thiết kế của chúng: \u0026ldquo;cái gì\u0026rdquo; so với \u0026ldquo;làm gì\u0026rdquo;.\nREST: Tập trung vào việc phơi bày các thực thể hoặc tài nguyên (danh từ). Client tương tác với các tài nguyên này bằng CRUD (Create, Read, Update, Delete) và các nguyên tắc lập trình hướng đối tượng.\ngRPC: Tập trung vào việc phơi bày các hành động hoặc thủ tục (động từ). Client gọi các hàm cụ thể trên server, ví dụ CreateUser(user_details). Đây là một thiết kế hướng dịch vụ, ánh xạ trực tiếp đến logic ứng dụng.\nCó một mối quan hệ nghịch đảo giữa sự dễ dàng trong thiết lập/gỡ lỗi ban đầu và khả năng bảo trì lâu dài trong các hệ thống đa ngôn ngữ. REST rất dễ bắt đầu, nhưng có thể dẫn đến các vấn đề tích hợp sau này do thiếu một hợp đồng chính thức. gRPC đòi hỏi nhiều công sức thiết lập hơn (định nghĩa tệp .proto, tạo mã), nhưng nó cung cấp một nền tảng vững chắc, an toàn về kiểu dữ liệu giúp ngăn ngừa các lỗi tích hợp, đặc biệt là trong kiến trúc microservices với nhiều nhóm và ngôn ngữ khác nhau.\n","permalink":"https://blog.nagih.io.vn/posts/rest--grpc/","summary":"\u003cp\u003ePhân Tích về Kiến Trúc API Hiện Đại | Rest \u0026amp; gRPC\u003c/p\u003e","title":"REST và gRPC"},{"content":"6 Cấp Độ Trưởng Thành Từ Deploy Thủ Công Đến Vận Hành Tinh Gọn\nLevel 0: Deploy Thủ Công Công cụ và Quy trình Quy trình thủ công: Việc triển khai được thực hiện bằng cách kết nối thủ công đến máy chủ thông qua các giao thức như FTP, SCP, hoặc SSH, sau đó sao chép từng tệp.\nQuản lý mã nguồn hỗn loạn: Nếu có sử dụng Git, quy trình làm việc thường là \u0026ldquo;Centralized Workflow\u0026rdquo;, nơi mọi người đều đẩy (push) mã nguồn trực tiếp lên nhánh chính (main hoặc master), gây ra sự bất ổn định và khó theo dõi.\nRủi ro và Nỗi đau Rủi ro bảo mật: Giao thức FTP truyền thông tin đăng nhập (username, password) dưới dạng văn bản thuần (plain text), khiến chúng dễ dàng bị \u0026ldquo;bắt\u0026rdquo; bởi bất kỳ ai trên mạng. Dữ liệu truyền đi cũng không được mã hóa, có nguy cơ bị tấn công xen giữa (man-in-the-middle), nơi kẻ tấn công có thể chèn mã độc vào các tệp đang được triển khai mà không bị phát hiện.\nHệ thống cực kỳ mong manh: Quy trình này rất dễ xảy ra lỗi. Chỉ cần quên một tệp, sao chép sai thư mục, hoặc một tệp truyền bị lỗi cũng có thể làm sập toàn bộ hệ thống.\nKhông có cơ chế Rollback: Khi một lần triển khai thất bại, không có cách nào dễ dàng và tự động để quay trở lại phiên bản ổn định trước đó.\nLevel 1: Script và Quản Lý Mã Nguồn Có Cấu Trúc Công cụ và Quy trình Sự ra đời của Script: \u0026ldquo;Deployment checklist\u0026rdquo; từ level 0 được mã hóa thành một kịch bản (script) triển khai đơn giản, thường sử dụng Bash. Script này tự động hóa các bước kết nối đến máy chủ, lấy mã nguồn mới nhất từ kho chứa, và khởi động lại các dịch vụ.\nQuy trình Git có cấu trúc: Nhóm nhận ra rằng việc đẩy trực tiếp lên nhánh main là không bền vững. Họ áp dụng một chiến lược phân nhánh chính thức, phổ biến nhất là Feature Branch Workflow.\nNhánh main giờ đây được coi là \u0026ldquo;bất khả xâm phạm\u0026rdquo; và luôn ở trạng thái sẵn sàng để triển khai.\nTất cả công việc mới (tính năng, sửa lỗi) được thực hiện trên các nhánh riêng biệt.\nCác thay đổi được tích hợp trở lại vào main thông qua Pull Request (hoặc Merge Request), cho phép thực hiện quy trình đánh giá mã nguồn (code review).\nLợi ích và Những Vấn đề Còn Tồn Tại Lợi ích: Bản thân quy trình triển khai giờ đây đã đáng tin cậy và nhất quán hơn. Nhánh main ổn định hơn. Việc đánh giá mã nguồn giúp cải thiện chất lượng.\nVấn đề còn tồn tại: Script không xử lý tốt các trường hợp thất bại. Không có kiểm thử tự động, lỗi vẫn được triển khai, chỉ là một cách nhất quán hơn. Các môi trường (development, staging, production) vẫn được cấu hình thủ công và không nhất quán, dẫn đến vấn đề kinh điển \u0026ldquo;nó chạy trên máy của tôi\u0026rdquo;.\nLevel 2: CI/CD Đây là một bước nhảy vọt. Trọng tâm chuyển từ một script triển khai đơn lẻ sang một đường ống (pipeline) tự động hóa hoàn toàn, hoạt động như một \u0026ldquo;nhà máy\u0026rdquo; trung tâm cho việc phân phối phần mềm. Đây là nơi thế giới \u0026ldquo;Dev\u0026rdquo; và \u0026ldquo;Ops\u0026rdquo; thực sự bắt đầu hợp nhất.\nCốt Lõi Tích hợp Liên tục (Continuous Integration - CI): Là thực tiễn tự động hóa việc tích hợp các thay đổi mã nguồn từ nhiều nhà phát triển vào một dự án duy nhất. Mỗi lần đẩy mã nguồn lên một nhánh sẽ kích hoạt một quy trình xây dựng (build) tự động và một bộ các bài kiểm thử tự động (unit test, integration test).\nPhân phối Liên tục (Continuous Delivery - CD): Là một phần mở rộng của CI. Sau khi các giai đoạn xây dựng và kiểm thử thành công, phần mềm sẽ được đóng gói và triển khai tự động đến một hoặc nhiều môi trường phi sản xuất (như staging). Việc triển khai lên production thường là một bước thủ công, chỉ cần một cú nhấp chuột.\nTriển khai Liên tục (Continuous Deployment - cũng là CD): Là hình thức tiên tiến nhất, nơi mọi thay đổi vượt qua tất cả các bài kiểm thử tự động đều được triển khai tự động lên production mà không cần sự can thiệp của con người.\nCông cụ Việc lựa chọn một công cụ CI/CD là một quyết định quan trọng ở giai đoạn này. Bảng dưới đây so sánh các lựa chọn phổ biến nhất.\nTính năng Jenkins GitLab CI GitHub Actions Thiết lập \u0026amp; Lưu trữ Cần cài đặt thủ công, thiết lập agent, tự lưu trữ (on-premise/cloud). Tích hợp sẵn trong GitLab, không cần cài đặt riêng. Tích hợp sẵn trong GitHub, không cần cài đặt riêng. Cấu hình Jenkinsfile (viết bằng Groovy) hoặc qua giao diện người dùng (UI). Tệp YAML (.gitlab-ci.yml) trong kho mã nguồn. Tệp YAML trong thư mục .github/workflows. Hệ sinh thái \u0026amp; Mở rộng Cực kỳ mạnh mẽ với hơn 1800 plugin, tùy biến cao nhưng có thể phức tạp và dễ gặp vấn đề tương thích. Tích hợp sâu với các tính năng của GitLab. Hệ sinh thái plugin nhỏ hơn Jenkins. Thị trường (Marketplace) rộng lớn với các \u0026ldquo;Actions\u0026rdquo; tái sử dụng. Dễ dàng tạo action tùy chỉnh. Trường hợp sử dụng lý tưởng Các quy trình phức tạp, yêu cầu tùy biến sâu, môi trường on-premise hoặc các hệ thống cũ (legacy). Các nhóm đã và đang sử dụng GitLab làm nền tảng chính, muốn một giải pháp \u0026ldquo;tất cả trong một\u0026rdquo;. Các nhóm ưu tiên GitHub, dự án mã nguồn mở, startup, cần sự đơn giản và khởi đầu nhanh chóng. Lợi ích và Thách thức Mới Lợi ích: Vòng lặp phản hồi nhanh hơn đáng kể, chất lượng mã nguồn được cải thiện, giảm rủi ro triển khai và tăng năng suất của nhà phát triển.\nThách thức: Bản thân \u0026ldquo;đường ống CI/CD\u0026rdquo; trở thành một phần mềm phức tạp cần được bảo trì. Các nhóm giờ đây phải đối mặt với những vấn đề mới như các bài kiểm thử chạy chậm hoặc không ổn định (flaky tests), quản lý các phụ thuộc phức tạp, và vấn đề dai dẳng về \u0026ldquo;trôi dạt môi trường\u0026rdquo; (environment drift), nơi môi trường staging và production không giống hệt nhau.\nLevel 3: Hạ Tầng Dưới Dạng Mã (IaC) và Container Hóa Để giải quyết vấn đề trôi dạt môi trường và làm cho việc quản lý hạ tầng trở nên nghiêm ngặt như phát triển ứng dụng, các nhóm áp dụng triết lý \u0026ldquo;mọi thứ đều là mã nguồn\u0026rdquo;.\nCốt Lõi Hạ tầng dưới dạng mã (Infrastructure as Code - IaC): Là việc quản lý và cấp phát hạ tầng (máy chủ, mạng, cơ sở dữ liệu) thông qua các tệp định nghĩa mà máy có thể đọc được (mã nguồn), thay vì cấu hình thủ công. Có hai cách tiếp cận chính:\nDeclarative: Bạn định nghĩa trạng thái cuối cùng mong muốn của hạ tầng. Công cụ (ví dụ: Terraform) sẽ tự tìm cách để đạt được trạng thái đó. Đây là cách tiếp cận chủ đạo trong IaC hiện đại.\nImperative: Bạn viết các kịch bản chỉ định các bước chính xác cần thực hiện để cấu hình hạ tầng (ví dụ: Ansible, Chef, Puppet).\nContainer hóa với Docker: Là người bạn đồng hành hoàn hảo của IaC. Docker giải quyết vấn đề \u0026ldquo;nó chạy trên máy của tôi\u0026rdquo; bằng cách đóng gói một ứng dụng và tất cả các phụ thuộc của nó vào một đơn vị duy nhất, được tiêu chuẩn hóa và bị cô lập gọi là container.\nDockerfile: \u0026ldquo;Công thức\u0026rdquo; hay bản thiết kế để xây dựng một image.\nImage: Một mẫu chỉ đọc (read-only) chứa ứng dụng và môi trường của nó.\nContainer: Một thực thể đang chạy (running instance) của một image. Nó nhẹ và có tính di động cao.\nQuy trình Mới Đường ống CI/CD được nâng cấp. Nó không còn chỉ triển khai mã nguồn; nó xây dựng một Docker image (một tạo phẩm nhất quán được đảm bảo) và sử dụng các công cụ IaC như Terraform để cấp phát một môi trường giống hệt nơi container sẽ chạy.\nLợi ích và Nút thắt Cổ chai Tiếp theo Lợi ích: Vấn đề trôi dạt môi trường được loại bỏ. Các lần triển khai giờ đây có tính nhất quán và độ tin cậy cao trên các môi trường dev, staging và production. Các thay đổi về hạ tầng được quản lý phiên bản, được đánh giá và có thể kiểm tra lại.\nNút thắt cổ chai tiếp theo: Tổ chức bây giờ đã thành công và có hàng trăm hoặc hàng nghìn container. Làm thế nào để quản lý chúng? Làm thế nào để xử lý mạng, mở rộng quy mô và kiểm tra sức khỏe cho tất cả các container này? Đây là vấn đề của việc điều phối (orchestration).\nLevel 4: Điều Phối Container và Kiến Trúc Cloud-Native Trọng tâm chuyển từ việc quản lý các container riêng lẻ sang quản lý một ứng dụng phân tán bao gồm nhiều container ở quy mô lớn. Điều này đòi hỏi một \u0026ldquo;nhạc trưởng\u0026rdquo; cho \u0026ldquo;dàn nhạc\u0026rdquo; container.\nCốt Lõi: Kubernetes (K8s) Kubernetes: Là hệ thống mã nguồn mở, tiêu chuẩn de-facto của ngành công nghiệp, dùng để tự động hóa việc triển khai, mở rộng quy mô và quản lý các ứng dụng được container hóa. Nó giải quyết vấn đề chạy các hệ thống phân tán một cách linh hoạt và có khả năng phục hồi.\n**Các đối tượng Kubernetes chính:\nPod: Đơn vị triển khai nhỏ nhất, cơ bản nhất trong Kubernetes. Nó là một lớp vỏ bọc quanh một hoặc nhiều container, chia sẻ tài nguyên lưu trữ và mạng. Hãy coi nó như \u0026ldquo;nguyên tử\u0026rdquo; cơ bản của một ứng dụng K8s.\nDeployment: Một đối tượng cấp cao hơn mô tả trạng thái mong muốn cho ứng dụng của bạn. Nó nói với Kubernetes rằng \u0026ldquo;Tôi muốn có 3 bản sao (replica) của pod máy chủ web của tôi chạy mọi lúc.\u0026rdquo; Bộ điều khiển Deployment (Deployment Controller) sẽ làm việc để biến trạng thái này thành hiện thực.\nService: Một lớp trừu tượng định nghĩa một tập hợp logic các Pod và một chính sách để truy cập chúng. Nó cung cấp một địa chỉ IP và tên DNS ổn định, để các phần khác của ứng dụng (hoặc người dùng bên ngoài) có thể kết nối đến các Pod, ngay cả khi chúng được tạo ra và phá hủy.\nLợi ích và Sự Phức Tạp Mới Lợi ích: Tổ chức đạt được khả năng mở rộng quy mô thực sự, tự phục hồi (Kubernetes tự động khởi động lại các container bị lỗi), và tính sẵn sàng cao. Các bản cập nhật và quay lui (rolling updates and rollbacks) giờ đây được quản lý một cách khai báo và an toàn.\nSự phức tạp mới: Bản thân Kubernetes là một hệ thống cực kỳ phức tạp. Việc học nó rất khó khăn. Quản lý, giám sát và bảo mật một cụm Kubernetes (cluster) trở thành một công việc toàn thời gian. Thách thức mới không còn là \u0026ldquo;làm thế nào để chạy ứng dụng của chúng ta?\u0026rdquo; mà là \u0026ldquo;làm thế nào để chạy Kubernetes một cách đáng tin cậy?\u0026rdquo;\nLevel 5: Vận Hành Dựa Trên Dữ Liệu (SRE, GitOps, \u0026amp; Observability) Đây là level cao nhất. Các hoạt động vận hành không còn là bị động hay thậm chí chỉ là tự động; chúng trở nên chủ động, được điều khiển bằng dữ liệu và được xem như một ngành kỹ thuật phần mềm.\nCốt Lõi Site Reliability Engineering - SRE: Một phương pháp triển khai cụ thể của DevOps, bắt nguồn từ Google. Nó coi các vấn đề vận hành như những bài toán phần mềm.\nSLI, SLO, và Ngân sách Lỗi (Error Budgets): SRE cung cấp một khung làm việc toán học cho độ tin cậy.\nSLI (Service Level Indicator - Chỉ số Cấp độ Dịch vụ): Một thước đo định lượng về một khía cạnh nào đó của dịch vụ (ví dụ: độ trễ yêu cầu, tỷ lệ lỗi).\nSLO (Service Level Objective - Mục tiêu Cấp độ Dịch vụ): Một giá trị mục tiêu cho một SLI trong một khoảng thời gian (ví dụ: 99.9% yêu cầu được phục vụ trong \u0026lt;200ms).\nError Budget (Ngân sách Lỗi): Là phần nghịch đảo của SLO (100%−SLO). Đây là lượng \u0026ldquo;không đáng tin cậy\u0026rdquo; mà nhóm được phép \u0026ldquo;tiêu thụ\u0026rdquo;. Nếu ngân sách lỗi còn dương, nhóm có thể phát hành tính năng mới. Nếu nó cạn kiệt, mọi công việc phải chuyển sang cải thiện độ tin cậy.\nSRE và DevOps: SRE trả lời câu hỏi \u0026ldquo;làm thế nào\u0026rdquo; cho cái \u0026ldquo;gì\u0026rdquo; của DevOps.\nGitOps: Sự tiến hóa của IaC và CI/CD. Git là nguồn chân lý duy nhất (single source of truth) cho toàn bộ trạng thái hệ thống (hạ tầng và ứng dụng).\nQuy trình làm việc: Các thay đổi được thực hiện thông qua Pull Request đến một kho chứa Git. Một agent bên trong cụm Kubernetes (như Argo CD hoặc Flux) liên tục so sánh trạng thái thực tế với trạng thái được khai báo trong Git và tự động điều chỉnh bất kỳ sự khác biệt nào.\nArgo CD và Flux: Argo CD giống một nền tảng hoàn chỉnh, có giao diện người dùng, trong khi Flux là một bộ công cụ mô-đun hơn, tập trung vào dòng lệnh và thường được coi là gần gũi hơn với cách tiếp cận \u0026ldquo;thuần Kubernetes\u0026rdquo;.\nKhả năng Quan sát (Observability): Vượt ra ngoài việc giám sát đơn giản (\u0026ldquo;máy chủ có hoạt động không?\u0026rdquo;) để đạt đến sự hiểu biết sâu sắc về hệ thống (\u0026ldquo;tại sao máy chủ lại chậm đối với người dùng ở khu vực cụ thể này?\u0026rdquo;).\nBa Trụ cột của Observability:\nLogs: Các bản ghi chi tiết, có dấu thời gian về các sự kiện riêng lẻ.\nMetrics: Dữ liệu số, được tổng hợp theo thời gian (ví dụ: mức sử dụng CPU, số lượng yêu cầu).\nTraces: Cho thấy hành trình từ đầu đến cuối của một yêu cầu khi nó di chuyển qua một hệ thống phân tán.\nCông cụ: Các ngăn xếp công cụ phổ biến bao gồm Prometheus \u0026amp; Grafana để theo dõi số liệu và trực quan hóa, và ELK Stack (Elasticsearch, Logstash, Kibana) để quản lý nhật ký.\nKết luận Hành động Đánh giá Mức độ Trưởng thành: Các tổ chức nên sử dụng mô hình này để xác định vị trí hiện tại của nhóm mình.\nTập trung vào Nút thắt Cổ chai Tiếp theo: Thay vì cố gắng nhảy từ Cấp độ 0 lên Cấp độ 5, chìa khóa là xác định điểm yếu lớn nhất hiện tại và áp dụng các thực tiễn của cấp độ tiếp theo để giải quyết nó. Quá trình này nên diễn ra từ từ và có kế hoạch.\nLộ trình Kỹ năng Tóm tắt: Để phát triển cá nhân hoặc xây dựng đội ngũ, một lộ trình kỹ năng có cấu trúc là cần thiết:\nNền tảng: Ngôn ngữ lập trình (Python/Go), Linux/Shell Scripting, Git.\nDevOps Cốt lõi: Công cụ CI/CD (Jenkins, GitLab CI, GitHub Actions), IaC (Terraform), Containers (Docker).\nNâng cao/Cloud-Native: Kubernetes, Nền tảng Đám mây (AWS/GCP/Azure), Giám sát/Quan sát (Prometheus, Grafana).\nTinh hoa/SRE: Hiểu biết sâu về hệ thống phân tán, triển khai SLI/SLO, tự động hóa nâng cao.\n","permalink":"https://blog.nagih.io.vn/posts/6-level-deploy/","summary":"\u003cp\u003e6 Cấp Độ Trưởng Thành Từ Deploy Thủ Công Đến Vận Hành Tinh Gọn\u003c/p\u003e","title":"6 Level Deploy"},{"content":"9 nguyên tắc cốt lõi và một số kỹ năng mở rộng khi khởi tạo bảng trong MySQL, đảm bảo ứng dụng không chỉ chạy đúng mà còn hiệu quả và dễ bảo trì\n1. Mọi Table Luôn Phải Có Các Column Mặc Định\nMột thiết kế table hoàn chỉnh cần có ít nhất 5 trường mặc định để theo dõi lịch sử và tính nhất quán của dữ liệu:\nversion: Ghi lại số lần chỉnh sửa của table, đồng thời liên quan đến các khái niệm khóa lạc quan (optimistic lock) và khóa bi quan (pessimistic lock)\ncreator_id: (Tùy chọn, tùy thuộc vào công ty) Ai là người tạo bản ghi này\nmodifier: Ai là người cuối cùng sửa đổi bản ghi, quan trọng để biết hành động cuối cùng trên table\ncreate_at: Thời gian bản ghi được tạo\nupdate_at: Thời gian bản ghi được cập nhật lần cuối\n2. Giải Thích Ngữ Nghĩa Các Column Bằng Comment\nKhi viết DDL (Data Definition Language) cho MySQL, PostgreSQL, hoặc bất kỳ hệ quản trị cơ sở dữ liệu nào, hãy luôn thêm comment giải thích ý nghĩa của từng column. Việc comment rõ ràng giúp các thành viên mới gia nhập team dễ dàng hiểu và làm quen với cấu trúc dữ liệu, tránh sự hiểu lầm về ngữ nghĩa của các trường\n3. Xóa Dữ Liệu Không Phải Xóa \u0026ldquo;Bay\u0026rdquo; (Xóa Logic)\nKhông bao giờ sử dụng lệnh DELETE để xóa vật lý dữ liệu trực tiếp trong môi trường sản phẩm. Thay vào đó, hãy sử dụng phương pháp xóa logic (soft delete) bằng cách thêm một trường để đánh dấu bản ghi đã bị xóa hay chưa, và thời gian xóa\nBan đầu có thể sử dụng hai trường: is_deleted (0: hoạt động, 1: đã xóa) và deleted_at (thời gian xóa)\nCách tối ưu hơn là chỉ sử dụng một trường deleted_at: Nếu giá trị là NULL nghĩa là bản ghi chưa bị xóa; nếu có giá trị thời gian, đó là thời gian bản ghi bị xóa\nLưu ý: Giá trị NULL có thể gây nhược điểm nghiêm trọng về hiệu suất index khi dữ liệu lớn, do đó cần cân nhắc kỹ hoặc tìm hiểu sâu hơn về NULL trong database\n4. Quy Ước Đặt Tên Với Prefix (Tiền Tố)\nCác trường (field) trong table nên có các tiền tố (prefix) để dễ dàng xác định nguồn gốc khi các bảng được join lại với nhau. Ví dụ, bảng account có thể có trường acc_number. Việc này cực kỳ quan trọng vì trong thực tế, chúng ta ít khi làm việc với dữ liệu độc lập mà thường phải join nhiều bảng (ít nhất 3 bảng là nguyên tắc làm việc). Nếu không có prefix, việc phân biệt ID hay create_at thuộc về bảng nào khi join sẽ gây ra sự hiểu nhầm và lỗi\n5. Tách Bảng Khi Có Quá Nhiều Trường (Vertical Partitioning)\nMột table không nên có quá nhiều trường (column), tối đa khoảng 20 trường. Nếu vượt quá, cần phải tách bảng dọc (vertical partition). Bảng có nhiều trường sẽ làm dữ liệu lưu trữ lớn, giảm hiệu suất truy vấn và tốn bộ nhớ\nTách bảng: Chia thành một bảng chính chứa các trường được truy cập thường xuyên và quan trọng (ví dụ: title, status, thumbnail của một bài post), và một bảng chi tiết chứa các trường ít quan trọng hơn hoặc chỉ hiển thị khi người dùng click vào (ví dụ: content, description)\nMối quan hệ giữa hai bảng này thường là 1-1, giúp việc join đơn giản và hiệu quả, không ảnh hưởng đến hiệu suất\n6. Chọn Kiểu Dữ Liệu và Độ Dài Thích Hợp\nMột hệ thống tốt không chỉ chạy đúng mà còn phải chạy hiệu quả. Việc chọn kiểu dữ liệu và độ dài phù hợp giúp:\nTiết kiệm bộ nhớ (memory) và dung lượng đĩa (disk)\nTối ưu tốc độ query\nGiảm tỷ lệ Input/Output (I/O). Ví dụ:\nTrường title không nên để VARCHAR(255) nếu độ dài thực tế chỉ khoảng 100 ký tự (như tiêu đề video YouTube/TikTok)\nTrường language chỉ cần CHAR(2) (ví dụ: \u0026ldquo;en\u0026rdquo;, \u0026ldquo;vi\u0026rdquo;) thay vì VARCHAR dài\nTrường status chỉ nên dùng TINYINT (kích thước 1 byte, lưu trữ 0-255) thay vì INT (kích thước 4 byte, lưu trữ 0-4 tỷ ID) nếu các giá trị chỉ là 1, 2, 3\n7. Nguyên Tắc Not NULL\nKhông nên cho phép giá trị NULL bừa bãi. NULL không phải là một số, một chuỗi hay một biến boolean; nó là một vùng không xác định. NULL có thể:\nLàm hỏng logic nghiệp vụ nếu quên xử lý\nGây lỗi index khi so sánh bằng NULL (ví dụ WHERE column IS NULL thường không sử dụng index hiệu quả). Các trường bắt buộc phải có giá trị (như title, status, create_at) nên được khai báo là NOT NULL. Khi không có giá trị, hãy sử dụng DEFAULT đi kèm với NOT NULL\n8. Chiến Lược Đánh Index\nIndex là chìa khóa để tối ưu hiệu suất truy vấn\nNên đánh index cho các trường ít trùng lặp và thường xuyên được sử dụng trong truy vấn, ví dụ: creator_id và create_at (quan trọng khi truy vấn theo thời gian). Luôn có prefix idx_ cho các index\nTrường deleted_at luôn cần được đánh index để tránh hiển thị các bản ghi đã bị xóa ra công khai, điều này có thể dẫn đến các vấn đề pháp lý (ví dụ: GDPR của Châu Âu)\nQUY TẮC VÀNG: Không nên đánh index cho các trường có dữ liệu lặp lại quá nhiều (ví dụ: trường status mà 90% bản ghi có cùng một giá trị). Việc đánh index trong trường hợp này thậm chí có thể làm chậm truy vấn hơn so với không đánh index, vì database sẽ quét toàn bộ table thay vì sử dụng index\nGiải pháp thay thế khi cần truy vấn các trường có nhiều giá trị trùng lặp:\nThêm trường tiền tố phạm vi thời gian: Ví dụ, kết hợp status với create_at theo phạm vi thời gian (WHERE status = 1 AND create_at BETWEEN '2025-06-15 00:00 :00' AND '2025-06-15 23:59:59') để giúp index hoạt động hiệu quả hơn\nChia table thành các phân vùng (Partition): Phù hợp với dữ liệu lớn, giúp chia nhỏ dữ liệu. Tuy nhiên, Partition không thay thế được index và có nhược điểm riêng, chỉ nên dùng khi thực sự cần và hiểu rõ\nTạo View: View có thể hoạt động rất tốt trong các truy vấn với stored procedure hoặc function, giúp truy vấn nhanh hơn khi dữ liệu được lặp lại và cảm thấy đúng đánh lặp lại\n9. Nguyên Tắc Normal Form (3NF, 4NF, 5NF)\nNormalization là một nguyên tắc cơ bản trong thiết kế database nhằm giảm thiểu sự dư thừa dữ liệu và cải thiện tính toàn vẹn dữ liệu\n3NF (Third Normal Form) là một nguyên tắc cơ bản cần nắm vững\nNgoài ra, còn có các dạng chuẩn mở rộng hơn như 4NF (Fourth Normal Form) và 5NF (Fifth Normal Form), giúp tối ưu hóa hơn nữa về sự mở rộng và tính linh hoạt của database\nViệc tìm hiểu sâu về các Normal Form này sẽ giúp bạn thiết kế database hiệu quả hơn cho các mô hình kinh doanh phức tạp\n","permalink":"https://blog.nagih.io.vn/posts/9-mysql-table-design-rules--skills/","summary":"\u003cp\u003e9 nguyên tắc cốt lõi và một số kỹ năng mở rộng khi khởi tạo bảng trong MySQL, đảm bảo ứng dụng không chỉ chạy đúng mà còn hiệu quả và dễ bảo trì\u003c/p\u003e","title":"9 MySQL Table Design Rules \u0026 Skills"},{"content":"Chúng ta đã biết cache rất hữu ích, nhưng nó có một giới hạn cố hữu: dung lượng nhỏ. Bộ nhớ tốc độ cao (như RAM) rất đắt đỏ, vì vậy cache không thể lưu trữ mọi thứ.\nCác Chính Sách \u0026ldquo;Dọn Dẹp\u0026rdquo; Chúng ta đã biết cache rất hữu ích, nhưng nó có một giới hạn cố hữu: dung lượng nhỏ. Bộ nhớ tốc độ cao (như RAM) rất đắt đỏ, vì vậy cache không thể lưu trữ mọi thứ.\nĐiều này dẫn đến một vấn đề không thể tránh khỏi: khi cache đã đầy và một mục dữ liệu mới cần được thêm vào, hệ thống phải quyết định loại bỏ một mục dữ liệu cũ để nhường chỗ. Quá trình này được gọi là Eviction.\nThuật toán được sử dụng để quyết định mục nào sẽ bị loại bỏ được gọi là Chính sách dọn dẹp (Eviction Policy).\nCác chiến lược dọn dẹp phổ biến FIFO (First-In, First-Out - Vào trước, Ra trước):\nNguyên tắc: Nó loại bỏ mục dữ liệu cũ nhất, bất kể nó có được sử dụng thường xuyên hay không. Nó hoạt động giống như một hàng đợi (queue).\nƯu điểm: Rất dễ cài đặt và có chi phí quản lý thấp.\nNhược điểm: Thường không hiệu quả vì nó có thể loại bỏ một mục rất phổ biến chỉ vì nó được nạp vào cache từ lâu.\nLRU (Least Recently Used - Ít được sử dụng gần đây nhất):\nNguyên tắc: Loại bỏ mục dữ liệu mà đã không được truy cập trong khoảng thời gian dài nhất.\nƯu điểm: Hiệu quả hơn FIFO rất nhiều trong hầu hết các trường hợp thực tế, vì nó giữ lại những dữ liệu đang được sử dụng tích cực.\nNhược điểm: Phức tạp hơn trong việc triển khai vì nó đòi hỏi phải theo dõi thời gian truy cập của mỗi mục, gây tốn thêm một chút bộ nhớ và xử lý.\nLFU (Least Frequently Used - Ít được sử dụng thường xuyên nhất):\nNguyên tắc: Loại bỏ mục dữ liệu được truy cập với số lần ít nhất.\nƯu điểm: Rất tốt trong việc xác định và giữ lại các mục dữ liệu \u0026ldquo;hot\u0026rdquo; (phổ biến) trong một thời gian dài, ngay cả khi chúng không được truy cập gần đây.\nNhược điểm: Phức tạp để triển khai hiệu quả. (ví dụ: một mục từng rất hot nhưng giờ không còn ai dùng nữa vẫn có thể chiếm chỗ trong cache một thời gian dài). Nó cũng có thể loại bỏ một mục mới được thêm vào nhưng chưa có cơ hội tích lũy đủ số lần truy cập.\nBảng so sánh các chính sách dọn dẹp Chính sách Nguyên tắc cốt lõi Ví dụ tương tự Ưu điểm Nhược điểm Phù hợp nhất cho FIFO Loại bỏ mục vào cache sớm nhất. Xếp hàng mua vé: người đến trước được phục vụ trước. Đơn giản, chi phí thấp. Không thông minh, có thể loại bỏ dữ liệu quan trọng. Các hệ thống có mẫu truy cập tuần tự, không lặp lại. LRU Loại bỏ mục ít được dùng đến gần đây nhất. Dọn dẹp bàn làm việc: trả lại cuốn sách bạn không đụng đến lâu nhất. Hiệu quả cao trong hầu hết các trường hợp, thích ứng tốt với sự thay đổi. Phức tạp hơn, cần theo dõi thời gian truy cập. Các ứng dụng thông thường, nơi dữ liệu gần đây có khả năng được tái sử dụng cao (ví dụ: trang tin tức, mạng xã hội). LFU Loại bỏ mục có số lần truy cập ít nhất. Thư viện cho mượn sách: loại bỏ những cuốn ít người mượn nhất. Giữ lại được các mục \u0026ldquo;hot\u0026rdquo; một cách ổn định. Phức tạp, có thể giữ lại dữ liệu \u0026ldquo;hot\u0026rdquo; đã lỗi thời, không thích ứng nhanh. Các hệ thống có một số dữ liệu cực kỳ phổ biến và ổn định (ví dụ: sản phẩm bán chạy, video viral). Giữ Cho Dữ Liệu Đồng Nhất: Các Chính Sách Ghi Khi một ứng dụng thực hiện thao tác ghi (write) hoặc cập nhật (update), một vấn đề nghiêm trọng nảy sinh. Bây giờ chúng ta có hai bản sao của cùng một dữ liệu: một trong cache và một trong cơ sở dữ liệu. Nếu chúng không được cập nhật đồng bộ, cache sẽ chứa dữ liệu cũ. Việc phục vụ stale data cho người dùng có thể dẫn đến các lỗi nghiêm trọng, thông tin sai lệch và trải nghiệm tồi tệ.\nChính sách ghi (Write Policy) là quy tắc xác định cách hệ thống xử lý các thao tác ghi để giải quyết vấn đề về tính nhất quán này.\nCác chính sách ghi cốt lõi Write-Through (Ghi Xuyên)\nQuy trình: Khi ứng dụng ghi dữ liệu, nó sẽ ghi đồng thời vào cả cache và cơ sở dữ liệu. Thao tác chỉ được coi là hoàn tất khi cả hai nơi đều đã ghi xong.\nLưu đồ: Ứng dụng -\u0026gt; Ghi vào Cache -\u0026gt; Ghi vào Database -\u0026gt; Hoàn tất\nƯu điểm: Tính nhất quán dữ liệu rất cao. Cache và database luôn đồng bộ. Đơn giản để triển khai và đáng tin cậy.\nNhược điểm: Độ trễ của thao tác ghi cao, vì ứng dụng phải chờ cả hai thao tác ghi hoàn tất.\nTrường hợp sử dụng: Các ứng dụng quan trọng nơi tính nhất quán dữ liệu là tối thượng, ví dụ như hệ thống ngân hàng, quản lý kho hàng.\nWrite-Back (Ghi Sau / Write-Behind)\nQuy trình: Khi ứng dụng ghi dữ liệu, nó chỉ ghi vào cache tốc độ cao trước. Thao tác được xác nhận hoàn tất ngay lập tức. Việc ghi vào cơ sở dữ liệu sẽ được trì hoãn và thực hiện sau đó, có thể là sau một khoảng thời gian nhất định hoặc khi mục cache đó sắp bị dọn dẹp. Hệ thống thường dùng một \u0026ldquo;bit bẩn\u0026rdquo; (dirty bit) để đánh dấu các mục trong cache đã bị thay đổi và cần được ghi lại vào database.\nLưu đồ: Ứng dụng -\u0026gt; Ghi vào Cache -\u0026gt; Hoàn tất. (Background: Cache -\u0026gt; Ghi vào Database)\nƯu điểm: Độ trễ ghi cực thấp và thông lượng cao. Giảm tải cho database bằng cách gộp nhiều lần ghi vào cùng một đối tượng thành một lần ghi duy nhất (write-coalescing).\nNhược điểm: Có nguy cơ mất dữ liệu nếu cache bị lỗi trước khi dữ liệu kịp ghi vào database. Phức tạp hơn để triển khai.\nTrường hợp sử dụng: Các ứng dụng có lượng ghi lớn, nơi hiệu năng là ưu tiên hàng đầu và có thể chấp nhận một rủi ro nhỏ về mất mát dữ liệu, ví dụ như ghi log hành vi người dùng, cập nhật số lượt xem bài viết.\nWrite-Around (Ghi Vòng)\nQuy trình: Khi ứng dụng ghi dữ liệu, nó sẽ ghi trực tiếp vào cơ sở dữ liệu, hoàn toàn bỏ qua cache. Dữ liệu chỉ được nạp vào cache sau này, khi có một yêu cầu đọc bị cache miss.\nLưu đồ: Ứng dụng -\u0026gt; Ghi vào Database -\u0026gt; Hoàn tất\nƯu điểm: Tránh \u0026ldquo;làm ô nhiễm\u0026rdquo; cache bằng những dữ liệu có thể không bao giờ được đọc lại.\nNhược điểm: Một yêu cầu đọc ngay sau khi ghi sẽ luôn luôn là cache miss, dẫn đến độ trễ đọc cao cho dữ liệu vừa được ghi.\nTrường hợp sử dụng: Các ứng dụng ghi dữ liệu nhưng hiếm khi đọc lại ngay sau đó, ví dụ như các hệ thống nhập dữ liệu hàng loạt (bulk data ingestion), lưu trữ log.\nCác chính sách ghi không tồn tại một cách độc lập. Chúng liên kết chặt chẽ với cách hệ thống xử lý một write miss (khi ứng dụng muốn ghi vào một mục không có trong cache). Có hai lựa chọn:\nWrite Allocate (Fetch on Write): Khi có write miss, hệ thống sẽ tải khối dữ liệu đó từ database vào cache trước, rồi mới thực hiện thao tác ghi.\nNo-Write Allocate: Khi có write miss, hệ thống sẽ ghi thẳng vào database, không tải dữ liệu đó vào cache.\n","permalink":"https://blog.nagih.io.vn/posts/cache-hit--cache-miss/","summary":"\u003cp\u003eChúng ta đã biết cache rất hữu ích, nhưng nó có một giới hạn cố hữu: dung lượng nhỏ. Bộ nhớ tốc độ cao (như RAM) rất đắt đỏ, vì vậy cache không thể lưu trữ mọi thứ.\u003c/p\u003e","title":"Các chính sách 'Dọn Dẹp' Cache"},{"content":" Các Mẫu Thiết Kế Cache-Aside (Lazy Loading) Đây là mẫu thiết kế phổ biến và trực quan nhất. Trong mẫu này, logic của ứng dụng chịu trách nhiệm hoàn toàn cho việc quản lý cache.\nQuy trình:\nỨng dụng cần đọc dữ liệu, nó sẽ kiểm tra cache trước.\nNếu có (cache hit), dữ liệu được trả về.\nNếu không có (cache miss), ứng dụng sẽ đọc dữ liệu từ database.\nSau đó, ứng dụng sẽ ghi dữ liệu vừa đọc được vào cache.\nKhi ghi dữ liệu, ứng dụng thường sẽ cập nhật database trước, sau đó vô hiệu hóa (invalidate) mục tương ứng trong cache. Ưu điểm: Ứng dụng có toàn quyền kiểm soát. Cache chỉ lưu những dữ liệu thực sự được yêu cầu, giúp tiết kiệm không gian. Hệ thống có khả năng chống chịu lỗi cache tốt (nếu cache sập, ứng dụng có thể đọc trực tiếp từ database).\nNhược điểm: Yêu cầu đầu tiên cho bất kỳ dữ liệu nào cũng sẽ là cache miss. Code của ứng dụng phức tạp hơn vì phải chứa logic quản lý cache.\nRead-Through Mẫu này trừu tượng hóa database khỏi ứng dụng. Ứng dụng chỉ cần \u0026ldquo;nói chuyện\u0026rdquo; với cache.\nQuy trình:\nỨng dụng yêu cầu dữ liệu từ cache.\nNếu cache có, nó sẽ trả về.\nNếu cache không có, chính cache sẽ chịu trách nhiệm đi lấy dữ liệu từ database, lưu lại rồi trả về cho ứng dụng.\nƯu điểm: Đơn giản hóa code ứng dụng vì logic caching được đóng gói trong cache provider.\nNhược điểm: Kém linh hoạt hơn. Cache provider phải hỗ trợ mẫu này.\nWrite-Through và Write-Behind (Write-Back) Đây là các mẫu tập trung vào việc ghi, thường đi đôi với Read-Through.\nWrite-Through: Ứng dụng ghi dữ liệu vào cache, và cache sẽ chịu trách nhiệm ghi đồng bộ dữ liệu đó vào database. Điều này đảm bảo tính nhất quán cao.\nWrite-Behind: Ứng dụng ghi dữ liệu vào cache, và cache sẽ ghi dữ liệu đó vào database một cách bất đồng bộ (trong nền). Điều này cho hiệu năng ghi rất cao.\nCache-Aside đặt trách nhiệm điều phối dữ liệu lên vai ứng dụng. Ứng dụng \u0026ldquo;biết\u0026rdquo; cả về cache và database.\nRead/Write-Through coi cache như một lớp mặt tiền (facade) cho database. Ứng dụng chỉ cần biết \u0026ldquo;lấy dữ liệu\u0026rdquo; hoặc \u0026ldquo;ghi dữ liệu\u0026rdquo; tại một điểm duy nhất là cache.\nMô hình Read-Through thúc đẩy sự phân tách trách nhiệm sạch sẽ hơn, dẫn đến code ứng dụng đơn giản và dễ bảo trì hơn. Tuy nhiên, nó lại ràng buộc chặt chẽ cache với database, khiến việc thay đổi database hoặc sử dụng cache cho các nguồn dữ liệu khác trở nên khó khăn. Ngược lại, Cache-Aside linh hoạt hơn – cache có thể chứa dữ liệu từ nhiều nguồn (database, API, file,\u0026hellip;) – nhưng phải trả giá bằng sự phức tạp tăng lên trong code ứng dụng. Đây là một sự đánh đổi kinh điển giữa đơn giản/đóng gói và linh hoạt/kiểm soát.\nDữ Liệu Cũ và Vô Hiệu Hóa Cache Vấn đề cốt lõi vẫn là stale data. Khi dữ liệu trong nguồn chính bị thay đổi bởi một tiến trình khác mà cache không hề hay biết, cache sẽ trở nên lỗi thời. Phục vụ dữ liệu lỗi thời này có thể gây ra những hậu quả tai hại.\nCache Invalidation là quá trình đánh dấu hoặc loại bỏ dữ liệu trong cache để nó không còn hợp lệ nữa.\nCác chiến lược vô hiệu hóa cache Time-To-Live (TTL) Expiration (Hết hạn theo thời gian):\nQuy trình: Đây là chiến lược đơn giản nhất. Khi dữ liệu được lưu vào cache, nó được gán một \u0026ldquo;tuổi thọ\u0026rdquo;, ví dụ 5 phút. Sau 5 phút, dữ liệu này tự động bị coi là không hợp lệ và sẽ bị xóa hoặc bỏ qua trong lần truy cập tiếp theo, buộc hệ thống phải lấy lại dữ liệu mới từ database.\nƯu điểm: Dễ triển khai, đảm bảo dữ liệu cuối cùng sẽ nhất quán.\nNhược điểm: Dữ liệu có thể bị lỗi thời trong suốt khoảng thời gian TTL. Việc chọn TTL phù hợp là một nghệ thuật cân bằng khó khăn: TTL quá ngắn sẽ làm giảm tỷ lệ cache hit, TTL quá dài sẽ tăng nguy cơ stale data.\nEvent-Driven Invalidation (Active Deletion - Xóa chủ động):\nQuy trình: Một cách tiếp cận chủ động hơn. Khi dữ liệu trong database được cập nhật (ví dụ, người dùng đổi ảnh đại diện), ứng dụng sẽ gửi một lệnh DELETE hoặc INVALIDATE rõ ràng đến cache để xóa mục tương ứng.\nƯu điểm: Đảm bảo dữ liệu được vô hiệu hóa gần như ngay lập tức, mang lại tính nhất quán cao hơn nhiều so với TTL.\nNhược điểm: Phức tạp hơn để triển khai. Nó đòi hỏi sự liên kết chặt chẽ giữa code ghi vào database và cache. Trong một hệ thống phân tán, nó rất dễ gặp phải các vấn đề về race condition (tranh chấp) hoặc lỗi mạng.\nVấn đề \u0026ldquo;khó\u0026rdquo; của cache invalidation không chỉ nằm ở việc khi nào cần vô hiệu hóa, mà là làm thế nào để đảm bảo việc vô hiệu hóa đó là chính xác và nguyên tử trong một môi trường có nhiều tiến trình chạy đồng thời.\nHãy xem xét kịch bản sau trong mẫu Cache-Aside:\nTiến trình A đọc dữ liệu X. Bị cache miss.\nTiến trình A đi đến database để đọc dữ liệu X (phiên bản cũ).\nTrong lúc đó, tiến trình B cập nhật dữ liệu X trong database và ngay lập tức gửi lệnh vô hiệu hóa cache cho X.\nTiến trình A, sau khi đọc xong dữ liệu X (phiên bản cũ) từ database, giờ đây lại ghi nó vào cache.\nKết quả: Cache bây giờ chứa dữ liệu X đã lỗi thời, và lệnh vô hiệu hóa của tiến trình B trở nên vô nghĩa. Dữ liệu lỗi thời này sẽ tồn tại trong cache cho đến khi TTL hết hạn. Kết luận Nếu có một điều cần đọng lại, đó là: Cache không phải là một viên đạn bạc, mà là một kỹ thuật mạnh mẽ đòi hỏi sự đánh đổi thông minh.\nMỗi quyết định bạn đưa ra – chọn loại cache nào, chính sách dọn dẹp ra sao, chính sách ghi nào, mẫu thiết kế nào – đều là một sự cân bằng giữa các yếu tố:\nHiệu năng và Chi phí\nĐộ phức tạp và Tính đơn giản\nTính nhất quán dữ liệu và Độ trễ\nMô hình tối ưu nhất mà mình biết ","permalink":"https://blog.nagih.io.vn/posts/cache-system-design/","summary":"","title":"Các mẫu thiết kế, xây dựng hệ thống với Cache và chiến lược vô hiệu hóa Cache"},{"content":"Nhiều người đã nghe về cache, có thể là \u0026ldquo;xóa cache trình duyệt\u0026rdquo; hay \u0026ldquo;cache của CPU\u0026rdquo;. Nhưng cache thực sự là gì? Nó hoạt động ra sao và tại sao nó lại quan trọng đến vậy?\nCache Là Gì? Câu chuyện về Thư viện và Chiếc bàn làm việc Hãy tưởng tượng bạn là một nhà nghiên cứu cần rất nhiều sách cho công việc của mình. Toàn bộ sách được lưu trữ trong một thư viện khổng lồ ở phía bên kia thành phố. Mỗi khi cần một thông tin, bạn phải mất công di chuyển đến thư viện, tìm đúng cuốn sách, đọc, rồi lại đi về. Quá trình này rất chậm chạp và tốn thời gian.\nBây giờ, bạn nghĩ ra một giải pháp thông minh hơn. Thay vì mỗi lần cần lại chạy đi, bạn sẽ mang những cuốn sách hay dùng nhất về đặt ngay trên chiếc bàn làm việc của mình. Chiếc bàn này tuy nhỏ, không thể chứa cả thư viện, nhưng nó ở ngay trước mặt bạn. Lần tới, khi cần thông tin từ những cuốn sách đó, bạn chỉ cần với tay là có ngay, nhanh hơn gấp trăm lần so với việc đi đến thư viện.\nThư viện khổng lồ chính là nơi lưu trữ dữ liệu chính, ví dụ như ổ cứng (HDD/SSD) hoặc Database. Nơi này có dung lượng lớn nhưng tốc độ truy cập khá chậm.\nChiếc bàn làm việc của bạn chính là Cache.\nCache là một lớp lưu trữ dữ liệu tốc độ cao, có kích thước nhỏ, dùng để chứa một tập hợp con của dữ liệu gốc. Mục đích của nó là để các yêu cầu truy xuất dữ liệu trong tương lai được phục vụ nhanh hơn rất nhiều so với việc phải lấy dữ liệu từ database. Về cơ bản, cache cho phép chúng ta tái sử dụng một cách hiệu quả những dữ liệu đã được truy xuất hoặc tính toán trước đó.\nTại sao Cache lại quan trọng ? Tăng tốc độ một cách chóng mặt (Performance): Đây là mục đích chính. Cache thường được triển khai trên các phần cứng truy cập nhanh như RAM (Bộ nhớ truy cập ngẫu nhiên). Tốc độ truy cập RAM nhanh hơn hàng trăm, thậm chí hàng nghìn lần so với ổ đĩa.\nGiảm tải cho hệ thống Backend: Thay vì mọi yêu cầu đều phải truy cập vào cơ sở dữ liệu, phần lớn các yêu cầu đọc sẽ được cache xử lý. Điều này giúp cơ sở dữ liệu không bị quá tải, đặc biệt là trong những thời điểm có lưu lượng truy cập tăng đột biến, và giữ cho toàn bộ hệ thống ổn định.\nTiết kiệm chi phí (Cost Efficiency): Ở quy mô lớn, việc phục vụ dữ liệu từ cache trong bộ nhớ (in-memory) có thể rẻ hơn đáng kể so với việc phải nâng cấp liên tục các máy chủ cơ sở dữ liệu hoặc trả chi phí cho lưu lượng mạng cao khi truy xuất dữ liệu từ các dịch vụ đám mây.\nCache Hit và Cache Miss Hoạt động của cache xoay quanh hai case chính: Cache Hit và Cache Miss. Khi một client (có thể là CPU, trình duyệt web, hoặc ứng dụng của bạn) cần dữ liệu, nó sẽ luôn hỏi cache trước tiên.\nCache Hit (Tìm thấy trong Cache): Đây là case lý tưởng. Cache sẽ ngay lập tức trả về dữ liệu này cho client. Quá trình này cực kỳ nhanh chóng.\nCache Miss (Không tìm thấy trong Cache): Đây là case không mong muốn. Khi đó, hệ thống buộc phải truy cập đến database để lấy dữ liệu. Sau khi lấy được, dữ liệu này sẽ được sao chép một bản vào cache để những lần yêu cầu sau sẽ trở thành cache hit, rồi mới được trả về cho client.\nCache không phải là một phép màu tăng tốc miễn phí. Nó đi kèm với sự đánh đổi và chi phí. Một cache miss vốn dĩ còn chậm hơn một hệ thống không có cache. Bởi vì trong một hệ thống không cache, thời gian truy xuất chỉ đơn giản là thời gian lấy dữ liệu từ nguồn chính. Còn trong một cache miss, tổng thời gian là Thời gian kiểm tra cache (và thất bại) + Thời gian lấy dữ liệu từ database.\nDo đó, mục tiêu của mọi chiến lược caching không chỉ đơn giản là \u0026ldquo;có cache\u0026rdquo;, mà là thiết kế một hệ thống nơi tổng thời gian tiết kiệm được từ vô số các cache hit phải lớn hơn rất nhiều so với tổng thời gian bị mất đi do các cache miss không thể tránh khỏi.\nTỷ lệ Cache Hit (Cache Hit Ratio) Công thức tính rất đơn giản\nTỷ lệ Cache Hit= Cache Hit​ / (Cache Hit + Cache Miss) Một tỷ lệ cache hit cao (thường từ 80-95% trở lên đối với nội dung tĩnh) cho thấy cache đang hoạt động rất hiệu quả. Ngược lại, một tỷ lệ thấp cho thấy cache đang không được sử dụng tốt, có thể do cấu hình sai, chính sách dọn dẹp không phù hợp, hoặc kích thước cache quá nhỏ.\nCache Phần cứng (CPU Cache) Hệ thống phân cấp bộ nhớ (Memory Hierarchy). Đây là một mô hình tổ chức bộ nhớ trong máy tính thành nhiều cấp, giống như một kim tự tháp. Càng ở đỉnh kim tự tháp, bộ nhớ càng nhanh, càng đắt và dung lượng càng nhỏ. Càng xuống đáy, bộ nhớ càng chậm, càng rẻ và dung lượng càng lớn.\n(1) Register (2) L1 Cache (3) L2 Cache (4) L3 Cache (5) RAM \u0026lt;- Redis (6) SSD (7) HDD CPU cache được chia thành nhiều Level, thường là L1, L2, và L3:\nL1 Cache (Level 1): Đây là bộ nhớ cache nhỏ nhất và nhanh nhất, được tích hợp ngay trong từng nhân (core) của CPU\nL2 Cache (Level 2): Lớn hơn L1 nhưng chậm hơn một chút. L2 cache có thể nằm riêng cho từng nhân hoặc chung cho một vài nhân, tùy vào kiến trúc CPU.\nL3 Cache (Level 3): Lớn nhất và chậm nhất trong các cấp CPU cache. L3 cache thường được dùng chung cho tất cả các nhân trên một con chip. Nó giúp tăng tốc độ giao tiếp giữa các nhân và giảm thiểu việc phải truy cập ra RAM.\nCache Phần mềm Cache Trình duyệt (Browser Cache): Khi bạn truy cập một trang web, trình duyệt của bạn sẽ tự động lưu các tài nguyên tĩnh như hình ảnh, file CSS, JavaScript vào một thư mục trên ổ cứng. Lần sau khi bạn quay lại trang đó, trình duyệt sẽ tải các tài nguyên này từ ổ cứng thay vì phải tải lại từ server, giúp trang web hiển thị gần như ngay lập tức. Đây là một dạng cache phía client (client-side), riêng tư cho mỗi người dùng.\nCache Mạng Phân phối Nội dung (CDN - Content Delivery Network): Đây là một mạng lưới các máy chủ proxy được đặt ở nhiều vị trí địa lý trên toàn cầu. Các máy chủ này lưu trữ (cache) bản sao của nội dung trang web (như video, hình ảnh, file tĩnh). Ví dụ điển hình là Netflix hay YouTube. Khi bạn ở Việt Nam và xem một video, rất có thể bạn đang nhận dữ liệu từ một máy chủ CDN đặt tại Singapore hoặc Hồng Kông, chứ không phải từ máy chủ gốc ở Mỹ. Điều này giúp giảm đáng kể độ trễ và tăng tốc độ tải.\nCache Cơ sở dữ liệu (Database Cache): Hầu hết các hệ quản trị cơ sở dữ liệu như MySQL, PostgreSQL đều có một bộ đệm cache nội bộ. Nó lưu lại kết quả của các câu truy vấn (query) được thực thi thường xuyên. Khi nhận được một câu truy vấn giống hệt, thay vì phải quét lại toàn bộ bảng dữ liệu, database sẽ trả về kết quả từ cache của nó.\nCache Ứng dụng (Application Cache / In-Memory Cache): Thường sử dụng các công cụ chuyên dụng như Redis hoặc Memcached. Lớp cache này có thể lưu trữ bất cứ thứ gì. Việc này giúp ứng dụng không phải tính toán lại hoặc truy vấn lại những thông tin tốn kém trên mỗi yêu cầu.\n","permalink":"https://blog.nagih.io.vn/posts/introdution-to-cache/","summary":"\u003cp\u003eNhiều người đã nghe về cache, có thể là \u0026ldquo;xóa cache trình duyệt\u0026rdquo; hay \u0026ldquo;cache của CPU\u0026rdquo;. Nhưng cache thực sự là gì? Nó hoạt động ra sao và tại sao nó lại quan trọng đến vậy?\u003c/p\u003e","title":"Giới thiệu về Cache"},{"content":"Giới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\nKAFKA ĐƯỢC DÙNG KHI NÀO ? Kiến trúc truyền thống - Lập trình nối tiếp Các function quá lệ thuộc vào nhau: Nếu 1 ngày nào đó, tính năng update cart của 1 nhân viên B bị lỗi thì khi user save order -\u0026gt; update cart nhưng bị lỗi ở đây và trả về lỗi, thực tế nếu hệ thống bỏ qua bước này và cho tới bước update inventory thì có được hay không ? Thực tế, mọi trang thương mại điện tử hiện nay đều có thể xử lý lỗi thành công, miễn là cho user có trải nghiệm tốt là được. Nếu xảy ra lỗi. Các hệ thống sẽ trả cho user phần bù đắp thiệt hại cho user (1 vourcher chẳng hạn) chứ không nên để cho user đặt hàng không thành công.\nTrong hình ảnh tiếp theo, tôi đã cung cấp thêm thời gian phản hồi, có thể thấy mỗi 1 request sẽ mất 150ms\nGiả sử nhân viên B phụ trách tính năng update cart nhưng code yếu thì làm sao ? Tức là tính năng update cart được tính toán nhiều quá, không hiệu quả, và kết quả là bị tắc đường ở đó. Và tất nhiên hệ thống phải đồng bộ. Chẳng hạn khi có 10.000 users bị tắc nghẽn ở đó thì phải làm như thế nào ?\nVà một ngày nào đó, lượng users tăng cao, và cần thêm tính năng mới - Thống kê. Tính năng này thống kê điểm tích lũy cho user để có thể tặng quà cho những người mua hàng nhiều nhất, tích điểm,\u0026hellip; Thì khi thêm 1 tính năng bất kỳ, đồng nghĩa với việc sẽ tăng thêm thời gian phản hồi, nguy cơ tăng lỗi cũng sẽ cao hơn\nKiến trúc phân tán Có thể thấy, tất cả các order đều được đẩy vào Message Queue, và ngay lập tức trả về response cho user, không cần quan tâm tới những tác vụ còn lại. Và tất nhiên các tác vụ update cart, update inventory, save payment, save shopping vẫn được tiến hành và được tiến hành theo đúng trình tự.\nVà nhắc lại trường hợp khi nãy, giả sử tính năng update inventory bị lỗi thì chuyện gì sẽ xảy ra? Điều đầu tiên là sẽ không ảnh hưởng tới trải nghiệm người dùng, tiếp theo là message queue có cơ chế tự động sửa lỗi những message bị error, nếu cố gắng sửa đổi trong vòng (10) lần mà không thành công, khi đó sẽ đưa con người vào trực tiếp tham gia quá trình sửa đổi này\nTỉ lệ phản hồi thay vì 150ms như kiến trúc truyền thống thì sẽ chỉ mất 20ms + 5ms từ save order tới message queue, ngay lập tức phản hồi tới user\nTrong kiến trúc phân tán, ta có thể quy định hệ thống làm việc với cường độ 100 orders/time, đến khi nào order hết trong MQ, hay có thể nói là chỉ chỉ đưa cho 100 reqs để làm mà thôi, không được vội vàng, còn lại phải xếp hàng lần lượt, cứ như vậy cho đến hết.\nVà bây giờ, nếu lượng users tăng cao và cần thêm tính năng mới thì cũng không hề ảnh hưởng tới dây chuyền sản xuất\nNếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","permalink":"https://blog.nagih.io.vn/posts/kafka/","summary":"\u003cp\u003eGiới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\u003c/p\u003e","title":"Kafka"},{"content":" 1. Microservices là gì? Hãy tưởng tượng bạn đang xây một ngôi nhà.\nKiến trúc nguyên khối (Monolith): Bạn xây toàn bộ ngôi nhà bằng một khối bê tông khổng lồ duy nhất. Mọi thứ dính liền với nhau. Nếu bạn muốn sửa đường ống nước trong bếp, bạn có thể phải đục cả bức tường lớn, ảnh hưởng đến phòng khách bên cạnh.\nKiến trúc Microservices: Bạn xây ngôi nhà bằng những viên gạch LEGO. Mỗi phòng (phòng khách, phòng ngủ, nhà bếp) là một khối LEGO riêng. Nếu muốn sửa bếp, bạn chỉ cần nhấc khối LEGO \u0026ldquo;nhà bếp\u0026rdquo; ra, sửa nó, rồi đặt lại mà không ảnh hưởng gì đến các phòng khác.\nTrong phần mềm, kiến trúc microservices là phương pháp chia một ứng dụng lớn thành nhiều dịch vụ (service) nhỏ, độc lập. Mỗi service đảm nhiệm một chức năng cụ thể, có database riêng, và được phát triển, triển khai, nâng cấp độc lập với các service khác.\n2. Các Service giao tiếp với nhau ra sao? Có giống Frontend gọi tới Backend không? Đây là câu hỏi cốt lõi và quan trọng nhất. Các service (vốn là các backend) giao tiếp với nhau qua mạng. Có hai kiểu giao tiếp chính:\nGiao tiếp Đồng bộ (Synchronous) Giống như một cuộc gọi điện thoại. Service A gọi đến Service B và phải chờ Service B trả lời rồi mới làm việc tiếp.\nCách thức: Thường sử dụng các giao thức như REST API (qua HTTP/S) hoặc gRPC.\nVí dụ: Khi bạn đặt hàng, Service Đơn Hàng sẽ gọi trực tiếp đến Service Kho Hàng để hỏi \u0026ldquo;Sản phẩm X còn hàng không?\u0026rdquo;. Service Đơn Hàng sẽ phải đợi câu trả lời từ Service Kho Hàng rồi mới cho phép khách đặt hàng.\nGiống Frontend gọi Backend không? Về mặt kỹ thuật (dùng REST API) thì giống, nhưng bản chất là khác. Đây là giao tiếp giữa các backend với nhau (backend-to-backend), diễn ra bên trong hệ thống mà người dùng không nhìn thấy.\nGiao tiếp Bất đồng bộ (Asynchronous) Giống như gửi email hoặc tin nhắn. Service A gửi một \u0026ldquo;thông điệp\u0026rdquo; (message) cho Service B rồi tiếp tục công việc của mình ngay lập tức, không cần chờ B trả lời. Service B sẽ nhận và xử lý thông điệp đó khi nào sẵn sàng.\nCách thức: Sử dụng một hệ thống trung gian gọi là Message Broker (hoặc Message Queue) như RabbitMQ, Kafka.\nVí dụ: Sau khi bạn đặt hàng thành công, Service Đơn Hàng sẽ gửi một thông điệp có nội dung \u0026ldquo;Đơn hàng #123 đã được tạo\u0026rdquo; vào một hàng đợi (queue). Service Thông Báo sẽ lắng nghe hàng đợi này, thấy có thông điệp mới liền lấy ra và gửi email xác nhận cho bạn. Service Đơn Hàng không cần quan tâm Service Thông Báo đã gửi email hay chưa.\nƯu điểm: Giúp các service hoàn toàn độc lập (decoupled). Nếu Service Thông Báo bị lỗi, các đơn hàng vẫn được tạo bình thường, các thông điệp sẽ nằm chờ trong queue để được xử lý sau.\n3. Có phải Microservices là kiến trúc ở Backend? Frontend chỉ cần 1 service? Đúng vậy, Microservices chủ yếu là một kiến trúc cho phần backend. Tuy nhiên, việc có nhiều service backend nhỏ lẻ lại tạo ra một vấn đề cho frontend: \u0026ldquo;Frontend nên gọi đến service nào?\u0026rdquo;.\nKhông thể để frontend (ứng dụng web, mobile) gọi trực tiếp đến 10 service backend khác nhau. Điều này rất phức tạp, khó quản lý và không an toàn. Giải pháp phổ biến nhất là sử dụng một API Gateway.\nAPI Gateway là gì? Hãy coi API Gateway như một anh chàng lễ tân của toàn bộ hệ thống.\nFrontend chỉ cần nói chuyện với \u0026ldquo;anh lễ tân\u0026rdquo; này thôi.\n\u0026ldquo;Anh lễ tân\u0026rdquo; sẽ chịu trách nhiệm xác thực yêu cầu, sau đó xem xét yêu cầu này thuộc về phòng ban nào (service nào) và chuyển tiếp đến đúng nơi.\nNó cũng có thể tổng hợp thông tin từ nhiều service trước khi trả về cho frontend.\nVí dụ: Để hiển thị trang chi tiết sản phẩm, frontend chỉ cần gửi 1 yêu cầu duy nhất đến API Gateway. API Gateway sẽ tự động gọi đến Service Sản Phẩm để lấy thông tin sản phẩm và gọi đến Service Đánh Giá để lấy các bình luận, sau đó gộp hai kết quả này lại và trả về cho frontend.\nVậy câu trả lời là: Backend được chia thành nhiều microservices, và thường có một lớp API Gateway làm điểm vào duy nhất cho tất cả các client (web, mobile\u0026hellip;).\n4. Vấn đề về Dữ liệu: Mỗi Service một Database? Đây là một trong những quy tắc vàng và cũng là thách thức lớn nhất của microservices: Mỗi microservice phải sở hữu và quản lý cơ sở dữ liệu (database) của riêng mình.\nTại sao? Để đảm bảo tính độc lập tuyệt đối. Nếu Service A và Service B dùng chung một database, khi Service A muốn thay đổi cấu trúc bảng, nó có thể làm sập Service B. Như vậy thì không còn gọi là độc lập nữa.\nThách thức: Làm sao để thực hiện một nghiệp vụ yêu cầu dữ liệu từ nhiều service? Ví dụ: làm sao để đảm bảo khi tạo đơn hàng (Service Đơn Hàng) thì số lượng tồn kho (Service Kho Hàng) cũng phải được trừ đi một cách nhất quán?\nGiải pháp: Cần sử dụng các pattern nâng cao như Saga Pattern để quản lý các giao dịch phân tán (distributed transactions). Đây là một chủ đề phức tạp, nhưng ý tưởng cơ bản là mỗi service sẽ thực hiện phần việc của mình và phát ra sự kiện để service tiếp theo thực hiện phần việc của nó.\n","permalink":"https://blog.nagih.io.vn/posts/microservices/","summary":"","title":"Giới thiệu về kiến trúc Microservices"}]