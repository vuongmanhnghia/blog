[{"content":"Các vấn đề về kết nối Internet phổ biến và cách khắc phục chi tiết\nI. CHUẨN ĐOÁN VẤN ĐỀ Bước 1: Kiểm tra kết nối vật lý # Kiểm tra card mạng có được nhận diện không lspci | grep -i network lspci | grep -i ethernet lsusb | grep -i wireless # Kiểm tra interface có tồn tại không ip link show ifconfig -a Kết quả mong đợi: Thấy các interface như eth0, wlan0, enp0s3\nBước 2: Kiểm tra trạng thái Interface # Xem trạng thái chi tiết ip addr show nmcli device status # Kiểm tra interface có UP không ip link show eth0 # Thay eth0 bằng interface của bạn Phân tích kết quả\nUP: Interface đã bật\nDOWN: Interface bị tắt\nNO-CARRIER: Không có tín hiệu (Dây mạng rút, không có sóng Wifi)\nBước 3: Test kết nối từng lớp # Layer 1-2: Kiểm tra link local ping -c 3 127.0.0.1 # Layer 3: Kiểm tra gateway ip route show # Xem default gateway ping -c 3 \u0026lt;gateway-ip\u0026gt; # Ping gateway # Layer 3: Kiểm tra DNS server ping -c 3 1.1.1.1 # Ping IP trực tiếp (Cloudflared / Google) # Layer 4: Kiểm tra phân giải tên miền nslookup google.com ping -c 3 google.com Bước 4: Kiểm tra cấu hình mạng # Kiểm tra IP configuration ip addr show route -n # Kiểm tra DNS setting cat /etc/resolv.conf system-resolve --status # Kiểm tra DHCP sudo dhclient -v eth0 # Test DHCP renewal Bước 5: Kiểm tra service và process # Kiểm tra network services systemctl status NetworkManager systemctl status networking systemctl status systemd-networkd # Kiểm tra Firewall sudo ufw status sudo iptables -L -n # Kiểm tra process sử dụng network ss -tuln # Listening ports netstart -rn # Routing table Bước 6: Xem Logs và Error messages journalctl -u NetworkManager -f dmesg | grep -i network dmesg | grep -i eth dmesg | grep -i wlan # Kernal messages dmes | tail -20 tail -f var/log/syslog | grep -i network Ma trận chuẩn đoán nhanh Triệu chứng Lệnh kiểm tra Nguyên nhân có thể Không thấy interface ip link show Driver không có/sai Interface DOWN ip link show Interface bị disable Không có IP ip addr show DHCP fail, static config sai Ping localhost fail ping 127.0.0.1 Network stack broken Ping gateway fail ping \u0026lt;gateway\u0026gt; L2/L3 problem Ping IP OK, domain fail nslookup google.com DNS problem Kết nối chậm traceroute google.com Routing/bandwidth issue Scripts auto chuẩn đoán lỗi #!/bin/bash echo \u0026#34;=== NETWORK DIAGNOSTIC REPORT ===\u0026#34; echo \u0026#34;Date: $(date)\u0026#34; echo echo \u0026#34;1. NETWORK INTERFACES:\u0026#34; ip link show echo echo \u0026#34;2. IP ADDRESSES:\u0026#34; ip addr show echo echo \u0026#34;3. ROUTING TABLE:\u0026#34; ip route show echo echo \u0026#34;4. DNS CONFIGURATION:\u0026#34; cat /etc/resolv.conf echo echo \u0026#34;5. CONNECTIVITY TESTS:\u0026#34; echo -n \u0026#34;Localhost: \u0026#34; ping -c 1 -W 2 127.0.0.1 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; GATEWAY=$(ip route | grep default | awk \u0026#39;{print $3}\u0026#39; | head -1) if [ ! -z \u0026#34;$GATEWAY\u0026#34; ]; then echo -n \u0026#34;Gateway ($GATEWAY): \u0026#34; ping -c 1 -W 2 $GATEWAY \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; fi echo -n \u0026#34;External DNS (8.8.8.8): \u0026#34; ping -c 1 -W 2 8.8.8.8 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; echo -n \u0026#34;Domain resolution (google.com): \u0026#34; nslookup google.com \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; echo echo \u0026#34;6. ACTIVE SERVICES:\u0026#34; systemctl is-active NetworkManager 2\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;NetworkManager: Active\u0026#34; || echo \u0026#34;NetworkManager: Inactive\u0026#34; systemctl is-active networking 2\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;networking: Active\u0026#34; || echo \u0026#34;networking: Inactive\u0026#34; Chạy scripts\nchmod +x network-diagnostic.sh ./network-diagnostic.sh II. XỬ LÝ LỖI 1. Không kết nối được mạng Kiểm tra trạng thái mạng\nip link show ip addr show nmcli device status Khắc phục\n# Khởi động lại network manager sudo systemctl restart NetworkManager # Hoặc khởi động lại networking service sudo systemctl restart networking 2. Lỗi DNS không phân giải được Kiểm tra DNS\nnslookup google.com dig google.com cat /etc/resolv.conf Khắc phục\n# Thay đổi DNS server sudo nano /etc/resolv.conf # Thêm các dòng sau: # Cloudflared nameserver 1.1.1.1 nameserver 1.0.0.1 # Google nameserver 8.8.8.8 nameserver 8.8.4.4 3. Lỗi drive card mạng Kiểm tra drive\nlspci -nnk | grep -iA2 net lsusb # cho USB WiFi adapter dmesg | grep -i network Khắc phục\n# Cài đặt driver thiếu sudo apt update sudo apt install linux-firmware sudo apt install firmware-iwlwifi # cho Intel WiFi # Khởi động lại sudo modprobe -r iwlwifi \u0026amp;\u0026amp; sudo modprobe iwlwifi 4. Lỗi Wifi không kết nối được iwconfig nmcli dev wifi list rfkill list Khắc phục\n# Bật WiFi nếu bị tắt sudo rfkill unblock wifi # Kết nối WiFi nmcli dev wifi connect \u0026#34;TenWiFi\u0026#34; password \u0026#34;MatKhau\u0026#34; # Reset network settings sudo rm /var/lib/NetworkManager/NetworkManager.state sudo systemctl restart NetworkManager 5. Lỗi IP conflict hoặc không nhận được IP ip route show dhclient -v Khắc phục\n# Renew IP address sudo dhclient -r sudo dhclient # Hoặc reset network interface sudo ifdown eth0 \u0026amp;\u0026amp; sudo ifup eth0 6. Lỗi firewall chặn kết nối Kiểm tra firewall\nsudo ufw status sudo iptables -L Khắc phục\n# Tạm thời tắt firewall để test sudo ufw disable # Hoặc mở port cần thiết sudo ufw allow 80 sudo ufw allow 443 sudo ufw allow ssh 7. Lỗi proxy settings Kiểm tra proxy\necho $http_proxy echo $https_proxy cat /etc/environment Khắc phục\n# Xóa proxy settings unset http_proxy unset https_proxy unset HTTP_PROXY unset HTTPS_PROXY # Hoặc cấu hình đúng proxy export http_proxy=http://proxy-server:port export https_proxy=http://proxy-server:port 8. Lỗi MTU size Kiểm tra và fix MTU\n# Kiểm tra MTU hiện tại ip link show # Thay đổi MTU sudo ip link set dev eth0 mtu 1400 # Hoặc cấu hình vĩnh viễn trong /etc/network/interfaces III. RESET HOÀN TOÀN NETWORKING # Backup cấu hình cũ nếu cần sudo cp -r /etc/NetworkManager /etc/NetworkManager.backup # Reset NetworkManager sudo rm -rf /etc/NetworkManager/system-connections/* sudo systemctl stop NetworkManager sudo systemctl start NetworkManager # Hoặc reinstall network packages sudo apt remove --purge network-manager sudo apt install network-manager ","permalink":"https://blog.nagih.io.vn/posts/internet-errors/","summary":"\u003cp\u003eCác vấn đề về kết nối Internet phổ biến và cách khắc phục chi tiết\u003c/p\u003e","title":"Các vấn đề về Internet và cách khắc phục"},{"content":"Chia sẻ mẫu Documentation cho lập trình viên Backend\nE-Library Management System - Backend Documentation 📋 Table of Contents System Overview Architecture API Documentation Database Schema Authentication \u0026amp; Security Setup \u0026amp; Deployment Testing Monitoring \u0026amp; Logging 🎯 System Overview Project: E-Library Management System\nVersion: v2.1.0\nTech Stack: Node.js, Express.js, MongoDB, Redis, Docker\nPurpose: Backend API cho hệ thống quản lý thư viện sách điện tử\nCore Features User authentication \u0026amp; authorization\nBook catalog management\nBook borrowing/returning system\nSearch \u0026amp; filtering\nUser notifications\nAdmin dashboard APIs\n🏗️ Architecture High-Level Architecture ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ Client Apps │─ │ Load Balancer │──│ API Gateway │ └─────────────────┘ └─────────────────┘ └─────────────────┘ │ ┌─────────────────────────────┼─────────────────────────────┐ │ │ │ ┌───────▼───────┐ ┌───────▼───────┐ ┌───────▼───────┐ │ │ │ │ Auth Service │ │ Book Service │ │ User Service │ │ │ │ └───────────────┘ └───────────────┘ └────────────────┘ │ │ │ └─────────────────────────────┼─────────────────────────────┘ │ ┌─────────────────────────────┼─────────────────────────────┐ │ │ │ ┌───────▼───────┐ ┌───────▼───────┐ ┌───────▼───────┐ │ │ │ │ MongoDB │ │ Redis │ │ File Store │ │ │ │ │ (Primary) │ │ (Caching) │ │ (Images) │ │ │ │ └───────────────┘ └───────────────┘ └───────────────┘ Service Dependencies Auth Service: JWT token validation, user roles\nBook Service: Book CRUD operations, search, categorization\nUser Service: User profile management, borrowing history\nNotification Service: Email/SMS notifications\nFile Service: Book cover uploads, PDF handling\n📡 API Documentation Base URL Production: https://api.elibrary.com/v2 Staging: https://staging-api.elibrary.com/v2 Development: http://localhost:3000/v2 Authentication All protected endpoints require Bearer token:\nAuthorization: Bearer \u0026lt;jwt_token\u0026gt; Response Format { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Request processed successfully\u0026#34;, \u0026#34;data\u0026#34;: {}, \u0026#34;pagination\u0026#34;: { \u0026#34;page\u0026#34;: 1, \u0026#34;limit\u0026#34;: 20, \u0026#34;total\u0026#34;: 100, \u0026#34;totalPages\u0026#34;: 5 }, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } Error Response { \u0026#34;success\u0026#34;: false, \u0026#34;error\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;VALIDATION_ERROR\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Invalid request data\u0026#34;, \u0026#34;details\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Email format is invalid\u0026#34; } ] }, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } 🔐 Authentication Endpoints POST /auth/register Description: Đăng ký tài khoản mới\nRequest Body:\n{ \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;SecurePass123!\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;+84901234567\u0026#34; } Response (201):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;User registered successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;isVerified\u0026#34;: false }, \u0026#34;token\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34; } } POST /auth/login Description: Đăng nhập hệ thống\nRequest Body:\n{ \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;SecurePass123!\u0026#34; } Response (200):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Login successful\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; }, \u0026#34;token\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34;, \u0026#34;refreshToken\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34; } } 📚 Book Management Endpoints GET /books Description: Lấy danh sách sách với phân trang và filter\nQuery Parameters:\npage (integer, default: 1): Trang hiện tại limit (integer, default: 20): Số sách per page category (string): Filter theo danh mục author (string): Filter theo tác giả search (string): Tìm kiếm theo title/author available (boolean): Chỉ lấy sách còn available Example Request:\nGET /books?page=1\u0026amp;limit=10\u0026amp;category=fiction\u0026amp;available=true Response (200):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;data\u0026#34;: { \u0026#34;books\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;The Great Gatsby\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;F. Scott Fitzgerald\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-0743273565\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;fiction\u0026#34;, \u0026#34;publishYear\u0026#34;: 1925, \u0026#34;description\u0026#34;: \u0026#34;A classic American novel...\u0026#34;, \u0026#34;coverImage\u0026#34;: \u0026#34;https://cdn.elibrary.com/covers/great-gatsby.jpg\u0026#34;, \u0026#34;totalCopies\u0026#34;: 5, \u0026#34;availableCopies\u0026#34;: 3, \u0026#34;rating\u0026#34;: 4.5, \u0026#34;createdAt\u0026#34;: \u0026#34;2025-09-01T10:00:00.000Z\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2025-09-15T14:30:00.000Z\u0026#34; } ] }, \u0026#34;pagination\u0026#34;: { \u0026#34;page\u0026#34;: 1, \u0026#34;limit\u0026#34;: 10, \u0026#34;total\u0026#34;: 156, \u0026#34;totalPages\u0026#34;: 16 } } POST /books Description: Thêm sách mới (Admin only)\nAuthentication: Required (Admin role)\nRequest Body:\n{ \u0026#34;title\u0026#34;: \u0026#34;New Book Title\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Author Name\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-1234567890\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;science\u0026#34;, \u0026#34;publishYear\u0026#34;: 2024, \u0026#34;description\u0026#34;: \u0026#34;Book description here...\u0026#34;, \u0026#34;totalCopies\u0026#34;: 3, \u0026#34;coverImage\u0026#34;: \u0026#34;base64_encoded_image_or_url\u0026#34; } Response (201):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book created successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;book\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123457\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;New Book Title\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Author Name\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-1234567890\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;science\u0026#34;, \u0026#34;publishYear\u0026#34;: 2024, \u0026#34;description\u0026#34;: \u0026#34;Book description here...\u0026#34;, \u0026#34;totalCopies\u0026#34;: 3, \u0026#34;availableCopies\u0026#34;: 3, \u0026#34;rating\u0026#34;: 0, \u0026#34;createdAt\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } } } PUT /books/:bookId Description: Cập nhật thông tin sách (Admin only)\nAuthentication: Required (Admin role)\nDELETE /books/:bookId Description: Xóa sách (Admin only)\nAuthentication: Required (Admin role)\n📖 Borrowing System Endpoints POST /borrowings Description: Mượn sách\nAuthentication: Required\nRequest Body:\n{ \u0026#34;bookId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;borrowDuration\u0026#34;: 14 } Response (201):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book borrowed successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;borrowing\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123458\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;bookId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;borrowDate\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34;, \u0026#34;dueDate\u0026#34;: \u0026#34;2025-09-30T10:30:00.000Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;active\u0026#34;, \u0026#34;renewalCount\u0026#34;: 0 } } } PUT /borrowings/:borrowingId/return Description: Trả sách\nAuthentication: Required\nResponse (200):\n{ \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book returned successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;borrowing\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123458\u0026#34;, \u0026#34;returnDate\u0026#34;: \u0026#34;2025-09-16T15:45:00.000Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;returned\u0026#34;, \u0026#34;lateFee\u0026#34;: 0 } } } GET /borrowings/my-books Description: Lấy danh sách sách đang mượn của user\nAuthentication: Required\n🗄️ Database Schema Users Collection { _id: ObjectId, email: String (unique, required), password: String (hashed, required), firstName: String (required), lastName: String (required), phoneNumber: String, role: String (enum: [\u0026#39;user\u0026#39;, \u0026#39;librarian\u0026#39;, \u0026#39;admin\u0026#39;], default: \u0026#39;user\u0026#39;), isVerified: Boolean (default: false), avatar: String, address: { street: String, city: String, zipCode: String }, preferences: { notifications: { email: Boolean (default: true), sms: Boolean (default: false) }, favoriteCategories: [String] }, createdAt: Date, updatedAt: Date } Books Collection { _id: ObjectId, title: String (required, indexed), author: String (required, indexed), isbn: String (unique, required), category: String (required, indexed), publishYear: Number, publisher: String, language: String (default: \u0026#39;vietnamese\u0026#39;), description: String, coverImage: String, pdfFile: String, totalCopies: Number (required, min: 1), availableCopies: Number (required), rating: Number (default: 0), reviewCount: Number (default: 0), tags: [String], createdAt: Date, updatedAt: Date, createdBy: ObjectId (ref: \u0026#39;User\u0026#39;) } Borrowings Collection { _id: ObjectId, userId: ObjectId (ref: \u0026#39;User\u0026#39;, required), bookId: ObjectId (ref: \u0026#39;Book\u0026#39;, required), borrowDate: Date (required), dueDate: Date (required), returnDate: Date, status: String (enum: [\u0026#39;active\u0026#39;, \u0026#39;returned\u0026#39;, \u0026#39;overdue\u0026#39;], required), renewalCount: Number (default: 0, max: 2), lateFee: Number (default: 0), notes: String, createdAt: Date, updatedAt: Date } Categories Collection { _id: ObjectId, name: String (required, unique), slug: String (required, unique), description: String, parentCategory: ObjectId (ref: \u0026#39;Category\u0026#39;), isActive: Boolean (default: true), sortOrder: Number (default: 0), createdAt: Date, updatedAt: Date } 🔒 Authentication \u0026amp; Security JWT Configuration { secret: process.env.JWT_SECRET, algorithm: \u0026#39;HS256\u0026#39;, expiresIn: \u0026#39;24h\u0026#39;, refreshTokenExpiresIn: \u0026#39;7d\u0026#39; } Password Requirements Minimum 8 characters At least 1 uppercase letter At least 1 lowercase letter At least 1 number At least 1 special character Rate Limiting { \u0026#34;/auth/login\u0026#34;: \u0026#34;5 requests per 15 minutes per IP\u0026#34;, \u0026#34;/auth/register\u0026#34;: \u0026#34;3 requests per hour per IP\u0026#34;, \u0026#34;/books\u0026#34;: \u0026#34;100 requests per 15 minutes per user\u0026#34;, \u0026#34;/borrowings\u0026#34;: \u0026#34;20 requests per hour per user\u0026#34; } CORS Configuration { origin: [ \u0026#39;https://elibrary.com\u0026#39;, \u0026#39;https://admin.elibrary.com\u0026#39;, \u0026#39;http://localhost:3000\u0026#39; // development only ], methods: [\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;, \u0026#39;PUT\u0026#39;, \u0026#39;DELETE\u0026#39;], allowedHeaders: [\u0026#39;Content-Type\u0026#39;, \u0026#39;Authorization\u0026#39;] } ⚙️ Setup \u0026amp; Deployment Environment Variables # Database MONGODB_URI=mongodb://localhost:27017/elibrary REDIS_URL=redis://localhost:6379 # Authentication JWT_SECRET=your-super-secret-jwt-key JWT_EXPIRES_IN=24h REFRESH_TOKEN_SECRET=your-refresh-token-secret # External Services EMAIL_SERVICE_API_KEY=your-email-service-key SMS_SERVICE_API_KEY=your-sms-service-key CLOUDINARY_URL=cloudinary://your-cloudinary-url # Server PORT=3000 NODE_ENV=production Development Setup # 1. Clone repository git clone https://github.com/company/elibrary-backend.git cd elibrary-backend # 2. Install dependencies npm install # 3. Copy environment file cp .env.example .env # 4. Start MongoDB and Redis docker-compose up -d mongo redis # 5. Run database migrations npm run migrate # 6. Start development server npm run dev Docker Deployment # docker-compose.prod.yml version: \u0026#39;3.8\u0026#39; services: app: build: . ports: - \u0026#34;3000:3000\u0026#34; environment: - NODE_ENV=production - MONGODB_URI=mongodb://mongo:27017/elibrary - REDIS_URL=redis://redis:6379 depends_on: - mongo - redis mongo: image: mongo:6.0 volumes: - mongo_data:/data/db environment: MONGO_INITDB_ROOT_USERNAME: admin MONGO_INITDB_ROOT_PASSWORD: password redis: image: redis:7-alpine volumes: - redis_data:/data volumes: mongo_data: redis_data: CI/CD Pipeline (GitHub Actions) name: Deploy to Production on: push: branches: [main] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-node@v3 with: node-version: \u0026#39;18\u0026#39; - run: npm ci - run: npm test deploy: needs: test runs-on: ubuntu-latest steps: - name: Deploy to server run: | ssh user@server \u0026#34;cd /app \u0026amp;\u0026amp; git pull \u0026amp;\u0026amp; docker-compose up -d --build\u0026#34; 🧪 Testing Test Structure tests/ ├── unit/ │ ├── controllers/ │ ├── services/ │ └── utils/ ├── integration/ │ ├── auth.test.js │ ├── books.test.js │ └── borrowings.test.js └── e2e/ └── api.test.js Running Tests # Unit tests npm run test:unit # Integration tests npm run test:integration # E2E tests npm run test:e2e # All tests with coverage npm run test:coverage Test Example // tests/integration/books.test.js describe(\u0026#39;Books API\u0026#39;, () =\u0026gt; { beforeEach(async () =\u0026gt; { await Book.deleteMany({}); await User.deleteMany({}); // Create test user and admin testUser = await User.create({ email: \u0026#39;test@example.com\u0026#39;, password: \u0026#39;hashedpassword\u0026#39;, firstName: \u0026#39;Test\u0026#39;, lastName: \u0026#39;User\u0026#39; }); userToken = jwt.sign({ userId: testUser._id }, process.env.JWT_SECRET); }); describe(\u0026#39;GET /books\u0026#39;, () =\u0026gt; { it(\u0026#39;should return paginated books\u0026#39;, async () =\u0026gt; { // Create test books await Book.create([ { title: \u0026#39;Book 1\u0026#39;, author: \u0026#39;Author 1\u0026#39;, isbn: \u0026#39;1111111111\u0026#39; }, { title: \u0026#39;Book 2\u0026#39;, author: \u0026#39;Author 2\u0026#39;, isbn: \u0026#39;2222222222\u0026#39; } ]); const response = await request(app) .get(\u0026#39;/v2/books?page=1\u0026amp;limit=10\u0026#39;) .expect(200); expect(response.body.success).toBe(true); expect(response.body.data.books).toHaveLength(2); expect(response.body.pagination.total).toBe(2); }); }); }); 📊 Monitoring \u0026amp; Logging Logging Configuration // config/logger.js const winston = require(\u0026#39;winston\u0026#39;); const logger = winston.createLogger({ level: process.env.LOG_LEVEL || \u0026#39;info\u0026#39;, format: winston.format.combine( winston.format.timestamp(), winston.format.errors({ stack: true }), winston.format.json() ), transports: [ new winston.transports.File({ filename: \u0026#39;logs/error.log\u0026#39;, level: \u0026#39;error\u0026#39; }), new winston.transports.File({ filename: \u0026#39;logs/combined.log\u0026#39; }), new winston.transports.Console({ format: winston.format.simple() }) ] }); Metrics Collection Response Time: Average API response time Request Rate: Requests per second Error Rate: 4xx/5xx error percentage Database Connection: MongoDB connection pool status Memory Usage: Node.js heap usage Active Users: Currently logged in users Health Check Endpoint // GET /health { \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34;, \u0026#34;services\u0026#34;: { \u0026#34;database\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;redis\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;external_apis\u0026#34;: \u0026#34;operational\u0026#34; }, \u0026#34;metrics\u0026#34;: { \u0026#34;uptime\u0026#34;: \u0026#34;72h 15m\u0026#34;, \u0026#34;memory_usage\u0026#34;: \u0026#34;245MB\u0026#34;, \u0026#34;cpu_usage\u0026#34;: \u0026#34;15%\u0026#34; } } Alerting Rules Response time \u0026gt; 2000ms for 5 minutes Error rate \u0026gt; 5% for 3 minutes Database connection lost Memory usage \u0026gt; 80% Disk space \u0026lt; 10% 📈 Error Codes Reference Code HTTP Status Description VALIDATION_ERROR 400 Request validation failed UNAUTHORIZED 401 Invalid or missing authentication FORBIDDEN 403 Insufficient permissions NOT_FOUND 404 Resource not found CONFLICT 409 Resource already exists RATE_LIMIT_EXCEEDED 429 Too many requests INTERNAL_ERROR 500 Server error SERVICE_UNAVAILABLE 503 External service unavailable 🔄 Changelog v2.1.0 (2025-09-16) Added\nBook rating and review system Advanced search with filters PDF file upload for digital books Notification system for due dates Changed\nImproved authentication with refresh tokens Enhanced error handling and logging Updated database schema for better performance Fixed\nMemory leaks in file upload Race condition in book borrowing Timezone issues in due date calculations v2.0.0 (2025-08-01) Added\nComplete API redesign Role-based access control Redis caching layer Docker containerization 📞 Support \u0026amp; Contact Development Team: backend-team@company.com DevOps Team: devops@company.com Documentation: https://docs.elibrary.com Issue Tracker: https://github.com/company/elibrary-backend/issues Last updated: September 16, 2025\n","permalink":"https://blog.nagih.io.vn/posts/backend-documentation/","summary":"\u003cp\u003eChia sẻ mẫu Documentation cho lập trình viên Backend\u003c/p\u003e","title":"Mẫu Documentation cho Backend"},{"content":"biến SSH từ một công cụ kết nối đơn thuần thành một hệ thống quản lý danh tính hiệu quả\nGiới thiệu ~/.ssh/config File ~/.ssh/config cho phép bạn tạo các bí danh (alias) và các quy tắc kết nối cụ thể cho từng máy chủ. Thay vì phải gõ các lệnh dài dòng với các tùy chọn phức tạp, bạn có thể định nghĩa tất cả trong file này. Cấu trúc của file bao gồm các khối Host, mỗi khối chứa các chỉ thị áp dụng cho host đó.\nKịch bản: Quản lý nhiều tài khoản GitHub (Cá nhân \u0026amp; Công việc) Đây là một kịch bản rất phổ biến. Mục tiêu là có thể làm việc trên các kho lưu trữ của cả hai tài khoản trên cùng một máy tính mà không cần phải thay đổi cấu hình thủ công mỗi lần chuyển đổi.\nTạo khóa SSH thứ hai:\nHãy chắc chắn rằng bạn đã tạo 1 cặp khóa mới dành cho công việc và đặt một tên file khác biệt, ví dụ: id_ed25519_work. Sau đó, thêm khóa công khai này vào tài khoản GitHub công việc.\nCấu hình ~/.ssh/config:\nMở file ~/.ssh/config (nếu chưa có, hãy tạo nó) và thêm vào nội dung sau:\n# Tài khoản GitHub cá nhân Host github.com-personal HostName github.com User git IdentityFile ~/.ssh/id_ed25519_personal IdentitiesOnly yes # Tài khoản GitHub công việc Host github.com-work HostName github.com User git IdentityFile ~/.ssh/id_ed25519_work IdentitiesOnly yes Phân tích Host github.com-personal: Đây là bí danh (alias) bạn sẽ sử dụng. Khi Git hoặc SSH thấy host này, nó sẽ áp dụng các quy tắc bên dưới.\nHostName github.com: Đây là tên máy chủ thực tế mà SSH sẽ kết nối đến.\nUser git: GitHub yêu cầu tất cả các kết nối SSH sử dụng user git.\nIdentityFile ~/.ssh/id_ed25519_personal: Yêu cầu SSH sử dụng file khóa riêng tư cụ thể này để xác thực.\nIdentitiesOnly yes: Cực kỳ quan trọng. Theo mặc định, SSH client có thể thử tất cả các khóa có sẵn trong ssh-agent hoặc các file mặc định. Khi kết nối đến GitHub, nếu gửi sai khóa, kết nối có thể bị từ chối sau vài lần thử. IdentitiesOnly yes buộc SSH client chỉ sử dụng duy nhất khóa được chỉ định trong IdentityFile cho host này, loại bỏ sự mơ hồ và ngăn ngừa lỗi xác thực.\nÁp dụng cấu hình vào Git Sau khi đã cấu hình ~/.ssh/config, bạn cần cập nhật URL của các kho lưu trữ Git để chúng sử dụng các bí danh mới.\nĐối với kho lưu trữ mới (khi git clone): Thay vì sử dụng URL SSH mặc định, hãy thay thế github.com bằng bí danh bạn đã tạo.\n# Clone kho lưu trữ công việc $ git clone git@github.com-work:work-organization/project.git Đối với kho lưu trữ đã có: Sử dụng lệnh git remote set-url để cập nhật URL của remote origin.\n# Điều hướng đến thư mục kho lưu trữ công việc của bạn $ cd path/to/work/project # Cập nhật URL của remote $ git remote set-url origin git@github.com-work:work-organization/project.git Bạn có thể kiểm tra lại bằng lệnh git remote -v.\nVới thiết lập này, quy trình làm việc của bạn sẽ trở nên hoàn toàn tự động. Khi bạn ở trong một thư mục dự án công việc, các lệnh Git sẽ tự động sử dụng khóa công việc. Khi ở trong dự án cá nhân, chúng sẽ sử dụng khóa cá nhân.\n","permalink":"https://blog.nagih.io.vn/posts/all-in-one/","summary":"\u003cp\u003ebiến SSH từ một công cụ kết nối đơn thuần thành một hệ thống quản lý danh tính hiệu quả\u003c/p\u003e","title":"Hướng dẫn quản lý nhiều khóa SSH trên 1 thiết bị"},{"content":"Hướng dẫn chi tiết từng bước để tạo và cấu hình khóa SSH cho tài khoản GitHub của bạn.\nBước 1: Tạo Cặp Khóa SSH với ssh-keygen Lựa chọn Thuật toán Mã hóa Việc lựa chọn thuật toán mã hóa là một quyết định quan trọng ảnh hưởng đến cả hiệu suất và bảo mật.\nEd25519 (Khuyến nghị): Đây là thuật toán hiện đại, được khuyến nghị sử dụng. Ed25519 cung cấp mức độ bảo mật rất cao với độ dài khóa ngắn hơn, giúp quá trình xác thực diễn ra nhanh hơn.\n$ ssh-keygen -t ed25519 -C \u0026#34;your_email@example.com\u0026#34; RSA (Lựa chọn thay thế): RSA là một thuật toán cũ. Nếu bạn cần hỗ trợ các hệ thống cũ không tương thích với Ed25519. Tuy nhiên, điều cực kỳ quan trọng là phải sử dụng độ dài khóa đủ lớn. Mức khuyến nghị tối thiểu hiện nay là 4096 bits để đảm bảo an toàn.\n$ ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; Trong quá trình tạo khóa, bạn sẽ được nhắc nhập một \u0026ldquo;passphrase\u0026rdquo;. Đây là một lớp bảo vệ cực kỳ quan trọng và rất nên được sử dụng. Passphrase này sẽ mã hóa file khóa riêng tư của bạn trên đĩa. Điều này có nghĩa là, ngay cả khi máy tính của bạn bị đánh cắp và kẻ tấn công có được file khóa riêng tư, họ cũng không thể sử dụng nó nếu không biết passphrase. Đây là tuyến phòng thủ cuối cùng để bảo vệ danh tính số của bạn.\nLưu khóa và Đặt tên file tùy chỉnh Theo mặc định, ssh-keygen sẽ lưu cặp khóa vào thư mục ~/.ssh/ với tên file là id_ed25519 và id_ed25519.pub (hoặc id_rsa cho RSA). Mặc dù bạn có thể chấp nhận giá trị mặc định. Đặc biệt khi bạn dự định quản lý nhiều khóa cho các tài khoản khác nhau. Ví dụ, bạn có thể đặt tên là ~/.ssh/id_ed25519_personal cho tài khoản cá nhân và ~/.ssh/id_ed25519_work cho tài khoản công việc. Điều này sẽ giúp việc quản lý trở nên dễ dàng hơn ở các bước nâng cao.\nBước 2: Quản Lý Khóa với ssh-agent Khởi động ssh-agent:\nChạy lệnh sau trong terminal để khởi động agent cho phiên làm việc hiện tại của bạn.\n$ eval \u0026#34;$(ssh-agent -s)\u0026#34; Thêm khóa riêng tư vào ssh-agent:\nSử dụng lệnh ssh-add để thêm khóa riêng tư của bạn vào agent. Bạn sẽ được yêu cầu nhập passphrase mà bạn đã tạo ở Bước 1.\n$ ssh-add ~/.ssh/your_private_key_filename Bước 3: Thêm Khóa Công Khai (Public Key) vào Tài Khoản GitHub Sao chép nội dung khóa công khai:\nmacOS:\n$ pbcopy \u0026lt; ~/.ssh/id_ed25519_personal.pub Windows (sử dụng Git Bash hoặc WSL):\n$ cat ~/.ssh/id_ed25519_personal.pub | clip Thêm khóa vào GitHub:\nTruy cập tài khoản GitHub của bạn trên trình duyệt.\nVào Settings (Cài đặt)\nTrong thanh bên trái, chọn SSH and GPG keys (Khóa SSH và GPG).\nNhấp vào nút New SSH key (Khóa SSH mới).\nTrong trường Title, đặt một cái tên mang tính mô tả cho khóa của bạn (ví dụ: \u0026ldquo;MacBook Pro Cá Nhân\u0026rdquo;).\nTrong trường Key, dán nội dung khóa công khai bạn đã sao chép.\nNhấp vào Add SSH key (Thêm khóa SSH) để hoàn tất.\nBước 4: Kiểm Tra Kết Nối Chạy lệnh kiểm tra:\n$ ssh -T git@github.com Xác thực máy chủ (lần đầu tiên):\nThe authenticity of host \u0026#39;github.com (IP_ADDRESS)\u0026#39; can\u0026#39;t be established. ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU. Are you sure you want to continue connecting (yes/no)? Đây là một tính năng bảo mật của SSH để chống lại các cuộc tấn công xen giữa (man-in-the-middle). Sau khi xác nhận, gõ yes và nhấn Enter.\nKết quả thành công:\nHi username! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. Điều này xác nhận rằng cặp khóa SSH của bạn đã được thiết lập chính xác và GitHub đã xác thực thành công danh tính của bạn.\n","permalink":"https://blog.nagih.io.vn/posts/setup-ssh/","summary":"\u003cp\u003eHướng dẫn chi tiết từng bước để tạo và cấu hình khóa SSH cho tài khoản GitHub của bạn.\u003c/p\u003e","title":"Hướng dẫn thiết lập khóa SSH cho github"},{"content":"Ngay cả với một thiết lập cẩn thận, các vấn đề vẫn có thể phát sinh. Việc hiểu rõ cách chẩn đoán và khắc phục các lỗi SSH phổ biến là một kỹ năng quan trọng.\nChế độ Verbose Trước khi thử bất kỳ giải pháp nào, bước đầu tiên luôn là thu thập thêm thông tin. Tùy chọn -v (verbose) của lệnh ssh sẽ in ra chi tiết quá trình kết nối, cho bạn biết file cấu hình nào đang được đọc, khóa nào đang được thử, và chính xác lỗi xảy ra ở đâu.\n$ ssh -vT git@github.com Error 1: Permission denied (publickey) Ý nghĩa: Đây là lỗi xác thực phổ biến nhất. Nó có nghĩa là máy chủ GitHub đã từ chối tất cả các khóa SSH mà client của bạn cung cấp.\nCác bước kiểm tra và khắc phục:\nKiểm tra khóa trên GitHub: Đảm bảo rằng khóa công khai của bạn đã được thêm chính xác vào tài khoản GitHub.\nKiểm tra ssh-agent: Chạy ssh-add -l để xem các khóa hiện có trong agent. Nếu danh sách trống hoặc không chứa khóa bạn cần, hãy chạy lại ssh-add ~/.ssh/your_private_key để thêm nó vào.\nKiểm tra quyền truy cập file: SSH yêu cầu quyền truy cập rất nghiêm ngặt. Thư mục ~/.ssh phải có quyền là 700 (drwx−−−−−−), và file khóa riêng tư của bạn phải có quyền là 600 (−rw−−−−−−−). Sử dụng các lệnh sau để sửa:\n$ chmod 700 ~/.ssh $ chmod 600 ~/.ssh/your_private_key Kiểm tra ~/.ssh/config: Nếu bạn đang sử dụng file cấu hình, hãy kiểm tra kỹ lưỡng xem Host alias có khớp với URL remote của Git không, và IdentityFile có trỏ đến đúng file khóa riêng tư không.\nError 2: Host key verification failed Ý nghĩa: Dấu vân tay của máy chủ GitHub đã thay đổi so với lần cuối bạn kết nối. Đây là một cơ chế bảo mật quan trọng để cảnh báo về khả năng có một cuộc tấn công Man-in-the-Middle.\nCách khắc phục an toàn:\nKhông bao giờ bỏ qua cảnh báo này một cách mù quáng.\nTruy cập trang tài liệu chính thức của GitHub để xác minh dấu vân tay máy chủ mới nhất của họ.\nNếu dấu vân tay khớp, bạn có thể an toàn xóa khóa cũ khỏi file ~/.ssh/known_hosts bằng lệnh:\n$ ssh-keygen -R github.com Error 3: Agent admitted failure to sign using the key Ý nghĩa: ssh-agent đang chạy nhưng không thể sử dụng khóa để tạo chữ ký số cần thiết cho việc xác thực. Lỗi này đôi khi xảy ra trên các hệ thống Linux.\nCách khắc phục: Giải pháp thường rất đơn giản là tải lại khóa vào agent. Chạy lệnh ssh-add thường sẽ giải quyết được vấn đề này.\nError 4: Key is already in use Ý nghĩa: Bạn đang cố gắng thêm một khóa công khai vào tài khoản GitHub, nhưng khóa đó đã được sử dụng ở một nơi khác - hoặc trên một tài khoản người dùng khác, hoặc trong một kho lưu trữ khác dưới dạng \u0026ldquo;deploy key\u0026rdquo;.\nNguyên tắc: Một khóa SSH phải là định danh duy nhất cho một người dùng trên toàn bộ nền tảng GitHub. Khi được sử dụng làm deploy key, nó cũng phải là duy nhất cho mỗi kho lưu trữ.\nCách khắc phục:\nSử dụng lệnh sau để xác định tài khoản nào đang sử dụng khóa đó:\n$ ssh -T -ai ~/.ssh/your_key git@github.com Gỡ khóa khỏi tài khoản hoặc kho lưu trữ cũ, hoặc đơn giản là tạo một cặp khóa hoàn toàn mới cho mục đích sử dụng mới.\nError 5: Các Phương Pháp Bảo Mật Tốt Nhất (Best Practices) và Tổng Kết Làm chủ SSH không chỉ dừng lại ở việc thiết lập thành công. Việc duy trì một tư thế bảo mật vững chắc đòi hỏi sự chú ý liên tục. Các phương pháp tốt nhất có thể được tóm gọn trong một vòng đời bảo mật của khóa SSH.\nVòng Đời Bảo Mật Của Khóa SSH Tạo (Creation):\nThuật toán mạnh: Luôn ưu tiên sử dụng Ed25519 vì hiệu suất và bảo mật vượt trội.\nPassphrase mạnh: Luôn đặt một passphrase mạnh và duy nhất cho mỗi khóa. Sử dụng trình quản lý mật khẩu để lưu trữ an toàn các passphrase này.\nBảo vệ (Protection):\nQuyền truy cập file: Duy trì quyền truy cập file chính xác là điều bắt buộc: chmod 700 ~/.ssh và chmod 600 ~/.ssh/private_key.\nBí mật tuyệt đối: Không bao giờ chia sẻ, gửi qua email, hoặc lưu trữ khóa riêng tư của bạn ở bất kỳ đâu ngoài máy tính cá nhân đã được bảo vệ. Chỉ có khóa công khai là an toàn để chia sẻ.\nSử dụng (Usage):\nSử dụng ssh-agent: Tận dụng ssh-agent để giảm thiểu số lần phải nhập passphrase, qua đó giảm nguy cơ bị keylogger ghi lại.\nCấu hình timeout cho agent: Để tăng cường bảo mật, hãy đặt thời gian tồn tại cho các khóa trong agent bằng tùy chọn -t. Lệnh ssh-add -t 3600 sẽ yêu cầu agent \u0026ldquo;quên\u0026rdquo; khóa sau một giờ (3600 giây) không hoạt động. Điều này cực kỳ hữu ích để bảo vệ chống lại việc truy cập trái phép nếu máy tính của bạn bị bỏ lại mà không được khóa.\nBảo trì (Maintenance):\nKiểm tra định kỳ (Audit): Lên lịch (ví dụ: hàng quý) để truy cập trang cài đặt SSH trên GitHub và xem lại danh sách các khóa đã được cấp quyền. Xóa ngay lập tức bất kỳ khóa nào bạn không nhận ra, không còn sử dụng, hoặc thuộc về các thiết bị đã mất.\nXoay vòng khóa (Rotation): Một thực hành bảo mật nâng cao là định kỳ tạo một cặp khóa mới và thay thế các khóa cũ. Việc này giới hạn \u0026ldquo;cửa sổ cơ hội\u0026rdquo; cho một kẻ tấn công nếu một khóa cũ bị xâm phạm mà bạn không hề hay biết.\n","permalink":"https://blog.nagih.io.vn/posts/error-handler/","summary":"\u003cp\u003eNgay cả với một thiết lập cẩn thận, các vấn đề vẫn có thể phát sinh. Việc hiểu rõ cách chẩn đoán và khắc phục các lỗi SSH phổ biến là một kỹ năng quan trọng.\u003c/p\u003e","title":"Hướng dẫn xử lý sự cố và các lỗi thường gặp khi thiết lập SSH"},{"content":"Những hạn chế của xác thực qua HTTPS và sự thay thế SSH\nTrong hệ sinh thái phát triển phần mềm hiện đại, GitHub không chỉ là một kho lưu trữ mã nguồn mà còn là trung tâm cộng tác, quản lý dự án và triển khai ứng dụng. Việc tương tác hiệu quả và an toàn với nền tảng này là một kỹ năng cơ bản đối với mọi nhà phát triển. Mặc dù HTTPS cung cấp một phương thức kết nối ban đầu đơn giản, việc chuyển sang sử dụng giao thức SSH (Secure Shell) là một bước tiến quan trọng, không chỉ nâng cao đáng kể mức độ bảo mật mà còn tối ưu hóa quy trình làm việc hàng ngày.\n1. Những Hạn Chế của Xác thực qua HTTPS Khi bắt đầu với Git và GitHub, hầu hết người dùng đều chọn HTTPS vì sự đơn giản của nó. Tuy nhiên, phương thức này có những hạn chế cố hữu. Xác thực qua HTTPS yêu cầu sử dụng Personal Access Token (PAT), một chuỗi ký tự hoạt động tương tự như mật khẩu.\nMặc dù dễ thiết lập, quy trình này bộc lộ sự bất tiện trong quá trình sử dụng lâu dài. Git sẽ thường xuyên yêu cầu người dùng nhập thông tin xác thực, làm gián đoạn luồng công việc. Mặc dù các công cụ hỗ trợ quản lý thông tin đăng nhập (credential helpers) có thể lưu trữ token, nhưng chúng lại đặt ra một vấn đề khác về mức độ an toàn của việc lưu trữ này. Quan trọng hơn, một PAT bị rò rỉ có thể cấp cho kẻ tấn công quyền truy cập không chỉ vào các kho lưu trữ mà còn có thể vào toàn bộ tài khoản GitHub, tùy thuộc vào phạm vi quyền hạn được cấp cho token đó.\nSo Sánh Nhanh: HTTPS và SSH trên GitHub Để tóm tắt những khác biệt chính, bảng dưới đây cung cấp một cái nhìn tổng quan về hai phương thức xác thực.\nTiêu chí HTTPS (với Personal Access Token) SSH Cơ chế Xác thực Dựa trên token (hoạt động như mật khẩu) Cặp khóa Public/Private (mật mã bất đối xứng) Mức độ Bảo mật Dễ bị lộ nếu token không được bảo vệ cẩn thận Rất cao; khóa riêng tư không bao giờ truyền qua mạng Sự tiện lợi Yêu cầu nhập lại token hoặc phụ thuộc vào credential helper Rất tiện lợi sau khi thiết lập, không cần nhập lại thông tin Thiết lập ban đầu Đơn giản, chỉ cần tạo token Phức tạp hơn một chút, yêu cầu tạo và quản lý cặp khóa Quản lý Truy cập Phân quyền thông qua phạm vi của token trên GitHub Có thể quản lý truy cập chi tiết qua từng khóa riêng lẻ ","permalink":"https://blog.nagih.io.vn/posts/https--ssh/","summary":"\u003cp\u003eNhững hạn chế của xác thực qua HTTPS và sự thay thế SSH\u003c/p\u003e","title":"SSH - Github"},{"content":"Sử dụng triết lý của Nix ứng dụng trong việc triển khai môi trường lập trình ứng dụng sao cho tối ưu và tốt nhất.\nTrong bài viết này, tôi sẽ hướng dẫn các bạn setup môi trường lập trình ứng dụng trên NixOS bằng IntelliJ IDEA và Nix Flakes thay vì sử dụng Android Studio. Đây là quy trình hiệu quả và phù hợp với triết lý của NixOS\nQuá trình này quản lý 2 nguyên tắc cốt lõi của NixOS\nQuản lý hệ thống bằng cách khai báo (Declarative System Management): Mọi package, phần mềm, cấu hình hệ thống được define trong file configuration.nix, giúp hệ thống luôn có thể tái tạo và có tính nhất quán\nMôi trường phát triển biệt lập (Isolated Development Environments): Sử dụng nix-shell để tạo ra môi trường chứa chính xác phiên bản của các công cụ đã được define cho từng project mà không làm ảnh hưởng tới hệ thống chính\nCác bước tiến hành Bước 1: Cài đặt các công cụ cơ bản trên hệ thống Điều đầu tiên, vì sử dụng IntelliJ IDEA nên bắt buộc rằng nó được cài trên hệ thống của bạn và đã bật tính năng Flakes của NixOS\nMở file cấu hình hệ thống NixOS của bạn\nThêm package jetbrains.idea-community hoặc idea-ultimate(nếu có premium) vào danh sách environment.systemPackages\nTrong bước này có thể thêm JDK mặc định nếu muốn, nhưng việc define JDK cho từng project sẽ tốt hơn nếu bạn không muốn cài trên hệ thống chính\n# .../configuration.nix { config, pkgs, ... }: { # Bật tính năng Flakes và nix-command mới nix.settings.experimental-features = [ \u0026#34;nix-command\u0026#34; \u0026#34;flakes\u0026#34; ]; environment.systemPackages = with pkgs; [ git # Git để quản lý mã nguồn jetbrains.idea-community # Thêm IntelliJ IDEA vào cấu hình ]; # ... các cấu hình khác } Rebuild NixOS để áp dụng thay đổi: sudo nixos-rebuild switch\nBước 2: Tạo môi trường phát triển riêng cho Project Đây là bước quan trọng nhất và là nơi sức mạnh của nix được thể hiện rõ nhất\nTạo thư mục chứa dự án\nmkdir my-app cd my-app Tạo file flake.nix. File này là trái tim của môi trường, nó sẽ define tất cả những công cụ cần thiết trong project: JDK, Maven, Gradle, \u0026hellip;\n{ description = \u0026#34;Môi trường phát triển Android trên NixOS (kênh Unstable)\u0026#34;; inputs = { nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-unstable\u0026#34;; flake-utils.url = \u0026#34;github:numtide/flake-utils\u0026#34;; }; outputs = { self, nixpkgs, flake-utils }: flake-utils.lib.eachDefaultSystem (system: let # Cấu hình để tự động chấp nhận giấy phép Android SDK pkgs = import nixpkgs { inherit system; config = { allowUnfree = true; android_sdk.accept_license = true; }; }; # \u0026#34;Lắp ráp\u0026#34; môi trường SDK bằng hàm và tham số tương thích android-sdk-env = pkgs.androidenv.composeAndroidPackages { platformVersions = [ \u0026#34;36\u0026#34; ]; buildToolsVersions = [ \u0026#34;36.0.0\u0026#34; ]; includeEmulator = true; platformToolsVersion = \u0026#34;36.0.0\u0026#34;; cmdLineToolsVersion = \u0026#34;11.0\u0026#34;; includeSystemImages = true; systemImageTypes = [ \u0026#34;google_apis\u0026#34; ]; abiVersions = [ \u0026#34;x86_64\u0026#34; ]; }; in { devShells.default = pkgs.mkShell { buildInputs = [ # Hàm cũ trả về một attribute set, cần truy cập .androidsdk android-sdk-env.androidsdk pkgs.jdk pkgs.qt6.qtwayland ]; shellHook = \u0026#39;\u0026#39; # Đường dẫn SDK cũng cần .androidsdk export ANDROID_SDK_ROOT=\u0026#34;${android-sdk-env.androidsdk}/libexec/android-sdk\u0026#34; export PATH=\u0026#34;$ANDROID_SDK_ROOT/cmdline-tools/latest/bin:$ANDROID_SDK_ROOT/platform-tools:$ANDROID_SDK_ROOT/emulator:$PATH\u0026#34; export QT_QPA_PLATFORM=xcb echo \u0026#34;✅ Môi trường Android cho API 36 (Unstable) đã sẵn sàng.\u0026#34; \u0026#39;\u0026#39;; }; }); } Lưu ý: Có thể thay đổi các version máy ảo Android cho phù hợp, tuy nhiên các công cần sử dụng đúng version để có thể hoạt động được với nhau (platformVersions, buildToolsVersions , platformToolsVersion)\nInstall và truy cập vào nix-shell\nnix develop ➜ nix develop ✅ Môi trường Android đã sẵn sàng. [nagih@nixos:~/Workspaces/noob/app/my-app]$ Bước 3: Cấu hình IntelliJ IDEA Bây giờ, ta sẽ khởi động IntelliJ IDEA bên trong môi trường Nix để có thể nhận diện được tất cả công cụ\nKhởi động IntelliJ: Từ terminal, gõ lệnh\nidea-community . Cài đặt Plugin Android mới: Nếu đây là lần đầu sử dụng IntelliJ cho Android, hãy vào Plugins -\u0026gt; Marketplace, Tìm kiếm Android và cài đặt\nTạo dự án mới\nTrong IntelliJ, vào Projects -\u0026gt; New Project\nChọn Android từ danh sách Generators bên trái\nChọn template, ví dụ Empty Views Activity và nhấn next\nĐiền thông tin project\nQuan trọng: Ở mục Build configuration language cần phù hợp với language đã được khai báo trong flake.nix (kotlin / groovy)\nSau khi tạo project, nếu thấy hiển thị lỗi này, hãy sửa theo hướng dẫn của phần Các lỗi phổ biến ở phía dưới\nBước 4: Tạo và khởi chạy máy ảo AVD (Android Virtual Device) Phương pháp 1: Tạo trong intelliJ (Recommand)\nTruy cập Device Manager\nNhấn + để thêm mới AVD\nChọn thiết bị mà bạn muốn sử dụng\nChọn System Image\nChọn tab x86 Images\nChọn System Image mà bạn đã cài đặt (Không chọn bất kỳ system image nào có nút Install)\nChọn lấy 1 System Image trong phần x86 Images (Không Install)\nThoát khỏi IntelliJ và nix-shell\nSửa file flake.nix theo System Image mà bạn đã chọn ở trên\nKích hoạt nix develop và tiếp tục\nKhởi chạy máy ảo\nSau khi tạo thành công máy ảo, có thể chưa hiện ngay trong phần Device Manager, lúc này hãy thoát IntelliJ và mở lại, bạn sẽ thấy nó. Sau đó chỉ cần nhấn nút Run.\nPhương pháp 2: Sử dụng CLI (Chạy máy ảo với cửa sổ riêng)\nClose hoàn toàn IntelliJ IDEA\nXác minh công cụ emulator và avdmanager có tồn tại trong môi trường hay không\nwhich emulator which avdmanager Nếu kết quả có các đường dẫn trỏ tới /nix/store/... cho cả 2 lệnh thì xin chúc mừng Nếu không thấy kết quả -\u0026gt; Điều này có nghĩa là flake.nix của bạn đang có vấn đề, hoặc có thể bạn chưa truy cập và nix develop Kiểm tra System Image\nsdkmanager --list_installed Tạo máy ảo (AVD) thông qua andmanager\navdmanager create avd --name \u0026#34;Pixel_API36\u0026#34; --package \u0026#34;system-images;android-36;google_apis;x86_64\u0026#34; --device \u0026#34;pixel_7_pro\u0026#34; name: Tên AVD\npackage: System image\ndevice: Loại thiết bị, nếu muốn kiểm tra có các thiết bị nào, hãy dùng lệnh avdmanager list device\nKhởi động IntelliJ\nKhởi động lại IntelliJ IDEA trong môi trường nix-shell\nidea-community . Open project mà khi nãy đã tạo (nếu đã bị thoát ra)\nMáy ảo AVD sẽ xuất hiện trong phần Device Manager. Bạn có thể thấy xuất hiện dấu !, điều này là bình thường vì chưa run AVD\nKhởi chạy máy ảo AVD\nOpen terminal bên trong IntelliJ IDEA\nemulator -avd [avd-name] \u0026amp; Các lỗi phổ biến 1. Lỗi khi tạo dự án Nguyên nhân\nLỗi này xảy ra do IntelliJ mặc định sử dụng template có sẵn (API 34) nhưng trong flake.nix difine API khác\nCố gắng tải API 34: Khi thấy công thức yêu cầu API 34 mà trong bếp không có, nó sẽ cố gắng tự đi \u0026ldquo;chợ\u0026rdquo; (tự tải về) và đặt vào kho (/nix/store). Bị NixOS chặn lại: NixOS thấy IntelliJ đang cố ghi vào \u0026ldquo;kho\u0026rdquo; chỉ đọc, nên đã chặn lại và báo lỗi Failed to read or create install properties file.34 Giải pháp\nTruy cập vào môi trường nix-shell\nCopy lấy đường dẫn của $ANDROID_SDK_ROOT\necho $ANDROID_SDK_ROOT Cấu hình cho IntelliJ\nTruy cập File -\u0026gt; Project Structure... Vào tab Platform Settings -\u0026gt; SDKs Nhấn + -\u0026gt; Add Android SDK\u0026hellip; và dán đường dẫn $ANDROID_SDK_ROOT (đường dẫn này đang trỏ đến SDK của bạn). Trong phần Build target sẽ xuất hiện SDK của bạn Cập nhật build.gradle\nMở file app/build.gradle.kts\nThay đổi compileSdk và targetSdk thành SDK mà bạn đã define (36)\nĐồng bộ Gradle:\nNhấn nút \u0026ldquo;Sync Now\u0026rdquo;. 2. \u0026ldquo;The skin directory, does not point to valid skin\u0026rdquo; Lỗi này có nghĩa là máy ảo (AVD) đang cố gắng sử dụng một \u0026ldquo;skin\u0026rdquo; (bộ giao diện mô phỏng viền cứng của điện thoại), nhưng không thể tìm thấy các file của skin đó ở đường dẫn được chỉ định.\nGiải pháp 1: Tắt Skin trong Cài đặt Máy ảo (Cách dễ nhất)\nCách đơn giản và hiệu quả nhất là yêu cầu máy ảo không cần tải skin nữa.\nMở Device Manager trong IntelliJ.\nTìm đến máy ảo đang bị lỗi của bạn và nhấn vào biểu tượng Edit (hình cây bút chì) ở cột Actions.\nCửa sổ \u0026ldquo;Virtual Device Configuration\u0026rdquo; sẽ hiện ra. Hãy tìm đến mục \u0026ldquo;Enable Device Frame\u0026rdquo; (Bật khung thiết bị).\nBỏ dấu tick ở ô này.\nNhấn Finish để lưu lại thay đổi.\nSau khi tắt skin, hãy thử khởi động lại máy ảo. Lỗi sẽ biến mất và máy ảo sẽ hiển thị dưới dạng một cửa sổ đơn giản chỉ có màn hình.\nGiải pháp 2: Sửa file cấu hình thủ công (Cách trực tiếp)\nNếu bạn không tìm thấy tùy chọn trong giao diện, bạn có thể chỉnh sửa file cấu hình trực tiếp.\nMở terminal và điều hướng đến thư mục cấu hình của máy ảo. Thay TenMayAo.avd bằng tên máy ảo của bạn (ví dụ: Pixel8Pro_API35.avd):\ncd ~/.android/avd/TenMayAo.avd/ Mở file config.ini bằng một trình soạn thảo văn bản (ví dụ: nano config.ini).\nTìm các dòng bắt đầu bằng skin.name và skin.path.\nThay đổi giá trị của chúng thành _no_skin hoặc xóa cả hai dòng đó đi.\nVí dụ, sửa từ:\nskin.name = pixel_8_pro skin.path = /some/invalid/nix/store/path Thành:\nskin.name = _no_skin skin.path = _no_skin Lưu file và thử khởi động lại máy ảo.\n","permalink":"https://blog.nagih.io.vn/posts/app-development/","summary":"\u003cp\u003eSử dụng triết lý của Nix ứng dụng trong việc triển khai môi trường lập trình ứng dụng sao cho tối ưu và tốt nhất.\u003c/p\u003e","title":"Hướng dẫn setup môi trường App Development trên nixos best practice"},{"content":"Thông thường khi cài windows, mặc định sẽ tự tạo phân vùng Boot EFI 512MB, bài viết này sẽ hướng dẫn bạn cách tùy biến size phân vùng EFI\nSử dụng Command Prompt trong quá trình cài đặt\nBước 1: Khởi động từ USB/DVD cài Windows\nKhi màn hình xuất hiện, nhấn Shift + F10 để mở Command Prompt Bước 2: Sử dụng DiskPart để tạo phân vùng\ndiskpart list disk select disk 0 (Chọn ổ đĩa cần cài) clean convert gpt Bước 3: Tạo phân vùng EFI với size tùy chỉnh\ncreate partition efi size=4096 format quick fs=fat32 label=\u0026#34;System\u0026#34; assign letter=S active Thay 4096 bằng size bạn muốn (MB)\nBước 4: Tạo phân vùng MSR\ncreate partition msr size=128 Bước 5: Tạo phân vùng chính cho Windows\ncreate partition primary format quick fs=ntfs label=\u0026#34;Windows\u0026#34; assign letter=C active exit Thông thường hay xảy ra trường hợp ổ C đang được định nghĩa là USB Boot, lúc này hãy cứ thao tác bằng giao diện như bình thường\n","permalink":"https://blog.nagih.io.vn/posts/custom-windows-efi/","summary":"\u003cp\u003eThông thường khi cài windows, mặc định sẽ tự tạo phân vùng Boot EFI 512MB, bài viết này sẽ hướng dẫn bạn cách tùy biến size phân vùng EFI\u003c/p\u003e","title":"Hướng dẫn tùy biến phân vùng EFI khi cài windows"},{"content":"Khối Quản lý Tiến trình (PCB) - \u0026ldquo;CMND\u0026rdquo; của Mọi Chương trình trong Máy tính\nGiới thiệu Hệ điều hành (Operating System - OS). Để quản lý từng mỗi chương trình đang chạy, hay còn gọi là process, process cần một bản thông tin chi tiết về từng thành viên. Bản thông tin này chính là Khối Quản lý Tiến trình (Process Control Block - PCB).\nĐể dễ hình dung nhất, hãy coi PCB chính là \u0026ldquo;Chứng minh nhân dân\u0026rdquo; (CMND) hay \u0026ldquo;Căn cước công dân\u0026rdquo; (CCCD) của một tiến trình. Đó là một tấm thẻ định danh chứa đựng mọi thông tin sống còn mà hệ điều hành cần để quản lý, giám sát và điều khiển tiến trình đó. Nếu không có \u0026ldquo;tấm thẻ\u0026rdquo; này, một tiến trình sẽ trở nên vô danh và không thể quản lý được đối với hệ điều hành.\n1. Khối Quản lý Tiến trình (PCB) chính xác là gì? Dấu vân tay Kỹ thuật số Về mặt hình thức, PCB là một cấu trúc dữ liệu cơ bản nằm trong nhân (kernel) của hệ điều hành. Nó còn được biết đến với các tên gọi khác như \u0026ldquo;Bộ mô tả Tiến trình\u0026rdquo; (Process Descriptor) hay \u0026ldquo;Khối điều khiển Tác vụ\u0026rdquo; (Task Control Block).5 Điều quan trọng cần nhấn mạnh là PCB không phải là một phần của chương trình người dùng viết ra; nó là một công cụ nội bộ, được tạo ra và sử dụng độc quyền bởi hệ điều hành để quản lý các tiến trình.\nVòng đời của một PCB Vòng đời của một PCB gắn liền với vòng đời của tiến trình mà nó đại diện:\nKhởi tạo: Ngay khi người dùng khởi chạy một ứng dụng (ví dụ, nhấp đúp vào biểu tượng Google Chrome), hệ điều hành sẽ tạo ra một tiến trình mới. Song song với đó, nó cấp phát bộ nhớ và khởi tạo một PCB tương ứng cho tiến trình này. Quản lý: Trong suốt thời gian tồn tại của tiến trình, hệ điều hành liên tục đọc và cập nhật thông tin trong PCB của nó khi trạng thái và việc sử dụng tài nguyên thay đổi. Kết thúc: Khi tiến trình hoàn thành nhiệm vụ hoặc bị chấm dứt, hệ điều hành sẽ thu hồi tất cả tài nguyên của nó và phá hủy PCB, giải phóng bộ nhớ đã cấp phát. Lưu trữ An toàn PCB chứa những thông tin cực kỳ quan trọng đối với sự ổn định của hệ thống. Do đó, nó được lưu trữ trong một vùng bộ nhớ được bảo vệ đặc biệt gọi là \u0026ldquo;không gian nhân\u0026rdquo; (kernel space). Cơ chế bảo vệ này ngăn chặn các chương trình người dùng truy cập và sửa đổi (dù vô tình hay cố ý) dữ liệu điều khiển của chính chúng hoặc của các tiến trình khác, một hành động có thể gây sập toàn bộ hệ thống.\nBảng Tiến trình (Process Table) Để theo dõi tất cả các tiến trình đang hoạt động, hệ điều hành duy trì một danh sách tổng thể, thường được gọi là Bảng Tiến trình (Process Table). Về cơ bản, đây là một mảng hoặc danh sách liên kết chứa các con trỏ trỏ đến từng PCB của mọi tiến trình đang hoạt động trong hệ thống. Bảng này giống như một cuốn danh bạ mà hệ điều hành dùng để tra cứu mọi tiến trình mà nó đang quản lý.\nTừ góc độ của nhân hệ điều hành, PCB không chỉ đơn thuần là một bản ghi thông tin; nó chính là hiện thân của tiến trình. Một chương trình trên đĩa cứng (ví dụ: chrome.exe) chỉ là một tập hợp các chỉ thị thụ động. Một tiến trình là sự thực thi\nchủ động của những chỉ thị đó. Và PCB chính là cấu trúc dữ liệu cụ thể hóa \u0026ldquo;sự chủ động\u0026rdquo; này. Nó là thực thể hữu hình, có thể quản lý được mà hệ điều hành tương tác. Tất cả các hành động quản lý của OS—lập lịch, cấp phát tài nguyên, chấm dứt—đều là các hoạt động được thực hiện trên hoặc dựa vào dữ liệu chứa trong PCB. Do đó, có thể nói rằng PCB là linh hồn kỹ thuật số, là bản chất của một tiến trình trong mắt hệ điều hành.\n2. Giải phẫu PCB - Nhìn vào bên trong \u0026ldquo;Tấm thẻ Căn cước\u0026rdquo; Mặc dù cấu trúc chính xác có thể khác nhau giữa các hệ điều hành (ví dụ, Linux và Windows), các loại thông tin cốt lõi về cơ bản là giống nhau. Chúng ta sẽ tiếp tục sử dụng phép ẩn dụ \u0026ldquo;Tấm thẻ Căn cước\u0026rdquo; để làm rõ mục đích của từng thành phần.\nPhân tích chi tiết các thành phần Thông tin Nhận dạng (Process Identification Data): Mã định danh Tiến trình (Process ID - PID): Một số nguyên duy nhất do hệ điều hành cấp để xác định tiến trình. Đây là trường thông tin quan trọng nhất, được sử dụng làm khóa trong hầu hết các bảng hệ thống khác. Ví von: Số CMND/CCCD duy nhất trên thẻ căn cước. Mã định danh Tiến trình Cha (Parent Process ID - PPID): PID của tiến trình đã tạo ra tiến trình này. Điều này thiết lập một cấu trúc phân cấp dạng cây cho các tiến trình. Mã định danh Người dùng (User ID - UID) \u0026amp; Nhóm (Group ID - GID): Xác định người dùng và nhóm sở hữu tiến trình, được sử dụng cho mục đích bảo mật và phân quyền. Trạng thái Tiến trình (Process State): Một trường ghi lại trạng thái hiện tại của tiến trình. Thông tin này rất quan trọng để bộ lập lịch biết được tiến trình nào đủ điều kiện để chạy. Mới (New): Tiến trình đang được tạo. Sẵn sàng (Ready): Tiến trình đã được nạp vào bộ nhớ và đang chờ đến lượt được cấp CPU. Đang chạy (Running): Các chỉ thị của tiến trình đang được thực thi bởi một lõi CPU. Đang chờ/Bị chặn (Waiting/Blocked): Tiến trình không thể tiếp tục cho đến khi một sự kiện nào đó xảy ra (ví dụ: chờ người dùng nhập liệu hoặc chờ đọc dữ liệu từ đĩa). Kết thúc (Terminated): Tiến trình đã hoàn thành và đang trong quá trình dọn dẹp. Ngữ cảnh Thực thi (Execution Context): Bộ đếm Chương trình (Program Counter - PC): Lưu địa chỉ bộ nhớ của chỉ thị tiếp theo sẽ được thực thi. Đây là yếu tố sống còn để có thể tiếp tục một tiến trình sau khi nó bị gián đoạn. Ví von: Một chiếc kẹp đánh dấu trang sách. Nó cho bạn biết chính xác cần bắt đầu đọc lại từ đâu. Các thanh ghi CPU (CPU Registers): Một bản sao lưu (snapshot) nội dung của các thanh ghi đa dụng, con trỏ ngăn xếp (stack pointer), v.v., của CPU tại thời điểm tiến trình bị ngắt. Các thanh ghi này chứa dữ liệu trung gian của các phép tính hiện tại. Ví von: Những dòng ghi chú trên giấy nháp khi đang giải một bài toán phức tạp. Bạn cần lưu chúng lại để có thể tiếp tục bài toán sau đó. Thông tin Quản lý Tài nguyên (Resource Management Information): Thông tin Lập lịch CPU (CPU Scheduling Information): Dữ liệu được bộ lập lịch của hệ điều hành sử dụng để quyết định tiến trình nào sẽ chạy tiếp theo. Bao gồm độ ưu tiên của tiến trình, con trỏ đến các hàng đợi lập lịch mà nó đang tham gia, và các tham số khác. Ví von: Nhóm lên máy bay hoặc hạng vé của hành khách (ví dụ: VIP, Thương gia, Phổ thông) quyết định thứ tự lên máy bay. Thông tin Quản lý Bộ nhớ (Memory Management Information): Thông tin về bộ nhớ được cấp phát cho tiến trình này, chẳng hạn như con trỏ đến bảng trang (page tables) hoặc bảng phân đoạn (segment tables) của nó. Điều này xác định không gian địa chỉ của tiến trình và ngăn nó truy cập vào bộ nhớ của các tiến trình khác. Ví von: Sổ đỏ hoặc giấy tờ nhà đất, xác định ranh giới của một mảnh đất. Thông tin Trạng thái I/O (I/O Status Information): Danh sách các thiết bị I/O được cấp phát cho tiến trình (ví dụ: một máy in cụ thể) và danh sách các tệp tin mà nó đang mở. Ví von: Một thẻ thư viện ghi lại những cuốn sách đang được mượn, hoặc danh sách các công cụ đã mượn từ một xưởng làm việc. Thông tin Kế toán (Accounting Information): Theo dõi việc sử dụng tài nguyên, chẳng hạn như lượng thời gian CPU mà tiến trình đã tiêu thụ, giới hạn thời gian, v.v. Thông tin này có thể được sử dụng để giám sát hệ thống hoặc tính phí trong môi trường doanh nghiệp. Ví von: Chi tiết sử dụng trên hóa đơn tiện ích (ví dụ: số kilowatt-giờ điện đã dùng). Bảng: Giải phẫu \u0026ldquo;Tấm thẻ Căn cước\u0026rdquo; của một Tiến trình Bảng dưới đây tóm tắt các thành phần chính của PCB và phép ví von tương ứng, giúp củng cố khái niệm một cách trực quan.\nComponent (Thành phần) Purpose (Mục đích) Analogy (Phép ví von) Process ID (PID) Một số duy nhất để nhận dạng tiến trình. Số CMND/CCCD Process State Hoạt động hiện tại của tiến trình (Đang chạy, Đang chờ, v.v.). Tình trạng hôn nhân (Độc thân, Đã kết hôn,\u0026hellip;) Program Counter (PC) Địa chỉ của lệnh tiếp theo sẽ thực thi. Dấu trang sách (Bookmark) CPU Registers Lưu trữ dữ liệu tạm thời cho phép tính hiện tại. Giấy nháp (Scratchpad) Memory Info Chi tiết về việc cấp phát bộ nhớ của tiến trình. Sổ đỏ / Giấy tờ nhà đất I/O Status Info Danh sách các tệp tin và thiết bị đang sử dụng. Thẻ thư viện và các vật dụng đã mượn Scheduling Info Độ ưu tiên để truy cập CPU. Mức độ ưu tiên / Vé VIP Accounting Info Ghi lại tài nguyên đã tiêu thụ (ví dụ: thời gian CPU). Hóa đơn tiền điện/nước 3. PCB trong Thực tiễn - Phép màu của Đa nhiệm (Chuyển đổi Ngữ cảnh) Vai trò quan trọng nhất của PCB là cho phép đa nhiệm (multitasking) thông qua một cơ chế gọi là \u0026ldquo;chuyển đổi ngữ cảnh\u0026rdquo; (context switch).1 Chuyển đổi ngữ cảnh là quá trình hệ điều hành dừng một tiến trình và bắt đầu một tiến trình khác.2 Điều này xảy ra hàng trăm, thậm chí hàng nghìn lần mỗi giây, tạo ra ảo giác về sự thực thi song song.\nTác nhân Kích hoạt Một cuộc chuyển đổi ngữ cảnh không xảy ra ngẫu nhiên. Nó được kích hoạt bởi các sự kiện cụ thể 20:\nĐa nhiệm: \u0026ldquo;Lát cắt thời gian\u0026rdquo; (time slice hoặc quantum) của một tiến trình đã hết, và bộ lập lịch quyết định đã đến lượt một tiến trình khác (đa nhiệm phủ đầu - preemptive multitasking). Chờ I/O: Tiến trình đang chạy yêu cầu một tác vụ tốn thời gian (như đọc một tệp từ đĩa) và chuyển sang trạng thái \u0026ldquo;Chờ\u0026rdquo;, giải phóng CPU cho một tiến trình khác. Ngắt (Interrupts): Một ngắt phần cứng xảy ra (ví dụ: người dùng nhấp chuột), yêu cầu hệ điều hành phải xử lý, và việc này có thể liên quan đến việc chuyển sang một tiến trình khác. Quy trình từng bước của một cuộc Chuyển đổi Ngữ cảnh Hãy tưởng tượng CPU đang chạy Tiến trình A (ví dụ: Microsoft Word) và cần chuyển sang Tiến trình B (ví dụ: Google Chrome).\nNgắt Xảy ra: Một sự kiện (như ngắt từ bộ đếm thời gian) báo hiệu cần phải chuyển đổi. Phần cứng CPU tự động chuyển quyền điều khiển cho nhân hệ điều hành. Lưu Ngữ cảnh của Tiến trình A: Hệ điều hành ngay lập tức tạm dừng Tiến trình A. Sau đó, nó sao chép một cách tỉ mỉ toàn bộ ngữ cảnh thực thi hiện tại từ phần cứng của CPU vào PCB của Tiến trình A. Ngữ cảnh này bao gồm Bộ đếm Chương trình, tất cả các thanh ghi CPU, và các thông tin trạng thái khác. Quá trình này giống như việc bạn cẩn thận lưu lại trò chơi trước khi thoát. Cập nhật Trạng thái: Hệ điều hành cập nhật trường \u0026ldquo;Trạng thái Tiến trình\u0026rdquo; trong PCB của Tiến trình A từ \u0026ldquo;Đang chạy\u0026rdquo; thành \u0026ldquo;Sẵn sàng\u0026rdquo; hoặc \u0026ldquo;Đang chờ\u0026rdquo;. Nó di chuyển PCB này vào hàng đợi thích hợp (ví dụ: hàng đợi sẵn sàng). Chọn Tiến trình Tiếp theo: Bộ lập lịch của hệ điều hành chạy thuật toán của mình, tham khảo các PCB trong hàng đợi sẵn sàng để chọn tiến trình tiếp theo sẽ chạy. Giả sử nó chọn Tiến trình B. Nạp Ngữ cảnh của Tiến trình B: Hệ điều hành lấy ngữ cảnh đã được lưu từ PCB của Tiến trình B và nạp nó vào phần cứng của CPU. Bộ đếm Chương trình được khôi phục, các thanh ghi được điền đầy bằng các giá trị đã lưu của Tiến trình B, và các con trỏ bộ nhớ được cập nhật. Tiếp tục Thực thi: Hệ điều hành chuyển quyền điều khiển từ nhân trở lại chương trình người dùng. Tiến trình B bắt đầu thực thi chỉ thị tiếp theo của nó, hoàn toàn không biết rằng nó đã từng bị tạm dừng. Nó tiếp tục chính xác từ nơi nó đã dừng lại. Phép ví von: Hai đầu bếp chia sẻ một khu vực làm việc Hãy tưởng tượng hai đầu bếp (Tiến trình A và B) phải chia sẻ chung một chiếc thớt và một con dao (CPU).\nĐầu bếp A đang thái rau. Người quản lý (Hệ điều hành) nói rằng thời gian của anh ta đã hết. Đầu bếp A ghi vào sổ tay của mình (PCB A): \u0026ldquo;Tôi đang thái cà rốt, con dao ở đây, còn lại 3 củ\u0026rdquo; (lưu PC, các thanh ghi, trạng thái). Sau đó, anh ta dọn dẹp khu vực làm việc và rời đi. Người quản lý gọi đầu bếp B. Đầu bếp B nhìn vào sổ tay của mình (PCB B), trong đó ghi: \u0026ldquo;Tôi đang thái hành tây, cần con dao nhỏ, đã thái được nửa củ thứ hai.\u0026rdquo; Đầu bếp B sắp xếp khu vực làm việc chính xác như trong ghi chú của mình (nạp ngữ cảnh) và ngay lập tức tiếp tục thái củ hành tây thứ hai. Quá trình chuyển đổi diễn ra liền mạch. Mặc dù quá trình chuyển đổi ngữ cảnh có vẻ kỳ diệu, nó không hề miễn phí. Nó là một chi phí hoạt động thuần túy (overhead); trong khoảng thời gian hệ điều hành đang lưu và nạp các PCB, không có công việc hữu ích nào của người dùng được thực hiện. Điều này tạo ra một sự đánh đổi cơ bản trong thiết kế hệ điều hành. Kích thước và độ phức tạp của PCB đóng góp trực tiếp vào chi phí này. Các nhà thiết kế hệ điều hành luôn phải đối mặt với một xung đột cốt lõi:\nChuyển đổi thường xuyên và nhanh chóng (lát cắt thời gian ngắn) làm cho hệ thống có cảm giác rất nhạy và tương tác tốt, nhưng một tỷ lệ lớn thời gian CPU bị lãng phí cho chi phí chuyển đổi. Chuyển đổi không thường xuyên và chậm hơn (lát cắt thời gian dài) hiệu quả hơn (ít thời gian lãng phí cho chi phí), nhưng hệ thống có thể cảm thấy ì ạch, vì một tiến trình duy nhất có thể độc chiếm CPU trong thời gian dài hơn. Do đó, thiết kế của PCB và thuật toán lập lịch có mối liên hệ mật thiết trong một bài toán cân bằng giữa việc cung cấp các tính năng nâng cao, đảm bảo khả năng phản hồi của hệ thống và tối đa hóa hiệu quả sử dụng CPU.\n4. Tại sao PCB là người hùng thầm lặng của Hệ điều hành Cấu trúc dữ liệu có vẻ đơn giản này lại là nền tảng cho máy tính hiện đại vì nhiều lý do.\nYếu tố cho phép Đa nhiệm: Như đã trình bày, nếu không có khả năng lưu và khôi phục trạng thái của PCB, việc chuyển đổi ngữ cảnh sẽ là không thể. Chúng ta sẽ bị mắc kẹt trong một thế giới đơn nhiệm. Nền tảng cho Lập lịch: Bộ lập lịch là \u0026ldquo;bộ não\u0026rdquo; quyết định tiến trình nào sẽ được sử dụng CPU, nhưng PCB là \u0026ldquo;hệ thần kinh\u0026rdquo; cung cấp tất cả các thông tin đầu vào (độ ưu tiên, trạng thái, việc sử dụng tài nguyên) để bộ não đó đưa ra quyết định thông minh. Người bảo vệ sự Ổn định của Hệ thống: Bằng cách lưu trữ ranh giới bộ nhớ và quyền sở hữu tài nguyên, PCB giúp hệ điều hành thực thi sự cô lập giữa các tiến trình, ngăn chặn một chương trình hoạt động sai cách làm hỏng các chương trình khác hoặc chính nhân hệ điều hành. Công cụ Quản lý Tài nguyên: Hệ điều hành sử dụng thông tin I/O và bộ nhớ trong các PCB để quản lý việc cấp phát tài nguyên, ngăn ngừa xung đột (ví dụ: hai tiến trình cố gắng ghi vào cùng một tệp tin đồng thời), và thậm chí giúp phát hiện tình trạng bế tắc (deadlock). Vượt ra ngoài Tiến trình đơn: Các khái niệm Nâng cao Một tiến trình có thể có nhiều luồng (thread), giống như các \u0026ldquo;tiến trình mini\u0026rdquo;. Trong trường hợp này, PCB chứa thông tin được chia sẻ chung (như không gian bộ nhớ), trong khi mỗi luồng sẽ có một Khối điều khiển Luồng (Thread Control Block - TCB) nhẹ hơn để lưu trữ ngữ cảnh thực thi riêng của nó (các thanh ghi, con trỏ ngăn xếp). Điều này cho phép đa nhiệm ở mức độ chi tiết hơn nữa ngay trong một ứng dụng duy nhất.\nCác trường thông tin và độ phức tạp cụ thể của cấu trúc PCB trong một hệ điều hành nhất định là sự phản ánh trực tiếp các mục tiêu và triết lý thiết kế của hệ điều hành đó. Một hệ điều hành thời gian thực (RTOS) cho hệ thống phanh của ô tô ưu tiên sự đoán trước và các thời hạn nghiêm ngặt. Do đó, PCB của nó có thể sẽ có các trường rất chi tiết và chặt chẽ liên quan đến các ràng buộc thời gian. Ngược lại, PCB của một máy chủ Linux (task_struct) nổi tiếng là phức tạp, chứa thông tin sâu rộng về quyền của người dùng/nhóm, giới hạn tài nguyên, và các tín hiệu giao tiếp liên tiến trình, phản ánh di sản đa người dùng và chú trọng bảo mật của nó. Điều này có nghĩa là PCB không chỉ là một triển khai kỹ thuật chung chung; nó là một tạo tác thể hiện triết lý kiến trúc và mục đích dự định của toàn bộ hệ điều hành.\n","permalink":"https://blog.nagih.io.vn/posts/process-control-block/","summary":"\u003cp\u003eKhối Quản lý Tiến trình (PCB) - \u0026ldquo;CMND\u0026rdquo; của Mọi Chương trình trong Máy tính\u003c/p\u003e","title":"Process Control Block"},{"content":"Phân Tích về Kiến Trúc API Hiện Đại | Rest \u0026amp; gRPC\nGiới thiệu REST, với tư cách là một kiểu kiến trúc, đã định hình nên các API web trong hơn hai thập kỷ, trở thành tiêu chuẩn de facto nhờ tính linh hoạt và khả năng tiếp cận phổ quát. Mặt khác, gRPC, một framework mã nguồn mở hiệu suất cao do Google phát triển, nổi lên như một giải pháp được thiết kế đặc biệt cho kỷ nguyên microservice, nơi hiệu suất, độ trễ thấp và các hợp đồng dịch vụ nghiêm ngặt là tối quan trọng.\nREST REST không phải là một giao thức hay một tiêu chuẩn, mà là một kiểu kiến trúc (architectural style) được định nghĩa bởi Roy Fielding vào năm 2000. Một hệ thống được coi là \u0026ldquo;RESTful\u0026rdquo; khi nó tuân thủ một tập hợp các ràng buộc kiến trúc được thiết kế để tối ưu hóa cho một hệ thống phân tán quy mô lớn như World Wide Web.\nKiến trúc cốt lõi của REST Sức mạnh và sự phổ biến của REST bắt nguồn từ sáu ràng buộc sau:\nTách Biệt Client-Server (Client-Server Decoupling): Server và client chỉ tương tác thông qua một giao diện chuẩn hóa. Sự tách biệt này cho phép chúng phát triển độc lập - client không cần biết về logic nghiệp vụ của server, và server không cần biết về giao diện của client miễn là hợp đồng giao diện không thay đổi.\nVô Trạng Thái (Statelessness): Trong kiến trúc REST, mỗi yêu cầu từ client đến server phải chứa tất cả thông tin cần thiết để server hiểu và xử lý nó. Server không lưu trữ bất kỳ trạng thái phiên nào của client giữa các yêu cầu.\nGiao Diện Đồng Nhất (Uniform Interface): Được thiết kế để đơn giản hóa và tách rời kiến trúc. Nó bao gồm 4 ràng buộc con:Đ\nIdentification of resources: Mọi tài nguyên đều được định danh duy nhất thông qua một URI (Uniform Resource Identifier).\nVí dụ: https://.../osers/123 thì 123 là ID duy nhất của order đó. Manipulation of resources through representations: Client tương tác với tài nguyên thông qua các biểu diễn của chúng (ví dụ: một tài liệu JSON hoặc XML). Biểu diễn này chứa đủ thông tin để client có thể sửa đổi hoặc xóa tài nguyên trên server.\nSelf-descriptive: Mỗi thông điệp chứa đủ thông tin để mô tả cách xử lý nó. Ví dụ, một header Content-Type cho biết định dạng media của thông điệp.\nHATEOAS: Client chỉ cần biết URI khởi đầu. Sau đó, tất cả các hành động và tài nguyên trong tương lai mà client có thể truy cập đều được khám phá thông qua các siêu liên kết có trong các phản hồi từ server.\nCacheability: Cho phép client hoặc các máy chủ trung gian lưu trữ các phản hồi, giúp giảm độ trễ và tải cho server.\nLayered System: Client không thể biết liệu nó đang kết nối trực tiếp đến server cuối cùng hay một máy chủ trung gian (microservices).\nCode on Demand: Đây là ràng buộc duy nhất không bắt buộc. Nó cho phép server tạm thời mở rộng hoặc tùy chỉnh chức năng của client bằng cách truyền mã thực thi (ví dụ: JavaScript).\nTriển khai đển hình Thông thường, REST được triển khai trên HTTP/1.1. Các tài nguyên được thao tác bằng HTTP tiêu chuẩn (GET, POST, PUT, DELETE), và dữ liệu thường được trao đổi bằng định dạng JSON.\nFramework gRPC - Hiệu Suất và Gọi Thủ Tục Từ Xa gRPC (gRPC Remote Procedure Call) là một framework RPC hiện đại, được xây dựng trên nền tảng các công nghệ hiệu suất cao. Thay vì tập trung vào tài nguyên, gRPC tập trung vào các dịch vụ và các thủ tục (hàm) mà client có thể gọi từ xa. Kiến trúc của nó được xây dựng trên ba trụ cột chính: Protocol Buffers, HTTP/2, và các mô hình streaming tiên tiến.\nMô Hình RPC Cốt lõi của gRPC là mô hình Gọi Thủ Tục Từ Xa (Remote Procedure Call). Ý tưởng là cho phép một client gọi một hàm trên một server từ xa một cách minh bạch, như thể nó là một lời gọi hàm cục bộ. Framework sẽ trừu tượng hóa toàn bộ quá trình giao tiếp mạng phức tạp, bao gồm tuần tự hóa dữ liệu, kết nối và xử lý lỗi.\n1. Protocol Buffers (Protobuf) Protobuf là Ngôn ngữ Định nghĩa Giao diện (Interface Definition Language - IDL) mặc định của gRPC. Nó đóng vai trò là bản thiết kế cho cả dịch vụ và cấu trúc dữ liệu.\nDesign-first: Với gRPC, bắt đầu bằng cách định nghĩa các dịch vụ cấu trúc dữ liệu trong một tệp .proto. Tệp này hoạt động như một hợp đồng chính thức giữa client và server.\nTạo mã tự động: Trình biên dịch protoc của Protobuf sau đó sẽ đọc tệp .proto này và tự động tạo ra các client stub (phía client) và server skeleton (phía server) với kiểu dữ liệu mạnh (strongly-typed).\n2. Giao thức HTTP/2 gRPC được xây dựng nguyên bản trên HTTP/2, một bản nâng cấp lớn so với HTTP/1.1, và tận dụng triệt để các tính năng của nó để đạt được hiệu suất vượt trội.\nBinary Framing: HTTP/2 truyền dữ liệu dưới dạng các khung nhị phân, hiệu quả hơn so với định dạng văn bản của HTTP/1.1.\nFull Multiplexing: Đây là tính năng đột phá nhất. HTTP/2 cho phép gửi và nhận nhiều yêu cầu và phản hồi đồng thời trên một kết nối TCP duy nhất, loại bỏ hoàn toàn vấn đề \u0026ldquo;chặn đầu hàng\u0026rdquo; (head-of-line blocking) của HTTP/1.1.\nHeader Compression: Sử dụng thuật toán HPACK, HTTP/2 nén các header của yêu cầu và phản hồi, giảm đáng kể dữ liệu dư thừa và chi phí mạng.\nHỗ trợ streaming nguyên bản: HTTP/2 được thiết kế để hỗ trợ streaming dữ liệu, một nền tảng cơ bản cho các mô hình giao tiếp tiên tiến của gRPC.\n3. Các mô hình Streaming tiên tiến Nhờ vào nền tảng HTTP/2, gRPC hỗ trợ bốn mô hình giao tiếp, mang lại sự linh hoạt vượt trội so với mô hình yêu cầu-phản hồi đơn lẻ của REST:\nUnary RPC: Mô hình yêu cầu-phản hồi cổ điển, tương tự như một lời gọi REST. Client gửi một yêu cầu duy nhất và nhận lại một phản hồi duy nhất.\nServer Streaming RPC: Client gửi một yêu cầu và nhận lại một luồng (stream) các phản hồi từ server. Rất hữu ích cho các trường hợp như đăng ký nhận thông báo hoặc cập nhật dữ liệu trực tiếp.\nClient Streaming RPC: Client gửi một luồng các thông điệp đến server, và server sẽ phản hồi bằng một thông điệp duy nhất sau khi đã nhận tất cả. Thích hợp cho việc tải lên các tệp lớn hoặc gửi dữ liệu đo lường từ xa.\nBidirectional Streaming RPC: Cả client và server đều có thể gửi các luồng thông điệp cho nhau một cách độc lập trên cùng một kết nối. Mô hình này lý tưởng cho các ứng dụng tương tác thời gian thực như chat hoặc game nhiều người chơi.\nBảng So Sánh Tổng Quan Tiêu Chí REST gRPC Mô hình Dựa trên tài nguyên (Resource-based) Gọi thủ tục từ xa (RPC) Tiêu chuẩn hóa Không có tiêu chuẩn chính thức, là một tập hợp các nguyên tắc Được định nghĩa rõ ràng và chi tiết Giao thức vận chuyển Thường là HTTP/1.1 (có thể dùng HTTP/2) HTTP/2 Định dạng dữ liệu mặc định JSON (cũng hỗ trợ XML, text, v.v.) Protocol Buffers (Protobuf) Các chế độ dịch vụ Chỉ Unary (yêu cầu-phản hồi đơn lẻ) Unary, Client streaming, Server streaming, Bidirectional streaming Thiết kế API Thường là Code-first (mã trước) Design-first (thiết kế trước) Mức độ ghép nối Ghép nối lỏng (Loosely coupled) Ghép nối chặt (Tightly coupled) Tạo mã Yêu cầu công cụ bên thứ ba (ví dụ: OpenAPI Generator) Tích hợp sẵn (thông qua trình biên dịch protoc) Hỗ trợ trình duyệt Hỗ trợ nguyên bản và phổ quát Yêu cầu lớp proxy (gRPC-Web) Lưu cache Hỗ trợ tốt thông qua các cơ chế HTTP tiêu chuẩn Không hỗ trợ mặc định, cần tự triển khai Triết Lý và Thiết Kế Sự khác biệt cơ bản nhất giữa REST và gRPC nằm ở triết lý thiết kế của chúng: \u0026ldquo;cái gì\u0026rdquo; so với \u0026ldquo;làm gì\u0026rdquo;.\nREST: Tập trung vào việc phơi bày các thực thể hoặc tài nguyên (danh từ). Client tương tác với các tài nguyên này bằng CRUD (Create, Read, Update, Delete) và các nguyên tắc lập trình hướng đối tượng.\ngRPC: Tập trung vào việc phơi bày các hành động hoặc thủ tục (động từ). Client gọi các hàm cụ thể trên server, ví dụ CreateUser(user_details). Đây là một thiết kế hướng dịch vụ, ánh xạ trực tiếp đến logic ứng dụng.\nCó một mối quan hệ nghịch đảo giữa sự dễ dàng trong thiết lập/gỡ lỗi ban đầu và khả năng bảo trì lâu dài trong các hệ thống đa ngôn ngữ. REST rất dễ bắt đầu, nhưng có thể dẫn đến các vấn đề tích hợp sau này do thiếu một hợp đồng chính thức. gRPC đòi hỏi nhiều công sức thiết lập hơn (định nghĩa tệp .proto, tạo mã), nhưng nó cung cấp một nền tảng vững chắc, an toàn về kiểu dữ liệu giúp ngăn ngừa các lỗi tích hợp, đặc biệt là trong kiến trúc microservices với nhiều nhóm và ngôn ngữ khác nhau.\n","permalink":"https://blog.nagih.io.vn/posts/rest--grpc/","summary":"\u003cp\u003ePhân Tích về Kiến Trúc API Hiện Đại | Rest \u0026amp; gRPC\u003c/p\u003e","title":"REST và gRPC"},{"content":"1 Số Labs từ Cơ bản tới Nâng cao về Operating\nTại sao Hệ Điều Hành Vẫn Quan Trọng trong Thế Giới Cloud-Native Trong lĩnh vực DevOps hiện đại, tồn tại một nghịch lý: trong khi các công cụ cấp cao như Kubernetes, Docker và Ansible trừu tượng hóa hệ điều hành bên dưới, việc hiểu sâu về Linux lại trở nên quan trọng hơn bao giờ hết. Hầu hết các công cụ DevOps cốt lõi đều được xây dựng để chạy tốt nhất trên Linux, biến nó thành nền tảng phổ biến cho cơ sở hạ tầng đám mây và tự động hóa.\nHướng dẫn này được thiết kế để nâng tầm kỹ sư từ một người dùng đơn thuần các công cụ này trở thành một kiến trúc sư hiểu rõ hoạt động bên trong của chúng. Hệ điều hành Linux không nên được xem như một hệ thống cũ kỹ, mà là \u0026ldquo;API\u0026rdquo; nền tảng, phổ quát cho mọi hoạt động tự động hóa cơ sở hạ tầng. Tám bài lab dưới đây được cấu trúc như một hành trình có phương pháp, phản ánh quy trình xử lý sự cố trong thực tế, bắt đầu từ các kiểm tra hệ thống cơ bản, đi sâu dần vào phân tích hiệu năng, gỡ lỗi nâng cao và cuối cùng là các nguyên tắc cốt lõi của container hóa. Đây không chỉ là một bộ sưu tập các lệnh; nó là một mô hình tư duy về hệ thống.\nLab 1: Điều Hướng và Quản Lý Hệ Thống Tệp Mục tiêu: Xây dựng \u0026ldquo;trí nhớ cơ bắp\u0026rdquo; để điều hướng hệ thống tệp Linux và thực hiện các thao tác tệp thiết yếu. Đây là nền tảng để tìm kiếm log, quản lý tệp cấu hình và chuẩn bị các tạo phẩm ứng dụng cho việc triển khai.\nCác Khái Niệm Cốt Lõi Triết lý \u0026ldquo;Mọi thứ đều là tệp\u0026rdquo;: Trong Linux, một nguyên tắc cốt lõi là mọi thứ, từ thiết bị phần cứng, socket mạng đến các thư mục, đều được biểu diễn dưới dạng tệp. Điều này cung cấp một giao diện thống nhất để tương tác với toàn bộ hệ thống. Tiêu chuẩn Phân cấp Hệ thống tệp (FHS): Cấu trúc thư mục trong Linux tuân theo một tiêu chuẩn, mang lại sự dễ đoán trong quản trị hệ thống. Các thư mục chính bao gồm /etc cho các tệp cấu hình, /var/log cho các tệp nhật ký, /home cho thư mục người dùng và /usr cho các tiện ích và ứng dụng hệ thống. Thực Hành (Từng bước) Bước 1: Xác định vị trí: Sử dụng lệnh pwd để in ra thư mục làm việc hiện tại và whoami để xác định người dùng hiện tại. Bước 2: Khám phá xung quanh: Sử dụng ls với các cờ phổ biến (-l, -a, -h) để liệt kê nội dung thư mục và hiểu định dạng đầu ra (quyền, chủ sở hữu, kích thước, ngày). Bước 3: Di chuyển: Thực hành điều hướng bằng cd, sử dụng cả đường dẫn tuyệt đối (ví dụ: cd /var/log) và tương đối (ví dụ: cd../..). Bước 4: Tạo và Xóa: Sử dụng touch để tạo các tệp trống, mkdir để tạo thư mục (và -p để tạo các thư mục cha), và rm để xóa tệp và thư mục (-r để xóa đệ quy). Bước 5: Thao tác với tệp: Sử dụng cp để sao chép, mv để di chuyển/đổi tên, và cat để hiển thị nội dung tệp. Lệnh Trường Hợp Sử Dụng Phổ Biến ls Liệt kê nội dung của một thư mục. cd Thay đổi thư mục làm việc hiện tại. pwd In ra đường dẫn đầy đủ của thư mục hiện tại. mkdir Tạo một thư mục mới. rm Xóa tệp hoặc thư mục. cp Sao chép tệp hoặc thư mục. mv Di chuyển hoặc đổi tên tệp hoặc thư mục. touch Tạo một tệp trống hoặc cập nhật dấu thời gian của tệp. cat Hiển thị nội dung của một tệp. head / tail Hiển thị phần đầu hoặc phần cuối của một tệp. Lab 2: Quản Lý Người Dùng, Nhóm và Quyền Truy Cập Mục tiêu: Bảo mật tài nguyên hệ thống bằng cách làm chủ quyền sở hữu tệp và các danh sách kiểm soát truy cập. Kỹ năng này có thể áp dụng trực tiếp vào việc bảo mật môi trường tác tử CI/CD, thiết lập quyền cho các tạo phẩm triển khai và cấu hình quyền truy cập của người dùng trên máy chủ.\nCác Khái Niệm Cốt Lõi Bộ ba Bảo mật: Mô hình quyền trong Linux dựa trên ba thực thể: user (người dùng, chủ sở hữu), group (nhóm), và other (những người khác). Giải mã Quyền: Mỗi thực thể có thể được cấp ba loại quyền cơ bản: read (r) (đọc), write (w) (ghi), và execute (x) (thực thi). Ý nghĩa của các quyền này khác nhau giữa tệp và thư mục. Ví dụ, quyền execute trên một thư mục cho phép người dùng cd vào thư mục đó, trong khi trên một tệp, nó cho phép chạy tệp đó như một chương trình. Thực Hành (Từng bước) Bước 1: Quản trị Người dùng và Nhóm: Tạo một người dùng mới với useradd, đặt mật khẩu với passwd, và tạo một nhóm mới với groupadd. Thêm người dùng vào nhóm vừa tạo.\nBước 2: Thay đổi Quyền sở hữu: Sử dụng chown để thay đổi chủ sở hữu của một tệp và chgrp (hoặc chown user:group) để thay đổi nhóm sở hữu. Luôn sử dụng\nsudo cho các hoạt động này khi cần thiết.\nBước 3: Sửa đổi Quyền bằng Ký hiệu Tượng trưng: Sử dụng chmod với ký hiệu tượng trưng (u+x, g-w, o=r) để thay đổi quyền một cách chi tiết và dễ đọc.\nBước 4: Sửa đổi Quyền bằng Ký hiệu Bát phân (Số): Giới thiệu các giá trị số (r=4, w=2, x=1) và trình bày cách thiết lập các quyền phổ biến như chmod 755 cho các tập lệnh và chmod 644 cho các tệp web.\nGiá trị Bát phân Ký hiệu Tượng trưng Trường Hợp Sử Dụng Phổ Biến 777 rwxrwxrwx Không an toàn, chỉ dùng cho mục đích tạm thời hoặc trong môi trường được kiểm soát chặt chẽ. 755 rwxr-xr-x Các tập lệnh thực thi, các thư mục cần người khác truy cập. 644 rw-r--r-- Các tệp nội dung web, tệp cấu hình chỉ đọc cho người khác. 600 rw------- Các tệp nhạy cảm như khóa riêng SSH, chỉ chủ sở hữu mới có thể đọc/ghi. Lab 3: Quản Lý Tiến Trình và Giám Sát Thời Gian Thực Mục tiêu: Học cách xem những gì đang chạy trên hệ thống, diễn giải việc sử dụng tài nguyên và quản lý các tiến trình hoạt động sai. Đây là tuyến phòng thủ đầu tiên khi khắc phục sự cố một ứng dụng chạy chậm hoặc không phản hồi, ngay cả bên trong một container.\nCác Khái Niệm Cốt Lõi Vòng đời Tiến trình: Một tiến trình là một thực thể của một chương trình đang chạy. Mỗi tiến trình có một Mã định danh Tiến trình (PID) duy nhất và có thể ở các trạng thái khác nhau như đang chạy (running), đang ngủ (sleeping), hoặc zombie (xác sống). Thực Hành (Từng bước) Bước 1: Liệt kê Tiến trình Tĩnh: Sử dụng ps aux để có một ảnh chụp nhanh chi tiết về tất cả các tiến trình đang chạy. Phân tích các cột chính: USER, PID, %CPU, %MEM, COMMAND. Bước 2: Giám sát Thời gian thực với top: Khởi chạy top và giải thích khu vực tóm tắt (tải trung bình, tác vụ, trạng thái CPU, bộ nhớ) và danh sách tiến trình tương tác. Trình bày cách sắp xếp theo bộ nhớ (M) và CPU (P). Bước 3: Giám sát Nâng cao với htop: Giới thiệu htop như một giải pháp thay thế thân thiện và tương tác hơn cho top. Hướng dẫn người dùng qua các tính năng chính của nó: hiển thị mã màu, cuộn dễ dàng, chế độ xem cây (F5), tìm kiếm (F3), và sắp xếp (F6). Bước 4: Chấm dứt Tiến trình: Sử dụng lệnh kill với PID để gửi tín hiệu. Giải thích sự khác biệt giữa SIGTERM (chấm dứt nhẹ nhàng, kill \u0026lt;PID\u0026gt;) và SIGKILL (chấm dứt cưỡng bức, kill -9 \u0026lt;PID\u0026gt;). Trình bày cách chấm dứt một tiến trình trực tiếp từ htop (F9). Các kỹ năng trong bài lab này không chỉ dành cho các máy chủ truyền thống; chúng là những công cụ chính để gỡ lỗi bên trong một container đang chạy. Khi một container sử dụng quá nhiều CPU hoặc bộ nhớ, quy trình chẩn đoán tiêu chuẩn là docker exec -it \u0026lt;container_id\u0026gt; bash theo sau là htop hoặc ps aux. Kubernetes hoặc Docker có thể cho biết rằng một container không khỏe mạnh, nhưng để tìm ra lý do tại sao, cần phải kiểm tra không gian tiến trình bị cô lập bên trong nó bằng chính các công cụ đã học.\nLab 4: Phân Tích Hiệu Năng Bộ Nhớ và I/O Đĩa Mục tiêu: Vượt ra ngoài việc giám sát CPU để chẩn đoán hai trong số những nút thắt hiệu năng phổ biến nhất: áp lực bộ nhớ và I/O đĩa chậm.\nCác Khái Niệm Cốt Lõi Mô hình Bộ nhớ Linux: Giải thích sự khác biệt giữa bộ nhớ used (đã sử dụng) và available (khả dụng), nhấn mạnh vai trò của buff/cache. Giải mã lý do tại sao \u0026ldquo;bộ nhớ trống thấp\u0026rdquo; thường là bình thường trong Linux. Giới thiệu về Bộ nhớ ảo, Hoán đổi (Swapping) và nguy cơ của Trình tiêu diệt Hết bộ nhớ (OOM Killer). Các Chỉ số I/O Đĩa: Xác định các chỉ số hiệu năng chính (KPI): IOPS (số thao tác mỗi giây), Thông lượng (MB/s), và Độ trễ/await (thời gian cho mỗi thao tác). Thực Hành (Từng bước) Bước 1: Phân tích Sử dụng Bộ nhớ: Sử dụng free -h để có cái nhìn tổng quan dễ đọc về việc sử dụng RAM và swap. Giải thích từng cột (total, used, free, buff/cache, available). Bước 2: Giám sát I/O Đĩa với iostat: Chạy iostat -x 1 để có cái nhìn thời gian thực, mở rộng về các thống kê đĩa. Tập trung vào việc diễn giải các cột quan trọng nhất: r/s, w/s (IOPS), rMB/s, wMB/s (Thông lượng), await (Độ trễ), và %util (Độ bão hòa). Bước 3: Xác định các Tiến trình Gây Tải I/O nặng với iotop: Sử dụng sudo iotop để xem một giao diện giống top của các tiến trình được xếp hạng theo I/O đĩa hiện tại của chúng. Điều này trả lời trực tiếp câu hỏi, \u0026ldquo;Tiến trình nào đang làm quá tải đĩa?\u0026rdquo;. Các chỉ số thu thập được trong bài lab này không phải là những con số tùy ý; chúng là dữ liệu thô cung cấp cho các khuôn khổ độ tin cậy cấp cao hơn như \u0026ldquo;Bốn Tín hiệu Vàng\u0026rdquo; của SRE của Google (Độ trễ, Lưu lượng, Lỗi, Độ bão hòa). Việc học cách đo lường chúng tại nguồn là một bước tiến từ quản trị hệ thống đơn thuần sang kỹ thuật đảm bảo độ tin cậy. Ví dụ, cột\nawait trong iostat là một thước đo trực tiếp về Độ trễ I/O đĩa. Các cột IOPS và thông lượng là thước đo trực tiếp về Lưu lượng đĩa. Cột %util trong iostat và %iowait từ top là các chỉ số trực tiếp về Độ bão hòa của đĩa và CPU. Bằng cách hiểu mối liên hệ này, ta có thể chẩn đoán các vấn đề hiệu năng với một tư duy chiến lược, tập trung vào các chỉ số thực sự quan trọng đối với sức khỏe của dịch vụ.\nLab 5: Các Lệnh Mạng và Xử Lý Sự Cố Thiết Yếu Mục tiêu: Xây dựng một bộ công cụ mạnh mẽ để chẩn đoán các vấn đề mạng, từ kiểm tra kết nối cơ bản đến kiểm tra các kết nối đang hoạt động và các vấn đề DNS—một công việc hàng ngày trong môi trường microservices.\nCác Khái Niệm Cốt Lõi Các khái niệm cơ bản về mạng bao gồm giao diện mạng, địa chỉ IP, cổng và socket, là những thành phần nền tảng cho mọi giao tiếp trên mạng.\nThực Hành (Từng bước) Bước 1: Kiểm tra Cấu hình Cục bộ: Sử dụng ip addr (thay thế hiện đại cho ifconfig) để xem các giao diện mạng và địa chỉ IP của chúng. Bước 2: Kiểm tra Kết nối Cơ bản: Sử dụng ping để kiểm tra khả năng tiếp cận và độ trễ, và traceroute để vạch ra đường đi của gói tin mạng đến một đích. Bước 3: Xử lý Sự cố DNS: Sử dụng dig và host để truy vấn các bản ghi DNS (A, CNAME, MX) và thực hiện tra cứu ngược. Điều này rất quan trọng để gỡ lỗi các vấn đề phát hiện dịch vụ (service discovery). Bước 4: Kiểm tra các Kết nối Đang hoạt động: Giới thiệu ss là công cụ thay thế hiện đại, nhanh hơn cho netstat. Sử dụng ss -tulpn để tìm các cổng đang lắng nghe và các tiến trình sử dụng chúng. Đây là chìa khóa để trả lời \u0026ldquo;Ứng dụng của tôi có đang lắng nghe trên đúng cổng không?\u0026rdquo; và \u0026ldquo;Cái gì đang kết nối với dịch vụ của tôi?\u0026rdquo;. Bước 5: Tương tác với Dịch vụ Web: Sử dụng curl để thực hiện các yêu cầu HTTP, xem các tiêu đề phản hồi (-I), và nhận chi tiết kết nối đầy đủ (-v), rất cần thiết để kiểm tra API và máy chủ web. Lệnh netstat Cũ Lệnh ss Hiện Đại Mục Đích netstat -tulpn ss -tulpn Liệt kê tất cả các cổng TCP/UDP đang lắng nghe và các tiến trình liên quan. netstat -tan ss -tan Hiển thị tất cả các kết nối TCP (cả đang lắng nghe và đã thiết lập). netstat -tun ss -tun Hiển thị tất cả các kết nối TCP và UDP. Lab 6: Thám Tử - Xử Lý Sự Cố Nâng Cao với strace Mục tiêu: Học cách sử dụng strace như công cụ gỡ lỗi tối thượng để xem chính xác một ứng dụng đang làm gì ở cấp độ lời gọi hệ thống, khi mà log và giám sát không đủ thông tin.\nCác Khái Niệm Cốt Lõi Ranh giới Kernel-Userspace: Lời gọi hệ thống (syscalls) là giao diện mà qua đó các ứng dụng yêu cầu dịch vụ từ nhân Linux (ví dụ: mở một tệp, gửi dữ liệu mạng). strace chặn và giải mã các lời gọi này, cung cấp một cái nhìn không bị che giấu về hoạt động của chương trình. Thực Hành (Từng bước) Bước 1: Truy vết Cơ bản: Chạy một lệnh đơn giản dưới strace (ví dụ: strace ls) để xem luồng đầu ra và hiểu định dạng của nó. Bước 2: Gắn vào một Tiến trình Đang chạy: Tìm PID của một tiến trình đang chạy (sử dụng ps hoặc htop từ Lab 3) và gắn vào nó với strace -p \u0026lt;PID\u0026gt;. Bước 3: Lọc Nhiễu: Sức mạnh thực sự của strace nằm ở khả năng lọc. Trình bày cách truy vết các syscall cụ thể với -e: Sự cố Truy cập Tệp: Sử dụng strace -e trace=file \u0026lt;command\u0026gt; để gỡ lỗi các lỗi \u0026ldquo;Permission denied\u0026rdquo; hoặc \u0026ldquo;No such file or directory\u0026rdquo; bằng cách xem chính xác đường dẫn tệp nào đang bị lỗi. Sự cố Mạng: Sử dụng strace -e trace=network \u0026lt;command\u0026gt; để xem các lời gọi connect, sendto, recvfrom, giúp gỡ lỗi các kết nối mạng chậm hoặc thất bại. Bước 4: Phân tích Hiệu năng: Giới thiệu cờ -T để hiển thị thời gian đã dành cho mỗi syscall, giúp xác định các nút thắt hiệu năng nơi ứng dụng đang chờ một thao tác I/O chậm. Log ứng dụng, các chỉ số và tài liệu mô tả những gì một chương trình nên làm. strace tiết lộ những gì nó thực sự đang làm. Nó là nguồn sự thật tối thượng để gỡ lỗi, bỏ qua tất cả các lớp trừu tượng ở cấp độ ứng dụng. Khi các công cụ khác cung cấp thông tin sai lệch hoặc im lặng, strace cung cấp một bản ghi khách quan, không bị lọc về ý định của chương trình, biến nó thành một kỹ năng quan trọng để giải quyết những lỗi \u0026ldquo;không thể\u0026rdquo;.\nLab 7: Các Thành Phần Xây Dựng Container: Namespaces Mục tiêu: Giải mã công nghệ container bằng cách trình bày thực tế cách các namespace của Linux tạo ra môi trường bị cô lập cho các tiến trình, mạng và hệ thống tệp.\nCác Khái Niệm Cốt Lõi Namespaces là gì? Namespaces là một tính năng của nhân Linux giúp phân vùng các tài nguyên hệ thống toàn cục sao cho một tiến trình bên trong một namespace nghĩ rằng nó có một phiên bản riêng của tài nguyên đó (ví dụ: cây tiến trình riêng, ngăn xếp mạng riêng). Đây là cốt lõi của sự cô lập container. Các loại Namespaces: Các loại namespace chính bao gồm PID (Process ID), Net (Network), MNT (Mount), UTS (Hostname), và User. Bài lab này sẽ tập trung vào namespace Mạng (net) như một ví dụ trực quan nhất. Thực Hành (Từng bước) Bước 1: Tạo Network Namespaces: Sử dụng ip netns add \u0026lt;name\u0026gt; để tạo hai namespace mạng riêng biệt (ví dụ: ns1, ns2). Bước 2: Xác minh Sự cô lập: Chạy ip netns exec \u0026lt;name\u0026gt; ip addr để cho thấy mỗi namespace chỉ có giao diện lo riêng của nó và đang ở trạng thái DOWN. Bước 3: Tạo một \u0026ldquo;Cáp Mạng Ảo\u0026rdquo;: Sử dụng ip link add veth-ns1 type veth peer name veth-ns2 để tạo một cặp ethernet ảo (một \u0026ldquo;dây cáp mạng\u0026rdquo; ảo). Bước 4: Kết nối các Namespaces: \u0026ldquo;Cắm\u0026rdquo; mỗi đầu của cáp ảo vào một namespace bằng cách sử dụng ip link set \u0026lt;veth-device\u0026gt; netns \u0026lt;name\u0026gt;. Bước 5: Cấu hình Mạng bị cô lập: Bên trong mỗi namespace, gán một địa chỉ IP cho giao diện veth (ip netns exec \u0026lt;name\u0026gt; ip addr add...) và bật giao diện lên (ip netns exec \u0026lt;name\u0026gt; ip link set... up). Bước 6: Kiểm tra Giao tiếp: Sử dụng ip netns exec ns1 ping \u0026lt;ns2_ip\u0026gt; để cho thấy hai môi trường bị cô lập giờ đây có thể giao tiếp với nhau qua mạng riêng của chúng, nhưng vẫn vô hình đối với máy chủ chủ (host). Lab 8: Người Quản Lý - Quản Lý Tài Nguyên với Control Groups (cgroups) Mục tiêu: Bổ sung cho sự cô lập từ Lab 7, bài lab này trình bày cách sử dụng cgroups để giới hạn tài nguyên (CPU, bộ nhớ) mà một tiến trình có thể tiêu thụ, hoàn thiện bức tranh về container hóa.\nCác Khái Niệm Cốt Lõi cgroups là gì? cgroups (control groups) là một tính năng của nhân Linux để giới hạn, tính toán và ưu tiên việc sử dụng tài nguyên cho một tập hợp các tiến trình. Trong khi namespaces cung cấp sự cô lập (\u0026ldquo;những gì bạn có thể thấy\u0026rdquo;), cgroups cung cấp sự giới hạn (\u0026ldquo;những gì bạn có thể sử dụng\u0026rdquo;). Controllers/Subsystems: cgroups được quản lý thông qua các hệ thống con như memory, cpu, và blkio, mỗi hệ thống con kiểm soát một tài nguyên cụ thể. Thực Hành (Từng bước) Bước 1: Tạo một cgroup: Sử dụng cgcreate -g memory,cpu:/my-app-group để tạo một cgroup mới được quản lý bởi các controller bộ nhớ và CPU. Hoặc, có thể tạo thư mục thủ công trong hệ thống tệp ảo /sys/fs/cgroup/. Bước 2: Đặt Giới hạn Bộ nhớ: Sử dụng echo \u0026quot;100M\u0026quot; \u0026gt; /sys/fs/cgroup/memory/my-app-group/memory.limit_in_bytes để đặt giới hạn bộ nhớ 100MB. Bước 3: Đặt Giới hạn CPU: Trình bày cách đặt hạn ngạch CPU. Ví dụ, echo 50000 \u0026gt;.../cpu.cfs_quota_us và echo 100000 \u0026gt;.../cpu.cfs_period_us để giới hạn tiến trình ở mức 50% của một lõi CPU. Bước 4: Chạy một Tiến trình trong cgroup: Sử dụng cgexec -g memory,cpu:/my-app-group \u0026lt;command\u0026gt; để chạy một tiến trình trong các giới hạn này. Bước 5: Quan sát Giới hạn: Giám sát tiến trình bằng htop và xem nó bị điều tiết (CPU) hoặc bị OOM killer chấm dứt khi vượt quá giới hạn bộ nhớ. Kiểm tra các tệp kế toán của cgroup (memory.usage_in_bytes, memory.failcnt) để thấy việc thực thi giới hạn trong thực tế. Các bài lab 7 và 8 không chỉ là các bài tập lý thuyết; chúng là một minh chứng thực tế về những gì Kubernetes làm \u0026ldquo;dưới mui xe\u0026rdquo; mỗi khi nó lập lịch cho một Pod. Sự cô lập mạng của một Pod là một network namespace. Dòng resources: { limits: { memory: \u0026quot;100Mi\u0026quot; } } trong tệp YAML của Pod được dịch trực tiếp thành một cấu hình cgroup trên node. Do đó, việc gỡ lỗi một Pod bị OOMKilled trong Kubernetes về cơ bản là việc hiểu sự tương tác giữa ứng dụng và giới hạn bộ nhớ cgroup do Kubelet áp đặt. Hướng dẫn này kết nối tệp YAML trừu tượng của Kubernetes với các tính năng cụ thể của nhân Linux, trao quyền cho kỹ sư để suy luận về hành vi của container từ các nguyên tắc cơ bản, giúp họ trở thành một người vận hành và xử lý sự cố Kubernetes hiệu quả hơn nhiều.\nNếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","permalink":"https://blog.nagih.io.vn/posts/labs-operating/","summary":"\u003cp\u003e1 Số Labs từ Cơ bản tới Nâng cao về Operating\u003c/p\u003e","title":"Labs Operating"},{"content":"6 Cấp Độ Trưởng Thành Từ Deploy Thủ Công Đến Vận Hành Tinh Gọn\nLevel 0: Deploy Thủ Công Công cụ và Quy trình Quy trình thủ công: Việc triển khai được thực hiện bằng cách kết nối thủ công đến máy chủ thông qua các giao thức như FTP, SCP, hoặc SSH, sau đó sao chép từng tệp.\nQuản lý mã nguồn hỗn loạn: Nếu có sử dụng Git, quy trình làm việc thường là \u0026ldquo;Centralized Workflow\u0026rdquo;, nơi mọi người đều đẩy (push) mã nguồn trực tiếp lên nhánh chính (main hoặc master), gây ra sự bất ổn định và khó theo dõi.\nRủi ro và Nỗi đau Rủi ro bảo mật: Giao thức FTP truyền thông tin đăng nhập (username, password) dưới dạng văn bản thuần (plain text), khiến chúng dễ dàng bị \u0026ldquo;bắt\u0026rdquo; bởi bất kỳ ai trên mạng. Dữ liệu truyền đi cũng không được mã hóa, có nguy cơ bị tấn công xen giữa (man-in-the-middle), nơi kẻ tấn công có thể chèn mã độc vào các tệp đang được triển khai mà không bị phát hiện.\nHệ thống cực kỳ mong manh: Quy trình này rất dễ xảy ra lỗi. Chỉ cần quên một tệp, sao chép sai thư mục, hoặc một tệp truyền bị lỗi cũng có thể làm sập toàn bộ hệ thống.\nKhông có cơ chế Rollback: Khi một lần triển khai thất bại, không có cách nào dễ dàng và tự động để quay trở lại phiên bản ổn định trước đó.\nLevel 1: Script và Quản Lý Mã Nguồn Có Cấu Trúc Công cụ và Quy trình Sự ra đời của Script: \u0026ldquo;Deployment checklist\u0026rdquo; từ level 0 được mã hóa thành một kịch bản (script) triển khai đơn giản, thường sử dụng Bash. Script này tự động hóa các bước kết nối đến máy chủ, lấy mã nguồn mới nhất từ kho chứa, và khởi động lại các dịch vụ.\nQuy trình Git có cấu trúc: Nhóm nhận ra rằng việc đẩy trực tiếp lên nhánh main là không bền vững. Họ áp dụng một chiến lược phân nhánh chính thức, phổ biến nhất là Feature Branch Workflow.\nNhánh main giờ đây được coi là \u0026ldquo;bất khả xâm phạm\u0026rdquo; và luôn ở trạng thái sẵn sàng để triển khai.\nTất cả công việc mới (tính năng, sửa lỗi) được thực hiện trên các nhánh riêng biệt.\nCác thay đổi được tích hợp trở lại vào main thông qua Pull Request (hoặc Merge Request), cho phép thực hiện quy trình đánh giá mã nguồn (code review).\nLợi ích và Những Vấn đề Còn Tồn Tại Lợi ích: Bản thân quy trình triển khai giờ đây đã đáng tin cậy và nhất quán hơn. Nhánh main ổn định hơn. Việc đánh giá mã nguồn giúp cải thiện chất lượng.\nVấn đề còn tồn tại: Script không xử lý tốt các trường hợp thất bại. Không có kiểm thử tự động, lỗi vẫn được triển khai, chỉ là một cách nhất quán hơn. Các môi trường (development, staging, production) vẫn được cấu hình thủ công và không nhất quán, dẫn đến vấn đề kinh điển \u0026ldquo;nó chạy trên máy của tôi\u0026rdquo;.\nLevel 2: CI/CD Đây là một bước nhảy vọt. Trọng tâm chuyển từ một script triển khai đơn lẻ sang một đường ống (pipeline) tự động hóa hoàn toàn, hoạt động như một \u0026ldquo;nhà máy\u0026rdquo; trung tâm cho việc phân phối phần mềm. Đây là nơi thế giới \u0026ldquo;Dev\u0026rdquo; và \u0026ldquo;Ops\u0026rdquo; thực sự bắt đầu hợp nhất.\nCốt Lõi Tích hợp Liên tục (Continuous Integration - CI): Là thực tiễn tự động hóa việc tích hợp các thay đổi mã nguồn từ nhiều nhà phát triển vào một dự án duy nhất. Mỗi lần đẩy mã nguồn lên một nhánh sẽ kích hoạt một quy trình xây dựng (build) tự động và một bộ các bài kiểm thử tự động (unit test, integration test).\nPhân phối Liên tục (Continuous Delivery - CD): Là một phần mở rộng của CI. Sau khi các giai đoạn xây dựng và kiểm thử thành công, phần mềm sẽ được đóng gói và triển khai tự động đến một hoặc nhiều môi trường phi sản xuất (như staging). Việc triển khai lên production thường là một bước thủ công, chỉ cần một cú nhấp chuột.\nTriển khai Liên tục (Continuous Deployment - cũng là CD): Là hình thức tiên tiến nhất, nơi mọi thay đổi vượt qua tất cả các bài kiểm thử tự động đều được triển khai tự động lên production mà không cần sự can thiệp của con người.\nCông cụ Việc lựa chọn một công cụ CI/CD là một quyết định quan trọng ở giai đoạn này. Bảng dưới đây so sánh các lựa chọn phổ biến nhất.\nTính năng Jenkins GitLab CI GitHub Actions Thiết lập \u0026amp; Lưu trữ Cần cài đặt thủ công, thiết lập agent, tự lưu trữ (on-premise/cloud). Tích hợp sẵn trong GitLab, không cần cài đặt riêng. Tích hợp sẵn trong GitHub, không cần cài đặt riêng. Cấu hình Jenkinsfile (viết bằng Groovy) hoặc qua giao diện người dùng (UI). Tệp YAML (.gitlab-ci.yml) trong kho mã nguồn. Tệp YAML trong thư mục .github/workflows. Hệ sinh thái \u0026amp; Mở rộng Cực kỳ mạnh mẽ với hơn 1800 plugin, tùy biến cao nhưng có thể phức tạp và dễ gặp vấn đề tương thích. Tích hợp sâu với các tính năng của GitLab. Hệ sinh thái plugin nhỏ hơn Jenkins. Thị trường (Marketplace) rộng lớn với các \u0026ldquo;Actions\u0026rdquo; tái sử dụng. Dễ dàng tạo action tùy chỉnh. Trường hợp sử dụng lý tưởng Các quy trình phức tạp, yêu cầu tùy biến sâu, môi trường on-premise hoặc các hệ thống cũ (legacy). Các nhóm đã và đang sử dụng GitLab làm nền tảng chính, muốn một giải pháp \u0026ldquo;tất cả trong một\u0026rdquo;. Các nhóm ưu tiên GitHub, dự án mã nguồn mở, startup, cần sự đơn giản và khởi đầu nhanh chóng. Lợi ích và Thách thức Mới Lợi ích: Vòng lặp phản hồi nhanh hơn đáng kể, chất lượng mã nguồn được cải thiện, giảm rủi ro triển khai và tăng năng suất của nhà phát triển.\nThách thức: Bản thân \u0026ldquo;đường ống CI/CD\u0026rdquo; trở thành một phần mềm phức tạp cần được bảo trì. Các nhóm giờ đây phải đối mặt với những vấn đề mới như các bài kiểm thử chạy chậm hoặc không ổn định (flaky tests), quản lý các phụ thuộc phức tạp, và vấn đề dai dẳng về \u0026ldquo;trôi dạt môi trường\u0026rdquo; (environment drift), nơi môi trường staging và production không giống hệt nhau.\nLevel 3: Hạ Tầng Dưới Dạng Mã (IaC) và Container Hóa Để giải quyết vấn đề trôi dạt môi trường và làm cho việc quản lý hạ tầng trở nên nghiêm ngặt như phát triển ứng dụng, các nhóm áp dụng triết lý \u0026ldquo;mọi thứ đều là mã nguồn\u0026rdquo;.\nCốt Lõi Hạ tầng dưới dạng mã (Infrastructure as Code - IaC): Là việc quản lý và cấp phát hạ tầng (máy chủ, mạng, cơ sở dữ liệu) thông qua các tệp định nghĩa mà máy có thể đọc được (mã nguồn), thay vì cấu hình thủ công. Có hai cách tiếp cận chính:\nDeclarative: Bạn định nghĩa trạng thái cuối cùng mong muốn của hạ tầng. Công cụ (ví dụ: Terraform) sẽ tự tìm cách để đạt được trạng thái đó. Đây là cách tiếp cận chủ đạo trong IaC hiện đại.\nImperative: Bạn viết các kịch bản chỉ định các bước chính xác cần thực hiện để cấu hình hạ tầng (ví dụ: Ansible, Chef, Puppet).\nContainer hóa với Docker: Là người bạn đồng hành hoàn hảo của IaC. Docker giải quyết vấn đề \u0026ldquo;nó chạy trên máy của tôi\u0026rdquo; bằng cách đóng gói một ứng dụng và tất cả các phụ thuộc của nó vào một đơn vị duy nhất, được tiêu chuẩn hóa và bị cô lập gọi là container.\nDockerfile: \u0026ldquo;Công thức\u0026rdquo; hay bản thiết kế để xây dựng một image.\nImage: Một mẫu chỉ đọc (read-only) chứa ứng dụng và môi trường của nó.\nContainer: Một thực thể đang chạy (running instance) của một image. Nó nhẹ và có tính di động cao.\nQuy trình Mới Đường ống CI/CD được nâng cấp. Nó không còn chỉ triển khai mã nguồn; nó xây dựng một Docker image (một tạo phẩm nhất quán được đảm bảo) và sử dụng các công cụ IaC như Terraform để cấp phát một môi trường giống hệt nơi container sẽ chạy.\nLợi ích và Nút thắt Cổ chai Tiếp theo Lợi ích: Vấn đề trôi dạt môi trường được loại bỏ. Các lần triển khai giờ đây có tính nhất quán và độ tin cậy cao trên các môi trường dev, staging và production. Các thay đổi về hạ tầng được quản lý phiên bản, được đánh giá và có thể kiểm tra lại.\nNút thắt cổ chai tiếp theo: Tổ chức bây giờ đã thành công và có hàng trăm hoặc hàng nghìn container. Làm thế nào để quản lý chúng? Làm thế nào để xử lý mạng, mở rộng quy mô và kiểm tra sức khỏe cho tất cả các container này? Đây là vấn đề của việc điều phối (orchestration).\nLevel 4: Điều Phối Container và Kiến Trúc Cloud-Native Trọng tâm chuyển từ việc quản lý các container riêng lẻ sang quản lý một ứng dụng phân tán bao gồm nhiều container ở quy mô lớn. Điều này đòi hỏi một \u0026ldquo;nhạc trưởng\u0026rdquo; cho \u0026ldquo;dàn nhạc\u0026rdquo; container.\nCốt Lõi: Kubernetes (K8s) Kubernetes: Là hệ thống mã nguồn mở, tiêu chuẩn de-facto của ngành công nghiệp, dùng để tự động hóa việc triển khai, mở rộng quy mô và quản lý các ứng dụng được container hóa. Nó giải quyết vấn đề chạy các hệ thống phân tán một cách linh hoạt và có khả năng phục hồi.\n**Các đối tượng Kubernetes chính:\nPod: Đơn vị triển khai nhỏ nhất, cơ bản nhất trong Kubernetes. Nó là một lớp vỏ bọc quanh một hoặc nhiều container, chia sẻ tài nguyên lưu trữ và mạng. Hãy coi nó như \u0026ldquo;nguyên tử\u0026rdquo; cơ bản của một ứng dụng K8s.\nDeployment: Một đối tượng cấp cao hơn mô tả trạng thái mong muốn cho ứng dụng của bạn. Nó nói với Kubernetes rằng \u0026ldquo;Tôi muốn có 3 bản sao (replica) của pod máy chủ web của tôi chạy mọi lúc.\u0026rdquo; Bộ điều khiển Deployment (Deployment Controller) sẽ làm việc để biến trạng thái này thành hiện thực.\nService: Một lớp trừu tượng định nghĩa một tập hợp logic các Pod và một chính sách để truy cập chúng. Nó cung cấp một địa chỉ IP và tên DNS ổn định, để các phần khác của ứng dụng (hoặc người dùng bên ngoài) có thể kết nối đến các Pod, ngay cả khi chúng được tạo ra và phá hủy.\nLợi ích và Sự Phức Tạp Mới Lợi ích: Tổ chức đạt được khả năng mở rộng quy mô thực sự, tự phục hồi (Kubernetes tự động khởi động lại các container bị lỗi), và tính sẵn sàng cao. Các bản cập nhật và quay lui (rolling updates and rollbacks) giờ đây được quản lý một cách khai báo và an toàn.\nSự phức tạp mới: Bản thân Kubernetes là một hệ thống cực kỳ phức tạp. Việc học nó rất khó khăn. Quản lý, giám sát và bảo mật một cụm Kubernetes (cluster) trở thành một công việc toàn thời gian. Thách thức mới không còn là \u0026ldquo;làm thế nào để chạy ứng dụng của chúng ta?\u0026rdquo; mà là \u0026ldquo;làm thế nào để chạy Kubernetes một cách đáng tin cậy?\u0026rdquo;\nLevel 5: Vận Hành Dựa Trên Dữ Liệu (SRE, GitOps, \u0026amp; Observability) Đây là level cao nhất. Các hoạt động vận hành không còn là bị động hay thậm chí chỉ là tự động; chúng trở nên chủ động, được điều khiển bằng dữ liệu và được xem như một ngành kỹ thuật phần mềm.\nCốt Lõi Site Reliability Engineering - SRE: Một phương pháp triển khai cụ thể của DevOps, bắt nguồn từ Google. Nó coi các vấn đề vận hành như những bài toán phần mềm.\nSLI, SLO, và Ngân sách Lỗi (Error Budgets): SRE cung cấp một khung làm việc toán học cho độ tin cậy.\nSLI (Service Level Indicator - Chỉ số Cấp độ Dịch vụ): Một thước đo định lượng về một khía cạnh nào đó của dịch vụ (ví dụ: độ trễ yêu cầu, tỷ lệ lỗi).\nSLO (Service Level Objective - Mục tiêu Cấp độ Dịch vụ): Một giá trị mục tiêu cho một SLI trong một khoảng thời gian (ví dụ: 99.9% yêu cầu được phục vụ trong \u0026lt;200ms).\nError Budget (Ngân sách Lỗi): Là phần nghịch đảo của SLO (100%−SLO). Đây là lượng \u0026ldquo;không đáng tin cậy\u0026rdquo; mà nhóm được phép \u0026ldquo;tiêu thụ\u0026rdquo;. Nếu ngân sách lỗi còn dương, nhóm có thể phát hành tính năng mới. Nếu nó cạn kiệt, mọi công việc phải chuyển sang cải thiện độ tin cậy.\nSRE và DevOps: SRE trả lời câu hỏi \u0026ldquo;làm thế nào\u0026rdquo; cho cái \u0026ldquo;gì\u0026rdquo; của DevOps.\nGitOps: Sự tiến hóa của IaC và CI/CD. Git là nguồn chân lý duy nhất (single source of truth) cho toàn bộ trạng thái hệ thống (hạ tầng và ứng dụng).\nQuy trình làm việc: Các thay đổi được thực hiện thông qua Pull Request đến một kho chứa Git. Một agent bên trong cụm Kubernetes (như Argo CD hoặc Flux) liên tục so sánh trạng thái thực tế với trạng thái được khai báo trong Git và tự động điều chỉnh bất kỳ sự khác biệt nào.\nArgo CD và Flux: Argo CD giống một nền tảng hoàn chỉnh, có giao diện người dùng, trong khi Flux là một bộ công cụ mô-đun hơn, tập trung vào dòng lệnh và thường được coi là gần gũi hơn với cách tiếp cận \u0026ldquo;thuần Kubernetes\u0026rdquo;.\nKhả năng Quan sát (Observability): Vượt ra ngoài việc giám sát đơn giản (\u0026ldquo;máy chủ có hoạt động không?\u0026rdquo;) để đạt đến sự hiểu biết sâu sắc về hệ thống (\u0026ldquo;tại sao máy chủ lại chậm đối với người dùng ở khu vực cụ thể này?\u0026rdquo;).\nBa Trụ cột của Observability:\nLogs: Các bản ghi chi tiết, có dấu thời gian về các sự kiện riêng lẻ.\nMetrics: Dữ liệu số, được tổng hợp theo thời gian (ví dụ: mức sử dụng CPU, số lượng yêu cầu).\nTraces: Cho thấy hành trình từ đầu đến cuối của một yêu cầu khi nó di chuyển qua một hệ thống phân tán.\nCông cụ: Các ngăn xếp công cụ phổ biến bao gồm Prometheus \u0026amp; Grafana để theo dõi số liệu và trực quan hóa, và ELK Stack (Elasticsearch, Logstash, Kibana) để quản lý nhật ký.\nKết luận Hành động Đánh giá Mức độ Trưởng thành: Các tổ chức nên sử dụng mô hình này để xác định vị trí hiện tại của nhóm mình.\nTập trung vào Nút thắt Cổ chai Tiếp theo: Thay vì cố gắng nhảy từ Cấp độ 0 lên Cấp độ 5, chìa khóa là xác định điểm yếu lớn nhất hiện tại và áp dụng các thực tiễn của cấp độ tiếp theo để giải quyết nó. Quá trình này nên diễn ra từ từ và có kế hoạch.\nLộ trình Kỹ năng Tóm tắt: Để phát triển cá nhân hoặc xây dựng đội ngũ, một lộ trình kỹ năng có cấu trúc là cần thiết:\nNền tảng: Ngôn ngữ lập trình (Python/Go), Linux/Shell Scripting, Git.\nDevOps Cốt lõi: Công cụ CI/CD (Jenkins, GitLab CI, GitHub Actions), IaC (Terraform), Containers (Docker).\nNâng cao/Cloud-Native: Kubernetes, Nền tảng Đám mây (AWS/GCP/Azure), Giám sát/Quan sát (Prometheus, Grafana).\nTinh hoa/SRE: Hiểu biết sâu về hệ thống phân tán, triển khai SLI/SLO, tự động hóa nâng cao.\n","permalink":"https://blog.nagih.io.vn/posts/6-level-deploy/","summary":"\u003cp\u003e6 Cấp Độ Trưởng Thành Từ Deploy Thủ Công Đến Vận Hành Tinh Gọn\u003c/p\u003e","title":"6 Level Deploy"},{"content":"9 nguyên tắc cốt lõi và một số kỹ năng mở rộng khi khởi tạo bảng trong MySQL, đảm bảo ứng dụng không chỉ chạy đúng mà còn hiệu quả và dễ bảo trì\n1. Mọi Table Luôn Phải Có Các Column Mặc Định\nMột thiết kế table hoàn chỉnh cần có ít nhất 5 trường mặc định để theo dõi lịch sử và tính nhất quán của dữ liệu:\nversion: Ghi lại số lần chỉnh sửa của table, đồng thời liên quan đến các khái niệm khóa lạc quan (optimistic lock) và khóa bi quan (pessimistic lock)\ncreator_id: (Tùy chọn, tùy thuộc vào công ty) Ai là người tạo bản ghi này\nmodifier: Ai là người cuối cùng sửa đổi bản ghi, quan trọng để biết hành động cuối cùng trên table\ncreate_at: Thời gian bản ghi được tạo\nupdate_at: Thời gian bản ghi được cập nhật lần cuối\n2. Giải Thích Ngữ Nghĩa Các Column Bằng Comment\nKhi viết DDL (Data Definition Language) cho MySQL, PostgreSQL, hoặc bất kỳ hệ quản trị cơ sở dữ liệu nào, hãy luôn thêm comment giải thích ý nghĩa của từng column. Việc comment rõ ràng giúp các thành viên mới gia nhập team dễ dàng hiểu và làm quen với cấu trúc dữ liệu, tránh sự hiểu lầm về ngữ nghĩa của các trường\n3. Xóa Dữ Liệu Không Phải Xóa \u0026ldquo;Bay\u0026rdquo; (Xóa Logic)\nKhông bao giờ sử dụng lệnh DELETE để xóa vật lý dữ liệu trực tiếp trong môi trường sản phẩm. Thay vào đó, hãy sử dụng phương pháp xóa logic (soft delete) bằng cách thêm một trường để đánh dấu bản ghi đã bị xóa hay chưa, và thời gian xóa\nBan đầu có thể sử dụng hai trường: is_deleted (0: hoạt động, 1: đã xóa) và deleted_at (thời gian xóa)\nCách tối ưu hơn là chỉ sử dụng một trường deleted_at: Nếu giá trị là NULL nghĩa là bản ghi chưa bị xóa; nếu có giá trị thời gian, đó là thời gian bản ghi bị xóa\nLưu ý: Giá trị NULL có thể gây nhược điểm nghiêm trọng về hiệu suất index khi dữ liệu lớn, do đó cần cân nhắc kỹ hoặc tìm hiểu sâu hơn về NULL trong database\n4. Quy Ước Đặt Tên Với Prefix (Tiền Tố)\nCác trường (field) trong table nên có các tiền tố (prefix) để dễ dàng xác định nguồn gốc khi các bảng được join lại với nhau. Ví dụ, bảng account có thể có trường acc_number. Việc này cực kỳ quan trọng vì trong thực tế, chúng ta ít khi làm việc với dữ liệu độc lập mà thường phải join nhiều bảng (ít nhất 3 bảng là nguyên tắc làm việc). Nếu không có prefix, việc phân biệt ID hay create_at thuộc về bảng nào khi join sẽ gây ra sự hiểu nhầm và lỗi\n5. Tách Bảng Khi Có Quá Nhiều Trường (Vertical Partitioning)\nMột table không nên có quá nhiều trường (column), tối đa khoảng 20 trường. Nếu vượt quá, cần phải tách bảng dọc (vertical partition). Bảng có nhiều trường sẽ làm dữ liệu lưu trữ lớn, giảm hiệu suất truy vấn và tốn bộ nhớ\nTách bảng: Chia thành một bảng chính chứa các trường được truy cập thường xuyên và quan trọng (ví dụ: title, status, thumbnail của một bài post), và một bảng chi tiết chứa các trường ít quan trọng hơn hoặc chỉ hiển thị khi người dùng click vào (ví dụ: content, description)\nMối quan hệ giữa hai bảng này thường là 1-1, giúp việc join đơn giản và hiệu quả, không ảnh hưởng đến hiệu suất\n6. Chọn Kiểu Dữ Liệu và Độ Dài Thích Hợp\nMột hệ thống tốt không chỉ chạy đúng mà còn phải chạy hiệu quả. Việc chọn kiểu dữ liệu và độ dài phù hợp giúp:\nTiết kiệm bộ nhớ (memory) và dung lượng đĩa (disk)\nTối ưu tốc độ query\nGiảm tỷ lệ Input/Output (I/O). Ví dụ:\nTrường title không nên để VARCHAR(255) nếu độ dài thực tế chỉ khoảng 100 ký tự (như tiêu đề video YouTube/TikTok)\nTrường language chỉ cần CHAR(2) (ví dụ: \u0026ldquo;en\u0026rdquo;, \u0026ldquo;vi\u0026rdquo;) thay vì VARCHAR dài\nTrường status chỉ nên dùng TINYINT (kích thước 1 byte, lưu trữ 0-255) thay vì INT (kích thước 4 byte, lưu trữ 0-4 tỷ ID) nếu các giá trị chỉ là 1, 2, 3\n7. Nguyên Tắc Not NULL\nKhông nên cho phép giá trị NULL bừa bãi. NULL không phải là một số, một chuỗi hay một biến boolean; nó là một vùng không xác định. NULL có thể:\nLàm hỏng logic nghiệp vụ nếu quên xử lý\nGây lỗi index khi so sánh bằng NULL (ví dụ WHERE column IS NULL thường không sử dụng index hiệu quả). Các trường bắt buộc phải có giá trị (như title, status, create_at) nên được khai báo là NOT NULL. Khi không có giá trị, hãy sử dụng DEFAULT đi kèm với NOT NULL\n8. Chiến Lược Đánh Index\nIndex là chìa khóa để tối ưu hiệu suất truy vấn\nNên đánh index cho các trường ít trùng lặp và thường xuyên được sử dụng trong truy vấn, ví dụ: creator_id và create_at (quan trọng khi truy vấn theo thời gian). Luôn có prefix idx_ cho các index\nTrường deleted_at luôn cần được đánh index để tránh hiển thị các bản ghi đã bị xóa ra công khai, điều này có thể dẫn đến các vấn đề pháp lý (ví dụ: GDPR của Châu Âu)\nQUY TẮC VÀNG: Không nên đánh index cho các trường có dữ liệu lặp lại quá nhiều (ví dụ: trường status mà 90% bản ghi có cùng một giá trị). Việc đánh index trong trường hợp này thậm chí có thể làm chậm truy vấn hơn so với không đánh index, vì database sẽ quét toàn bộ table thay vì sử dụng index\nGiải pháp thay thế khi cần truy vấn các trường có nhiều giá trị trùng lặp:\nThêm trường tiền tố phạm vi thời gian: Ví dụ, kết hợp status với create_at theo phạm vi thời gian (WHERE status = 1 AND create_at BETWEEN '2025-06-15 00:00 :00' AND '2025-06-15 23:59:59') để giúp index hoạt động hiệu quả hơn\nChia table thành các phân vùng (Partition): Phù hợp với dữ liệu lớn, giúp chia nhỏ dữ liệu. Tuy nhiên, Partition không thay thế được index và có nhược điểm riêng, chỉ nên dùng khi thực sự cần và hiểu rõ\nTạo View: View có thể hoạt động rất tốt trong các truy vấn với stored procedure hoặc function, giúp truy vấn nhanh hơn khi dữ liệu được lặp lại và cảm thấy đúng đánh lặp lại\n9. Nguyên Tắc Normal Form (3NF, 4NF, 5NF)\nNormalization là một nguyên tắc cơ bản trong thiết kế database nhằm giảm thiểu sự dư thừa dữ liệu và cải thiện tính toàn vẹn dữ liệu\n3NF (Third Normal Form) là một nguyên tắc cơ bản cần nắm vững\nNgoài ra, còn có các dạng chuẩn mở rộng hơn như 4NF (Fourth Normal Form) và 5NF (Fifth Normal Form), giúp tối ưu hóa hơn nữa về sự mở rộng và tính linh hoạt của database\nViệc tìm hiểu sâu về các Normal Form này sẽ giúp bạn thiết kế database hiệu quả hơn cho các mô hình kinh doanh phức tạp\n","permalink":"https://blog.nagih.io.vn/posts/9-mysql-table-design-rules--skills/","summary":"\u003cp\u003e9 nguyên tắc cốt lõi và một số kỹ năng mở rộng khi khởi tạo bảng trong MySQL, đảm bảo ứng dụng không chỉ chạy đúng mà còn hiệu quả và dễ bảo trì\u003c/p\u003e","title":"9 MySQL Table Design Rules \u0026 Skills"},{"content":"Giới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\nKAFKA ĐƯỢC DÙNG KHI NÀO ? Kiến trúc truyền thống - Lập trình nối tiếp Các function quá lệ thuộc vào nhau: Nếu 1 ngày nào đó, tính năng update cart của 1 nhân viên B bị lỗi thì khi user save order -\u0026gt; update cart nhưng bị lỗi ở đây và trả về lỗi, thực tế nếu hệ thống bỏ qua bước này và cho tới bước update inventory thì có được hay không ? Thực tế, mọi trang thương mại điện tử hiện nay đều có thể xử lý lỗi thành công, miễn là cho user có trải nghiệm tốt là được. Nếu xảy ra lỗi. Các hệ thống sẽ trả cho user phần bù đắp thiệt hại cho user (1 vourcher chẳng hạn) chứ không nên để cho user đặt hàng không thành công.\nTrong hình ảnh tiếp theo, tôi đã cung cấp thêm thời gian phản hồi, có thể thấy mỗi 1 request sẽ mất 150ms\nGiả sử nhân viên B phụ trách tính năng update cart nhưng code yếu thì làm sao ? Tức là tính năng update cart được tính toán nhiều quá, không hiệu quả, và kết quả là bị tắc đường ở đó. Và tất nhiên hệ thống phải đồng bộ. Chẳng hạn khi có 10.000 users bị tắc nghẽn ở đó thì phải làm như thế nào ?\nVà một ngày nào đó, lượng users tăng cao, và cần thêm tính năng mới - Thống kê. Tính năng này thống kê điểm tích lũy cho user để có thể tặng quà cho những người mua hàng nhiều nhất, tích điểm,\u0026hellip; Thì khi thêm 1 tính năng bất kỳ, đồng nghĩa với việc sẽ tăng thêm thời gian phản hồi, nguy cơ tăng lỗi cũng sẽ cao hơn\nKiến trúc phân tán Có thể thấy, tất cả các order đều được đẩy vào Message Queue, và ngay lập tức trả về response cho user, không cần quan tâm tới những tác vụ còn lại. Và tất nhiên các tác vụ update cart, update inventory, save payment, save shopping vẫn được tiến hành và được tiến hành theo đúng trình tự.\nVà nhắc lại trường hợp khi nãy, giả sử tính năng update inventory bị lỗi thì chuyện gì sẽ xảy ra? Điều đầu tiên là sẽ không ảnh hưởng tới trải nghiệm người dùng, tiếp theo là message queue có cơ chế tự động sửa lỗi những message bị error, nếu cố gắng sửa đổi trong vòng (10) lần mà không thành công, khi đó sẽ đưa con người vào trực tiếp tham gia quá trình sửa đổi này\nTỉ lệ phản hồi thay vì 150ms như kiến trúc truyền thống thì sẽ chỉ mất 20ms + 5ms từ save order tới message queue, ngay lập tức phản hồi tới user\nTrong kiến trúc phân tán, ta có thể quy định hệ thống làm việc với cường độ 100 orders/time, đến khi nào order hết trong MQ, hay có thể nói là chỉ chỉ đưa cho 100 reqs để làm mà thôi, không được vội vàng, còn lại phải xếp hàng lần lượt, cứ như vậy cho đến hết.\nVà bây giờ, nếu lượng users tăng cao và cần thêm tính năng mới thì cũng không hề ảnh hưởng tới dây chuyền sản xuất\nNếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","permalink":"https://blog.nagih.io.vn/posts/kafka/","summary":"\u003cp\u003eGiới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\u003c/p\u003e","title":"Kafka"},{"content":"Tổng quan về kiến trúc microservices\n1. Kiến trúc Microservices là gì? Hãy tưởng tượng bạn đang xây một ngôi nhà.\nKiến trúc nguyên khối (Monolith): Bạn xây toàn bộ ngôi nhà bằng một khối bê tông khổng lồ duy nhất. Mọi thứ dính liền với nhau. Nếu bạn muốn sửa đường ống nước trong bếp, bạn có thể phải đục cả bức tường lớn, ảnh hưởng đến phòng khách bên cạnh.\nKiến trúc Microservices: Bạn xây ngôi nhà bằng những viên gạch LEGO. Mỗi phòng (phòng khách, phòng ngủ, nhà bếp) là một khối LEGO riêng. Nếu muốn sửa bếp, bạn chỉ cần nhấc khối LEGO \u0026ldquo;nhà bếp\u0026rdquo; ra, sửa nó, rồi đặt lại mà không ảnh hưởng gì đến các phòng khác.\nTrong phần mềm, kiến trúc microservices là phương pháp chia một ứng dụng lớn thành nhiều dịch vụ (service) nhỏ, độc lập. Mỗi service đảm nhiệm một chức năng cụ thể, có database riêng, và được phát triển, triển khai, nâng cấp độc lập với các service khác.\n2. Các Service giao tiếp với nhau ra sao? Có giống Frontend gọi tới Backend không? Đây là câu hỏi cốt lõi và quan trọng nhất. Các service (vốn là các backend) giao tiếp với nhau qua mạng. Có hai kiểu giao tiếp chính:\nGiao tiếp Đồng bộ (Synchronous) Giống như một cuộc gọi điện thoại. Service A gọi đến Service B và phải chờ Service B trả lời rồi mới làm việc tiếp.\nCách thức: Thường sử dụng các giao thức như REST API (qua HTTP/S) hoặc gRPC. Ví dụ: Khi bạn đặt hàng, Service Đơn Hàng sẽ gọi trực tiếp đến Service Kho Hàng để hỏi \u0026ldquo;Sản phẩm X còn hàng không?\u0026rdquo;. Service Đơn Hàng sẽ phải đợi câu trả lời từ Service Kho Hàng rồi mới cho phép khách đặt hàng. Giống Frontend gọi Backend không? Về mặt kỹ thuật (dùng REST API) thì giống, nhưng bản chất là khác. Đây là giao tiếp giữa các backend với nhau (backend-to-backend), diễn ra bên trong hệ thống mà người dùng không nhìn thấy. Giao tiếp Bất đồng bộ (Asynchronous) Giống như gửi email hoặc tin nhắn. Service A gửi một \u0026ldquo;thông điệp\u0026rdquo; (message) cho Service B rồi tiếp tục công việc của mình ngay lập tức, không cần chờ B trả lời. Service B sẽ nhận và xử lý thông điệp đó khi nào sẵn sàng.\nCách thức: Sử dụng một hệ thống trung gian gọi là Message Broker (hoặc Message Queue) như RabbitMQ, Kafka. Ví dụ: Sau khi bạn đặt hàng thành công, Service Đơn Hàng sẽ gửi một thông điệp có nội dung \u0026ldquo;Đơn hàng #123 đã được tạo\u0026rdquo; vào một hàng đợi (queue). Service Thông Báo sẽ lắng nghe hàng đợi này, thấy có thông điệp mới liền lấy ra và gửi email xác nhận cho bạn. Service Đơn Hàng không cần quan tâm Service Thông Báo đã gửi email hay chưa. Ưu điểm: Giúp các service hoàn toàn độc lập (decoupled). Nếu Service Thông Báo bị lỗi, các đơn hàng vẫn được tạo bình thường, các thông điệp sẽ nằm chờ trong queue để được xử lý sau. 3. Có phải Microservices là kiến trúc ở Backend? Frontend chỉ cần 1 service? Đúng vậy, Microservices chủ yếu là một kiến trúc cho phần backend. Tuy nhiên, việc có nhiều service backend nhỏ lẻ lại tạo ra một vấn đề cho frontend: \u0026ldquo;Frontend nên gọi đến service nào?\u0026rdquo;.\nKhông thể để frontend (ứng dụng web, mobile) gọi trực tiếp đến 10 service backend khác nhau. Điều này rất phức tạp, khó quản lý và không an toàn. Giải pháp phổ biến nhất là sử dụng một API Gateway.\nAPI Gateway là gì? Hãy coi API Gateway như một anh chàng lễ tân của toàn bộ hệ thống.\nFrontend chỉ cần nói chuyện với \u0026ldquo;anh lễ tân\u0026rdquo; này thôi. \u0026ldquo;Anh lễ tân\u0026rdquo; sẽ chịu trách nhiệm xác thực yêu cầu, sau đó xem xét yêu cầu này thuộc về phòng ban nào (service nào) và chuyển tiếp đến đúng nơi. Nó cũng có thể tổng hợp thông tin từ nhiều service trước khi trả về cho frontend. Ví dụ: Để hiển thị trang chi tiết sản phẩm, frontend chỉ cần gửi 1 yêu cầu duy nhất đến API Gateway. API Gateway sẽ tự động gọi đến Service Sản Phẩm để lấy thông tin sản phẩm và gọi đến Service Đánh Giá để lấy các bình luận, sau đó gộp hai kết quả này lại và trả về cho frontend.\nVậy câu trả lời là: Backend được chia thành nhiều microservices, và thường có một lớp API Gateway làm điểm vào duy nhất cho tất cả các client (web, mobile\u0026hellip;).\n4. Vấn đề về Dữ liệu: Mỗi Service một Database? Đây là một trong những quy tắc vàng và cũng là thách thức lớn nhất của microservices: Mỗi microservice phải sở hữu và quản lý cơ sở dữ liệu (database) của riêng mình.\nTại sao? Để đảm bảo tính độc lập tuyệt đối. Nếu Service A và Service B dùng chung một database, khi Service A muốn thay đổi cấu trúc bảng, nó có thể làm sập Service B. Như vậy thì không còn gọi là độc lập nữa. Thách thức: Làm sao để thực hiện một nghiệp vụ yêu cầu dữ liệu từ nhiều service? Ví dụ: làm sao để đảm bảo khi tạo đơn hàng (Service Đơn Hàng) thì số lượng tồn kho (Service Kho Hàng) cũng phải được trừ đi một cách nhất quán? Giải pháp: Cần sử dụng các pattern nâng cao như Saga Pattern để quản lý các giao dịch phân tán (distributed transactions). Đây là một chủ đề phức tạp, nhưng ý tưởng cơ bản là mỗi service sẽ thực hiện phần việc của mình và phát ra sự kiện để service tiếp theo thực hiện phần việc của nó. Nếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","permalink":"https://blog.nagih.io.vn/posts/microservices/","summary":"\u003cp\u003eTổng quan về kiến trúc microservices\u003c/p\u003e","title":"Microservices"}]