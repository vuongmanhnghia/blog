
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    [{"authors":null,"categories":null,"content":"Giới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\nKAFKA ĐƯỢC DÙNG KHI NÀO ? Kiến trúc truyền thống - Lập trình nối tiếp Các function quá lệ thuộc vào nhau: Nếu 1 ngày nào đó, tính năng update cart của 1 nhân viên B bị lỗi thì khi user save order -\u0026gt; update cart nhưng bị lỗi ở đây và trả về lỗi, thực tế nếu hệ thống bỏ qua bước này và cho tới bước update inventory thì có được hay không ? Thực tế, mọi trang thương mại điện tử hiện nay đều có thể xử lý lỗi thành công, miễn là cho user có trải nghiệm tốt là được. Nếu xảy ra lỗi. Các hệ thống sẽ trả cho user phần bù đắp thiệt hại cho user (1 vourcher chẳng hạn) chứ không nên để cho user đặt hàng không thành công.\nTrong hình ảnh tiếp theo, tôi đã cung cấp thêm thời gian phản hồi, có thể thấy mỗi 1 request sẽ mất 150ms\nGiả sử nhân viên B phụ trách tính năng update cart nhưng code yếu thì làm sao ? Tức là tính năng update cart được tính toán nhiều quá, không hiệu quả, và kết quả là bị tắc đường ở đó. Và tất nhiên hệ thống phải đồng bộ. Chẳng hạn khi có 10.000 users bị tắc nghẽn ở đó thì phải làm như thế nào ?\nVà một ngày nào đó, lượng users tăng cao, và cần thêm tính năng mới - Thống kê. Tính năng này thống kê điểm tích lũy cho user để có thể tặng quà cho những người mua hàng nhiều nhất, tích điểm,… Thì khi thêm 1 tính năng bất kỳ, đồng nghĩa với việc sẽ tăng thêm thời gian phản hồi, nguy cơ tăng lỗi cũng sẽ cao hơn\nKiến trúc phân tán Có thể thấy, tất cả các order đều được đẩy vào Message Queue, và ngay lập tức trả về response cho user, không cần quan tâm tới những tác vụ còn lại. Và tất nhiên các tác vụ update cart, update inventory, save payment, save shopping vẫn được tiến hành và được tiến hành theo đúng trình tự.\nVà nhắc lại trường hợp khi nãy, giả sử tính năng update inventory bị lỗi thì chuyện gì sẽ xảy ra? Điều đầu tiên là sẽ không ảnh hưởng tới trải nghiệm người dùng, tiếp theo là message queue có cơ chế tự động sửa lỗi những message bị error, nếu cố gắng sửa đổi trong vòng (10) lần mà không thành công, khi đó sẽ đưa con người vào trực tiếp tham gia quá trình sửa đổi này\nTỉ lệ phản hồi thay vì 150ms như kiến trúc truyền thống thì sẽ chỉ mất 20ms + 5ms từ save order tới message queue, ngay lập tức phản hồi tới user\nTrong kiến trúc phân tán, ta có thể quy định hệ thống làm việc với cường độ 100 orders/time, đến khi nào order hết trong MQ, hay có thể nói là chỉ chỉ đưa cho 100 reqs để làm mà thôi, không được vội vàng, còn lại phải xếp hàng lần lượt, cứ như vậy cho đến hết.\nVà bây giờ, nếu lượng users tăng cao và cần thêm tính năng mới thì cũng không hề ảnh hưởng tới dây chuyền sản xuất\n","date":1754697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1754804428,"objectID":"f9d6810e0d8cd7211c87a4e9797eb33b","permalink":"https://blog.nagih.io.vn/post/architecture/","publishdate":"2025-08-09T00:00:00Z","relpermalink":"/post/architecture/","section":"post","summary":"Giới thiệu về kiến trúc truyền thống và kiến trúc phân tán, sự ra đời của Kafka\n","tags":null,"title":"Kafka","type":"post"},{"authors":null,"categories":null,"content":"Tổng quan về kiến trúc microservices\n1. Kiến trúc Microservices là gì? Hãy tưởng tượng bạn đang xây một ngôi nhà.\nKiến trúc nguyên khối (Monolith): Bạn xây toàn bộ ngôi nhà bằng một khối bê tông khổng lồ duy nhất. Mọi thứ dính liền với nhau. Nếu bạn muốn sửa đường ống nước trong bếp, bạn có thể phải đục cả bức tường lớn, ảnh hưởng đến phòng khách bên cạnh.\nKiến trúc Microservices: Bạn xây ngôi nhà bằng những viên gạch LEGO. Mỗi phòng (phòng khách, phòng ngủ, nhà bếp) là một khối LEGO riêng. Nếu muốn sửa bếp, bạn chỉ cần nhấc khối LEGO “nhà bếp” ra, sửa nó, rồi đặt lại mà không ảnh hưởng gì đến các phòng khác.\nTrong phần mềm, kiến trúc microservices là phương pháp chia một ứng dụng lớn thành nhiều dịch vụ (service) nhỏ, độc lập. Mỗi service đảm nhiệm một chức năng cụ thể, có database riêng, và được phát triển, triển khai, nâng cấp độc lập với các service khác.\n2. Các Service giao tiếp với nhau ra sao? Có giống Frontend gọi tới Backend không? Đây là câu hỏi cốt lõi và quan trọng nhất. Các service (vốn là các backend) giao tiếp với nhau qua mạng. Có hai kiểu giao tiếp chính:\nGiao tiếp Đồng bộ (Synchronous) Giống như một cuộc gọi điện thoại. Service A gọi đến Service B và phải chờ Service B trả lời rồi mới làm việc tiếp.\nCách thức: Thường sử dụng các giao thức như REST API (qua HTTP/S) hoặc gRPC.\nVí dụ: Khi bạn đặt hàng, Service Đơn Hàng sẽ gọi trực tiếp đến Service Kho Hàng để hỏi “Sản phẩm X còn hàng không?”. Service Đơn Hàng sẽ phải đợi câu trả lời từ Service Kho Hàng rồi mới cho phép khách đặt hàng.\nGiống Frontend gọi Backend không? Về mặt kỹ thuật (dùng REST API) thì giống, nhưng bản chất là khác. Đây là giao tiếp giữa các backend với nhau (backend-to-backend), diễn ra bên trong hệ thống mà người dùng không nhìn thấy.\nGiao tiếp Bất đồng bộ (Asynchronous) Giống như gửi email hoặc tin nhắn. Service A gửi một “thông điệp” (message) cho Service B rồi tiếp tục công việc của mình ngay lập tức, không cần chờ B trả lời. Service B sẽ nhận và xử lý thông điệp đó khi nào sẵn sàng.\nCách thức: Sử dụng một hệ thống trung gian gọi là Message Broker (hoặc Message Queue) như RabbitMQ, Kafka.\nVí dụ: Sau khi bạn đặt hàng thành công, Service Đơn Hàng sẽ gửi một thông điệp có nội dung “Đơn hàng #123 đã được tạo” vào một hàng đợi (queue). Service Thông Báo sẽ lắng nghe hàng đợi này, thấy có thông điệp mới liền lấy ra và gửi email xác nhận cho bạn. Service Đơn Hàng không cần quan tâm Service Thông Báo đã gửi email hay chưa.\nƯu điểm: Giúp các service hoàn toàn độc lập (decoupled). Nếu Service Thông Báo bị lỗi, các đơn hàng vẫn được tạo bình thường, các thông điệp sẽ nằm chờ trong queue để được xử lý sau.\n3. Có phải Microservices là kiến trúc ở Backend? Frontend chỉ cần 1 service? Đúng vậy, Microservices chủ yếu là một kiến trúc cho phần backend. Tuy nhiên, việc có nhiều service backend nhỏ lẻ lại tạo ra một vấn đề cho frontend: “Frontend nên gọi đến service nào?”.\nKhông thể để frontend (ứng dụng web, mobile) gọi trực tiếp đến 10 service backend khác nhau. Điều này rất phức tạp, khó quản lý và không an toàn. Giải pháp phổ biến nhất là sử dụng một API Gateway.\nAPI Gateway là gì? Hãy coi API Gateway như một anh chàng lễ tân của toàn bộ hệ thống.\nFrontend chỉ cần nói chuyện với “anh lễ tân” này thôi.\n“Anh lễ tân” sẽ chịu trách nhiệm xác thực yêu cầu, sau đó xem xét yêu cầu này thuộc về phòng ban nào (service nào) và chuyển tiếp đến đúng nơi.\nNó cũng có thể tổng hợp thông tin từ nhiều service trước khi trả về cho frontend.\nVí dụ: Để hiển thị trang chi tiết sản phẩm, frontend chỉ cần gửi 1 yêu cầu duy nhất đến API Gateway. API Gateway sẽ tự động gọi đến Service Sản Phẩm để lấy thông tin sản phẩm và gọi đến Service Đánh Giá để lấy các bình luận, sau đó gộp hai kết quả này lại và trả về cho frontend.\nVậy câu trả lời là: Backend được chia thành nhiều microservices, và thường có một lớp API Gateway làm điểm vào duy nhất cho tất cả các client (web, mobile…).\n4. Vấn đề về Dữ liệu: Mỗi Service một Database? Đây là một trong những quy tắc vàng và cũng là thách thức lớn nhất của microservices: Mỗi microservice phải sở hữu và quản lý cơ sở dữ liệu (database) của riêng mình.\nTại sao? Để đảm bảo tính độc lập tuyệt đối. Nếu Service A và Service B dùng chung một database, khi Service A muốn thay đổi cấu trúc bảng, nó có thể làm sập Service B. Như vậy thì không còn gọi là độc lập nữa.\nThách thức: Làm sao để thực hiện một nghiệp vụ yêu cầu dữ liệu từ nhiều service? Ví dụ: làm sao để đảm bảo khi tạo đơn hàng (Service Đơn Hàng) thì số lượng tồn kho (Service Kho Hàng) cũng phải được trừ đi một cách nhất quán?\nGiải pháp: Cần sử dụng các pattern nâng cao như Saga Pattern để quản lý các giao dịch phân tán (distributed transactions). Đây là một chủ đề phức tạp, nhưng ý tưởng cơ bản là mỗi service sẽ thực hiện phần việc của mình và phát ra sự kiện để service tiếp theo thực hiện phần việc của nó.\n","date":1754524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1754804428,"objectID":"6f7eb678d11b2b6bc21a9dbcc6fb0131","permalink":"https://blog.nagih.io.vn/post/microservices/","publishdate":"2025-08-07T00:00:00Z","relpermalink":"/post/microservices/","section":"post","summary":"Tổng quan về kiến trúc microservices\n","tags":null,"title":"Microservices","type":"post"},{"authors":null,"categories":null,"content":"Cache Toàn Tập: Từ Chiếc Tủ Lạnh Mini Đến Trái Tim Của Hệ Thống Hiệu Năng Cao Chào các bạn, những người đồng nghiệp và những tâm hồn đam mê công nghệ!\nTrong thế giới phát triển phần mềm, chúng ta luôn bị ám ảnh bởi một từ khóa: hiệu năng. Làm thế nào để ứng dụng chạy nhanh hơn? Làm sao để trang web tải trong chớp mắt? Làm sao để hệ thống chịu được hàng triệu lượt truy cập mà không sụp đổ? Giữa vô vàn câu trả lời, có một khái niệm nền tảng, một kỹ thuật được áp dụng ở mọi quy mô, từ con chip nhỏ bé trong CPU đến các hệ thống phân tán toàn cầu. Đó chính là Cache.\nNhiều người đã nghe về cache, có thể là “xóa cache trình duyệt” hay “cache của CPU”. Nhưng cache thực sự là gì? Nó hoạt động ra sao và tại sao nó lại quan trọng đến vậy?\nBài viết này là một hành trình toàn diện, đưa bạn đi từ những khái niệm cơ bản nhất đến các chiến lược chuyên sâu trong thiết kế hệ thống. Dù bạn là sinh viên mới bắt đầu, một lập trình viên đang xây dựng ứng dụng, hay một kiến trúc sư hệ thống, hy vọng rằng sau khi đọc xong, bạn sẽ có một cái nhìn rõ ràng và sâu sắc về “vũ khí bí mật” mang tên cache.\nHãy cùng bắt đầu!\nCache Là Gì? Một Khái Niệm Thay Đổi Cuộc Chơi Để hiểu về cache, hãy bắt đầu bằng một câu chuyện đơn giản.\nCâu chuyện về Thư viện và Chiếc bàn làm việc Hãy tưởng tượng bạn là một nhà nghiên cứu cần rất nhiều sách cho công việc của mình. Toàn bộ sách được lưu trữ trong một thư viện khổng lồ ở phía bên kia thành phố. Mỗi khi cần một thông tin, bạn phải mất công di chuyển đến thư viện, tìm đúng cuốn sách, đọc, rồi lại đi về. Quá trình này rất chậm chạp và tốn thời gian.1\nBây giờ, bạn nghĩ ra một giải pháp thông minh hơn. Thay vì mỗi lần cần lại chạy đi, bạn sẽ mang những cuốn sách hay dùng nhất, hoặc những cuốn bạn dự đoán sẽ cần sớm, về đặt ngay trên chiếc bàn làm việc của mình. Chiếc bàn này tuy nhỏ, không thể chứa cả thư viện, nhưng nó ở ngay trước mặt bạn. Lần tới, khi cần thông tin từ những cuốn sách đó, bạn chỉ cần với tay là có ngay, nhanh hơn gấp trăm lần so với việc đi đến thư viện.1\nTrong thế giới máy tính, câu chuyện này diễn ra liên tục.\nThư viện khổng lồ chính là nơi lưu trữ dữ liệu chính (primary storage), ví dụ như ổ cứng (HDD/SSD) hoặc cơ sở dữ liệu (database). Nơi này có dung lượng lớn nhưng tốc độ truy cập chậm.2\nChiếc bàn làm việc của bạn chính là Cache.\nCache là một lớp lưu trữ dữ liệu tốc độ cao, có kích thước nhỏ, dùng để chứa một tập hợp con của dữ liệu gốc. Mục đích của nó là để các yêu cầu truy xuất dữ liệu trong tương lai được phục vụ nhanh hơn rất nhiều so với việc phải lấy dữ liệu từ nơi lưu trữ chính.5 Về cơ bản, cache cho phép chúng ta tái sử dụng một cách hiệu quả những dữ liệu đã được truy xuất hoặc tính toán trước đó.6\nTại sao Cache lại quan trọng đến vậy? Sử dụng cache mang lại ba lợi ích cốt lõi, biến nó trở thành một kỹ thuật không thể thiếu trong hầu hết mọi hệ thống máy tính hiện đại.\nTăng tốc độ một cách chóng mặt (Performance): Đây là mục đích chính. Cache thường được triển khai trên các phần cứng truy cập nhanh như RAM (Bộ nhớ truy cập ngẫu nhiên). Tốc độ truy cập RAM nhanh hơn hàng trăm, thậm chí hàng nghìn lần so với ổ đĩa cơ. Việc phục vụ dữ liệu từ cache giúp giảm độ trễ (latency) và tăng số lượng thao tác I/O mỗi giây (IOPS) một cách đáng kể, làm cho ứng dụng trở nên mượt mà và phản hồi nhanh hơn.6\nGiảm tải cho hệ thống Backend: Cache hoạt động như một tấm khiên, che chắn cho cơ sở dữ liệu hoặc các dịch vụ API. Thay vì mọi yêu cầu đều phải “đập” vào cơ sở dữ liệu, phần lớn các yêu cầu đọc sẽ được cache xử lý. Điều này giúp cơ sở dữ liệu không bị quá tải, đặc biệt là trong những thời điểm có lưu lượng truy cập tăng đột biến, và giữ cho toàn bộ hệ thống ổn định.8\nTiết kiệm chi phí (Cost Efficiency): Ở quy mô lớn, việc phục vụ dữ liệu từ cache trong bộ nhớ (in-memory) có thể rẻ hơn đáng kể so với việc phải nâng cấp liên tục các máy chủ cơ sở dữ liệu hoặc trả chi phí cho lưu lượng mạng cao khi truy xuất dữ liệu từ các dịch vụ đám mây.6\nQuy trình cơ bản: Cache Hit và Cache Miss Hoạt động của cache xoay quanh hai kịch bản chính: Cache Hit và Cache Miss. Khi một client (có thể là CPU, trình duyệt web, hoặc ứng dụng của bạn) cần dữ liệu, nó sẽ luôn hỏi cache trước tiên.7\nCache Hit (Tìm thấy trong Cache): Đây là kịch bản lý tưởng. Dữ liệu được yêu cầu có tồn tại trong cache. Cache sẽ ngay lập tức trả về dữ liệu này cho client. Quá trình này cực kỳ nhanh chóng.7\nCache Miss (Không tìm thấy trong Cache): Đây là kịch bản không mong muốn. Dữ liệu được yêu cầu không có trong cache. Khi đó, hệ thống buộc phải thực hiện “chuyến đi dài” đến nơi lưu trữ chính (cơ sở dữ liệu) để lấy dữ liệu. Sau khi lấy được, dữ liệu này sẽ được sao chép một bản vào cache để những lần yêu cầu sau sẽ trở thành cache hit, rồi mới được trả về cho client.7\nDưới đây là một lưu đồ mô tả quy trình này:\nCode snippet\ngraph TD A(Bắt đầu: Client yêu cầu dữ liệu) --\u0026gt; B{Kiểm tra Cache}; B -- Tìm thấy --\u0026gt; C[Cache Hit]; C --\u0026gt; D(Trả dữ liệu từ Cache cho Client); D --\u0026gt; E(Kết thúc); B -- Không tìm thấy --\u0026gt; F[Cache Miss]; F --\u0026gt; …","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1754804389,"objectID":"1323f3bb4e0ee2358523cdda91afb187","permalink":"https://blog.nagih.io.vn/post/design-system/cache/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/design-system/cache/","section":"post","summary":"Cache Toàn Tập: Từ Chiếc Tủ Lạnh Mini Đến Trái Tim Của Hệ Thống Hiệu Năng Cao Chào các bạn, những người đồng nghiệp và những tâm hồn đam mê công nghệ!\nTrong thế giới phát triển phần mềm, chúng ta luôn bị ám ảnh bởi một từ khóa: hiệu năng. Làm thế nào để ứng dụng chạy nhanh hơn? Làm sao để trang web tải trong chớp mắt? Làm sao để hệ thống chịu được hàng triệu lượt truy cập mà không sụp đổ? Giữa vô vàn câu trả lời, có một khái niệm nền tảng, một kỹ thuật được áp dụng ở mọi quy mô, từ con chip nhỏ bé trong CPU đến các hệ thống phân tán toàn cầu. Đó chính là Cache.\n","tags":null,"title":"","type":"post"}]