[{"content":" Step 1: Create a temporary branch (Orphan) An orphan branch is a special branch, it has no commit history but still keeps all files in the workspace\n1 git checkout --orphan latest_commit Step 2: Add all files and commit At this time, all file are \u0026ldquo;staged\u0026rdquo; status (ready to commit)\n1 2 git add -A git commit -m \u0026#34;Init commit\u0026#34; Step 3: Delete the old main branch 1 git branch -D main Step 4: Rename current branch to main 1 git branch -m main Step 5: Update the remote repository If you have pushed code, you must \u0026ldquo;force push\u0026rdquo; to replace the old history on the server\n1 git push origin main -f ","date":"2026-01-22T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/restore-git-commits/","title":"Completely restore Git commits (Orphan Branch)"},{"content":"Lệnh du (Disk Usage) là công cụ mạnh mẽ để kiểm tra dung lượng ổ đĩa, nhưng nếu chỉ gõ du trần thì kết quả trả về sẽ rất rối mắt và khó đọc\nĐể dùng du như một \u0026ldquo;Pro\u0026rdquo; (chuyên nghiệp, hiệu quả), bạn cần kết hợp các cờ (flags) và đường ống (pipe) để lọc dữ liệu. Dưới đây là các tuyệt chiêu hay dùng nhất:\n1. Combo \u0026ldquo;Huyền thoại\u0026rdquo;: Xem tổng dung lượng thư mục hiện tại Đây là lệnh bạn sẽ dùng 90% thời gian.\n1 du -sh Hoặc xem cụ thể từng thư mục con cấp 1:\n1 du -sh * -s (summary): Chỉ hiện tổng số, không liệt kê từng file nhỏ bên trong.\n-h (human-readable): Hiển thị đơn vị dễ đọc (K, M, G) thay vì số block.\n2. Combo \u0026ldquo;Thám tử\u0026rdquo;: Tìm 10 thư mục/file nặng nhất (Quan trọng) Khi ổ cứng bị đầy, bạn cần biết thằng nào đang chiếm chỗ. Lệnh du không tự sắp xếp, nên ta phải kết hợp với sort.\n1 du -ah . | sort -rh | head -n 10 -a (all): Hiển thị cả file lẫn thư mục (để bắt được các file log hoặc backup lẻ tẻ nhưng nặng).\n.: Thư mục hiện tại (hoặc thay bằng /var, /home\u0026hellip;).\nsort -rh: Sắp xếp (sort) theo dạng đảo ngược (reverse) và hiểu được đơn vị K/M/G (human-numeric-sort).\nhead -n 10: Chỉ lấy 10 dòng đầu tiên (top 10 nặng nhất).\n3. Combo \u0026ldquo;Khoan cắt bê tông\u0026rdquo;: Giới hạn độ sâu thư mục Nếu bạn muốn kiểm tra thư mục gốc / nhưng sợ nó liệt kê hàng triệu file, hãy dùng --max-depth (hoặc -d).\n1 sudo du -h --max-depth=1 / --max-depth=1 (hoặc -d 1): Chỉ hiển thị dung lượng của các thư mục con cấp 1, không đi sâu hơn. Rất gọn gàng để nhìn tổng quan. 4. Combo \u0026ldquo;Tính tổng\u0026rdquo;: Cộng dồn dung lượng Đôi khi bạn muốn check dung lượng của một vài folder cụ thể và muốn biết tổng của chúng là bao nhiêu.\n1 du -ch folder1 folder2 folder3 -c (total): Thêm một dòng \u0026ldquo;total\u0026rdquo; ở cuối cùng cộng dồn tất cả lại. 5. Combo \u0026ldquo;Lọc rác\u0026rdquo;: Loại trừ file không cần thiết Bạn muốn tính dung lượng thư mục web nhưng muốn bỏ qua các file log hoặc cache?\n1 du -sh --exclude=\u0026#34;*.log\u0026#34; --exclude=\u0026#34;cache\u0026#34; /var/www/html --exclude: Bỏ qua các file hoặc thư mục khớp với mẫu. 6. Combo \u0026ldquo;Thời gian\u0026rdquo;: Xem thư mục nào mới được sửa đổi Vừa thấy dung lượng tăng vọt? Hãy xem thư mục nào vừa được cập nhật dung lượng gần đây kèm thời gian:\n1 du -ha --time | sort -rh | head -n 10 --time: Hiển thị thêm cột ngày giờ sửa đổi lần cuối của file/folder. Bảng tóm tắt các phím tắt cho \u0026ldquo;Pro\u0026rdquo; Flag Ý nghĩa (Dễ nhớ) -h Human (Dễ đọc: KB, MB, GB) -s Summary (Tóm tắt, không in dài dòng) -a All (Hiện cả file lẻ, không chỉ folder) -c Count/Total (Tính tổng ở dòng cuối) -d N Depth (Độ sâu N cấp thư mục) ⭐ Pro Tip: Dùng ncdu (Nếu được phép cài đặt) Nếu bạn được quyền cài thêm phần mềm, hãy quên du đi và cài ncdu. Đây là phiên bản du có giao diện đồ họa dòng lệnh, cho phép bạn dùng phím mũi tên để đi vào/ra các thư mục và xóa file trực tiếp cực nhanh.\nCài đặt:\n1 sudo apt install ncdu Sử dụng:\n1 ncdu / ","date":"2026-01-17T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/du/","title":"Hướng dẫn đầy đủ command `du`"},{"content":"Để bật Swap (bộ nhớ ảo) cho Ubuntu, cách đơn giản và phổ biến nhất hiện nay là tạo một Swap File (tệp hoán đổi). Cách này linh hoạt hơn so với việc chia phân vùng ổ cứng (Swap Partition)\nBước 1: Kiểm tra Swap hiện có Trước tiên, hãy kiểm tra xem hệ thống đã có swap chưa:\n1 sudo swapon --show Hoặc:\n1 free -h Nếu kết quả trống hoặc phần Swap hiển thị 0B, nghĩa là chưa có swap.\nBước 2: Tạo Swap File Ví dụ này sẽ tạo một file Swap dung lượng 2GB (bạn có thể thay 2G bằng 1G, 4G tùy nhu cầu và dung lượng ổ cứng còn trống).\nChạy lệnh sau:\n1 sudo fallocate -l 2G /swapfile Lưu ý: Nếu lệnh fallocate báo lỗi (hiếm gặp), bạn có thể dùng lệnh sudo dd if=/dev/zero of=/swapfile bs=1024 count=2097152.\nBước 3: Phân quyền cho file Swap Vì lý do bảo mật, chỉ có tài khoản root mới được phép đọc/ghi file này.\n1 sudo chmod 600 /swapfile Bước 4: Thiết lập file thành vùng Swap Báo cho hệ thống biết file này sẽ được dùng làm bộ nhớ ảo:\n1 sudo mkswap /swapfile Bước 5: Kích hoạt Swap Bật swap lên:\n1 sudo swapon /swapfile Bây giờ hãy kiểm tra lại xem đã nhận chưa:\n1 sudo swapon --show Bước 6: Giữ cấu hình vĩnh viễn (Quan trọng) Nếu chỉ làm đến Bước 5, khi khởi động lại máy (Reboot), Swap sẽ bị tắt. Để tự động bật Swap mỗi khi khởi động, bạn cần thêm thông tin vào file /etc/fstab.\nCách an toàn nhất là chạy lệnh backup file cấu hình trước:\n1 sudo cp /etc/fstab /etc/fstab.bak Sau đó chạy lệnh này để thêm cấu hình swap vào cuối file:\n1 echo \u0026#39;/swapfile none swap sw 0 0\u0026#39; | sudo tee -a /etc/fstab Bước 7: Tối ưu hóa Swap (Tùy chọn - Khuyên dùng) Tham số swappiness quy định mức độ ưu tiên sử dụng Swap của hệ thống (từ 0 đến 100).\nMặc định là 60: Hệ thống sẽ khá tích cực đẩy dữ liệu từ RAM sang Swap.\nNên chỉnh về 10: Hệ thống sẽ cố gắng dùng hết RAM vật lý trước rồi mới dùng đến Swap (giúp máy chạy mượt hơn).\nKiểm tra chỉ số hiện tại:\n1 cat /proc/sys/vm/swappiness Để đổi thành 10, hãy sửa file cấu hình:\n1 sudo nano /etc/sysctl.conf Kéo xuống cuối file và thêm dòng này vào:\n1 vm.swappiness=10 Nhấn Ctrl + O (Enter) để lưu và Ctrl + X để thoát.\nBonus: Cách xóa Swap (Nếu không muốn dùng nữa) Nếu bạn muốn tắt và xóa file swap đi, hãy làm theo thứ tự:\nTắt swap: sudo swapoff -v /swapfile\nXóa dòng cấu hình trong /etc/fstab (dùng lệnh sudo nano /etc/fstab và xóa dòng /swapfile...).\nXóa file: sudo rm /swapfile\n","date":"2026-01-17T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/setup-swap/","title":"Hướng dẫn setup Swap trên Linux"},{"content":"Hướng dẫn chi tiết dựng một cluster on Cloud. Sử dụng Containerd làm Container Runtime (thay thế cho Docker đã cũ).\nGiả định ban đầu 3 EC2 instances Ubuntu 22.04 LTS\n1 Master node: 10.0.1.10\n2 Worker nodes: 10.0.1.20, 10.0.2.20\nTất cả trong cùng VPC và Subnet\nSecurity Group đã cấu hình đúng (all traffic giữa các nodes)\nSSH access vào tất cả nodes\nPHẦN 1: CHUẨN BỊ HỆ THỐNG (Trên tất cả 3 nodes) Bước 1.1: Cập nhật hệ thống 1 sudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade -y Bước 1.2: Set hostname và cập nhật /etc/hosts Master node:\n1 sudo hostnamectl set-hostname k8s-master Worker 1:\n1 sudo hostnamectl set-hostname k8s-worker-1 Worker 2:\n1 sudo hostnamectl set-hostname k8s-worker-2 Trên tất cả 3 nodes, cập nhật /etc/hosts:\n1 2 3 4 5 sudo tee -a /etc/hosts \u0026lt;\u0026lt; EOF 10.0.1.10 k8s-master 10.0.1.20 k8s-worker-1 10.0.2.20 k8s-worker-2 EOF Verify:\n1 2 3 4 hostname ping -c 2 k8s-master ping -c 2 k8s-worker-1 ping -c 2 k8s-worker-2 Bước 1.3: Tắt Swap 1 2 3 4 5 6 7 8 9 # Tắt swap ngay lập tức sudo swapoff -a # Tắt swap vĩnh viễn (comment dòng swap trong fstab) sudo sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab # Verify swap đã tắt free -h # Dòng Swap phải hiển thị: 0B Giải thích:\nKubernetes yêu cầu swap phải tắt\nLý do:\nSwap làm giảm performance của containers\nK8s scheduler dựa vào memory limits để schedule pods\nNếu swap bật, containers có thể dùng swap → OOM killer không hoạt động đúng\nPods có thể bị chậm không đoán trước được\nBước 1.4: Load kernel modules cần thiết 1 2 3 4 5 6 7 8 9 10 11 12 13 # Tạo file config để load modules khi boot cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF # Load modules ngay lập tức sudo modprobe overlay sudo modprobe br_netfilter # Verify modules đã được load lsmod | grep overlay lsmod | grep br_netfilter Giải thích từng module:\n1. overlay module - Hỗ trợ OverlayFS filesystem\nContainer runtime (containerd) sử dụng overlay2 storage driver\nOverlayFS cho phép layer filesystem của container images\nMỗi container image có nhiều layers (base image, app layer, config layer\u0026hellip;)\nOverlayFS merge các layers này thành một filesystem duy nhất\nHiệu quả hơn về storage và performance so với copy toàn bộ filesystem\n2. br_netfilter module - Cho phép iptables xem và xử lý traffic đi qua Linux bridge\nTại sao cần:\nK8s sử dụng Linux bridge để connect containers\nTraffic giữa pods phải đi qua bridge\nIptables rules cần inspect traffic này để:\nImplement network policies\nLoad balancing (Services)\nNAT cho traffic ra ngoài cluster\nNếu không có module này, iptables không thấy traffic qua bridge → network policies không work\nCụ thể:\nPod A (10.244.1.5) → Pod B (10.244.2.8)\nTraffic đi qua cni0 bridge\nbr_netfilter cho phép iptables rules apply lên traffic này\nVD: NetworkPolicy block Pod A → Pod B sẽ không work nếu không có module này\nTại sao phải load modules này?\nMặc định Ubuntu không load tự động\nK8s và CNI (Cilium) cần modules này để hoạt động\nLoad vào /etc/modules-load.d/ để tự động load khi reboot\nBước 1.5: Configure sysctl parameters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Tạo file sysctl config cho K8s cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF # Apply sysctl params ngay lập tức sudo sysctl --system # Verify các settings sysctl net.bridge.bridge-nf-call-iptables sysctl net.bridge.bridge-nf-call-ip6tables sysctl net.ipv4.ip_forward # Tất cả phải = 1 Giải thích từng parameter:\n1. net.bridge.bridge-nf-call-iptables = 1\nChức năng: Cho phép iptables xử lý traffic qua bridge\nTại sao cần:\nKhi packets đi qua Linux bridge (cni0), chúng cần được iptables filter\nK8s Services sử dụng iptables rules để load balance\nNetworkPolicies sử dụng iptables để enforce rules\nNếu = 0, traffic qua bridge sẽ bypass iptables → Services không work\nVí dụ cụ thể:\n1 2 3 4 5 6 7 Client → Service ClusterIP (10.96.0.100:80) ↓ iptables DNAT rule: 10.96.0.100:80 → Pod IP (10.244.1.5:8080) ↓ Traffic qua bridge cni0 ↓ Đến PodNếu net.bridge.bridge-nf-call-iptables = 0 =\u0026gt; Traffic qua bridge không đi qua iptables DNAT =\u0026gt; Service ClusterIP không work 2. net.bridge.bridge-nf-call-ip6tables = 1\nChức năng: Tương tự như trên nhưng cho IPv6\nTại sao cần:\nNếu cluster support dual-stack (IPv4 + IPv6)\nIPv6 traffic cũng cần đi qua ip6tables rules\nBest practice là enable cả hai\n3. net.ipv4.ip_forward = 1\nChức năng: Enable IP forwarding (routing)\nTại sao cần:\nNode phải forward packets giữa các interfaces\nPackets từ Pod A → Pod B trên node khác phải được forward\nNếu = 0, node chỉ nhận packets destined cho chính nó\nVí dụ chi tiết:\n1 2 3 4 5 6 7 8 9 10 11 Scenario: Pod trên Worker-1 muốn nói chuyện với Pod trên Worker-2 Worker-1: - Pod A (10.244.1.5) gửi packet đến Pod B (10.244.2.8) - Packet từ Pod A → cni0 bridge → eth0 → ra ngoài node - Nếu ip_forward = 0 =\u0026gt; Kernel DROP packet vì destination không phải Worker-1 - Nếu ip_forward = 1 =\u0026gt; Kernel forward packet qua eth0 ra ngoài Worker-2: - Packet đến eth0 → cni0 bridge → Pod B - Cũng cần ip_forward = 1 để accept và forward packet Tóm lại tại sao cần 3 settings này:\nbridge-nf-call-iptables: Để Services và NetworkPolicies hoạt động\nip_forward: Để pods trên các nodes khác nhau có thể communicate\nNếu thiếu bất kỳ setting nào → cluster networking sẽ broken\nBước 1.6: Disable UFW firewall (nếu có) 1 2 3 4 5 6 7 8 9 # Check UFW status sudo ufw status # Nếu active, disable nó sudo ufw disable # Verify sudo ufw status # Output: Status: inactive Giải thích:\nUFW (Uncomplicated Firewall) là frontend cho iptables trên Ubuntu\nK8s và Cilium quản lý iptables rules riêng\nUFW có thể conflict với K8s networking rules\nTại sao disable:\nK8s tạo hàng trăm iptables rules động\nUFW có thể block những rules này\nSecurity Group của AWS đã handle security ở network level\nProduction: Nên rely vào Security Group + K8s NetworkPolicies thay vì UFW\nPHẦN 2: CÀI ĐẶT CONTAINER RUNTIME (Trên tất cả 3 nodes) Bước 2.1: Cài đặt containerd 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Add Docker\u0026#39;s official GPG key sudo apt-get install -y ca-certificates curl gnupg lsb-release sudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\ sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg # Add Docker repository echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null # Update apt và install containerd sudo apt-get update sudo apt-get install -y containerd.io Giải thích:\ncontainerd: Container runtime cho K8s (thay thế Docker)\nTại sao dùng containerd:\nK8s đã deprecate Docker runtime (dockershim removed từ v1.24)\ncontainerd là industry standard (CNCF project)\nNhẹ hơn Docker (không có Docker daemon overhead)\nNative support cho K8s CRI (Container Runtime Interface)\nDocker repository: containerd được distribute qua Docker repos\nGPG key: Verify package authenticity để tránh install malicious packages\nArchitecture so sánh:\n1 2 3 4 5 6 7 Docker (cũ): kubelet → dockershim → Docker Engine → containerd → runc → container Containerd (mới): kubelet → CRI Plugin → containerd → runc → container → Giảm 2 layers, hiệu quả hơn Bước 2.2: Configure containerd 1 2 3 # Generate default config sudo mkdir -p /etc/containerd containerd config default | sudo tee /etc/containerd/config.toml Giải thích:\nconfig default: Generate default configuration\nFile config ở /etc/containerd/config.toml định nghĩa:\nPlugins enabled\nStorage locations\nRegistry mirrors\nRuntime options\nNetworking config\nCritical: Enable SystemdCgroup\n1 2 # Enable SystemdCgroup trong config sudo sed -i \u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/\u0026#39; /etc/containerd/config.toml Giải thích SystemdCgroup:\nCgroup (Control Group): Linux kernel feature để limit resources (CPU, memory, I/O)\nHai loại cgroup drivers:\ncgroupfs: Traditional cgroup management\nsystemd: Systemd quản lý cgroups\nTại sao phải dùng systemd cgroup driver:\nK8s kubelet mặc định dùng systemd cgroup driver\nContainerd phải dùng cùng driver với kubelet\nNếu mismatch (kubelet dùng systemd, containerd dùng cgroupfs):\nHai systems quản lý cgroups riêng biệt\nResource accounting không chính xác\nOOM killer có thể kill sai process\nPods có thể restart không rõ lý do\nVí dụ vấn đề khi mismatch:\n1 2 3 4 5 6 7 8 9 10 11 Scenario: Pod request 100Mi memory Kubelet (systemd cgroup): - Tạo cgroup: /sys/fs/cgroup/memory/kubepods/pod123/ - Set limit: 100Mi Containerd (cgroupfs): - Tạo cgroup khác: /sys/fs/cgroup/memory/default/pod123/ - Không thấy limit của kubelet - Container có thể dùng \u0026gt; 100Mi - Kubelet nghĩ pod đang OOM nhưng thực ra không Verify config:\n1 2 grep SystemdCgroup /etc/containerd/config.toml # Output phải là: SystemdCgroup = true Bước 2.3: Restart và enable containerd 1 2 3 4 5 6 7 8 sudo systemctl restart containerd sudo systemctl enable containerd sudo systemctl status containerd # Phải thấy: active (running) # Verify containerd hoạt động sudo ctr version Troubleshooting nếu containerd failed:\n1 2 3 4 5 6 7 8 9 10 # Xem logs sudo journalctl -u containerd -n 50 --no-pager # Check config syntax containerd config dump # Common issues: # - Syntax error trong config.toml # - Conflicting cgroup settings # - Missing kernel modules PHẦN 3: CÀI ĐẶT KUBERNETES COMPONENTS (Trên tất cả 3 nodes) Bước 3.1: Cài đặt kubeadm, kubelet, kubectl 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Add Kubernetes GPG key sudo mkdir -p /etc/apt/keyrings curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | \\ sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg # Add Kubernetes repository echo \u0026#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /\u0026#39; | \\ sudo tee /etc/apt/sources.list.d/kubernetes.list # Update apt và install packages sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl # Hold packages để prevent auto-upgrade sudo apt-mark hold kubelet kubeadm kubectl # Verify installation kubelet --version kubeadm version kubectl version --client Bước 3.2: Enable kubelet service 1 2 3 4 5 # Enable kubelet để auto-start sudo systemctl enable kubelet # Check status (sẽ fail lúc này là bình thường) sudo systemctl status kubelet Giải thích:\nKubelet sẽ fail/crashloop lúc này vì chưa có cluster\nTại sao fail: Kubelet cần config từ kubeadm init\nAfter kubeadm init: kubelet sẽ tự start và work\nEnable ngay để nó auto-start sau khi init\nPHẦN 4: INITIALIZE KUBERNETES MASTER NODE (Chỉ trên Master) Bước 4.1: Pre-flight checks 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # Verify tất cả prerequisites echo \u0026#34;=== Checking Prerequisites ===\u0026#34; # 1. Check swap is disabled echo \u0026#34;Swap status:\u0026#34; free -h | grep Swap # 2. Check required ports are available echo -e \u0026#34;\\nChecking required ports:\u0026#34; sudo netstat -tlnp | grep -E \u0026#39;6443|2379|2380|10250|10251|10252\u0026#39; # Không nên thấy output gì (ports phải available) # 3. Check containerd is running echo -e \u0026#34;\\nContainerd status:\u0026#34; sudo systemctl is-active containerd # 4. Check kernel modules echo -e \u0026#34;\\nKernel modules:\u0026#34; lsmod | grep -E \u0026#39;overlay|br_netfilter\u0026#39; # 5. Check sysctl settings echo -e \u0026#34;\\nSysctl settings:\u0026#34; sysctl net.bridge.bridge-nf-call-iptables net.ipv4.ip_forward # 6. Check hostname resolution echo -e \u0026#34;\\nHostname resolution:\u0026#34; ping -c 1 k8s-master ping -c 1 k8s-worker-1 ping -c 1 k8s-worker-2 Giải thích: Pre-flight checks đảm bảo môi trường ready cho kubeadm init\nBước 4.2: Initialize cluster với kubeadm 1 2 3 4 5 sudo kubeadm init \\ --pod-network-cidr=10.244.0.0/16 \\ --apiserver-advertise-address=10.0.1.10 \\ --skip-phases=addon/kube-proxy \\ --v=5 Giải thích chi tiết từng parameter:\n1. \u0026ndash;pod-network-cidr=10.244.0.0/16\nChức năng: Define IP range cho pod network\nTại sao cần:\nMỗi pod cần một unique IP address\nCIDR này chia subnet cho từng node\nCNI plugin (Cilium) sẽ allocate IPs từ range này\nCách hoạt động:\n1 2 3 4 5 6 7 8 Cluster CIDR: 10.244.0.0/16 (65,536 IPs) ↓ Node 1: 10.244.0.0/24 (256 IPs cho pods trên node này) Node 2: 10.244.1.0/24 (256 IPs cho pods trên node này) Node 3: 10.244.2.0/24 (256 IPs cho pods trên node này)... Pod trên Node 1: 10.244.0.5 Pod trên Node 2: 10.244.1.8 Quan trọng: CIDR này KHÔNG được overlap với:\nVPC CIDR (10.0.0.0/16)\nService CIDR (default: 10.96.0.0/12)\nCác networks khác\nTại sao dùng 10.244.0.0/16:\nConvention phổ biến\n/16 cho phép 256 subnets (/24), mỗi subnet 256 IPs\nĐủ lớn cho hầu hết clusters\n2. \u0026ndash;apiserver-advertise-address=10.0.1.10\nChức năng: IP address mà API server listen và advertise\nTại sao cần specify:\nMaster node có thể có nhiều IPs (public IP, private IP)\nPhải chỉ rõ IP nào dùng cho cluster communication\nWorker nodes sẽ dùng IP này để connect đến API server\nPhải dùng private IP:\nCluster communication nên qua private network\nFaster và không bị charge bandwidth\nSecure hơn (không expose API server qua internet)\nVí dụ:\n1 2 3 4 5 6 7 8 9 Master node có: - Public IP: 54.123.45.67 - Private IP: 10.0.1.10 Nếu không specify: → kubeadm có thể pick public IP→ Workers phải connect qua internet→ Slow và expensive Với --apiserver-advertise-address=10.0.1.10: → Workers connect qua private IP→ Fast và free 3. \u0026ndash;skip-phases=addon/kube-proxy\nChức năng: Skip cài đặt kube-proxy\nTại sao skip:\nCilium sẽ thay thế kube-proxy\nCilium implement Service load balancing bằng eBPF\nHiệu quả hơn kube-proxy (dùng iptables)\nkube-proxy làm gì:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Traditional (kube-proxy): Client → Service ClusterIP (10.96.0.100:80) ↓ kube-proxy tạo iptables rules: DNAT 10.96.0.100:80 → Pod1 (10.244.1.5:8080) 33% → Pod2 (10.244.2.8:8080) 33% → Pod3 (10.244.1.9:8080) 34% ↓ Traffic đến Pod Với Cilium (eBPF): Client → Service ClusterIP ↓ eBPF program trong kernel: - Lookup service endpoints - Load balance - Direct forward đến Pod ↓ Nhanh hơn vì không qua iptables Performance difference:\niptables: O(n) với n là số rules\neBPF: O(1) lookup\nVới 1000+ services, eBPF nhanh hơn rất nhiều\n4. \u0026ndash;v=5\nChức năng: Verbosity level cho logging\nLevels:\n0: Errors only\n1: Warnings\n2: Info\n5: Debug (chi tiết hơn)\n10: Trace (rất chi tiết)\nTại sao dùng v=5: Để debug nếu init fail\nQuá trình kubeadm init:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 Step 1: [preflight] Pre-flight checks - Check swap disabled - Check ports available - Check containerd running - Check required images Step 2: [certs] Generate certificates - /etc/kubernetes/pki/ca.crt (CA certificate) - /etc/kubernetes/pki/apiserver.crt (API server cert) - /etc/kubernetes/pki/etcd/ca.crt (etcd CA) - ... và nhiều certs khác Step 3: [kubeconfig] Generate kubeconfig files - /etc/kubernetes/admin.conf (admin user) - /etc/kubernetes/kubelet.conf (kubelet) - /etc/kubernetes/controller-manager.conf - /etc/kubernetes/scheduler.conf Step 4: [control-plane] Start control plane components - Static pods: API server, Controller Manager, Scheduler - Manifests: /etc/kubernetes/manifests/ - kube-apiserver.yaml - kube-controller-manager.yaml - kube-scheduler.yaml - etcd.yaml Step 5: [etcd] Start etcd - etcd là distributed key-value store - Store tất cả cluster state Step 6: [upload-config] Upload kubelet/kubeadm configs - ConfigMaps chứa cluster configuration Step 7: [mark-control-plane] Mark master node - Taint master: node-role.kubernetes.io/control-plane:NoSchedule - Nghĩa là: Không schedule workload pods lên master Step 8: [bootstrap-token] Generate join token - Token để workers join cluster - Có thời hạn 24h Step 9: [addons] Install addons - CoreDNS (DNS server cho cluster) - Skip kube-proxy (do --skip-phases) Output quan trọng:\n1 2 3 4 5 6 7 8 9 10 Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Then you can join any number of worker nodes by running: kubeadm join 10.0.1.10:6443 --token abc123... \\ --discovery-token-ca-cert-hash sha256:xyz789... LƯU Ý QUAN TRỌNG:\nSave join command vào file text\nToken expires sau 24h\nNếu mất, có thể generate token mới\nBước 4.3: Setup kubeconfig 1 2 3 4 5 6 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # Verify kubectl hoạt động kubectl get nodes Giải thích kubeconfig:\nFile config: ~/.kube/config chứa:\nCluster information (API server URL, CA cert)\nUser credentials (client cert, client key)\nContext (cluster + user + namespace)\nStructure của kubeconfig:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 apiVersion: v1 kind: Config clusters: - cluster: certificate-authority-data: \u0026lt;base64-encoded-ca-cert\u0026gt; server: https://10.0.1.10:6443 name: kubernetes contexts: - context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetes current-context: kubernetes-admin@kubernetes users: - name: kubernetes-admin user: client-certificate-data: \u0026lt;base64-encoded-client-cert\u0026gt; client-key-data: \u0026lt;base64-encoded-client-key\u0026gt; Tại sao cần kubeconfig:\nkubectl cần authenticate với API server\nTLS mutual authentication:\nServer cert: kubectl verify server\nClient cert: server verify kubectl\nWithout kubeconfig: kubectl get nodes → connection refused\nVerify kubectl:\n1 2 3 4 5 6 kubectl get nodes # Output: # NAME STATUS ROLES AGE VERSION # k8s-master NotReady control-plane 1m v1.34.3 # NotReady là bình thường vì chưa có CNI plugin Bước 4.4: Verify control plane pods 1 2 3 4 5 6 7 8 # Check control plane pods kubectl get pods -n kube-system # Hoặc xem chi tiết hơn kubectl get pods -n kube-system -o wide # Check static pod manifests ls -la /etc/kubernetes/manifests/ Giải thích:\nControl plane components chạy như static pods\nStatic pods: Managed trực tiếp bởi kubelet, không qua API server\nManifests ở /etc/kubernetes/manifests/\nKubelet watch directory này và ensure pods luôn chạy\nExpected output:\n1 2 3 4 5 6 NAME READY STATUS RESTARTS coredns-xxx 0/1 Pending 0 etcd-k8s-master 1/1 Running 0 kube-apiserver-k8s-master 1/1 Running 0 kube-controller-manager-k8s-master 1/1 Running 0 kube-scheduler-k8s-master 1/1 Running 0 Giải thích từng component:\n1. etcd:\nDistributed key-value database\nStore ALL cluster state:\nPods, Services, ConfigMaps, Secrets\nNode information\nCluster configuration\nHigh availability: Có thể chạy multiple etcd instances\nSử dụng Raft consensus algorithm\n2. kube-apiserver:\nFrontend của control plane\nExpose K8s API (REST)\nAll cluster operations go through API server\nAuthenticate, authorize, validate requests\nGhi data vào etcd\n3. kube-controller-manager:\nChạy các controllers:\nNode Controller: Monitor nodes\nReplication Controller: Ensure đúng số replicas\nEndpoints Controller: Populate Endpoints objects\nService Account Controller: Tạo default ServiceAccounts\n\u0026hellip; và nhiều controllers khác\n4. kube-scheduler:\nWatch for new pods không có node assigned\nSelect node phù hợp nhất cho pod\nFactors: Resource requirements, affinity/anti-affinity, taints/tolerations\n5. coredns:\nDNS server cho cluster\nResolve service names thành ClusterIPs\nStatus: Pending (chờ CNI plugin)\nTại sao coredns Pending:\nCoreDNS pods cần network để start\nChưa có CNI plugin → không có pod network → Pending\nPHẦN 5: CÀI ĐẶT CILIUM CNI (Chỉ trên Master) Bước 5.1: Download và install Cilium CLI 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Get latest Cilium CLI version CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt) # Set architecture CLI_ARCH=amd64 # Download Cilium CLI curl -L --fail --remote-name-all \\ https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum} # Verify checksum sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum # Extract và install sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin # Cleanup rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum} # Verify cilium version --client Giải thích:\nCilium CLI: Tool để install và manage Cilium\nInstall vào /usr/local/bin/ để available globally\nChecksum verification để ensure file integrity\nBước 5.2: Install Cilium vào cluster 1 2 3 4 5 6 7 8 cilium install \\ --version 1.18.5 \\ --set ipam.mode=kubernetes \\ --set routingMode=tunnel \\ --set tunnelProtocol=vxlan \\ --set ipv4NativeRoutingCIDR=10.0.0.0/16 \\ --set bpf.masquerade=true \\ --set kubeProxyReplacement=true Giải thích chi tiết từng parameter:\n1. \u0026ndash;version 1.18.5\nSpecify Cilium version\nVersion stability và features\n2. \u0026ndash;set ipam.mode=kubernetes\nIPAM (IP Address Management): Cách allocate IPs cho pods\nModes available:\nkubernetes: K8s allocate IPs (default)\ncluster-pool: Cilium manage IP pool\neni: AWS ENI mode\nMode kubernetes:\nK8s controller-manager allocate pod CIDR cho mỗi node\nCilium chỉ assign IPs trong CIDR đó\nĐơn giản và work với mọi cloud provider\nVí dụ:\n1 2 3 4 5 6 7 8 9 10 11 Cluster pod-network-cidr: 10.244.0.0/16 K8s allocate: Node k8s-master: 10.244.0.0/24 Node k8s-worker-1: 10.244.1.0/24 Node k8s-worker-2: 10.244.2.0/24 Cilium trên mỗi node: - Nhận pod CIDR từ K8s - Assign IPs cho pods trên node đó - VD: Pod1 trên worker-1 → 10.244.1.5 3. \u0026ndash;set tunnel=vxlan\nTunnel mode: Cách pods trên các nodes khác nhau communicate\nOptions:\ndisabled: Native routing (no encapsulation)\nvxlan: VXLAN overlay (default)\ngeneve: Geneve overlay\nVXLAN (Virtual Extensible LAN):\nEncapsulate pod traffic trong UDP packets\nTạo overlay network trên top của existing network\nCách hoạt động:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Pod A (10.244.1.5) trên Worker-1 → Pod B (10.244.2.8) trên Worker-2 Without VXLAN (native routing): Pod A → eth0 Worker-1 → AWS VPC routing → eth0 Worker-2 → Pod B Problem: AWS VPC không biết route 10.244.x.x With VXLAN: Pod A → Cilium agent encapsulate trong VXLAN ↓ Original packet: src: 10.244.1.5 dst: 10.244.2.8 ↓ Encapsulated packet: Outer header: src: 10.0.1.11 (Worker-1 IP) dst: 10.0.1.12 (Worker-2 IP) UDP port: 8472 Inner header: src: 10.244.1.5 dst: 10.244.2.8 ↓ AWS VPC route bình thường (knows 10.0.1.x) ↓ Worker-2 nhận, Cilium decapsulate ↓ Pod B nhận original packet Tại sao dùng VXLAN trên AWS:\nAWS VPC không support custom routing cho pod IPs\nVXLAN \u0026ldquo;hide\u0026rdquo; pod IPs bên trong node IPs\nAlternative: AWS ENI mode (phức tạp hơn, cần IAM permissions)\n4. \u0026ndash;set ipv4NativeRoutingCIDR=10.0.0.0/16\nChức năng: Define CIDR cho native routing (không encapsulate)\nTại sao cần:\nTraffic trong VPC CIDR (10.0.0.0/16) không cần encapsulate\nHiệu quả hơn cho pod-to-node communication\nNode-to-node trong VPC có thể communicate directly\nVí dụ:\n1 2 3 4 5 6 7 8 9 10 11 VPC CIDR: 10.0.0.0/16 Pod CIDR: 10.244.0.0/16 Traffic từ Pod (10.244.1.5) → Node (10.0.1.12): - Destination trong ipv4NativeRoutingCIDR - Không encapsulate - Direct routing Traffic từ Pod (10.244.1.5) → Pod khác (10.244.2.8): - Destination KHÔNG trong ipv4NativeRoutingCIDR - Encapsulate với VXLAN 5. \u0026ndash;set bpf.masquerade=true\nMasquerade (NAT): Change source IP khi traffic ra ngoài cluster\neBPF masquerade: Implement NAT trong eBPF (fast)\nTại sao cần:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Scenario: Pod muốn access internet Pod IP: 10.244.1.5 (private, không routable qua internet) ↓ Cilium eBPF masquerade: Change src IP: 10.244.1.5 → 10.0.1.11 (node IP) ↓ Packet ra internet với src = node IP ↓ Response về node IP ↓ Cilium unmasquerade: dst = node IP → 10.244.1.5 ↓ Pod nhận response Traditional (iptables) vs eBPF masquerade:\n1 2 3 4 5 6 7 8 9 iptables: - Rules trong POSTROUTING chain - O(n) với n là số rules - Slow với nhiều pods eBPF: - Program trong kernel - O(1) lookup - Much faster 6. \u0026ndash;set kubeProxyReplacement=true\nChức năng: Cilium thay thế kube-proxy hoàn toàn\nImplementation: Service load balancing với eBPF\nTraditional kube-proxy:\n1 2 3 4 5 6 7 8 Client → Service ClusterIP ↓ kube-proxy (iptables rules): - 1000s của rules - DNAT để forward đến pod - Load balance round-robin ↓ Pod Cilium replacement:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Client → Service ClusterIP ↓ Cilium eBPF program: - Hash map lookup (O(1)) - Load balance (consistent hashing, least connections, ...) - Direct forward ↓ Pod Benefits: - Faster (no iptables overhead) - More load balancing algorithms - Better scalability - Source IP preservation Bước 5.3: Wait for Cilium to be ready 1 2 # Wait for Cilium installation cilium status --wait --wait-duration=5m Giải thích:\n--wait: Block until Cilium ready\n--wait-duration=5m: Timeout after 5 minutes\nCommand check:\nCilium pods running\nCilium agents connected\neBPF programs loaded\nExpected output:\n1 2 3 4 5 6 7 8 9 10 11 12 /¯¯\\ /¯¯\\__/¯¯\\ Cilium: OK \\__/¯¯\\__/ Operator: OK /¯¯\\__/¯¯\\ Hubble: disabled \\__/¯¯\\__/ ClusterMesh: disabled \\__/ DaemonSet cilium Desired: 3, Ready: 3/3, Available: 3/3 Deployment cilium-operator Desired: 2, Ready: 2/2, Available: 2/2 Containers: cilium Running: 3 cilium-operator Running: 2 Cluster Pods: 3/3 managed by Cilium Bước 5.4: Verify Cilium installation 1 2 3 4 5 6 7 8 9 10 11 # Check Cilium pods kubectl get pods -n kube-system -l k8s-app=cilium -o wide # Check Cilium DaemonSet kubectl get ds -n kube-system cilium # View Cilium status cilium status # Check Cilium version cilium version Giải thích:\nCilium runs as DaemonSet: 1 pod trên mỗi node\nCilium agent: Manage networking trên node đó\nCilium operator: Manage cluster-wide resources\nArchitecture:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Master node: - cilium-xxxxx (agent pod) - Manage networking cho master - Load eBPF programs Worker-1: - cilium-yyyyy (agent pod) - Manage networking cho worker-1 - Handle pod connectivity Worker-2: - cilium-zzzzz (agent pod) - Manage networking cho worker-2 - Handle pod connectivity Cilium Operator (Deployment, 2 replicas): - Manage CiliumNetworkPolicies - Garbage collection - Syncing Bước 5.5: Verify node status 1 2 3 4 5 6 # Check nodes - should be Ready now kubectl get nodes # Expected output: # NAME STATUS ROLES AGE VERSION # k8s-master Ready control-plane 10m v1.29.x Giải thích:\nSau khi Cilium installed, node chuyển từ NotReady → Ready\nTại sao:\nkubelet check network plugin available\nCilium provide CNI plugin\nNode có thể schedule pods\nBước 5.6: Verify CoreDNS pods 1 2 3 4 5 6 7 # Check CoreDNS - should be Running now kubectl get pods -n kube-system -l k8s-app=kube-dns # Expected output: # NAME READY STATUS RESTARTS AGE # coredns-xxx 1/1 Running 0 10m # coredns-yyy 1/1 Running 0 10m Giải thích:\nCoreDNS pods trước đó Pending (no network)\nSau khi Cilium installed → có network → Running\nCoreDNS provide DNS service cho cluster\nPHẦN 6: JOIN WORKER NODES (Trên Worker-1 và Worker-2) Bước 6.1: Lấy join command từ Master Trên Master node:\n1 2 # Generate new join command (nếu mất command từ kubeadm init) kubeadm token create --print-join-command Output example:\n1 2 3 kubeadm join 10.0.1.10:6443 \\ --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1234567890abcdef... Giải thích join command:\n10.0.1.10:6443: API server address (master private IP + API port) \u0026ndash;token: Bootstrap token để authenticate join request \u0026ndash;discovery-token-ca-cert-hash: SHA256 hash của CA cert để verify API server Security của join process:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Worker → Master: \u0026#34;Tôi muốn join với token XYZ\u0026#34; ↓ Master verify token ↓ Master gửi CA certificate ↓ Worker verify CA cert hash ↓ Worker trust CA ↓ Mutual TLS established ↓ Worker download cluster info ↓ Worker start kubelet ↓ Worker registered trong cluster Tại sao cần CA cert hash:\nPrevent man-in-the-middle attacks\nWorker verify đang nói chuyện với đúng master\nWithout hash: Attacker có thể fake master và steal credentials\nBước 6.2: Join workers vào cluster Trên Worker-1 và Worker-2:\n1 2 3 4 5 # Run join command với sudo sudo kubeadm join 10.0.1.10:6443 \\ --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:1234567890abcdef... \\ --v=5 Giải thích quá trình join:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Step 1: [preflight] Pre-flight checks - Check swap disabled - Check required ports - Check containerd running Step 2: [discovery] Discover cluster info - Connect to API server - Verify CA certificate hash - Download cluster CA certificate Step 3: [kubelet-start] Configure kubelet - Generate kubelet.conf with cluster info - Start kubelet service Step 4: [kubelet-finalize] Finalize kubelet - Download cluster config - Register node với API server Step 5: Bootstrap TLS - Generate node certificate - Submit CertificateSigningRequest (CSR) - API server auto-approve CSR - Download signed certificate Expected output:\n1 2 3 4 5 6 7 8 [preflight] Running pre-flight checks [discovery] Downloading cluster info [kubelet-start] Writing kubelet configuration to file [kubelet-start] Starting the kubelet [kubelet-finalize] Updating kubelet configuration This node has joined the cluster: * Certificate signing request was sent to apiserver * Kubelet was informed of the new secure connection details Troubleshooting nếu join failed:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Common errors: # 1. Token expired (24h) # Error: \u0026#34;invalid token\u0026#34; # Solution: Generate new token trên master # 2. Cannot connect to API server # Error: \u0026#34;connection refused\u0026#34; # Solution: Check Security Group, verify API server running # 3. CA cert hash mismatch # Error: \u0026#34;invalid discovery token CA certificate hash\u0026#34; # Solution: Get correct hash từ master # 4. Node already joined # Error: \u0026#34;node already exists\u0026#34; # Solution: kubeadm reset trước, rồi join lại Bước 6.3: Verify join success trên Master Trên Master node:\n1 2 3 4 5 6 7 8 9 10 11 # Check tất cả nodes kubectl get nodes # Expected output: # NAME STATUS ROLES AGE VERSION # k8s-master Ready control-plane 20m v1.34.3 # k8s-worker-1 Ready \u0026lt;none\u0026gt; 2m v1.34.3 # k8s-worker-2 Ready \u0026lt;none\u0026gt; 2m v1.34.3 # Check với details kubectl get nodes -o wide Output với details:\n1 2 3 4 NAME STATUS ROLES AGE VERSION INTERNAL-IP OS-IMAGE KERNEL-VERSION k8s-master Ready control-plane 20m v1.34.3 10.0.1.10 Ubuntu 22.04.3 LTS 5.15.0-xxx k8s-worker-1 Ready \u0026lt;none\u0026gt; 2m v1.34.3 10.0.1.20 Ubuntu 22.04.3 LTS 5.15.0-xxx k8s-worker-2 Ready \u0026lt;none\u0026gt; 2m v1.34.3 10.0.2.20 Ubuntu 22.04.3 LTS 5.15.0-xxx Giải thích columns:\nSTATUS: Ready = node healthy và ready to schedule pods\nROLES: control-plane cho master, none cho workers\nINTERNAL-IP: Private IP dùng cho cluster communication\nVERSION: K8s version running trên node\nBước 6.4: Verify Cilium agents trên workers 1 2 3 4 5 6 7 8 # Check Cilium pods trên tất cả nodes kubectl get pods -n kube-system -l k8s-app=cilium -o wide # Expected output: # NAME READY STATUS NODE # cilium-xxxxx 1/1 Running k8s-master # cilium-yyyyy 1/1 Running k8s-worker-1 # cilium-zzzzz 1/1 Running k8s-worker-2 Giải thích:\nCilium DaemonSet tự động deploy pods lên workers mới\nMỗi worker có 1 Cilium agent pod\nAgent manage networking trên node đó\nPHẦN 7: VERIFY VÀ TEST CLUSTER (KHÔNG LÀM CŨNG ĐƯỢC) Bước 7.1: Verify cluster health Trên Master node:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Check component status kubectl get componentstatuses # Check all pods trong kube-system kubectl get pods -n kube-system # Check all nodes kubectl get nodes -o wide # Check Cilium status cilium status # Check Cilium connectivity cilium connectivity test componentstatuses output:\n1 2 3 4 NAME STATUS MESSAGE scheduler Healthy ok controller-manager Healthy ok etcd-0 Healthy {\u0026#34;health\u0026#34;:\u0026#34;true\u0026#34;} Giải thích:\nTất cả components phải Healthy\nNếu có Unhealthy: Check logs của component đó\nBước 7.2: Deploy test nginx application 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Create nginx deployment kubectl create deployment nginx --image=nginx --replicas=3 # Verify deployment kubectl get deployments # Check pods được schedule kubectl get pods -o wide # Expected output: # NAME READY STATUS NODE # nginx-xxx 1/1 Running k8s-worker-1 # nginx-yyy 1/1 Running k8s-worker-2 # nginx-zzz 1/1 Running k8s-worker-1 Giải thích:\nreplicas=3: 3 pod instances\nScheduler distribute pods across workers\nPods có IPs từ pod CIDR (10.244.x.x)\nBước 7.3: Expose nginx service 1 2 3 4 5 6 7 8 9 # Expose deployment as NodePort service kubectl expose deployment nginx --port=80 --type=NodePort # Get service details kubectl get svc nginx # Output: # NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE # nginx NodePort 10.96.123.45 \u0026lt;none\u0026gt; 80:32456/TCP 1m Giải thích Service types:\nClusterIP (default): Only accessible within cluster\nNodePort: Accessible via any node IP + NodePort\nLoadBalancer: Cloud provider load balancer (AWS ELB)\nNodePort hoạt động:\n1 2 3 4 5 6 7 8 9 10 Client → Node IP:NodePort (10.0.1.11:32456) ↓ Cilium eBPF load balance đến một trong 3 nginx pods: - nginx-xxx (10.244.1.5:80) 33% - nginx-yyy (10.244.2.8:80) 33% - nginx-zzz (10.244.1.9:80) 34% ↓ Pod process request ↓ Response về client Bước 7.4: Test service connectivity Test từ trong cluster:\n1 2 3 4 5 6 7 # Test với ClusterIP kubectl run test-pod --image=busybox --rm -it --restart=Never -- \\ wget -O- http://nginx # Test với service DNS name kubectl run test-pod --image=busybox --rm -it --restart=Never -- \\ wget -O- http://nginx.default.svc.cluster.local Giải thích DNS trong K8s:\nService DNS format: \u0026lt;service-name\u0026gt;.\u0026lt;namespace\u0026gt;.svc.cluster.local\nnginx.default.svc.cluster.local:\nnginx: service name\ndefault: namespace\nsvc.cluster.local: cluster domain\nCoreDNS resolve service name → ClusterIP\nTest từ bên ngoài cluster (từ laptop):\n1 2 3 4 5 6 7 8 9 10 # Get NodePort NODEPORT=$(kubectl get svc nginx -o jsonpath=\u0026#39;{.spec.ports[0].nodePort}\u0026#39;) # Get worker node public IP WORKER_IP=$(kubectl get nodes k8s-worker-1 -o jsonpath=\u0026#39;{.status.addresses[?(@.type==\u0026#34;ExternalIP\u0026#34;)].address}\u0026#39;) # Test với curl curl http://$WORKER_IP:$NODEPORT # Expected output: nginx welcome page HTML Giải thích:\nConnect đến bất kỳ node IP nào với NodePort\nCilium forward request đến pod (có thể trên node khác)\nResponse route back qua node nhận request\nBước 7.5: Test pod-to-pod connectivity 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Get pod IPs kubectl get pods -o wide # Exec vào một pod POD1=$(kubectl get pods -l app=nginx -o jsonpath=\u0026#39;{.items[0].metadata.name}\u0026#39;) kubectl exec -it $POD1 -- /bin/bash # Trong pod, test connectivity đến pod khác # Get IP của pod khác POD2_IP=$(kubectl get pods -l app=nginx -o jsonpath=\u0026#39;{.items[1].status.podIP}\u0026#39;) # Ping pod khác ping -c 3 $POD2_IP # Curl đến pod khác curl http://$POD2_IP # Exit pod exit Giải thích:\nTest direct pod-to-pod connectivity\nVerify Cilium overlay network hoạt động\nPods trên different nodes phải communicate được\nBước 7.6: Test DNS resolution 1 2 3 4 5 6 7 8 9 10 # Create test pod kubectl run dnstest --image=busybox --rm -it --restart=Never -- sh # Trong pod, test DNS nslookup kubernetes.default nslookup nginx.default.svc.cluster.local nslookup google.com # Exit exit Giải thích:\nkubernetes.default: Built-in service để access API server\nnginx.default.svc.cluster.local: Service tạo ở bước trước\ngoogle.com: External DNS (verify outbound connectivity)\nDNS resolution flow:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Pod query: nginx.default.svc.cluster.local ↓ Send DNS query đến CoreDNS (10.96.0.10:53) ↓ CoreDNS lookup service: - Check services trong namespace default - Find nginx service - Return ClusterIP: 10.96.123.45 ↓ Pod nhận ClusterIP ↓ Pod connect đến ClusterIP ↓ Cilium eBPF intercept, load balance đến pod Bước 7.7: Verify Cilium network policies (Optional) 1 2 3 4 5 6 7 8 9 10 11 12 # Cilium connectivity test (comprehensive) cilium connectivity test # Test sẽ: # - Deploy test pods # - Test pod-to-pod connectivity # - Test pod-to-service connectivity # - Test pod-to-external connectivity # - Test network policies # - Clean up test resources # Mất khoảng 5-10 phút Giải thích:\ncilium connectivity test là comprehensive test suite\nVerify tất cả aspects của cluster networking\nNếu pass: Cluster networking hoàn toàn functional\nBước 7.8: Check cluster resource usage 1 2 3 4 5 6 7 8 9 10 11 12 13 # Check node resources kubectl top nodes # Requires metrics-server (optional) # Check pod resources kubectl top pods -A # Describe node kubectl describe node k8s-worker-1 # Check allocatable resources kubectl get nodes -o json | \\ jq \u0026#39;.items[] | {name: .metadata.name, capacity: .status.capacity, allocatable: .status.allocatable}\u0026#39; Giải thích:\nCapacity: Total resources trên node\nAllocatable: Resources available cho pods (capacity - system reserved)\ntop commands: Requires metrics-server addon\nPHẦN 8: CLEANUP VÀ TROUBLESHOOTING Bước 8.1: Cleanup test resources 1 2 3 4 5 6 7 # Delete nginx deployment và service kubectl delete deployment nginx kubectl delete service nginx # Verify cleanup kubectl get pods kubectl get svc Bước 8.2: Common troubleshooting commands Node issues:\n1 2 3 4 5 6 7 8 9 10 11 # Describe node để xem events kubectl describe node \u0026lt;node-name\u0026gt; # Check kubelet logs sudo journalctl -u kubelet -f # Check kubelet status sudo systemctl status kubelet # Restart kubelet nếu cần sudo systemctl restart kubelet Pod issues:\n1 2 3 4 5 6 7 8 9 10 11 # Describe pod kubectl describe pod \u0026lt;pod-name\u0026gt; # Get pod logs kubectl logs \u0026lt;pod-name\u0026gt; # Get previous pod logs (nếu pod restart) kubectl logs \u0026lt;pod-name\u0026gt; --previous # Exec vào pod kubectl exec -it \u0026lt;pod-name\u0026gt; -- /bin/bash Networking issues:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Check Cilium status cilium status # Check Cilium pods kubectl get pods -n kube-system -l k8s-app=cilium # Cilium agent logs kubectl logs -n kube-system \u0026lt;cilium-pod-name\u0026gt; # Check connectivity cilium connectivity test # Verify eBPF maps cilium bpf endpoint list DNS issues:\n1 2 3 4 5 6 7 8 # Check CoreDNS pods kubectl get pods -n kube-system -l k8s-app=kube-dns # CoreDNS logs kubectl logs -n kube-system \u0026lt;coredns-pod-name\u0026gt; # Test DNS từ pod kubectl run -it --rm debug --image=busybox --restart=Never -- nslookup kubernetes.default Certificate issues:\n1 2 3 4 5 # Check certificate expiration sudo kubeadm certs check-expiration # Renew certificates (nếu cần) sudo kubeadm certs renew all Bước 8.3: Reset cluster (nếu cần start over) Trên tất cả nodes:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # Reset kubeadm sudo kubeadm reset -f # Clean up sudo rm -rf /etc/cni/net.d sudo rm -rf /var/lib/cni/ sudo rm -rf /var/lib/etcd sudo rm -rf /var/lib/kubelet sudo rm -rf /etc/kubernetes sudo rm -rf ~/.kube # Clean Cilium sudo rm -rf /var/run/cilium sudo rm -rf /var/lib/cilium sudo rm -rf /sys/fs/bpf/cilium # Delete Cilium interfaces sudo ip link delete cilium_host 2\u0026gt;/dev/null || true sudo ip link delete cilium_net 2\u0026gt;/dev/null || true sudo ip link delete cilium_vxlan 2\u0026gt;/dev/null || true # Flush iptables sudo iptables -F \u0026amp;\u0026amp; sudo iptables -t nat -F \u0026amp;\u0026amp; sudo iptables -t mangle -F \u0026amp;\u0026amp; sudo iptables -X # Restart services sudo systemctl restart containerd sudo systemctl restart kubelet # Reboot (recommended) sudo reboot Sau khi reboot, có thể init cluster lại từ đầu\nPHẦN 9: POST-SETUP RECOMMENDATIONS Bước 9.1: Label nodes (Optional nhưng recommended) 1 2 3 4 5 6 7 8 9 10 11 12 # Label workers với role kubectl label node k8s-worker-1 node-role.kubernetes.io/worker=worker kubectl label node k8s-worker-2 node-role.kubernetes.io/worker=worker # Verify kubectl get nodes # Output sẽ show roles: # NAME ROLES # k8s-master control-plane # k8s-worker-1 worker # k8s-worker-2 worker Giải thích:\nLabels giúp organize và select nodes\nRole labels purely cosmetic nhưng helpful\nCó thể dùng trong nodeSelector, affinity rules\nBước 9.2: Setup kubectl autocompletion (Quality of life) 1 2 3 4 5 6 7 8 # For bash echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;complete -o default -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # Test k get nodes # Should work Bước 9.3: Install metrics-server (For resource monitoring) 1 2 3 4 5 6 7 8 9 10 11 12 13 # Install metrics-server kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml # Patch metrics-server để work với self-signed certs kubectl patch deployment metrics-server -n kube-system --type=\u0026#39;json\u0026#39; \\ -p=\u0026#39;[{\u0026#34;op\u0026#34;: \u0026#34;add\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/spec/template/spec/containers/0/args/-\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;--kubelet-insecure-tls\u0026#34;}]\u0026#39; # Wait for metrics-server ready kubectl rollout status deployment metrics-server -n kube-system # Test kubectl top nodes kubectl top pods -A Giải thích:\nmetrics-server collect resource metrics từ kubelets\nEnable kubectl top commands\nRequired cho Horizontal Pod Autoscaler (HPA)\nBước 9.4: Setup Helm (Package manager for K8s) 1 2 3 4 5 6 7 8 9 10 # Download và install Helm curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash # Verify helm version # Add popular repos helm repo add stable https://charts.helm.sh/stable helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update Bước 9.5: Backup cluster config 1 2 3 4 5 6 7 8 9 10 11 12 13 # Backup admin kubeconfig cp ~/.kube/config ~/kubeconfig-backup-$(date +%Y%m%d).yaml # Backup etcd (important!) sudo ETCDCTL_API=3 etcdctl \\ --endpoints=https://127.0.0.1:2379 \\ --cacert=/etc/kubernetes/pki/etcd/ca.crt \\ --cert=/etc/kubernetes/pki/etcd/server.crt \\ --key=/etc/kubernetes/pki/etcd/server.key \\ snapshot save /tmp/etcd-backup-$(date +%Y%m%d).db # Download backup về laptop scp ubuntu@\u0026lt;master-ip\u0026gt;:/tmp/etcd-backup-*.db ./ TÓM TẮT WORKFLOW 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 1. CHUẨN BỊ (Tất cả nodes) - Update system - Set hostname và /etc/hosts - Tắt swap - Load kernel modules - Configure sysctl - Disable firewall 2. CONTAINER RUNTIME (Tất cả nodes) - Install containerd - Configure containerd với SystemdCgroup - Start containerd 3. K8S COMPONENTS (Tất cả nodes) - Install kubeadm, kubelet, kubectl - Enable kubelet 4. INIT MASTER (Master only) - kubeadm init với proper flags - Setup kubeconfig - Verify control plane 5. INSTALL CILIUM (Master only) - Install Cilium CLI - cilium install với proper config - Verify Cilium ready - Nodes chuyển Ready 1. JOIN WORKERS (Workers only - Get join command từ master - kubeadm join - Verify nodes joined 7. VERIFY CLUSTER - Check nodes Ready - Deploy test app - Test connectivity - Test DNS - Cilium connectivity test 8. POST-SETUP - Label nodes - Setup autocompletion - Install metrics-server - Backup config ","date":"2026-01-16T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/setup-k8s-cluster-on-cloud/","title":"Hướng dẫn setup K8S Cluster on Cloud"},{"content":"Thông thường, trong thực tế triển khai Kubernetes (K8s), các kiến trúc sẽ biến thiên tùy vào nhu cầu về hiệu năng, chi phí và độ tin cậy.\nDưới đây là câu trả lời chi tiết và bảng xếp hạng các trường hợp từ phổ biến nhất đến ít phổ biến hơn (từ dễ đến khó).\n1. Trả lời câu hỏi \u0026ldquo;Thông thường\u0026rdquo; Về Hardware: Thường là Khác nhau (Heterogeneous) hoặc chia theo nhóm. Trong Cloud (AWS, GCP, Azure), người ta dùng các \u0026ldquo;Node Pool\u0026rdquo; khác nhau (con thiên về CPU, con thiên về RAM, con có GPU) để tối ưu chi phí.\nVề LAN: Thường là Cùng một mạng ảo (VPC/VNET) nhưng có thể chia thành nhiều Subnet khác nhau (khác dải IP nội bộ) để đảm bảo tính sẵn sàng cao (High Availability).\n2. Xếp hạng các trường hợp của 1 K8s Cluster Hạng 1: Cùng LAN (VPC) – Khác Hardware (Phổ biến nhất) Đây là tiêu chuẩn của các dịch vụ Managed Kubernetes (EKS, GKE, AKS).\nĐặc điểm: Các Node nằm trong cùng một mạng ảo để đảm bảo độ trễ thấp (latency \u0026lt; 1ms). Tuy nhiên, Hardware thường khác nhau (Node Pool A dùng m5.large cho Web, Node Pool B dùng g4dn cho AI).\nƯu điểm: Tối ưu chi phí, hiệu năng cao, dễ quản lý networking.\nNhược điểm: Nếu toàn bộ Data Center gặp sự cố thì sập cả Cluster.\nHạng 2: Khác LAN (Multi-AZ) – Cùng/Khác Hardware (Tiêu chuẩn cho Production) Các Node nằm ở các Availability Zone (AZ) khác nhau (ví dụ: một cụm ở Đông Anh, một cụm ở Hòa Lạc).\nĐặc điểm: Các Node vẫn thuộc cùng một Cluster nhưng nằm ở các Subnet khác nhau, kết nối qua đường truyền tốc độ cao của nhà cung cấp Cloud.\nƯu điểm: Tính sẵn sàng cực cao (HA). Nếu 1 trung tâm dữ liệu cháy, Cluster vẫn sống.\nNhược điểm: Độ trễ mạng cao hơn một chút so với Hạng 1, chi phí truyền tải dữ liệu giữa các Zone (Inter-AZ transfer fee).\nHạng 3: Cùng LAN – Cùng Hardware (Môi trường On-premise/Lab) Thường thấy ở các công ty tự xây dựng server vật lý (Bare-metal) hoặc các phòng Lab.\nĐặc điểm: Mua 1 lô 10 server giống hệt nhau về cấu hình, cắm chung vào 1 Switch.\nƯu điểm: Cấu hình cực kỳ đơn giản, hiệu năng đồng nhất, dễ dự đoán tài nguyên.\nNhược điểm: Thiếu linh hoạt. Lãng phí nếu có ứng dụng chỉ cần ít tài nguyên nhưng phải chạy trên server khủng.\nHạng 4: Khác LAN (Multi-Region / Hybrid Cloud) – Khác Hardware Cluster trải dài qua các vùng địa lý (ví dụ: 1 Node ở Singapore, 1 Node ở Mỹ) hoặc vừa dưới On-prem vừa trên Cloud.\nĐặc điểm: Kết nối qua VPN hoặc Direct Connect/Interconnect.\nƯu điểm: Phục vụ người dùng toàn cầu, tuân thủ chủ quyền dữ liệu.\nNhược điểm: Cực kỳ phức tạp. Độ trễ mạng (Latency) là kẻ thù của K8s (đặc biệt là Etcd). Thường người ta sẽ dùng nhiều Cluster riêng biệt (Multi-cluster) thay vì 1 Cluster trải dài như thế này.\nHạng 5: Edge Computing (WAN/Internet) – Hardware cực kỳ khác biệt Các Node là các thiết bị IoT, Raspberry Pi hoặc máy tính nhúng đặt tại các cửa hàng, nhà máy.\nĐặc điểm: Kết nối qua Internet không ổn định. Dùng các bản phân phối như K3s hoặc KubeEdge.\nƯu điểm: Xử lý dữ liệu tại chỗ (Edge).\nNhược điểm: Khó quản lý nhất, bảo mật thấp, kết nối chập chờn.\nTóm tắt bảng so sánh Tiêu chí Hạng 1 (Phổ biến nhất) Hạng 2 (Chuẩn Prod) Hạng 3 (On-prem) Hạng 4 (Hybrid/Multi-Region) Hardware Khác nhau (Node Pool) Khác nhau Giống nhau Khác nhau Mạng (LAN) Cùng 1 mạng ảo Khác Subnet (Multi-AZ) Cùng 1 Switch vật lý Khác mạng (VPN/Internet) Độ trễ (Latency) Rất thấp Thấp Cực thấp Cao (Nguy hiểm) Mục đích Tối ưu chi phí/hiệu năng Sẵn sàng cao (HA) Dễ quản trị Toàn cầu hóa/Tuân thủ Lời khuyên: Nếu bạn đang bắt đầu, hãy chọn Hạng 1 hoặc Hạng 2. Đừng cố gắng xây dựng 1 Cluster chạy trên các mạng có độ trễ cao (Hạng 4) trừ khi bạn là chuyên gia về Network và K8s.\nNhưng cứ thử đi đừng sợ =)))\n","date":"2025-12-31T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/cluster-case/","title":"Các trường hợp triển khai K8S Cluster"},{"content":"Hướng dẫn chi tiết sử dụng kubeadm để dựng một cluster trên Ubuntu (20.04 hoặc 22.04). Sử dụng Containerd làm Container Runtime (thay thế cho Docker đã cũ).\nHướng dẫn chi tiết sử dụng kubeadm để dựng một cluster trên Ubuntu (20.04 hoặc 22.04). Sử dụng Containerd làm Container Runtime (thay thế cho Docker đã cũ).\nMô hình Lab 1 Master Node (Control Plane): Điều khiển cluster.\n2 Worker Nodes: Nơi chạy các ứng dụng (Pod).\nYêu cầu phần cứng: Tối thiểu 2 CPU, 2GB RAM mỗi node.\nPHẦN 1: CẤU HÌNH CHUNG (Thực hiện trên TẤT CẢ các Node) Làm các bước này trên cả Master và Worker.\nBước 1: Tắt Swap Memory Kubernetes yêu cầu tắt Swap để hoạt động ổn định.\n1 2 sudo swapoff -a sudo sed -i /swap/d /etc/fstab Giải thích: K8s Scheduler cần biết chính xác lượng RAM khả dụng để phân phối Pod. Nếu dùng Swap (RAM ảo trên ổ cứng), hiệu năng sẽ giảm và K8s không tính toán được tài nguyên thực tế, dẫn đến crash.\nBước 2: Cấu hình Kernel Module và Network Load các module cần thiết và cấu hình IP forwarding.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Load module overlay và br_netfilter cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter # Cấu hình sysctl cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF sudo sysctl --system Giải thích:\nbr_netfilter: Cho phép traffic đi qua cầu nối mạng (bridge) được xử lý bởi iptables (tường lửa Linux). Điều này cần thiết để K8s quản lý mạng giữa các Pod. ip_forward: Cho phép Linux chuyển tiếp gói tin IP, biến server thành một router mềm để Pods có thể giao tiếp với bên ngoài. Bước 3: Cài đặt Container Runtime (Containerd) K8s cần một phần mềm để chạy các container. Chúng ta dùng containerd.\nCài đặt containerd:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Cài đặt các gói phụ thuộc sudo apt-get update sudo apt-get install -y ca-certificates curl gnupg # Thêm Docker GPG key (Containerd nằm trong repo của Docker) sudo install -m 0755 -d /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg sudo chmod a+r /etc/apt/keyrings/docker.gpg # Thêm repository echo \\ \u0026#34;deb [arch=\u0026#34;$(dpkg --print-architecture)\u0026#34; signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\ \u0026#34;$(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;)\u0026#34; stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null # Cài đặt containerd sudo apt-get update sudo apt-get install -y containerd.io Cấu hình Cgroup cho Containerd (RẤT QUAN TRỌNG):\n1 2 3 4 5 6 7 8 9 # Tạo file config mặc định sudo mkdir -p /etc/containerd sudo containerd config default | sudo tee /etc/containerd/config.toml # Sửa SystemdCgroup = true sudo sed -i \u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/g\u0026#39; /etc/containerd/config.toml # Restart containerd sudo systemctl restart containerd Giải thích:\nCgroup (Control Group): Là tính năng Linux để giới hạn tài nguyên (CPU/RAM) cho process. Tại sao phải sửa config? Ubuntu dùng systemd để quản lý init system. Nếu Containerd dùng cgroupfs (mặc định) còn Kubelet dùng systemd, sẽ xảy ra xung đột quản lý tài nguyên. Ta phải ép cả 2 cùng dùng systemd. Bước 4: Cài đặt kubeadm, kubelet và kubectl kubeadm: Tool để dựng cluster.\nkubelet: Agent chạy trên mọi node để quản lý container.\nkubectl: Tool dòng lệnh để user điều khiển cluster.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Cài đặt các gói cần thiết sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl gpg # Download public signing key của Kubernetes curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg # Thêm repository K8s echo \u0026#39;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/kubernetes.list # Cài đặt sudo apt-get update sudo apt-get install -y kubelet kubeadm kubectl sudo apt-mark hold kubelet kubeadm kubectl Giải thích: apt-mark hold dùng để khóa phiên bản, ngăn không cho lệnh apt upgrade tự động nâng cấp K8s, vì việc nâng cấp K8s cần quy trình riêng thủ công để tránh sập hệ thống.\nPHẦN 2: KHỞI TẠO MASTER NODE (Chỉ làm trên Master) Bước 1: Khởi tạo Cluster Chạy lệnh sau trên Master Node.\n1 sudo kubeadm init Quá trình này mất vài phút. Nó sẽ tải các image của K8s (API Server, Etcd, Scheduler\u0026hellip;) về và chạy chúng.\nBước 2: Cấu hình kubectl cho user hiện tại Sau khi lệnh trên chạy xong, nó sẽ hiện ra hướng dẫn. Bạn cần chạy 3 lệnh này để có thể dùng lệnh kubectl:\n1 2 3 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Giải thích: admin.conf chứa \u0026ldquo;chìa khóa\u0026rdquo; (certificate) để truy cập vào API Server với quyền admin cao nhất.\nBước 3: Cài đặt Network Plugin (CNI) Cluster đã chạy nhưng các Pod chưa thể nói chuyện với nhau. Ta cần cài CNI. Ở đây dùng Cilium.\n1 2 3 4 5 6 7 CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt) CLI_ARCH=amd64 if [ \u0026#34;$(uname -m)\u0026#34; = \u0026#34;aarch64\u0026#34; ]; then CLI_ARCH=arm64; fi curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum} sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum} 1 2 3 4 5 cilium install \\ --version \u0026lt;latest-version\u0026gt; \\ --set kubeProxyReplacement=true \\ --set k8sServiceHost=\u0026lt;IP control-plane\u0026gt; \\ --set k8sServicePort=6443 1 2 3 # Kiểm tra cilium status --wait kubectl get nodes Giải thích:\nK8s không tự cung cấp mạng cho Pod, nó chỉ đưa ra chuẩn CNI (Container Network Interface). Cilium là một plugin thực thi chuẩn đó, giúp tạo ra mạng ảo (Overlay Network) để Pod ở Node A có thể ping thấy Pod ở Node B. PHẦN 3: JOIN WORKER NODES (Làm trên các Worker) Bước 1: Lấy lệnh Join Khi chạy kubeadm init ở Phần 2 xong, dòng cuối cùng của output sẽ là lệnh join. Nếu lỡ quên hoặc xóa mất, hãy chạy lệnh này trên Master để lấy lại:\n1 kubeadm token create --print-join-command Bước 2: Thực thi trên Worker Copy lệnh output ở trên và dán vào terminal của các máy Worker Node. Ví dụ:\n1 sudo kubeadm join \u0026lt;MASTER_IP\u0026gt;:6443 --token \u0026lt;token\u0026gt; --discovery-token-ca-cert-hash sha256:\u0026lt;hash\u0026gt; Giải thích:\nLệnh này giúp Worker Node xác thực với Master Node thông qua Token. Sau khi xác thực, Kubelet trên Worker sẽ nhận chỉ đạo từ Master. PHẦN 4: KIỂM TRA (Verify) Quay lại Master Node, chạy lệnh:\n1 kubectl get nodes Kết quả mong đợi:\n1 2 3 4 NAME STATUS ROLES AGE VERSION master Ready control-plane 10m v1.29.0 worker-1 Ready \u0026lt;none\u0026gt; 2m v1.29.0 worker-2 Ready \u0026lt;none\u0026gt; 2m v1.29.0 Nếu trạng thái là NotReady: Chờ khoảng 1-2 phút để CNI khởi động xong. Nếu vẫn NotReady: Kiểm tra lại bước tắt Swap hoặc file config của containerd. Tổng kết kiến trúc: OS Layer: Ubuntu + Tắt Swap + IP Forwarding.\nRuntime Layer: Containerd (quản lý container).\nK8s Layer: Kubelet (giao tiếp với Master), Kube-proxy (quản lý mạng).\nNetwork Layer: Cilium (kết nối các Pod).\nBÀI VIẾT LIÊN QUAN Hướng dẫn setup K8S Cluster Bare-metal ","date":"2025-12-31T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/setup-k8s-cluster/","title":"Hướng dẫn setup K8S Cluster"},{"content":"Đây là một bài toán thực tế rất thú vị (thường gọi là Bare-metal Kubernetes). Khi chuyển từ môi trường ảo hóa (VM) sang 3 thiết bị vật lý thật\nĐây là một bài toán thực tế rất thú vị (thường gọi là Bare-metal Kubernetes). Khi chuyển từ môi trường ảo hóa (VM) sang 3 thiết bị vật lý thật (ví dụ: 3 chiếc Laptop cũ, hoặc 1 PC + 2 Laptop, hoặc Raspberry Pi) kết nối qua Wi-Fi, thách thức lớn nhất không phải là cài đặt K8s, mà là Mạng (Networking).\nDưới đây là hướng dẫn nâng cao để xử lý các vấn đề đặc thù khi chạy K8s trên Wi-Fi.\nTHÁCH THỨCC IP Động (DHCP): Wi-Fi thường cấp IP ngẫu nhiên mỗi khi khởi động lại. K8s sẽ \u0026ldquo;chết\u0026rdquo; nếu IP của Node thay đổi.\nĐộ trễ (Latency): Wi-Fi không ổn định bằng dây LAN. Database của K8s (Etcd) rất nhạy cảm với độ trễ, nếu mạng lag quá, cluster sẽ tự vỡ (crash).\nDNS: Các máy không tự biết tên nhau (ví dụ: máy Master không biết worker-1 là ai).\nQUY HOẠCH MẠNG (Ví dụ) Giả sử dải mạng Wi-Fi nhà bạn là 192.168.1.x. Chúng ta sẽ chọn 3 IP cố định (tránh dải DHCP của Router cấp cho điện thoại để khỏi trùng).\nMaster Node: 192.168.1.100 (Hostname: k8s-master)\nWorker 1: 192.168.1.101 (Hostname: k8s-worker1)\nWorker 2: 192.168.1.102 (Hostname: k8s-worker2)\nBƯỚC 1: CẤU HÌNH IP TĨNH (QUAN TRỌNG NHẤT) Làm trên từng máy tương ứng.\nTrên Ubuntu Server (bản mới), mạng được quản lý bởi Netplan.\nKiểm tra tên card mạng Wi-Fi:\n1 ip a Tìm cái tên bắt đầu bằng w (ví dụ: wlan0 hoặc wlp2s0). Giả sử là wlan0.\nTạo file cấu hình Netplan: Chúng ta sẽ dùng lệnh tee để tạo file config mới. (Lưu ý: Thay thế SSID-WIFI và PASSWORD bằng thông tin wifi nhà bạn).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # Trên máy MASTER (đặt IP .100) cat \u0026lt;\u0026lt;EOF | sudo tee /etc/netplan/01-netcfg.yaml network: version: 2 renderer: networkd wifis: wlan0: dhcp4: no addresses: - 192.168.1.100/24 routes: - to: default via: 192.168.1.1 nameservers: addresses: [8.8.8.8, 1.1.1.1] access-points: \u0026#34;TEN_WIFI_NHA_BAN\u0026#34;: password: \u0026#34;MAT_KHAU_WIFI\u0026#34; EOF (Làm tương tự cho Worker 1 (.101) và Worker 2 (.102) - chỉ sửa dòng addresses).\nApply cấu hình:\n1 sudo netplan apply Nếu mất kết nối SSH, hãy SSH lại vào IP mới.\nBƯỚC 2: ĐỒNG BỘ DANH BẠ (FILE HOSTS) Vì không có DNS Server nội bộ, ta phải khai báo thủ công để các máy gọi nhau bằng tên.\nThực hiện trên CẢ 3 MÁY:\nĐặt Hostname cho đúng chuẩn:\n1 2 3 4 5 6 7 8 # Trên máy Master sudo hostnamectl set-hostname k8s-master # Trên máy Worker 1 sudo hostnamectl set-hostname k8s-worker1 # Trên máy Worker 2 sudo hostnamectl set-hostname k8s-worker2 Sửa file /etc/hosts: Dùng tee -a để thêm vào cuối file hosts trên TẤT CẢ CÁC MÁY:\n1 2 3 4 5 cat \u0026lt;\u0026lt;EOF | sudo tee -a /etc/hosts 192.168.1.100 k8s-master 192.168.1.101 k8s-worker1 192.168.1.102 k8s-worker2 EOF BƯỚC 3: CẤU HÌNH TƯỜNG LỬA (FIREWALL) Các máy vật lý thường bật sẵn tường lửa (UFW). Để đơn giản cho việc học (Lab), ta nên tắt nó đi để tránh việc các Node không ping thấy nhau.\nTrên cả 3 máy:\n1 sudo ufw disable (Nếu bạn muốn bảo mật hơn, hãy comment, mình sẽ đưa list các port cần mở).\nBƯỚC 4: CÀI ĐẶT K8S (NHƯ BÀI TRƯỚC) Thực hiện lại các bước ở bài trước trên cả 3 máy:\nTắt Swap.\nLoad module kernel (overlay, br_netfilter).\nCài containerd (nhớ sửa SystemdCgroup = true).\nCài kubeadm, kubelet, kubectl.\nBƯỚC 5: KHỞI TẠO CLUSTER (TỐI ƯU CHO WI-FI) Đây là bước nâng cao. Vì Wi-Fi có độ trễ, ta cần cấu hình để K8s \u0026ldquo;kiên nhẫn\u0026rdquo; hơn, không đánh dấu Node là chết (NotReady) quá sớm khi mạng lag nhẹ.\nTrên Master Node:\nTạo file config cho kubeadm: Thay vì chạy kubeadm init ngay, ta tạo file config để tinh chỉnh.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 cat \u0026lt;\u0026lt;EOF | tee kubeadm-config.yaml apiVersion: kubeadm.k8s.io/v1beta3 kind: ClusterConfiguration kubernetesVersion: v1.29.0 controlPlaneEndpoint: \u0026#34;k8s-master:6443\u0026#34; networking: podSubnet: 192.168.0.0/16 --- apiVersion: kubelet.config.k8s.io/v1beta1 kind: KubeletConfiguration cgroupDriver: systemd shutdownGracePeriod: 30s shutdownGracePeriodCritical: 10s EOF Chạy Init với file config:\n1 sudo kubeadm init --config kubeadm-config.yaml Cài đặt Network Plugin (Calico): (Thực hiện như bài trước).\nBƯỚC 6: JOIN WORKER VÀ KIỂM TRA Lấy lệnh join từ Master và chạy trên 2 Worker (như bài trước). Trên Master, kiểm tra: 1 kubectl get nodes -o wide Lưu ý cột INTERNAL-IP phải đúng là 192.168.1.100, .101, .102. Nếu nó hiện IP lạ (ví dụ IP của Docker bridge), cluster sẽ lỗi. MẸO NÂNG CAO (PRO TIPS) CHO MÔ HÌNH NÀY 1. Điều khiển Cluster từ Laptop cá nhân (Remote Access) Bạn không muốn lúc nào cũng phải SSH vào máy Master để gõ lệnh kubectl. Bạn muốn gõ lệnh ngay trên Laptop Windows/Mac của mình.\nTrên máy Master: Copy nội dung file config: 1 cat ~/.kube/config Trên Laptop cá nhân: Cài kubectl cho Windows/Mac. Tạo file ~/.kube/config và paste nội dung vừa copy vào. Mở file đó ra, tìm dòng server: https://192.168.1.100:6443. Đảm bảo IP đúng là IP của máy Master (vì đôi khi nó để là 127.0.0.1). Giờ bạn có thể ngồi sofa điều khiển cluster. 2. Xử lý lỗi Etcd do Wi-Fi lag Nếu thấy cluster hay bị mất kết nối, bạn cần tăng thời gian timeout của Etcd. Sửa file /etc/kubernetes/manifests/etcd.yaml trên máy Master. Thêm dòng sau vào phần command:\n1 2 - --heartbeat-interval=500 - --election-timeout=5000 (Mặc định là 100ms và 1000ms. Tăng lên giúp nó chịu được mạng lag tốt hơn).\n3. Tiết kiệm băng thông\nKhi bạn deploy một ứng dụng, cả 3 máy sẽ cùng kéo Image từ Internet về qua Wi-Fi. Điều này sẽ làm mạng rất lag.\nGiải pháp: Kéo image trên 1 máy, sau đó dùng lệnh ctr (của containerd) để export image và copy sang các máy kia (hoặc dựng một Local Registry - nhưng cái này để bài sau nhé).\n","date":"2025-12-31T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/setup-k8s-cluster-bare-metal/","title":"Hướng dẫn setup K8S Cluster on Premise"},{"content":"Nếu UnionFS là ý tưởng, thì OverlayFS là bản thực thi xuất sắc nhất hiện nay trên Linux. Nó khắc phục được sự cồng kềnh và chậm chạp của các thế hệ trước (như AUFS hay Device Mapper)\nTiếp nối câu chuyện về UnionFS, chúng ta sẽ đi sâu vào OverlayFS (cụ thể là driver overlay2 trong Docker).\n1. Kiến trúc 4 thành phần của OverlayFS Khác với cách nói chung chung \u0026ldquo;xếp lớp\u0026rdquo;, OverlayFS định nghĩa cấu trúc rất rõ ràng với 4 thư mục chính khi mount:\nLowerDir (Tầng dưới - Read-only):\nĐây chính là các Docker Image layers.\nNó có thể bao gồm nhiều lớp xếp chồng lên nhau.\nĐặc điểm: Chỉ được đọc, tuyệt đối không được sửa.\nUpperDir (Tầng trên - Read-Write):\nĐây là Container layer.\nNơi chứa tất cả những thay đổi bạn thực hiện khi container đang chạy (file mới tạo, file bị sửa).\nMerged (Tầng hợp nhất - View):\nĐây là điểm mount mà người dùng nhìn thấy (ví dụ /var/lib/docker/overlay2/.../merged).\nNó ảo hóa việc gộp LowerDir và UpperDir.\nWorkDir (Tầng đệm):\nĐây là thư mục nội bộ để OverlayFS xử lý các tác vụ trung gian (như chuẩn bị file trước khi di chuyển sang UpperDir) để đảm bảo tính toàn vẹn dữ liệu (atomicity). 2. Cơ chế hoạt động chi tiết (Deep Dive) OverlayFS hoạt động ở cấp độ File (Tệp tin), không phải cấp độ Block (Khối đĩa). Điều này rất quan trọng để hiểu hiệu năng.\nA. Đọc file (Reading)\nNếu file nằm ở UpperDir: Hệ thống đọc ngay lập tức (Rất nhanh).\nNếu file không có ở Upper mà chỉ có ở Lower: Hệ thống đọc từ Lower.\nHiệu năng: Gần như tốc độ ổ cứng gốc (Native speed).\nB. Ghi file (Writing \u0026amp; Copy_up) - Điểm mấu chốt\nĐây là lúc cơ chế Copy-on-Write (CoW) của OverlayFS hoạt động, thuật ngữ chuyên ngành gọi là copy_up:\nBạn mở một file 100MB có sẵn trong Image (Lower) để sửa.\nOverlayFS nhận lệnh ghi. Nó tạm dừng lại.\nNó tìm file đó ở LowerDir.\nNó COPY toàn bộ file 100MB đó lên UpperDir.\nSau khi copy xong, nó mới cho phép ứng dụng ghi dữ liệu vào bản sao ở UpperDir.\nLưu ý quan trọng: OverlayFS hoạt động theo file. Dù bạn chỉ sửa 1 ký tự trong file 1GB, nó cũng phải copy cả file 1GB đó lên trên. Đây là lý do nó chậm hơn Volume khi ghi lần đầu.\nC. Xóa file (Deleting \u0026amp; Whiteout)\nLàm sao xóa file ở LowerDir (vốn Read-only)?\nOverlayFS tạo ra một file đặc biệt trong UpperDir gọi là Whiteout file (thường là một character device với major/minor number là 0/0).\nFile này trùng tên với file cần xóa.\nKhi bạn nhìn vào thư mục Merged, OverlayFS thấy file Whiteout này và sẽ \u0026ldquo;ẩn\u0026rdquo; file gốc ở dưới đi.\n3. Tại sao Overlay2 lại tốt hơn các UnionFS cũ (như AUFS)? Trước đây Docker dùng AUFS, nhưng giờ chuyển sang Overlay2 vì 2 lý do cực lớn:\n1. Page Cache Sharing (Chia sẻ bộ nhớ đệm) - Cực kỳ quan trọng\nHãy tưởng tượng bạn chạy 10 Container từ cùng một Image node:latest.\nImage này có file /usr/bin/node (nặng 50MB).\nVới các công nghệ cũ (Device Mapper): Nó có thể tải 10 bản copy vào RAM -\u0026gt; Tốn 500MB RAM.\nVới OverlayFS: Vì các lớp LowerDir là giống hệt nhau về mặt vật lý, Linux Kernel thông minh nhận ra chúng cùng chung một Inode trên ổ cứng.\nKernel chỉ tải file /usr/bin/node vào RAM một lần duy nhất (Page Cache).\nCả 10 container đều dùng chung vùng nhớ đệm đó.\nKết quả: Tiết kiệm RAM khủng khiếp khi chạy nhiều container giống nhau (ví dụ trong Kubernetes).\n2. Tốc độ và Sự đơn giản\nOverlayFS được tích hợp trực tiếp vào Linux Kernel Mainline. Nó không cần cài thêm module ngoài. Code của nó gọn nhẹ hơn nhiều so với AUFS.\nTốc độ tạo container (mount overlay) nhanh hơn rất nhiều so với việc tạo snapshot của Device Mapper.\n4. Giới hạn của OverlayFS\nDù rất tốt, OverlayFS vẫn có điểm yếu mà bạn cần biết khi vận hành hệ thống:\nRename Directory (Đổi tên thư mục): OverlayFS (chuẩn POSIX) không hỗ trợ hoàn hảo việc đổi tên thư mục nếu thư mục đó nằm ở lớp Lower và bạn muốn đổi tên nó ở lớp Upper. Docker phải dùng mẹo (copy thư mục cũ sang tên mới rồi xóa cũ) -\u0026gt; Rất tốn kém nếu thư mục lớn.\nKhông phù hợp ghi dữ liệu lớn: Như đã nói, vì cơ chế copy toàn bộ file (copy_up), nên tuyệt đối không để Database file trên OverlayFS.\nInode exhaustion (Cạn kiệt Inode): Đây là vấn đề của driver overlay cũ. Driver overlay2 đã khắc phục được điều này, nhưng nếu bạn tạo quá nhiều file nhỏ trong container, bạn vẫn có thể làm hết Inode của ổ cứng host.\nTóm lại: OverlayFS là sự kết hợp hoàn hảo giữa tốc độ đọc (nhờ Page Cache sharing) và khả năng quản lý layer linh hoạt. Tuy nhiên, bản chất \u0026ldquo;Copy nguyên file\u0026rdquo; khi ghi đè khiến nó luôn thua Volume ở các tác vụ ghi nặng (Write-heavy workloads).\nBài viết liên quan UnionFS Tại sao overlay2 trên Docker lại có hiệu năng kém hơn Volume/Bind Mount ? ","date":"2025-12-28T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/overlayfs/","title":"OverlayFS - overlay2 on Docker"},{"content":"Nguyên nhân cốt lõi nằm ở Cơ chế Copy-on-Write (CoW) và lớp trung gian (Overhead)\nMặc dù overlay2 là driver lưu trữ (storage driver) tốt nhất và được khuyến nghị mặc định cho Docker hiện nay, nhưng về mặt vật lý và logic, nó không thể nhanh bằng Volume hoặc Bind Mount.\nDưới đây là 4 lý do kỹ thuật chi tiết giải thích tại sao overlay2 lại chậm hơn, đi sâu vào cơ chế xử lý file:\n1. Cơ chế copy_up ở cấp độ File (File-level Copy-on-Write) - Nguyên nhân lớn nhất Đây là sự khác biệt chí mạng giữa overlay2 và Volume.\nVolume/Bind Mount (Native Filesystem - ext4/xfs):\nKhi bạn sửa một file 1GB, hệ thống file (filesystem) chỉ đơn giản là tìm đến địa chỉ (block) của file đó trên ổ cứng và ghi đè dữ liệu mới vào.\nNếu bạn chỉ sửa 1KB cuối file, nó chỉ ghi đúng 1KB đó. Chi phí gần như bằng 0.\nOverlay2:\noverlay2 hoạt động ở cấp độ File, không phải cấp độ Block.\nKhi bạn sửa một file (vốn nằm ở lớp Image/Read-only), overlay2 buộc phải kích hoạt quy trình copy_up.\nQuy trình: Nó phải đọc toàn bộ file gốc từ lớp dưới $\\rightarrow$ Tạo một file mới ở lớp trên (UpperDir) $\\rightarrow$ Ghi toàn bộ dữ liệu cũ vào $\\rightarrow$ Sau đó mới áp dụng thay đổi của bạn.\nHệ quả: Nếu bạn sửa 1 byte trong file log nặng 1GB nằm trong Image, hệ thống phải tốn công Copy cả 1GB đó sang lớp ghi. Điều này gây ra độ trễ (latency) cực lớn (I/O burst) ngay tại thời điểm ghi lần đầu tiên.\n2. Overhead của VFS (Virtual File System) và Tra cứu Inode Volume là đường thẳng, overlay2 là đường vòng.\nVolume:\nỨng dụng gọi lệnh open() $\\rightarrow$ Hệ điều hành trỏ thẳng tới Inode trên đĩa $\\rightarrow$ Xong.\nĐường đi ngắn nhất, ít rào cản nhất.\nOverlay2:\nKhi ứng dụng gọi lệnh open() hoặc ls, Kernel không thể đi thẳng.\nNó phải đi qua lớp logic của OverlayFS driver.\nDriver này phải kiểm tra xem file đó nằm ở UpperDir hay LowerDir? (Quét các lớp).\nNó phải kiểm tra xem file đó có bị đánh dấu là \u0026ldquo;Whiteout\u0026rdquo; (đã xóa giả) hay không?\nViệc logic \u0026ldquo;nếu - thì\u0026rdquo; này tốn CPU cycles. Mặc dù rất nhỏ cho mỗi file, nhưng với các ứng dụng web đọc/ghi hàng nghìn file nhỏ (như PHP, Node.js node_modules), độ trễ sẽ cộng dồn lại thành đáng kể.\n3. Vấn đề với các thao tác Metadata (Rename, chmod, chown) Một số thao tác tưởng chừng đơn giản lại trở nên phức tạp trên OverlayFS:\nRename (Đổi tên thư mục):\nTrên Volume (ext4), đổi tên thư mục chỉ là việc sửa đổi metadata, tốn vài mili-giây bất kể thư mục nặng bao nhiêu GB.\nTrên OverlayFS, chuẩn POSIX không hỗ trợ đầy đủ việc đổi tên thư mục nếu nó nằm ở lớp Read-only. Hệ thống có thể phải thực hiện việc \u0026ldquo;Copy toàn bộ thư mục sang tên mới rồi xóa cũ\u0026rdquo;. Nếu thư mục đó chứa nhiều data, đây là thảm họa hiệu năng.\nLưu ý: Các phiên bản Kernel mới có tính năng \u0026ldquo;redirect_dir\u0026rdquo; để giảm nhẹ vấn đề này, nhưng nó vẫn phức tạp hơn native.\n4. Không tận dụng được tối đa các tính năng của Filesystem gốc Volume nằm trực tiếp trên ext4 hoặc xfs của máy chủ (Host). Nó hưởng trọn vẹn các tính năng tối ưu của các hệ thống file này (như extent mapping, delayed allocation\u0026hellip;).\nOverlayFS là một lớp phủ. Mọi yêu cầu phải đi qua nó trước khi xuống ext4/xfs. Lớp trung gian này đôi khi làm cản trở các thuật toán tối ưu hóa luồng I/O của hệ điều hành.\n5. Tóm tắt so sánh trực quan Hãy tưởng tượng bạn muốn sửa một dòng chữ trong một trang sách:\nVolume/Bind Mount: Bạn cầm bút, viết thẳng lên trang sách đó. (Nhanh, trực tiếp).\nOverlay2: Trang sách đó được ép plastic (Read-only).\nBạn phải lấy một tờ giấy trắng (Upper layer).\nBạn phải đặt tờ giấy trắng lên trên trang sách.\nBạn phải đồ lại (trace) toàn bộ nội dung của trang sách cũ lên tờ giấy mới (copy_up).\nSau đó bạn mới sửa dòng chữ trên tờ giấy mới.\nKết luận:\nChính vì thao tác \u0026ldquo;đồ lại\u0026rdquo; (copy_up) và việc phải quản lý nhiều tờ giấy xếp chồng lên nhau khiến overlay2 luôn chậm hơn việc viết trực tiếp (Volume).\nĐó là lý do tại sao quy tắc vàng trong Docker luôn là: Code để trong Container (Overlay2) vì ít khi sửa đổi, nhưng Data (Database, Logs) bắt buộc phải để trong Volume.\nBài viết liên quan UnionFS OverlayFS ","date":"2025-12-28T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/overlay2-vs-volume--bind-mount/","title":"Tại sao overlay2 trên Docker lại có hiệu năng kém hơn Volume và Bind Mount ?"},{"content":"UnionFS cho phép bạn \u0026ldquo;xếp chồng\u0026rdquo; nhiều thư mục (hoặc ổ đĩa) khác nhau lên nhau để tạo thành một hệ thống tệp tin duy nhất và thống nhất\nUnionFS (Union File System) là một dịch vụ hệ thống tệp tin (filesystem service) cho Linux, FreeBSD và NetBSD.\n1. Cơ chế hoạt động (Hãy tưởng tượng về các \u0026ldquo;Layer\u0026rdquo;) Để dễ hình dung, hãy tưởng tượng UnionFS giống như các Layer (lớp) trong Photoshop hoặc các tấm phim trong suốt xếp chồng lên nhau:\nXếp chồng: Bạn có thư mục A và thư mục B. UnionFS cho phép bạn gộp chúng lại thành thư mục C.\nThứ tự ưu tiên: Khi bạn nhìn vào thư mục C, bạn sẽ thấy nội dung của cả A và B. Nếu cả A và B đều có một file tên là text.txt, thì file nằm ở lớp trên (ví dụ là A) sẽ được hiển thị, file ở lớp dưới (B) sẽ bị che khuất.\nTrong suốt: Người dùng hoặc ứng dụng khi truy cập vào thư mục C sẽ không biết nó được ghép từ A và B, họ chỉ thấy một thư mục bình thường.\n2. Hai tính năng kỹ thuật quan trọng UnionFS trở nên mạnh mẽ nhờ hai cơ chế xử lý file:\nCopy-on-Write (CoW):\nThường thì lớp dưới cùng là Read-only (Chỉ đọc - không thể sửa), và lớp trên cùng là Writeable (Có thể ghi).\nNếu bạn muốn sửa một file nằm ở Read-only layer, UnionFS sẽ tự động copy file đó lên lớp Writeable layer, sau đó áp dụng thay đổi trên bản copy đó. File gốc ở dưới vẫn giữ nguyên.\nWhiteout (Xóa giả):\nNếu bạn xóa một file nằm ở Read-only layer, UnionFS không thể xóa nó thật (vì là chỉ đọc).\nThay vào đó, nó tạo ra một \u0026ldquo;dấu hiệu\u0026rdquo; (whiteout) ở lớp trên cùng để che file đó đi. Hệ thống nhìn vào sẽ tưởng là file đã bị xóa.\n3. Ứng dụng thực tế (Tại sao lại cần UnionFS?) UnionFS (và các biến thể hiện đại hơn như OverlayFS, AuFS) là công nghệ cốt lõi của nhiều công cụ phổ biến:\nDocker \u0026amp; Container: Đây là ứng dụng nổi tiếng nhất.\nMột Docker Image gồm nhiều lớp (layers) xếp chồng lên nhau (ví dụ: lớp OS, lớp thư viện, lớp ứng dụng).\nKhi bạn chạy container, Docker dùng công nghệ kiểu UnionFS để gộp các lớp read-only đó lại và thêm một lớp writable mỏng ở trên cùng để bạn thao tác. Điều này giúp tiết kiệm dung lượng ổ cứng cực lớn (các container có thể dùng chung các lớp dưới).\nLive CD / Live USB Linux:\nKhi bạn chạy Ubuntu từ USB mà không cài đặt, hệ điều hành nằm trên USB là dạng nén, chỉ đọc (Read-only).\nMọi thay đổi bạn làm (tạo file, cài phần mềm) được lưu vào RAM (lớp Writable).\nUnionFS gộp lớp USB và lớp RAM lại để bạn dùng như một máy tính bình thường. Khi tắt máy, lớp RAM mất đi, USB vẫn nguyên vẹn.\nFirmware Router/IoT: Giúp khôi phục cài đặt gốc dễ dàng. Hệ điều hành gốc nằm ở lớp dưới (bảo vệ tuyệt đối), cài đặt của người dùng nằm ở lớp trên. Khi \u0026ldquo;Reset\u0026rdquo;, chỉ cần xóa lớp trên là xong.\n4. Tình trạng hiện nay Mặc dù thuật ngữ \u0026ldquo;UnionFS\u0026rdquo; vẫn hay được dùng để chỉ chung cho công nghệ này, nhưng dự án UnionFS gốc hiện nay ít được sử dụng trực tiếp trong các nhân Linux hiện đại.\nThay vào đó, OverlayFS là công nghệ kế thừa, ổn định hơn và đã được tích hợp chính thức vào Linux Kernel, đang được sử dụng bởi Docker và hầu hết các hệ thống hiện nay.\nTóm lại: UnionFS là công nghệ \u0026ldquo;xếp hình\u0026rdquo; các thư mục, cho phép giữ nguyên file gốc trong khi vẫn có thể chỉnh sửa trên một lớp ảo phủ lên trên.\nBài viết liên quan OverlayFS Tại sao overlay2 trên Docker lại có hiệu năng kém hơn Volume/Bind Mount ? ","date":"2025-12-28T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/unionfs/","title":"UnionFS - Union File System"},{"content":"OpenSSH (Open Secure Shell) là bộ công cụ mã nguồn mở triển khai giao thức SSH. Đây là \u0026ldquo;tiêu chuẩn vàng\u0026rdquo; được cài đặt mặc định trên hầu hết các hệ điều hành Linux, macOS và cả Windows hiện đại\nĐể hiểu rõ cách nó hoạt động, chúng ta sẽ mổ xẻ từng thành phần trong bộ OpenSSH Suite theo chức năng của chúng: Server, Client, Quản lý khóa, và Truyền tải.\nI. Kết nối cơ bản 1. sshd (SSH Daemon) - \u0026ldquo;Người gác cổng\u0026rdquo; Đây là thành phần quan trọng nhất chạy trên Server.\nVai trò:\nLuôn luôn chạy ngầm (background process) trên máy chủ.\nLắng nghe tại cổng 22 (mặc định) để chờ kết nối từ bên ngoài.\nQuyết định ai được vào, ai bị chặn.\nCách hoạt động:\nKhi nhận được tín hiệu kết nối từ Client, sshd sẽ thực hiện bắt tay (handshake) để thiết lập mã hóa.\nNó kiểm tra danh tính người dùng (dựa trên Password hoặc SSH Key).\nNếu xác thực thành công, sshd sẽ tạo ra một phiên làm việc (session) mới và khởi chạy môi trường dòng lệnh (shell) cho người dùng đó.\nMọi lệnh bạn gõ từ máy mình sẽ được sshd nhận, thực thi trên server, rồi gửi kết quả trả về cho bạn.\nFile cấu hình: /etc/ssh/sshd_config (Nơi bạn chỉnh port, tắt login root, tắt password\u0026hellip;).\n2. ssh (SSH Client) - \u0026ldquo;Khách\u0026rdquo; Đây là lệnh bạn gõ trên máy tính cá nhân (Client).\nVai trò:\nKhởi tạo kết nối đến Server.\nĐọc các file cấu hình của người dùng để biết nên kết nối thế nào (dùng key nào, port nào).\nMã hóa dữ liệu bạn gõ và gửi đi.\nCách hoạt động:\nBạn gõ ssh user@host.\nssh tìm file ~/.ssh/config (nếu có) để xem có cài đặt đặc biệt nào không.\nNó kết nối đến sshd ở phía kia.\nNó kiểm tra ~/.ssh/known_hosts để xem server này có phải server quen không (tránh giả mạo).\nSau khi kết nối xong, nó biến thành cái \u0026ldquo;loa\u0026rdquo;: Bạn gõ gì nó gửi đi, Server trả lời gì nó hiện lên màn hình.\nII. Bộ công cụ quản lý khóa (Key Management) 1. ssh-keygen - \u0026ldquo;Máy đúc chìa\u0026rdquo; Vai trò: Tạo ra cặp khóa Public/Private.\nCách hoạt động: Nó dùng thuật toán toán học (RSA, Ed25519) để sinh ra 2 chuỗi ký tự ngẫu nhiên có liên kết toán học với nhau.\nNó tạo file id_rsa (Private - Cất kỹ).\nNó tạo file id_rsa.pub (Public - Mang đi phát).\n2. ssh-copy-id - \u0026ldquo;Người đưa thư\u0026rdquo; Vai trò: Copy Public Key lên Server một cách an toàn và đúng chuẩn.\nCách hoạt động:\nNó kết nối SSH vào server (lần này vẫn cần mật khẩu).\nNó lấy nội dung file id_rsa.pub của bạn.\nNó tự động tạo thư mục ~/.ssh trên server (nếu chưa có).\nNó ghi nội dung key vào file ~/.ssh/authorized_keys trên server.\nNó set quyền (permission) cho file đó thật chặt chẽ để chỉ user đó mới đọc được (nếu quyền lỏng lẻo, SSH sẽ từ chối key).\n3. ssh-agent \u0026amp; ssh-add - \u0026ldquo;Quản gia giữ chìa\u0026rdquo; Vấn đề: Để bảo mật, khi tạo Private Key, bạn thường đặt thêm mật khẩu (passphrase) cho chính cái Key đó. Nghĩa là mỗi lần dùng Key để login, bạn lại phải nhập pass của Key. Rất phiền.\nGiải pháp:\nssh-agent: Là một chương trình chạy ngầm trong RAM máy bạn.\nssh-add: Bạn gõ lệnh này, nhập pass của Key một lần duy nhất. ssh-agent sẽ giải mã Key đó và giữ nó trong RAM.\nKết quả: Từ đó về sau, khi bạn ssh đi đâu, ssh sẽ hỏi mượn Key từ ssh-agent chứ không hỏi bạn nữa. Bạn không cần gõ pass lại cho đến khi tắt máy.\nIII. Bộ công cụ truyền file OpenSSH tận dụng đường hầm bảo mật đã thiết lập để truyền file.\n1. scp (Secure Copy) Vai trò: Copy file nhanh gọn.\nCách hoạt động: Nó mở một kết nối SSH, nhưng thay vì chạy shell, nó chạy một quy trình copy dữ liệu. Nó đọc file nguồn, mã hóa, gửi qua đường hầm, và bên kia ghi lại thành file đích.\nLưu ý: scp đang dần bị thay thế bởi sftp trong các phiên bản mới vì lý do kiến trúc bảo mật, nhưng cách dùng vẫn y hệt.\n2. sftp (Secure File Transfer Protocol) Vai trò: Quản lý file từ xa (giống FTP nhưng an toàn).\nCách hoạt động:\nNó là một Subsystem (hệ thống con) của SSH.\nKhi kết nối, sshd sẽ kích hoạt phân hệ SFTP server.\nNó cho phép bạn thực hiện nhiều thao tác hơn scp: liệt kê file, đổi tên, xóa file, tạo thư mục, resume (tải tiếp) file bị đứt quãng.\nIV. Các file cấu hình quan trọng (Cần nhớ) Để làm chủ OpenSSH, bạn phải biết các file này nằm đâu:\nVị trí Tên file Vai trò Thuộc về Trên Server /etc/ssh/sshd_config Cấu hình toàn bộ hành vi của Server (Port, Quyền login\u0026hellip;). sshd Trên Server ~/.ssh/authorized_keys Danh sách các Public Key được phép mở cửa vào nhà. sshd Trên Client /etc/ssh/ssh_config Cấu hình mặc định cho mọi user trên máy client. ssh Trên Client ~/.ssh/config Cấu hình riêng cho cá nhân bạn (Alias, User, Port riêng cho từng server). ssh Trên Client ~/.ssh/known_hosts Lưu \u0026ldquo;vân tay\u0026rdquo; (fingerprint) của các server đã từng kết nối. Nếu server bị thay đổi (hoặc bị hack), vân tay thay đổi, file này sẽ cảnh báo bạn. ssh V. Tóm tắt quy trình phối hợp: Bạn dùng ssh-keygen tạo khóa.\nBạn dùng ssh-copy-id ném khóa sang Server (vào file authorized_keys).\nBạn gõ ssh.\nClient (ssh) hỏi Agent (ssh-agent) lấy khóa.\nClient nói chuyện với Server (sshd).\nServer kiểm tra authorized_keys, thấy khớp -\u0026gt; Cho vào.\n","date":"2025-12-20T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/openssh-suite/","title":"Vai trò và cách hoạt động của OpenSSH Suite"},{"content":"Hệ thống mạng (Networking) đầy đủ, bảo mật và chuẩn doanh nghiệp (Enterprise-grade) trên AWS\n1. Core Infrastructure VPC (Virtual Private Cloud): Mạng ảo riêng biệt của bạn trên đám mây AWS. Đây là container chứa tất cả các tài nguyên mạng khác.\nSubnets (Mạng con): Chia nhỏ VPC thành các mạng nhỏ hơn. Một kiến trúc chuẩn thường chia làm 3 tầng (3-tier architecture) trên mỗi Availability Zone (AZ):\nPublic Subnet: Chứa các resource cần truy cập trực tiếp từ Internet (Load Balancer, Bastion Host, NAT Gateway).\nPrivate Subnet (App): Chứa các ứng dụng backend. Có thể ra Internet qua NAT nhưng không nhận kết nối trực tiếp từ ngoài vào.\nDatabase/Isolated Subnet: Chứa Database. Hoàn toàn cô lập, không có đường ra Internet (chỉ nhận kết nối từ App Subnet).\nCIDR Block: Dải địa chỉ IP cho VPC và Subnets (VD: 10.0.0.0/16).\n2. Internet Connectivity Để các resource giao tiếp với thế giới bên ngoài:\nInternet Gateway (IGW): Cổng kết nối giúp Public Subnet giao tiếp 2 chiều với Internet.\nNAT Gateway (Network Address Translation): Đặt tại Public Subnet. Giúp các instance trong Private Subnet đi ra Internet (để tải update, patch) nhưng chặn Internet truy cập ngược vào trong.\nEgress-only Internet Gateway: Tương tự NAT Gateway nhưng dành cho IPv6.\n3. Routing \u0026amp; Traffic Management Điều hướng dòng chảy của dữ liệu:\nRoute Tables: Bảng chỉ đường. Mỗi Subnet phải liên kết với một Route Table để biết traffic đi đâu (VD: Traffic 0.0.0.0/0 trỏ về IGW hay NAT Gateway).\nElastic Load Balancer (ELB): Phân phối tải.\nALB (Application Load Balancer): Layer 7 (HTTP/HTTPS), xử lý routing thông minh dựa trên path, host.\nNLB (Network Load Balancer): Layer 4 (TCP/UDP), hiệu năng cực cao, độ trễ thấp.\nRoute 53: Dịch vụ DNS của AWS. Dùng để phân giải tên miền và health check.\n4. Security Security Groups (SG): Firewall cấp độ Instance (Stateful). Bạn quy định port nào được mở (VD: Chỉ cho phép port 80 từ Load Balancer vào Web Server).\nNetwork ACLs (NACLs): Firewall cấp độ Subnet (Stateless). Dùng để chặn (Deny) các IP cụ thể hoặc làm lớp bảo vệ thô.\nAWS WAF (Web Application Firewall): Bảo vệ ứng dụng web khỏi các cuộc tấn công phổ biến (SQL Injection, XSS) - thường gắn vào ALB hoặc CloudFront.\nAWS Network Firewall: Firewall cao cấp cho toàn bộ VPC, hỗ trợ Deep Packet Inspection (IPS/IDS) và lọc domain.\nAWS Shield: Chống tấn công DDoS.\n5. Private Connectivity Kết nối các dịch vụ AWS hoặc các VPC với nhau mà không đi qua Internet công cộng:\nVPC Endpoints (AWS PrivateLink):\nInterface Endpoint: Giúp EC2 trong Private Subnet kết nối tới các dịch vụ AWS (như CloudWatch, SNS, Systems Manager) qua mạng nội bộ AWS, không cần NAT Gateway.\nGateway Endpoint: Dành riêng cho S3 và DynamoDB (miễn phí và hiệu năng cao hơn).\nVPC Peering: Kết nối trực tiếp 2 VPC với nhau (như thể chúng cùng 1 mạng).\nTransit Gateway (TGW): \u0026ldquo;Hub\u0026rdquo; trung tâm để kết nối hàng trăm VPC và mạng On-premise với nhau. Đây là giải pháp thay thế VPC Peering khi hệ thống lớn.\n6. Hybrid Connectivity Kết nối AWS với Data Center vật lý hoặc văn phòng:\nSite-to-Site VPN: Kết nối qua đường truyền Internet nhưng được mã hóa (IPsec).\nAWS Direct Connect (DX): Đường dây cáp vật lý riêng nối từ Data Center của bạn thẳng đến AWS (băng thông cao, ổn định, bảo mật).\nClient VPN: Cho phép nhân viên kết nối từ xa vào VPC (như OpenVPN).\n7. Monitoring \u0026amp; Observability Để biết chuyện gì đang xảy ra trong mạng:\nVPC Flow Logs: Ghi lại thông tin về traffic đi vào/ra các network interface (cho biết IP nào đang kết nối, port nào bị chặn\u0026hellip;).\nTraffic Mirroring: Sao chép traffic mạng để gửi tới các công cụ phân tích bảo mật (IDS) hoặc giám sát chuyên sâu.\np/s: Nếu bạn đang viết Terraform, mỗi gạch đầu dòng trên sẽ tương ứng với một resource hoặc module trong code của bạn.\n","date":"2025-12-16T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/aws-networking/","title":"AWS - Networking"},{"content":"Để trả lời câu này sâu sắc, chúng ta không chỉ nhìn ở bề nổi (gõ lệnh -\u0026gt; ra kết quả), mà phải nhìn xuống tầng Kernel và System Calls\n1. Phân tích cú pháp (Parsing) \u0026amp; Tokenization Khi bạn gõ ví dụ: ls -l /var/log và nhấn Enter:\nShell (Bash/Zsh) sẽ đọc dòng chữ đó.\nNó cắt chuỗi thành các Tokens (từ đơn):\nCommand: ls\nArgument: -l\nArgument: /var/log\n2. Kiểm tra Alias và Hàm (Aliases \u0026amp; Functions) Trước khi tìm file để chạy, Shell kiểm tra Alias trước:\nAlias: Có phải bạn đã đặt alias ls='ls --color=auto' không? Nếu có, nó sẽ thay thế ls bằng lệnh đầy đủ.\nFunctions: Có hàm nào tên là ls được định nghĩa trong .bashrc không?\n3. Kiểm tra Shell Built-in (Lệnh nội tại) Shell kiểm tra xem lệnh này có phải là Built-in không.\nBuilt-in: Là lệnh nằm ngay trong code của Shell, không cần gọi file bên ngoài (Ví dụ: cd, echo, alias, export).\nTại sao cd phải là built-in? Vì nếu cd là một chương trình bên ngoài, khi chạy nó sẽ tạo ra một tiến trình con (child process), tiến trình con đổi thư mục rồi tắt đi, tiến trình cha (Shell hiện tại) vẫn ở thư mục cũ. Do đó cd phải do chính Shell thực hiện. External: ls không phải built-in, nên Shell tiếp tục bước sau.\n4. Mở rộng (Expansion) Shell xử lý các ký tự đặc biệt trước khi chạy lệnh:\nBrace expansion: echo {a,b} -\u0026gt; a b\nVariable expansion: $HOME -\u0026gt; /home/user\nCommand substitution: $(date) -\u0026gt; Sun Nov 30...\nGlobbing (Wildcards): *.txt -\u0026gt; danh sách file đuôi txt.\n5. Tìm kiếm đường dẫn (Path Resolution) Nếu lệnh không chứa đường dẫn tuyệt đối (như /bin/ls) mà chỉ là ls, Shell sẽ tìm trong biến môi trường $PATH.\nNó quét lần lượt: /usr/local/bin -\u0026gt; /usr/bin -\u0026gt; /bin\u0026hellip;\nĐể tối ưu, Shell thường dùng Hash Table (bảng băm) để nhớ vị trí các lệnh đã chạy trước đó (gõ hash để xem).\n6. Cơ chế Fork - Exec - Wait (Trái tim của Linux Process) Đây là bước quan trọng nhất về mặt hệ thống (System Internals). Khi đã tìm thấy file thực thi /usr/bin/ls, Shell thực hiện 3 bước thần thánh:\nfork() (Phân thân):\nShell (Process cha - Parent) gọi system call fork() để tạo ra một bản sao y hệt của chính nó (Process con - Child).\nLúc này, ta có 2 tiến trình giống hệt nhau đang chạy.\nexec() (Thay thế - Cụ thể là execve):\nTrong Process con, nó gọi system call execve().\nLệnh này sẽ xóa sạch bộ nhớ của Process con và nạp mã nguồn của chương trình mới (/usr/bin/ls) vào thay thế.\nProcess con giờ đây chính thức biến thành chương trình ls.\nwait() (Chờ đợi):\nProcess cha (Shell) gọi wait() và tạm dừng hoạt động (ngủ) để chờ Process con chạy xong. 7. Nạp thư viện động (Dynamic Linking) Trước khi ls thực sự chạy code của nó, Kernel thấy file này cần các thư viện .so (Shared Objects, giống .dll bên Windows).\nTrình liên kết động (ld-linux.so) sẽ được gọi để load các thư viện cần thiết (như libc.so, libselinux.so\u0026hellip;) vào bộ nhớ.\nDevOps Tip: Dùng lệnh ldd /bin/ls để xem nó cần thư viện nào.\n8. Thực thi và I/O Chương trình ls chạy, đọc thư mục, format kết quả.\nNó ghi kết quả ra Standard Output (stdout - File Descriptor 1). Mặc định stdout trỏ về màn hình terminal của bạn nên bạn thấy chữ hiện lên.\n9. Kết thúc (Termination) Khi ls chạy xong, nó gọi exit(0) (0 nghĩa là thành công).\nKernel gửi tín hiệu SIGCHLD cho Process cha (Shell) báo rằng \u0026ldquo;Con ông xong việc rồi\u0026rdquo;.\nShell thức dậy từ lệnh wait(), thu thập Exit Code (mã thoát).\nDevOps Tip: Mã này được lưu vào biến $?. Bạn có thể echo $? để xem. (0 = OK, khác 0 = Lỗi). 10. Prompt quay lại Shell in lại dấu nhắc lệnh (ví dụ: user@host:~$) và chờ đợi lệnh tiếp theo của bạn.\n","date":"2025-11-30T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/system-call/","title":"Điều gì sẽ xảy ra khi gõ bất kỳ command nào trong terminal trên Linux ?"},{"content":"Khi bạn gõ sudo apt update, không đơn giản là hệ thống \u0026ldquo;bật công tắc\u0026rdquo; quyền admin. Đó là một chuỗi các thao tác kiểm tra nghiêm ngặt, thay đổi định danh (Identity) và làm sạch môi trường.\nTrước khi tìm hiểu về Sudo, bạn nên hiểu về Điều gì sảy ra sau khi sử dụng Command (non-sudo)\nGiai đoạn 1: Tại Shell (User Space) Ngay khi bạn nhấn Enter, Shell (Bash/Zsh) của bạn bắt đầu làm việc:\nParsing (Phân tích cú pháp):\nShell cắt chuỗi sudo fdisk -l thành các token:\nMain Command: sudo\nArgument 1: fdisk\nArgument 2: -l\nPath Resolution (Tìm đường dẫn):\nShell tìm xem sudo nằm ở đâu bằng cách quét biến $PATH của user hiện tại (/usr/local/bin, /usr/bin, /bin\u0026hellip;).\nNó tìm thấy /usr/bin/sudo.\nGiai đoạn 2: Khởi chạy Sudo - Quyền lực ngầm (SUID) Trước khi lệnh chạy, hãy nhìn vào file thực thi của sudo\n1 2 ls -l /usr/bin/sudo # Kết quả: -rwsr-xr-x 1 root root ... Bạn thấy chữ s ở phần quyền hạn (rws) không? Đó là SUID bit.\nBình thường: Khi bạn chạy một chương trình, nó chạy với quyền của bạn (User ID của bạn).\nVới SUID: Khi bạn chạy sudo, hệ điều hành sẽ chạy nó với quyền của người sở hữu file (ở đây là root).\nShell gọi Kernel để chạy /usr/bin/sudo. Đây là điểm mấu chốt đầu tiên:\nCơ chế SUID (Set User ID):\nKernel nhìn vào metadata (Inode) của file /usr/bin/sudo và thấy bit s (-rwsr-xr-x).\nThay vì chạy sudo với quyền của user devops, Kernel khởi chạy tiến trình sudo với quyền của người sở hữu file này -\u0026gt; Root.\nKết quả: Tiến trình sudo vừa sinh ra đã có Effective UID = 0 (Quyền tối cao).\nGiai đoạn 3. Policy Check - /etc/sudoers Dù sudo đang chạy với quyền root, nó chưa vội thực thi lệnh của bạn. Nó phải kiểm tra xem bạn có \u0026ldquo;đủ tuổi\u0026rdquo; không.\nNó đọc file /etc/sudoers (và thư mục /etc/sudoers.d/).\nNó kiểm tra:\nUser của bạn có nằm trong nhóm được phép (thường là wheel hoặc sudo) không?\nBạn được phép chạy lệnh gì? (ALL commands hay chỉ một số lệnh cụ thể).\nBạn có cần nhập mật khẩu không? (NOPASSWD hay mặc định).\nGiai đoạn 4. Xác thực qua PAM (Pluggable Authentication Modules) Nếu cấu hình yêu cầu mật khẩu, sudo không tự kiểm tra mật khẩu (nó không đọc /etc/shadow). Nó nhờ một \u0026ldquo;bảo vệ\u0026rdquo; chuyên nghiệp tên là PAM.\nsudo gửi yêu cầu đến thư viện PAM.\nPAM hỏi mật khẩu của User hiện tại (không phải mật khẩu root).\nNếu nhập sai 3 lần -\u0026gt; PAM báo lỗi -\u0026gt; sudo ghi log cảnh báo và thoát.\nCơ chế Timestamp:\nNếu bạn nhập đúng, sudo sẽ tạo một file timestamp (thường ở /run/sudo/ts/). Trong vòng 15 phút (mặc định), nếu bạn gọi lại sudo, nó kiểm tra timestamp này còn hạn không. Nếu còn, nó bỏ qua bước hỏi mật khẩu.\nGiai đoạn 5. Làm sạch và Thiết lập Môi trường (Environment Sanitization) Để tránh việc user lợi dụng các biến môi trường để hack quyền root, sudo sẽ:\nXóa bỏ các biến nguy hiểm: Đặc biệt là LD_PRELOAD (biến này cho phép chèn mã độc vào thư viện động) và LD_LIBRARY_PATH.\nReset $PATH:\nsudo ghi đè biến $PATH cũ bằng giá trị secure_path trong /etc/sudoers (để bao gồm /sbin, /usr/sbin).\n*Nhờ bước này, hệ thống mới \u0026ldquo;nhìn thấy\u0026rdquo; lệnh fdisk nằm trong /usr/sbin*\nThiết lập biến định danh:\n$HOME trỏ về /root.\n$USER, $LOGNAME chuyển thành root.\n(Trừ khi bạn dùng sudo -E để giữ nguyên môi trường cũ - nhưng rất rủi ro).\nGiai đoạn 6. Ghi Log (Logging) Trước khi thực sự chạy lệnh, sudo ghi lại hành động này để làm bằng chứng (Audit trail).\nGhi vào: /var/log/auth.log (Ubuntu/Debian) hoặc /var/log/secure (RHEL/CentOS).\nNội dung: \u0026ldquo;User A đã chạy lệnh B vào giờ C tại thư mục D\u0026rdquo;.\nGiai đoạn 7. Fork và Exec (Chuyển giao quyền lực) Bây giờ mọi thủ tục đã xong, sudo thực hiện bước cuối cùng để chạy lệnh bạn muốn (ví dụ: apt update).\nfork(): sudo tạo ra một tiến trình con (Child process).\nTrong tiến trình con:\nGọi system call setuid(0) và setgid(0): Lệnh này chính thức đóng dấu \u0026ldquo;Tôi là Root\u0026rdquo; vào tiến trình con này vĩnh viễn.\nGọi execve(): Thay thế mã nguồn của sudo bằng mã nguồn của lệnh đích (apt).\nTrong tiến trình cha (sudo):\nNó vẫn chạy và đợi (wait) tiến trình con.\nNó đóng vai trò trung gian chuyển tiếp tín hiệu (Signals). Ví dụ: Bạn bấm Ctrl+C, sudo nhận được và chuyển nó cho tiến trình con đang chạy apt.\nGiai đoạn 8. Kết thúc Lệnh apt chạy xong và trả về Exit Code (0).\nsudo nhận Exit Code đó và trả lại cho Shell của bạn.\nShell hiển thị lại dấu nhắc lệnh.\nTóm tắt luồng đi (Flowchart dạng text) User gõ lệnh: sudo vim /etc/hosts\nKernel: Chạy binary sudo với quyền Root (do SUID bit).\nSudo:\nĐọc /etc/sudoers.\nHỏi PAM: \u0026ldquo;Mật khẩu thằng này đúng không?\u0026rdquo;.\nPAM: \u0026ldquo;Đúng\u0026rdquo;.\nGhi log vào /var/log/auth.log.\nXóa biến môi trường độc hại, set lại $PATH.\nfork() -\u0026gt; Tạo process con.\nProcess Con:\nsetuid(0) (Thành root thật sự).\nexecve(\u0026quot;vim\u0026quot;).\nVim: Mở ra với quyền root.\n","date":"2025-11-30T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/sudo/","title":"Điều gì xảy ra khi bạn sử dụng lệnh Sudo ?"},{"content":"Inode (viết tắt của Index Node) là một khái niệm cốt lõi và cực kỳ quan trọng trong các hệ thống tập tin (filesystem) của Linux và Unix.\nĐể hiểu đơn giản: Nếu coi dữ liệu của một file là \u0026ldquo;nội dung cuốn sách\u0026rdquo;, thì Inode chính là \u0026ldquo;thẻ mục lục\u0026rdquo; của cuốn sách đó trong thư viện.\n1. Inode chứa những gì? Mỗi file trên Linux được gán một số định danh duy nhất gọi là Inode number. Inode là một cấu trúc dữ liệu lưu trữ tất cả thông tin về file (metadata), trừ tên file và nội dung thực sự của file.\nThông tin trong một Inode bao gồm:\nLoại file: (File thường, thư mục, symbolic link, block device\u0026hellip;).\nQuyền hạn (Permissions): Read, Write, Execute cho Owner, Group, và Others.\nChủ sở hữu (Owner/Group): User ID (UID) và Group ID (GID).\nKích thước file (File size): Dung lượng tính bằng byte.\nTem thời gian (Timestamps):\nCreated (thời điểm tạo).\nModified (lần cuối sửa nội dung).\nAccessed (lần cuối mở file).\nSố lượng liên kết cứng (Hard link count): Có bao nhiêu tên file trỏ vào inode này.\nVị trí dữ liệu (Pointers to data blocks): Quan trọng nhất, nó chỉ ra vị trí cụ thể trên ổ cứng nơi dữ liệu thực sự của file được lưu trữ.\n2. Cái gì KHÔNG nằm trong Inode? Đây là điểm thú vị nhất: Tên file (Filename) không nằm trong Inode.\nTên file được lưu trong dữ liệu của Thư mục (Directory) chứa file đó.\nThư mục thực chất là một file đặc biệt, nội dung của nó chỉ là một danh sách ánh xạ giữa Tên file và Số Inode tương ứng.\n3. Quy trình truy cập một file diễn ra như thế nào? Khi bạn gõ lệnh cat data.txt hoặc mở một file, hệ thống sẽ làm như sau:\nĐọc thư mục hiện tại để tìm tên data.txt.\nLấy số Inode tương ứng với tên data.txt (ví dụ: Inode #12345).\nTruy cập vào Inode #12345 để kiểm tra quyền hạn (bạn có quyền đọc không?).\nNếu có quyền, nó dùng các \u0026ldquo;con trỏ\u0026rdquo; trong Inode để tìm đến các khối (blocks) trên ổ cứng chứa nội dung văn bản.\nHiển thị nội dung lên màn hình.\n4. Tại sao Inode lại quan trọng? a. Hard Links (Liên kết cứng)\nVì tên file và dữ liệu file (Inode) tách biệt nhau, nên Linux cho phép nhiều tên file khác nhau cùng trỏ vào một số Inode duy nhất.\nNếu bạn tạo một hard link cho File A thành File B, cả hai đều trỏ vào cùng một Inode.\nXóa File A không làm mất dữ liệu, vì Inode vẫn còn (do File B vẫn giữ liên kết). Dữ liệu chỉ thực sự bị xóa khi số lượng liên kết (link count) trong Inode giảm về 0.\nb. Di chuyển file (Move) rất nhanh\nKhi bạn dùng lệnh mv để di chuyển file trong cùng một phân vùng (partition), hệ thống không hề sao chép dữ liệu của file. Nó chỉ đơn giản là cập nhật lại đường dẫn trong các thư mục để trỏ về số Inode cũ. Do đó, việc di chuyển file 10GB diễn ra tức thì.\nc. Lỗi \u0026ldquo;No space left on device\u0026rdquo; dù ổ cứng còn trống\nMỗi phân vùng (partition) có một số lượng Inode giới hạn được định sẵn khi format (định dạng).\nNếu bạn tạo hàng triệu file cực nhỏ (ví dụ 1KB), bạn có thể dùng hết số lượng Inode cho phép dù dung lượng ổ cứng (GB) vẫn còn trống rất nhiều.\nKhi hết Inode, bạn không thể tạo thêm file mới nào nữa.\n5. Các lệnh thường dùng với Inode Xem số Inode của file:\n1 2 3 ls -i ten_file # Hoặc ls -li Xem chi tiết thông tin Inode:\n1 stat ten_file Kiểm tra dung lượng và số lượng Inode còn trống:\n1 2 df -i # Cột IUse% cho biết bạn đã dùng bao nhiêu phần trăm Inode. ","date":"2025-11-30T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/inode/","title":"Inode trong Linux File System"},{"content":" 1. \u0026ldquo;Everything is a file\u0026rdquo; Trong Linux, mọi thứ đều là tập tin (hoặc được biểu diễn như một tập tin):\nDữ liệu: Văn bản, hình ảnh, code.\nThiết bị phần cứng: Ổ cứng (/dev/sda), bàn phím, chuột.\nTiến trình (Process): Thông tin về RAM, CPU (/proc).\nSocket/Pipe: Giao tiếp mạng.\n2. Cấu trúc thư mục chuẩn (Filesystem Hierarchy Standard - FHS) Folder Meaning / (Root) Gốc của hệ thống. Chỉ user root mới có quyền ghi. /bin \u0026amp; /usr/bin Chứa các lệnh cơ bản (ls, cp, docker). /sbin \u0026amp; /usr/sbin Chứa lệnh quản trị hệ thống (iptables, reboot). /etc Quan trọng: Chứa file cấu hình (Nginx, SSH, Systemd). Đây là nơi Configuration Management (Ansible/Chef) tác động nhiều nhất. /var Quan trọng: Chứa dữ liệu biến đổi (Variable). - /var/log: Log hệ thống (cần monitor để tránh đầy ổ cứng). - /var/lib: Dữ liệu database (MySQL, Docker containers). /home Thư mục cá nhân của user. /root Thư mục cá nhân của user root. /tmp File tạm. Sẽ bị xóa khi reboot. Cảnh báo: Đừng lưu data quan trọng ở đây. /boot Kernel và Bootloader. /opt Phần mềm bên thứ 3 (thường dùng cho các ứng dụng cài thủ công như Java, Tomcat). /proc \u0026amp; /sys Virtual Filesystem: Không chiếm dung lượng ổ cứng, nằm trên RAM. Chứa thông tin kernel, process. Monitoring tool (Prometheus/Nagios) đọc data từ đây. /dev Device files (/dev/null, /dev/zero, /dev/random). 3. Cơ chế hoạt động (Under the Hood) A. Inode (Index Node)\nMỗi file có 2 phần:\nData: Nội dung thực sự của file.\nInode: Metadata (Quyền hạn, chủ sở hữu, kích thước, vị trí block trên ổ cứng, thời gian tạo\u0026hellip;).\nKịch bản:\nLỗi: \u0026ldquo;No space left on device\u0026rdquo; nhưng df -h thấy ổ cứng vẫn còn trống 50%.\nNguyên nhân: Hết Inode (do tạo quá nhiều file nhỏ, ví dụ: session files của PHP hoặc cache).\nCheck: df -i\nB. Superblock\nChứa thông tin về chính File System đó (tổng số block, kích thước block, trạng thái mount). Nếu Superblock hỏng, FS sẽ không thể mount được.\nC. Journaling (Nhật ký)\nCác FS hiện đại (ext4, xfs) đều là Journaling File System. Nó ghi lại các thay đổi dự kiến vào một vùng log trước khi ghi thật sự.\nLợi ích: Giúp phục hồi dữ liệu nhanh chóng nếu mất điện đột ngột, giảm thiểu rủi ro lỗi file system (fsck). 4. Các loại File System phổ biến Khi format ổ đĩa hoặc mount volume cho Database, bạn cần chọn đúng loại:\next4 (Fourth Extended Filesystem):\nChuẩn mực, ổn định, tương thích tốt.\nDùng cho: OS disk, General purpose.\nXFS:\nHiệu năng cao với file lớn, mở rộng tốt (Scalability). Là mặc định của RHEL/CentOS.\nDùng cho: Database server, CI/CD artifacts storage.\nLưu ý: XFS không thể thu nhỏ (shrink) partition, chỉ có thể mở rộng.\nBtrfs \u0026amp; ZFS:\nHỗ trợ nâng cao: Snapshot, Pooling, Checksum (chống bit rot).\nDùng cho: Storage Server, Backup server, Container storage driver.\n5. Quyền hạn (Permissions) \u0026amp; Security A. Cơ bản (UGO - User Group Other)\nRead (4), Write (2), Execute (1).\nLệnh: chmod, chown.\nB. Nâng cao (Special Permissions)\nSUID (Set User ID): Chạy file với quyền của người sở hữu file (thường là root) thay vì người chạy lệnh. (Ví dụ: lệnh passwd). Nguy cơ bảo mật cao.\nSGID: File tạo ra trong thư mục sẽ thừa kế Group của thư mục đó (Hữu ích cho Shared Folder).\nSticky Bit: Chỉ người tạo file mới xóa được file trong thư mục chung (Ví dụ: /tmp).\nC. ACL (Access Control Lists)\nKhi quyền UGO không đủ chi tiết (VD: Muốn user A đọc, user B ghi, user C không làm gì trên cùng 1 file), dùng setfacl và getfacl.\n6. Quản lý lưu trữ (Storage Management) A. Mounting\nGắn một thiết bị lưu trữ vào cây thư mục.\nLệnh: mount /dev/sdb1 /mnt/data\nPersist (Bền vững): Cấu hình trong /etc/fstab để tự mount khi khởi động lại. Lưu ý: Sai cú pháp fstab có thể làm máy không boot được.\nB. LVM (Logical Volume Manager)\nLớp trừu tượng giữa ổ cứng vật lý và File System.\nPhysical Volume (PV): Ổ cứng thật.\nVolume Group (VG): Gom các PV lại thành 1 cục to.\nLogical Volume (LV): Cắt VG ra để dùng (giống partition).\nLợi ích cho DevOps: Có thể mở rộng dung lượng ổ cứng (Resize) online mà không cần tắt server (Zero downtime).\n7. File System trong thế giới Container (Docker/K8s) A. Union File System (OverlayFS)\nDocker images được xây dựng từ các Layers (lớp).\nLowerDir: Các lớp Read-only (Base image).\nUpperDir: Lớp Read-write (Container layer).\nMerged: Cái bạn nhìn thấy khi chạy container.\nCơ chế Copy-on-Write (CoW): Khi container sửa một file từ image gốc, nó copy file đó lên lớp UpperDir để sửa, file gốc vẫn nguyên vẹn.\nB. Volumes \u0026amp; Bind Mounts\nDữ liệu trong container là Ephemeral (mất khi container chết).\nĐể lưu dữ liệu bền vững (Database), phải dùng Volume (Docker quản lý tại /var/lib/docker/volumes) hoặc Bind Mount (map thư mục host vào container).\n8. Các lệnh và kỹ năng Troubleshooting cần thiết Kiểm tra dung lượng:\ndf -hT: Xem dung lượng tổng quát và loại FS.\ndu -sh *: Xem thư mục nào chiếm nhiều chỗ nhất.\nncdu: Công cụ giao diện dòng lệnh để soi dung lượng (rất tiện).\nKiểm tra I/O Performance:\niostat -xz 1: Xem tốc độ đọc ghi, %iowait.\niotop: Xem tiến trình nào đang \u0026ldquo;ăn\u0026rdquo; ổ cứng.\nXử lý file đang mở (Locked files):\nlsof | grep deleted: Tìm các file đã bị xóa nhưng process vẫn đang giữ (nguyên nhân phổ biến khiến xóa log rồi mà dung lượng không giảm).\nGiải pháp: Restart process đó (ví dụ: systemctl reload nginx).\nMount/Unmount:\nmount -a: Mount tất cả trong fstab.\numount -l: Lazy unmount (dùng khi thư mục đang bị busy/treo).\nBài viết liên quan Inode ","date":"2025-11-30T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/file-system/","title":"Linux File System"},{"content":"Netstat là công cụ dòng lệnh dùng để hiển thị chi tiết các kết nối mạng (TCP/UDP), bảng định tuyến và các cổng đang lắng nghe, giúp quản trị viên giám sát và xử lý sự cố hệ thống.\n1. Tư duy cốt lõi: Tại sao cần Netstat? Khi một ứng dụng bị lỗi kết nối, DevOps Engineer sẽ đặt ra các câu hỏi sau và netstat là công cụ trả lời:\nAvailability: Port của service có đang mở (Listening) không?\nBinding: Service đang lắng nghe trên IP nào? (Localhost 127.0.0.1 hay Public 0.0.0.0)?\nProcess Mapping: Process nào (PID) đang chiếm dụng port đó?\nPerformance: Có bao nhiêu kết nối đang ở trạng thái chờ (TIME_WAIT, CLOSE_WAIT)?\nSecurity: Có IP lạ nào đang kết nối vào server không?\n2. \u0026ldquo;Vũ khí\u0026rdquo; thường dùng: Các Flag quan trọng Combo: netstat -tulpn\nĐây là lệnh đầu tiên tôi gõ khi debug network.\n-t (TCP): Chỉ hiện các kết nối TCP.\n-u (UDP): Chỉ hiện các kết nối UDP.\n-l (Listening): Chỉ hiện các socket đang lắng nghe (Server mode).\n-p (Process): Hiển thị PID và tên chương trình (Cần quyền sudo).\n-n (Numeric): Rất quan trọng. Hiển thị IP và Port bằng số thay vì phân giải tên miền (DNS resolution). Nếu không có -n, lệnh sẽ chạy rất chậm khi DNS server gặp vấn đề.\nVí dụ output:\n1 2 3 Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 1234/nginx tcp 0 0 127.0.0.1:3306 0.0.0.0:* LISTEN 5678/mysqld Phân tích:\nNginx đang mở port 80 cho tất cả IP (0.0.0.0)\nMySQL chỉ cho phép kết nối từ nội bộ (127.0.0.1). Đây là một check-point về bảo mật.\n3. Phân tích sâu về TCP States (Quan trọng cho Performance) Cần đặc biệt chú ý đến cột State. Nó phản ánh sức khỏe của ứng dụng.\na. ESTABLISHED\nKết nối đang hoạt động bình thường.\nUse case: Đếm số lượng user đang online (concurrent connections).\n1 netstat -anp | grep :80 | grep ESTABLISHED | wc -l -a (All):\nTất cả các socket, bao gồm cả các socket đang lắng nghe (Listening) và các socket đã thiết lập kết nối.\nNếu không có cờ này, mặc định netstat thường chỉ hiện các kết nối đã thiết lập.\n-n (Numeric): Đã giải thích ở trên\n-p (Program):\nHiển thị PID (Process ID) và tên chương trình đang sở hữu kết nối đó (ví dụ: 1234/nginx)\nCần root hoặc sudo để thấy PID của các process không thuộc user hiện tại\nwc -l: Công cụ đếm\n-l (Lines Flag này bảo wc chỉ đếm số dòng.\n-\u0026gt; Kết quả cuối cùng trả về một con số duy nhất (Ví dụ: 50 nghĩa là có 50 người đang kết nối vào web server).\nb. TIME_WAIT\nKết nối đã đóng, nhưng kernel giữ lại socket một lúc để đảm bảo các gói tin lạc đường được xử lý xong.\nVấn đề: Nếu server có quá nhiều TIME_WAIT (hàng nghìn), server có thể bị cạn kiệt Ephemeral Ports (hết port để mở kết nối mới).\nGiải pháp: Tinh chỉnh sysctl (net.ipv4.tcp_tw_reuse, net.ipv4.tcp_fin_timeout).\nc. CLOSE_WAIT\nĐây là trạng thái nguy hiểm nhất.\nÝ nghĩa: Phía bên kia đã đóng kết nối, nhưng ứng dụng trên server của bạn chưa đóng socket.\nNguyên nhân: Thường là do bug trong code (quên socket.close()) hoặc ứng dụng bị treo/deadlock.\nHành động: Báo ngay cho team Dev hoặc restart service để giải phóng tài nguyên.\nd. SYN_SENT\nServer gửi yêu cầu kết nối nhưng không nhận được phản hồi.\nNguyên nhân: Thường do Firewall chặn hoặc IP đích không tồn tại. 4. Netstat trong Security \u0026amp; Audit (Bảo mật) a. Phát hiện DDoS hoặc Traffic bất thường\nBạn muốn biết IP nào đang kết nối nhiều nhất vào server?\n1 netstat -ntu | awk \u0026#39;{print $5}\u0026#39; | cut -d: -f1 | sort | uniq -c | sort -nr | head -10 Lệnh này sẽ liệt kê Top 10 IP đang kết nối. b. Kiểm tra Backdoor/Malware\nNếu thấy một port lạ mở (ví dụ: 4444, 6666) và process name lạ hoặc không có tên:\n1 netstat -tulpn Kiểm tra PID đó là gì: ps -ef | grep \u0026lt;PID\u0026gt;.\n5. Routing và Interface Statistics Ngoài socket, netstat còn dùng để check tầng mạng thấp hơn.\na. Routing Table (netstat -r hoặc netstat -rn)\nTương đương lệnh route -n hoặc ip route.\nDùng để kiểm tra Default Gateway (0.0.0.0) có đúng không khi server không ra được internet. b. Interface Statistics (netstat -i)\n1 2 Iface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 1500 12345 0 0 0 12345 0 0 0 BMRU RX-ERR / TX-ERR: Nếu số này tăng, có thể do cáp mạng hỏng, switch lỗi hoặc duplex mismatch.\nRX-DRP (Drop): Server quá tải, CPU không xử lý kịp gói tin, hoặc firewall (iptables) đang drop gói tin.\n6. Sự chuyển dịch: Netstat vs. SS (Socket Statistics) Đây là kiến thức phân biệt giữa Junior và Senior.\nNetstat: Đọc thông tin từ /proc/net/tcp. Khi hệ thống có hàng chục nghìn kết nối, việc đọc file này rất chậm và tốn CPU.\nSS (iproute2 package): Lấy thông tin trực tiếp từ kernel space qua Netlink API. Nhanh hơn rất nhiều.\nBảng chuyển đổi cho DevOps:\nMục đích Lệnh Netstat (Cũ) Lệnh SS (Mới - Khuyên dùng) Xem tất cả TCP/UDP port đang listen netstat -tulpn ss -tulpn Xem kết nối đã thiết lập netstat -atn ss -atn Xem tóm tắt thống kê (Summary) netstat -s ss -s (Rất gọn và đẹp) Lọc theo port netstat -an | grep :80 ss -tn sport = :80 7. Tổng kết: Checklist cho DevOps Engineer Khi sử dụng netstat, hãy luôn nhớ quy trình tư duy này:\nCheck Listening: Service có chạy và bind đúng IP/Port không? (-tulpn)\nCheck Connection: Ai đang kết nối vào? (-an)\nCheck State: Có bị leak connection (CLOSE_WAIT) hay cạn resource (TIME_WAIT) không?\nCheck Bottleneck: Có IP nào spam kết nối không? (Dùng awk để lọc).\nPerformance: Nếu server tải cao, hãy chuyển sang dùng ss thay vì netstat.\n","date":"2025-11-30T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/netstat/","title":"Netstat - Công cụ giám sát Networking"},{"content":" Bước 1: Backup Database tại Server cũ Sử dụng pg_dump\n1 docker exec -t my_postgres_container pg_dumpall -c -U postgres \u0026gt; ~/backup/my_db_backup.sql pg_dumpall: Lệnh backup toàn bộ các database có trong đó.\n-c: Thêm lệnh DROP DATABASE trước khi tạo lại (giúp làm sạch khi restore).\n-U postgres: Dùng user postgres để thực hiện.\nBước 2: Di chuyển my_db_backup.sql sang Server mới Có thể kéo trực tiếp từ server cũ sang server mới hoặc kéo về máy cá nhân sau đó đẩy lên server mới\nBước 3: Restore tại Server mới 1 cat my_db_backup.sql | doker exec -i my_postgres_container -U postgres -d my_db ","date":"2025-11-21T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/how-to-backup-postgres-database-in-docker-container/","title":"Hướng dẫn backup database postgres trong container và sử dụng trong server mới"},{"content":"Hướng dẫn xây dựng mô hình Nginx làm Reverse Proxy kết hợp với Certbot theo mô hình Sidecar (hoặc chạy định kỳ) để quản lý SSL.\nDưới đây là hướng dẫn triển khai theo chuẩn Infrastructure as Code (IaC). Toàn bộ cấu hình nằm trong file, có thể đẩy lên Git.\nKiến trúc Chúng ta sẽ có 1 file docker-compose.yml quản lý Gateway, bao gồm:\nService Nginx: Chịu trách nhiệm routing và hứng traffic (Port 80/443).\nService Certbot: Chịu trách nhiệm xin và gia hạn SSL.\nShared Volumes: Để Nginx và Certbot cùng đọc/ghi được file chứng chỉ.\nCác bước cấu hình Bước 1: Chuẩn bị cấu trúc thư mục Tạo một thư mục quản lý Gateway riêng biệt (để tách biệt với code ứng dụng).\n1 2 mkdir -p ~/nginx-gateway/{conf.d,certbot/conf,certbot/www} cd ~/nginx-gateway conf.d: Chứa file config của các domain (Virtual Hosts).\ncertbot/conf: Nơi lưu chứng chỉ SSL thật.\ncertbot/www: Nơi lưu file xác thực (ACME Challenge) để Let\u0026rsquo;s Encrypt kiểm tra.\nCác folders và file này là để ánh xạ vào volumes của nginx container\nBước 2: Tạo file Docker Compose Tạo file compose.yml:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 services: nginx: image: nginx:alpine container_name: nginx-gateway restart: unless-stopped ports: - \u0026#34;80:80\u0026#34; - \u0026#34;443:443\u0026#34; volumes: - ./conf.d:/etc/nginx/conf.d - ./certbot/conf:/etc/letsencrypt - ./certbot/www:/var/www/certbot command: \u0026#34;/bin/sh -c \u0026#39;while :; do sleep 6h \u0026amp; wait $${!}; nginx -s reload; done \u0026amp; nginx -g \\\u0026#34;daemon off;\\\u0026#34;\u0026#39;\u0026#34; certbot: image: certbot/certbot container_name: certbot volumes: - ./certbot/conf:/etc/letsencrypt - ./certbot/www:/var/www/certbot entrypoint: \u0026#34;/bin/sh -c \u0026#39;trap exit TERM; while :; do certbot renew; sleep 12h \u0026amp; wait $${!}; done;\u0026#39;\u0026#34; networks: default: name: nginx-network external: true Nginx Command: Đoạn script nhỏ giúp Nginx tự động reload config mỗi 6 tiếng để cập nhật SSL mới (nếu có) mà không cần restart container (Zero Downtime).\nCertbot Entrypoint: Chạy vòng lặp kiểm tra gia hạn SSL mỗi 12 tiếng.\nNetwork: Sử dụng nginx-network để kết nối với các container ứng dụng khác.\nBước 3: Config Nginx (Vấn đề \u0026ldquo;Con gà - Quả trứng\u0026rdquo;) Đây là điểm khó chịu nhất khi làm thủ công: Nginx cần file SSL để khởi động, nhưng chưa có SSL thì Nginx không chạy để Certbot xin SSL được.\nGiải pháp: Chúng ta config 2 giai đoạn.\nGiai đoạn 1: Config HTTP để xin SSL\nTạo file config cho domain của bạn: nano conf.d/domain.com.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 server { listen 80; server_name domain.com www.domain.com; # Cho phép Certbot truy cập thư mục này để xác thực location /.well-known/acme-challenge/ { root /var/www/certbot; } location / { return 301 https://$host$request_uri; # Redirect tạm, nhưng chưa có HTTPS thì cứ để đó } } Run Nginx:\n1 docker compose up -d nginx Giai đoạn 2: Xin SSL bằng Certbot\nChạy lệnh này một lần duy nhất để lấy chứng chỉ:\n1 docker compose run --rm --entrypoint certbot certonly --webroot --webroot-path /var/www/certbot -d domain.com -d www.domain.com Nếu thành công, nó sẽ báo \u0026ldquo;Successfully received certificate\u0026rdquo;.\nGiai đoạn 3: Config HTTPS hoàn chỉnh (Production)\nBây giờ đã có file SSL trong thư mục ./certbot/conf, bạn sửa lại file conf.d/domain.com.conf để cấu hình đầy đủ:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 server { listen 80; server_name domain.com www.domain.com; location /.well-known/acme-challenge/ { root /var/www/certbot; } location / { return 301 https://$host$request_uri; } } server { listen 443 ssl; server_name domain.com www.domain.com; # Đường dẫn này được map từ volume docker ssl_certificate /etc/letsencrypt/live/domain.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/domain.com/privkey.pem; # Best Practice SSL Params (Optional but recommended) ssl_protocols TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; location / { # Proxy pass vào tên container của App (trong cùng network) proxy_pass http://my-website-container:80; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } Cuối cùng, reload Nginx để nhận config mới:\n1 docker compose exec nginx nginx -s reload Bước 4: Quy trình vận hành (Workflow) Từ giờ, khi bạn muốn thêm một domain mới (ví dụ: api.domain.com), quy trình là:\nTạo file config: Tạo conf.d/api.domain.com.conf (chỉ có block port 80).\nReload Nginx: docker compose exec nginx nginx -s reload.\nXin SSL: Chạy lệnh docker compose run --rm certbot ....\nUpdate config: Thêm block port 443 vào file config.\nReload Nginx: Lần cuối.\nLưu ý 1 docker compose run --rm --entrypoint certbot certonly --webroot --webroot-path /var/www/certbot -d domain.com -d www.domain.com Sau khi run command Xin SSL bằng Certbot, hãy lưu ý các điều này để tránh xảy ra các lỗi thường gặp\nTắt Cloudflare Proxy (Đám mây màu cam) nếu đang sử dụng Cloudflare để trỏ tên miền tới server\nKiểm tra Tường lửa (Firewall)\nKiểm tra ufw đã mở port 80/tcp và 443/tcp chưa\n1 sudo ufw status Nếu chưa, chạy command sau để mở port:\n1 2 3 sudo ufw allow 80/tcp sudo ufw allow 443/tcp sudo ufw reload Kiểm tra tình trạng của Nginx Container\nChú ý cú pháp các file trong ./conf.d\n","date":"2025-11-21T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/how-to-config-nginx-use-docker/","title":"Hướng dẫn cấu hình Nginx làm Reverse Proxy kết hợp Certbot thông qua Docker"},{"content":" 1. Tạo user thường + tắt SSH root 1 2 adduser nagih usermod -aG sudo nagih Copy SSH key:\n1 2 rsync -av /root/.ssh /home/nagih/ chown -R nagih:nagih /home/nagih/.ssh Disable SSH root:\n1 sudo nano /etc/ssh/sshd_config Sửa:\n1 2 PermitRootLogin no PasswordAuthentication no # nếu bạn dùng SSH key Reload:\n1 sudo systemctl reload sshd 2. Đặt hostname, timezone, locale đúng Log hợp lệ để debug. Script không phát điên khi timezone sai.\n1 2 sudo hostnamectl set-hostname server-01 sudo timedatectl set-timezone Asia/Ho_Chi_Minh 3. Cập nhật hệ thống + bật auto security updates 1 sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y Bật auto security patch:\n1 2 sudo apt install unattended-upgrades -y sudo dpkg-reconfigure unattended-upgrades 4. Firewall: UFW/NFTABLES Ngăn dịch vụ lạ bị expose.\nUFW cách đơn giản:\n1 2 3 4 5 6 7 8 sudo ufw default deny incoming sudo ufw default allow outgoing sudo ufw allow 22/tcp sudo ufw allow 80/tcp sudo ufw allow 443/tcp sudo ufw enable Nếu bạn DevOps hardcore, dùng nftables hoặc firewalld.\n5. Fail2ban chống brute force 1 sudo apt install fail2ban -y Tạo cấu hình:\n1 sudo nano /etc/fail2ban/jail.local Ví dụ:\n1 2 3 4 [sshd] enabled = true maxretry = 5 bantime = 1h Restart:\n1 sudo systemctl restart fail2ban 6. SSH hardening nâng cao Trong /etc/ssh/sshd_config thêm:\n1 2 3 4 5 6 7 Protocol 2 X11Forwarding no AllowAgentForwarding no AllowTcpForwarding no ClientAliveInterval 300 ClientAliveCountMax 2 PasswordAuthentication no Nếu bạn muốn whitelist user:\n1 AllowUsers nagih deploy 7.Giới hạn sudo để tránh phá server Rất nên có /etc/sudoers.d/99-safe:\n1 2 nagih ALL=(ALL) NOPASSWD: /usr/bin/systemctl, /usr/bin/journalctl, /usr/bin/docker nagih ALL=(ALL) !/bin/rm -rf / Tuỳ nhu cầu.\n8. Swap (nếu server ít RAM) 1 2 3 4 sudo fallocate -l 2G /swapfile sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile Thêm vào /etc/fstab:\n1 /swapfile swap swap defaults 0 0 9. Ứng dụng logs chuẩn hóa journalctl -u service\nLogrotate cho file log custom\nĐồng bộ giờ với NTP\nCài chrony:\n1 sudo apt install chrony -y 10. Disable dịch vụ không cần Giảm attack surface:\n1 2 3 4 systemctl list-unit-files --type=service sudo systemctl disable --now bluetooth.service sudo systemctl disable --now cups.service sudo systemctl disable --now avahi-daemon.service 11. Bật AppArmor hoặc SELinux (nếu dùng Ubuntu hoặc CentOS) Ubuntu:\n1 sudo aa-status CentOS:\n1 sestatus 12. Cấu hình phân quyền file Không cho world-writable file\nCheck SUID/SGID\n1 sudo find / -perm /6000 -type f 2\u0026gt;/dev/null Nếu không hiểu file nào → mình đọc giúp.\n13. Cài monitoring tối thiểu Prometheus Node Exporter:\n1 sudo useradd -rs /bin/false node_exporter Cài binary → systemd → kết nối Grafana.\nCòn không thì dùng Netdata cho nhanh.\n14. Cấu hình backups Tối thiểu:\nbackup /etc\nbackup database\nsnapshot volume (nếu cloud)\nscript cron: rsync → S3/Backblaze\n15. Nếu chạy Docker Hardening Docker:\n1 2 sudo usermod -aG docker nagih sudo systemctl enable docker Cấu hình daemon:\n/etc/docker/daemon.json:\n1 2 3 4 5 6 7 { \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;10m\u0026#34;, \u0026#34;max-file\u0026#34;: \u0026#34;3\u0026#34; } } Cài compose plugin:\n1 sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 16. Nếu chạy web service Reverse proxy: Nginx / Caddy\nHSTS\nCertbot hoặc Traefik cert auto\nRate-limit\n17. Tắt IPv6 nếu không dùng 1 sudo nano /etc/sysctl.conf Thêm:\n1 2 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 1 sudo sysctl -p 18. Kiểm thử security tổng quan 1 ss -tulpn Đảm bảo chỉ có:\n22 80 443 Kiểm tra SSH:\n1 ssh -v yourserver Test brute-force protection:\n1 fail2ban-client status sshd 19. Automation lại toàn bộ Dùng:\nAnsible\nTerraform + cloud-init\nbash script\nSản xuất không ai setup tay hoài được.\n20. Viết tài liệu 1 trang về server OS version\nDịch vụ đang chạy\nUser có quyền sudo\nPort mở\nBackup location\nCách restart service\nSSH key location\nCực hữu ích khi giao server cho team khác.\nBunus: Scripts tự động setup cơ bản SERVER-BASELINE.SH\n1 sudo bash server-baseline.sh server-baseline.sh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 #!/bin/bash set -e USERNAME=\u0026#34;nagih\u0026#34; PUBKEY=\u0026#34;ssh-ed25519 AAAA...YOUR_KEY_HERE\u0026#34; echo \u0026#34;[1/10] Creating user...\u0026#34; if ! id \u0026#34;$USERNAME\u0026#34; \u0026gt;/dev/null 2\u0026gt;\u0026amp;1; then adduser --disabled-password --gecos \u0026#34;\u0026#34; \u0026#34;$USERNAME\u0026#34; usermod -aG sudo \u0026#34;$USERNAME\u0026#34; else echo \u0026#34;User already exists, skipping.\u0026#34; fi echo \u0026#34;[2/10] Installing SSH key...\u0026#34; mkdir -p /home/$USERNAME/.ssh echo \u0026#34;$PUBKEY\u0026#34; \u0026gt; /home/$USERNAME/.ssh/authorized_keys chmod 700 /home/$USERNAME/.ssh chmod 600 /home/$USERNAME/.ssh/authorized_keys chown -R $USERNAME:$USERNAME /home/$USERNAME/.ssh echo \u0026#34;[3/10] SSH Hardening...\u0026#34; SSHCONF=\u0026#34;/etc/ssh/sshd_config\u0026#34; sed -i \u0026#39;s/#\\?PasswordAuthentication .*/PasswordAuthentication no/\u0026#39; $SSHCONF sed -i \u0026#39;s/#\\?PermitRootLogin .*/PermitRootLogin no/\u0026#39; $SSHCONF sed -i \u0026#39;s/#\\?X11Forwarding .*/X11Forwarding no/\u0026#39; $SSHCONF sed -i \u0026#39;s/#\\?AllowAgentForwarding .*/AllowAgentForwarding no/\u0026#39; $SSHCONF sed -i \u0026#39;s/#\\?AllowTcpForwarding .*/AllowTcpForwarding no/\u0026#39; $SSHCONF # Thêm AllowUsers nếu chưa có if ! grep -q \u0026#34;AllowUsers\u0026#34; $SSHCONF; then echo \u0026#34;AllowUsers $USERNAME\u0026#34; \u0026gt;\u0026gt; $SSHCONF fi systemctl reload sshd echo \u0026#34;[4/10] Updating system...\u0026#34; apt update \u0026amp;\u0026amp; apt upgrade -y echo \u0026#34;[5/10] Installing essential tools...\u0026#34; apt install -y unattended-upgrades fail2ban ufw htop curl echo \u0026#34;[6/10] Enabling auto security updates...\u0026#34; dpkg-reconfigure --priority=low unattended-upgrades echo \u0026#34;[7/10] Configuring UFW firewall...\u0026#34; ufw default deny incoming ufw default allow outgoing ufw allow 22/tcp ufw allow 80/tcp ufw allow 443/tcp ufw --force enable echo \u0026#34;[8/10] Configuring Fail2ban...\u0026#34; cat \u0026gt;/etc/fail2ban/jail.local \u0026lt;\u0026lt;EOF [sshd] enabled = true maxretry = 5 bantime = 1h EOF systemctl restart fail2ban echo \u0026#34;[9/10] Setting timezone to Asia/Ho_Chi_Minh...\u0026#34; timedatectl set-timezone Asia/Ho_Chi_Minh echo \u0026#34;[10/10] Cleaning up...\u0026#34; apt autoremove -y echo echo \u0026#34;======================================\u0026#34; echo \u0026#34; Baseline complete!\u0026#34; echo \u0026#34; Login using: ssh $USERNAME@your-server\u0026#34; echo \u0026#34;======================================\u0026#34; Thay SSH key\nTrong script:\n1 PUBKEY=\u0026#34;ssh-ed25519 AAAA...YOUR_KEY_HERE\u0026#34; Dán public key của bạn vào.\nLưu file, chạy:\n1 2 chmod +x server-baseline.sh sudo ./server-baseline.sh ","date":"2025-11-14T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/server-hardening-checklist/","title":"Những điều cần làm ngay sau khi sở hữu 1 server Linux (VPS, Cloud)"},{"content":" 1. User management command useradd Tạo user mới.\n1 2 sudo useradd nagih sudo useradd -m -s /bin/bash nagih -m tạo home -s set shell. adduser (wrapper dễ dùng hơn) Ubuntu thường dùng cái này.\n1 sudo adduser nagih userdel Xoá user.\n1 2 sudo userdel nagih sudo userdel -r nagih # xoá cả home usermod Sửa thông tin user.\n1 2 3 4 5 6 7 8 # thêm user vào group sudo usermod -aG docker nagih # đổi shell sudo usermod -s /bin/zsh nagih # đổi home directory sudo usermod -d /new/home nagih passwd Đổi mật khẩu user.\n1 2 3 4 5 6 7 sudo passwd nagih # lock password sudo passwd -l nagih # unlock sudo passwd -u nagih chage Quản lý tuổi mật khẩu (password aging).\n1 2 sudo chage -l nagih sudo chage -E 2025-01-01 nagih id Xem UID/GID của user.\n1 id nagih whoami Xem user hiện tại.\n1 whoami last / lastlog Xem lịch sử login.\n1 2 last lastlog su Switch user.\n1 su - nagih loginctl Nếu dùng systemd – quản lý session của user.\n1 2 loginctl list-sessions loginctl show-user nagih 2. Group management command groupadd Tạo group.\n1 2 sudo groupadd devops sudo groupadd -g 1500 customgroup -g GID flag (Group ID) groupdel Xoá group.\n1 sudo groupdel devops groupmod Sửa group.\n1 2 sudo groupmod -n newname oldname sudo groupmod -g 1600 devops -n change group name -g GID gpasswd Quản lý member của group.\n1 2 sudo gpasswd -a nagih docker sudo gpasswd -d nagih docker -a add member to group -d delete member from group newgrp Switch group tạm thời.\n1 newgrp docker Tạo một shell mới.\nShell này dùng docker như nhóm chính (effective GID).\nCác quyền file và lệnh yêu cầu group docker hoạt động ngay lập tức.\nKhi bạn exit, bạn quay lại shell cũ (vẫn chưa có quyền).\n3. Important user related files Không phải command nhưng bạn luôn gặp:\n1 2 3 4 5 6 7 8 9 10 11 # danh sách user /etc/passwd # danh sách group /etc/group # mật khẩu (hash) /etc/shadow # quyền sudo /etc/sudoers Xem file:\n1 2 3 cat /etc/passwd cat /etc/group sudo visudo 4. Tool to check what user is running who / w Ai đang đăng nhập.\n1 2 who w finger (nếu cài) Thông tin user.\n1 finger nagih 5. Permission control tool chown Đổi chủ sở hữu file.\n1 sudo chown nagih:devops file.txt chmod Đổi permission.\n1 chmod 755 script.sh 6. Bonus: command DevOps thường dùng liên quan user trong container useradd trong Dockerfile 1 2 RUN groupadd -g 1000 app \u0026amp;\u0026amp; useradd -u 1000 -g app -m app USER app id trong container 1 docker exec app id ","date":"2025-11-14T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/management-command/","title":"Tất cả các commands quản lý quan trọng trên linux"},{"content":"bridged network là phương pháp chuyên nghiệp và linh hoạt nhất cho máy chủ ảo, vì nó cho phép máy ảo của bạn hoạt động như một thiết bị vật lý thực thụ trên mạng của bạn.\nTổng quan Workflow Chuẩn bị (Trên máy Host): Thu thập thông tin mạng và chọn IP tĩnh cho máy ảo. Cấu hình Mạng Host (Trên máy Host): Tạo một \u0026ldquo;cầu nối mạng\u0026rdquo; (hình) để kết nối card mạng vật lý với máy ảo. Cấu hình Máy ảo (Trên máy Host): Cấu hình sử dụng network bridge vừa tạo. Cấu hình IP Tĩnh (Trong máy ảo Guest): Truy cập vào máy ảo và thiết lập IP tĩnh bằng netplan. Kiểm tra và Hoàn tất. Bước 1: Chuẩn bị (Trên máy Host) Tìm tên card mạng vật lý và Gateway:\n1 2 ip addr # Tìm tên card mạng, vd: eno1, eth0, wlp3s0 ip route # Tìm địa chỉ Default Gateway Giả sử card mạng vật lý của bạn là eno1 và Gateway là 192.168.0.1.\nChọn IP tĩnh cho máy ảo:\nDựa vào Gateway 192.168.0.1, bạn biết mạng của mình là 192.168.0.x.\nKiểm tra dải DHCP trên router của bạn (ví dụ: 192.168.0.100 - 192.168.0.199).\nChọn một IP nằm ngoài dải DHCP đó để tránh xung đột. Ví dụ: 192.168.0.55.\nKiểm tra xem IP này có đang được sử dụng không: ping -c 3 192.168.0.55. Nếu không có phản hồi là tốt.\nTổng hợp thông tin:\nThông tin Giá trị ví dụ Ghi chú Tên card mạng vật lý eno1 Ghi lại tên thật của bạn Địa chỉ IP tĩnh (cho VM) 192.168.0.55 IP bạn vừa chọn Gateway 192.168.0.1 Địa chỉ router của bạn Netmask / CIDR 255.255.255.0 / 24 Ghi 24 là đủ DNS Servers 1.1.1.1, 1.0.0.1 Dùng DNS bạn muốn Bước 2: Cấu hình Cầu nối Mạng trên Host (nmcli) Tạo một cầu nối ảo tên br0:\n1 sudo nmcli con add type bridge con-name br0 ifname br0 Cấu hình IP cho cầu nối br0: Cầu nối này sẽ \u0026ldquo;tiếp quản\u0026rdquo; địa chỉ IP của máy Host.\n1 2 3 # Lấy IP hiện tại của máy host, vd: 192.168.0.40 # Bạn có thể giữ IP động hoặc đặt IP tĩnh cho máy host, ở đây ta đặt tĩnh cho ổn định sudo nmcli con mod br0 ipv4.addresses 192.168.0.40/24 ipv4.gateway 192.168.0.1 ipv4.dns \u0026#34;1.1.1.1,1.0.0.1\u0026#34; ipv4.method manual Gán card mạng vật lý eno1 vào cầu nối br0\n1 2 # Thay \u0026#39;eno1\u0026#39; bằng tên card mạng thật của bạn sudo nmcli con add type bridge-slave con-name br0-slave ifname eno1 master br0 Kích hoạt cầu nối:\n1 2 3 4 5 # Tắt kết nối cũ của card vật lý (nếu đang hoạt động) sudo nmcli con down eno1 # Kích hoạt cầu nối sudo nmcli con up br0 Lưu ý: Bạn có thể bị mất kết nối mạng trong giây lát. Sau bước này, máy host của bạn sẽ truy cập mạng thông qua br0.\nKiểm tra lại: Chạy ip addr. Bạn sẽ thấy br0 có địa chỉ IP, và eno1 không có IP nhưng có trạng thái master br0.\nBước 3: Cấu hình Máy ảo sử dụng Cầu nối Bây giờ, hãy chỉ cho máy ảo của bạn sử dụng br0.\nCách 1: Dùng virt-manager (GUI):\nTắt máy ảo.\nMở virt-manager, chọn máy ảo và vào phần Details (Biểu tượng bóng đèn).\nChọn mục \u0026ldquo;NIC\u0026rdquo; (Network Interface Controller).\nTrong phần \u0026ldquo;Network source\u0026rdquo;, chọn \u0026ldquo;Bridge device\u0026rdquo;.\nTrong ô \u0026ldquo;Device name\u0026rdquo;, nhập br0.\nLưu lại.\nCách 2: Dùng virsh (Dòng lệnh):\nTắt máy ảo: virsh shutdown ten_may_ao\nMở file cấu hình XML của máy ảo: virsh edit ten_may_ao\nTìm đến phần \u0026lt;interface\u0026gt;. Nó sẽ trông giống như thế này:\n1 2 3 4 \u0026lt;interface type=\u0026#39;network\u0026#39;\u0026gt; \u0026lt;source network=\u0026#39;default\u0026#39;/\u0026gt; ... \u0026lt;/interface\u0026gt; Sửa nó thành:\n1 2 3 4 5 \u0026lt;interface type=\u0026#39;bridge\u0026#39;\u0026gt; \u0026lt;source bridge=\u0026#39;br0\u0026#39;/\u0026gt; \u0026lt;model type=\u0026#39;virtio\u0026#39;/\u0026gt; \u0026lt;!-- Giữ nguyên model type nếu có --\u0026gt; ... \u0026lt;/interface\u0026gt; Lưu và thoát.\nBước 4: Cấu hình IP Tĩnh trong Máy ảo (Netplan) Khởi động máy ảo của bạn và đăng nhập.\nTìm tên file cấu hình netplan trong /etc/netplan/ (ví dụ: 00-installer-config.yaml).\nMở file đó để chỉnh sửa: sudo nano /etc/netplan/00-installer-config.yaml.\nXóa nội dung cũ và thay bằng cấu hình sau (sử dụng thông tin bạn đã chuẩn bị ở Bước 1). Cẩn thận với thụt đầu dòng!\n1 2 3 4 5 6 7 8 9 10 network: ethernets: ens3: # \u0026lt;-- Thay bằng tên card mạng trong máy ảo (dùng \u0026#39;ip a\u0026#39; để xem) dhcp4: no addresses: - 192.168.0.55/24 # \u0026lt;-- IP tĩnh bạn đã chọn gateway4: 192.168.0.1 nameservers: addresses: [1.1.1.1, 1.0.0.1] version: 2 Lưu file (Ctrl + X, Y, Enter).\nÁp dụng cấu hình: sudo netplan apply.\nBước 5: Kiểm tra và Hoàn tất Trong máy ảo:\nip a: Kiểm tra xem máy ảo đã nhận đúng IP 192.168.0.55 chưa.\nping 192.168.0.1: Ping tới gateway.\nping google.com: Ping ra Internet để kiểm tra DNS.\nTrên máy Host (hoặc một máy tính khác cùng mạng):\nping 192.168.0.55: Ping tới địa chỉ IP mới của máy ảo. Nếu tất cả các bước ping đều thành công, bạn đã hoàn tất! Máy ảo của bạn giờ đây đã là một thành viên chính thức trên mạng LAN với một địa chỉ IP tĩnh đáng tin cậy.\n","date":"2025-11-10T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/setup-bridge-network/","title":"Hướng dẫn thiết lập Network Bridge giữa máy Host và máy ảo"},{"content":"Việc lệnh docker stats không hiển thị thông tin về bộ nhớ (MEM USAGE / LIMIT) cho các container là một sự cố khá phổ biến. Nguyên nhân chính thường liên quan đến tính năng theo dõi bộ nhớ của cgroups chưa được kích hoạt.\nViệc lệnh docker stats không hiển thị thông tin về bộ nhớ (MEM USAGE / LIMIT) cho các container là một sự cố khá phổ biến. Nguyên nhân chính thường liên quan đến tính năng theo dõi bộ nhớ của cgroups chưa được kích hoạt.\nBước 1: Kiểm tra cấu hình Docker 1 docker info Nếu tính năng này bị thiếu, bạn có thể sẽ thấy các cảnh báo ở cuối kết quả, tương tự như sau:\nWARNING: No memory limit support\nWARNING: No swap limit support\nBước 2: Kích hoạt Memory Cgroup cho Kernel Mở file cmdline.txt\n1 sudo nano /boot/cmdline.txt Thêm các tham số cấu hình\n1 cgroup_enable=memory cgroup_memory=1 Lưu ý: Tệp cmdline.txt chứa tất cả các tham số trên một dòng duy nhất. Hãy chắc chắn rằng bạn chỉ thêm các tham số này vào cuối dòng đó, cách nhau bởi dấu cách.\nLưu và khởi động lại\n1 sudo reboot ","date":"2025-11-02T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/fix-error-docker-stats/","title":"Hướng dẫn sửa lỗi Docker Stats không hiển thị mức sử dụng memory"},{"content":"Thiết lập Cloudflare Tunnel là một bước nâng cao cực kỳ mạnh mẽ cho server của bạn. Nó giúp bạn phơi bày (expose) các dịch vụ đang chạy trên server ra internet một cách an toàn mà không cần mở bất kỳ cổng nào trên Firewall.\nMục tiêu: Chạy một ứng dụng web trên server (ví dụ: localhost:3000).\nTạo một Tunnel để kết nối server với Cloudflare.\nTruy cập ứng dụng web đó qua một tên miền phụ (ví dụ: app.yourdomain.com) với HTTPS mà không cần mở cổng 80/443 trên server.\nPhase 0: Điều Kiện Cần Có Tài khoản Cloudflare: Hoàn toàn miễn phí.\nTên miền đã thêm vào Cloudflare: Bạn phải quản lý DNS của tên miền đó thông qua Cloudflare.\nServer đã cài đặt: Một VPS hoặc máy chủ vật lý đang chạy (ví dụ: Ubuntu 22.04).\nMột dịch vụ đang chạy trên server: Ví dụ, một ứng dụng Node.js đang lắng nghe ở cổng 3000.\nPhase 1: Cài Đặt cloudflared trên Server SSH vào Server\nCài đặt Cloudflared\nXác định kiến trúc CPU\n1 uname -a Kết quả phổ biến sẽ là:\nx86_64 hoặc amd64: Hầu hết các máy chủ và máy tính để bàn hiện nay.\naarch64 hoặc arm64: Các máy chủ ARM, Raspberry Pi 4/5 (64-bit), máy Mac M1/M2.\narmv7l: Raspberry Pi cũ hơn (32-bit).\nTải file thực thi phù hợp từ GitHub của Cloudflare\n1 2 3 4 5 6 7 8 # x86_64 / AMD64 (64-bit) wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 # ARM64 / aarch64 (64-bit) wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-arm64 # ARM (32-bit) wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-arm Cài đặt file vừa tải\n1 2 3 4 5 6 7 8 9 # Đổi tên file cho gọn (thay amd64 bằng arm64 hoặc arm nếu cần) # Lưu ý: Tên file cùng với file vừa tải ở trên mv cloudflared-linux-amd64 cloudflared # Cấp quyền thực thi chmod +x cloudflared # Di chuyển vào thư mục bin của hệ thống sudo mv cloudflared /usr/local/bin/ Kiểm tra cài đặt\n1 cloudflared --version Phase 2: Xác Thực cloudflared với Tài Khoản Cloudflare Bước này sẽ liên kết daemon cloudflared trên server của bạn với tài khoản Cloudflare.\nChạy lệnh đăng nhập:\n1 cloudflared tunnel login Thực hiện xác thực:\nLệnh trên sẽ in ra một đường link URL trong terminal.\nCopy và Paste vào trình duyệt trên máy tính cá nhân của bạn.\nĐăng nhập vào tài khoản Cloudflare của bạn.\nChọn tên miền bạn muốn sử dụng cho Tunnel.\nNhấn Authorize.\nXác nhận thành công:\nSau khi xác thực thành công trên trình duyệt, cloudflared trên server của bạn sẽ tự động tải về một file chứng chỉ (cert.pem) và lưu nó vào thư mục ~/.cloudflared/. File này chính là Key để server của bạn giao tiếp với Cloudflare. Phase 3: Cấu Hình Tunnel Giờ là bước quan trọng nhất: tạo một Tunnel có tên và định nghĩa cách nó sẽ định tuyến lưu lượng truy cập.\nTạo một Tunnel có tên:\nHãy chọn một cái tên dễ nhớ cho tunnel của bạn (ví dụ: main-tunnel).\n1 cloudflared tunnel create main-tunnel Lệnh này sẽ đăng ký tunnel với Cloudflare và trả về một UUID (một chuỗi ID duy nhất) cho tunnel đó. Nó cũng sẽ tạo một file credentials (\u0026lt;UUID\u0026gt;.json) trong thư mục ~/.cloudflared/. Hãy lưu lại UUID này.\nTạo file cấu hình:\ncloudflared sử dụng một file config.yml để biết cách định tuyến các yêu cầu.\n1 vi ~/.cloudflared/config.yml Dán nội dung sau vào file. Hãy thay thế UUID bằng UUID bạn nhận được ở bước trên.\n1 2 3 4 5 6 7 8 9 10 11 12 13 # UUID của tunnel bạn vừa tạo tunnel: 8e34e9a6-0935-4563-87c1-652a5d7a825a # Đường dẫn đến file credentials credentials-file: /home/your_username/.cloudflared/8e34e9a6-0935-4563-87c1-652a5d7a825a.json # Cấu hình định tuyến (ingress rules) ingress: # Quy tắc 1: Gửi traffic từ app.yourdomain.com đến dịch vụ ở localhost:3000 - hostname: app.yourdomain.com service: http://localhost:3000 # Quy tắc cuối cùng: Bắt buộc phải có. # Nó sẽ trả về lỗi 404 cho bất kỳ request nào không khớp với các quy tắc trên. - service: http_status:404 Thay your_username bằng tên người dùng của bạn trên server.\nThay app.yourdomain.com bằng tên miền phụ bạn muốn sử dụng.\nThay http://localhost:3000 bằng địa chỉ và cổng của dịch vụ bạn muốn phơi bày.\nPhase 4: Định Tuyến DNS Chạy lệnh định tuyến DNS:\n1 cloudflared tunnel route dns my-web-app app.yourdomain.com Lệnh này sẽ tự động tạo một bản ghi CNAME trong phần quản lý DNS của bạn trên Cloudflare, trỏ tên miền phụ của bạn vào tunnel.\nPhase 5: Chạy Tunnel như một Dịch Vụ (Service) Để tunnel luôn chạy kể cả khi bạn đóng cửa sổ SSH hoặc khởi động lại server, bạn cần cài đặt nó như một dịch vụ hệ thống (systemd).\nDi chuyển file cấu hình và credentials đến vị trí hệ thống:\nDịch vụ systemd sẽ tìm file cấu hình ở /etc/cloudflared/, không phải trong thư mục home của bạn.\n1 2 3 4 5 6 7 8 # Tạo thư mục cấu hình sudo mkdir /etc/cloudflared # Sao chép file config và đổi tên thành config.yml sudo cp ~/.cloudflared/config.yml /etc/cloudflared/config.yml # Sao chép file credentials sudo cp ~/.cloudflared/\u0026lt;UUID\u0026gt;.json /etc/cloudflared/ Lưu ý: Bạn cần sửa lại đường dẫn credentials-file trong /etc/cloudflared/config.yml để trỏ đến vị trí mới: /etc/cloudflared/\u0026lt;UUID\u0026gt;.json.\n1 2 sudo nano /etc/cloudflared/config.yml # Sửa dòng credentials-file thành: credentials-file: /etc/cloudflared/8e34e9a6-0935-4563-87c1-652a5d7a825a.json Cài đặt và khởi chạy dịch vụ:\n1 2 3 4 5 6 7 8 # Cài đặt dịch vụ systemd sudo cloudflared service install # Khởi động dịch vụ sudo systemctl start cloudflared # (Tùy chọn) Kiểm tra trạng thái dịch vụ sudo systemctl status cloudflared Nếu bước này xảy ra lỗi, bạn cần kiểm tra xem có tồn tại user cloudflared hay không, nếu có hãy cấp quyền cho cloudflared. Nếu không có hãy tạo mới user cloudflared và cấp quyền.\n1 2 3 4 5 6 7 8 9 10 11 # Kiểm tra có tồn tại user cloudflared không id cloudflared # Nếu không có user cloudflared sudo useradd -r -M -s /usr/sbin/nologin cloudflared # Phân quyền sở hữu sudo chown -R cloudflared:cloudflared /etc/cloudflared sudo chmod 640 /etc/cloudflared/* # Hãy quay lại Bước 2: Cài đặt và khởi tạo dịch vụ Xong! Bây giờ, hãy thử truy cập https://app.yourdomain.com trên trình duyệt. Bạn sẽ thấy ứng dụng của mình đang chạy, được bảo vệ bởi Cloudflare với HTTPS, trong khi server của bạn không hề mở bất kỳ cổng nào ra ngoài internet.\nTích Hợp với Docker và Docker Compose Nếu bạn đang dùng Docker, việc chạy cloudflared trong một container riêng là cách làm khá Ok.\nBạn có thể thêm một service cloudflared vào file docker-compose.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 services: web-app: build: . # ... các cấu hình khác của bạn networks: - app-network cloudflared: image: cloudflare/cloudflared:latest restart: unless-stopped command: tunnel --no-autoupdate run --token \u0026lt;YOUR_TUNNEL_TOKEN\u0026gt; depends_on: - web-app networks: - app-network networks: app-network: driver: bridge Trong trường hợp này, bạn sẽ lấy Token của Tunnel từ trang quản trị Cloudflare Zero Trust thay vì dùng file cert.pem và credentials.json.\nTrong trang quản trị Cloudflare, bạn sẽ cấu hình Public Hostname (app.yourdomain.com) để trỏ đến service bên trong mạng Docker (ví dụ: http://web-app:3000).\nps: Cách làm này phù hợp với quy trình tự động hóa và IaC (Infrastructure as Code)\n","date":"2025-10-19T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/cloudflared-tunnel-workflow/","title":"Hướng dẫn setup cloudflared tunnel cơ bản"},{"content":"Kỹ thuật backup database định kỳ là một kỹ năng cực kỳ quan trọng đối với bất kỳ ai làm DevOps. Một chiến lược backup tốt sẽ giúp bạn cứu sống cả hệ thống khi có sự cố.\nI. Các Nguyên Tắc Vàng 1. RPO \u0026amp; RTO RPO (Recovery Point Objective): Lượng dữ liệu tối đa chấp nhận mất. RTO là 1h có nghĩa là nếu hệ thống sập, bạn có thể khôi phục trạng thái của nó cách đây 1h. Hay có thể được gọi là Tần suất backup\nRTO (Recovery Time Objective): Thời gian tối đa để hệ thống hoạt động trở lại sau sự cố. Quyết định Tốc độ và Mức độ tự động hóa\n2. Backup Types Full Backup: Sao lưu toàn bộ database. Đơn giản để khôi phục nhưng tốn tài nguyên và thời gian\nDifferential Backup: Backup những gì thay đổi của lần Full Backup cuối cùng\nIncremential Backup: Backup những gì thay đổi từ lần backup gần nhất. Tốc độ nhất nhưng cũng phức tạp nhất\n3. Quy Tắc 3-2-1 3 Bản copies: Luôn có 3 bản backup dữ liệu\n2 Loại Media: Lưu trữ trên ít nhất 2 thiết bị lưu trữ khác nhau\n1 Bản off-site: Giữ ít nhất 1 bản sao ở địa điểm vật lý khác\n4. Bảo mật và Mã hóa Luôn mã hóa file backup, cả khi đang truyền đi (in-transit) và khi đã lưu trữ (at-rest).\nQuản lý chặt chẽ quyền truy cập vào các file backup.\n5. Quan trọng nhất: KIỂM TRA RESTORE! Một bản backup chưa được kiểm tra khôi phục thành công thì không được coi là một bản backup.\nHãy lên lịch kiểm tra restore định kỳ (ví dụ: hàng quý) trên một môi trường staging để đảm bảo các file backup của bạn thực sự hoạt động.\nII. Kỹ Thuật 1. Cron Job \u0026amp; Shell Script Bước 1: Viết Shell Script backup (backup.sh)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #!/bin/bash # --- Cấu hình --- # Thông tin kết nối Database DB_USER=\u0026#34;your_db_user\u0026#34; DB_PASSWORD=\u0026#34;your_db_password\u0026#34; DB_HOST=\u0026#34;localhost\u0026#34; DB_NAME=\u0026#34;your_db_name\u0026#34; # Thư mục lưu trữ backup trên server BACKUP_DIR=\u0026#34;/path/to/your/backups\u0026#34; # --- Logic Backup --- # Tạo thư mục backup nếu chưa tồn tại mkdir -p ${BACKUP_DIR} # Tạo tên file backup với định dạng ngày-tháng-năm DATE=$(date +%Y-%m-%d_%H-%M-%S) FILE_NAME=\u0026#34;${DB_NAME}_${DATE}.sql.gz\u0026#34; BACKUP_FILE=\u0026#34;${BACKUP_DIR}/${FILE_NAME}\u0026#34; # Đặt biến môi trường để pg_dump không hỏi mật khẩu export PGPASSWORD=${DB_PASSWORD} # Thực hiện backup bằng pg_dump, nén bằng gzip và lưu vào file # -U: user, -h: host, -d: database name # | gzip \u0026gt; : pipe output của pg_dump vào gzip để nén echo \u0026#34;Dang bat dau backup database: ${DB_NAME}...\u0026#34; pg_dump -U ${DB_USER} -h ${DB_HOST} -d ${DB_NAME} | gzip \u0026gt; ${BACKUP_FILE} # Xóa biến môi trường PGPASSWORD để bảo mật unset PGPASSWORD # Kiểm tra xem backup có thành công không if [ $? -eq 0 ]; then echo \u0026#34;Backup thanh cong: ${BACKUP_FILE}\u0026#34; else echo \u0026#34;Backup that bai!\u0026#34; exit 1 fi # Xóa các file backup cũ hơn 7 ngày echo \u0026#34;Xoa cac file backup cu hon 7 ngay...\u0026#34; find ${BACKUP_DIR} -type f -name \u0026#34;*.sql.gz\u0026#34; -mtime +7 -delete echo \u0026#34;Hoan tat.\u0026#34; Bước 2: Cấp quyền thực thi cho script\n1 chmod +x backup.sh Bước 3: Lên lịch auto run với Cron\nMở crontab để chỉnh sửa\n1 crontab -e Thêm dòng sau vào cuối file để chạy script vào lúc 2 giờ sáng mỗi ngày\n1 2 # Chạy backup vào 2:00 AM hàng ngày 0 2 * * * /path/to/your/backup.sh \u0026gt;\u0026gt; /path/to/your/logs/backup.log 2\u0026gt;\u0026amp;1 0 2 * * * : Cú pháp cron cho \u0026ldquo;0 phút, 2 giờ, mỗi ngày, mỗi tháng, mỗi ngày trong tuần\u0026rdquo;.\n\u0026raquo; /path/to/your/logs/backup.log 2\u0026gt;\u0026amp;1: Ghi lại output (cả standard output và error) vào một file log để bạn có thể kiểm tra lại.\n2. Backup Database trong Docker Giả sử bạn có một container PostgreSQL đang chạy tên là my_postgres_container\nCách 1: Dùng docker exec và Cron trên máy Host\nScript backup_docker.sh sẽ được sửa lại một chút:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash # --- Cấu hình --- CONTAINER_NAME=\u0026#34;my_postgres_container\u0026#34; DB_USER=\u0026#34;your_db_user\u0026#34; DB_NAME=\u0026#34;your_db_name\u0026#34; BACKUP_DIR=\u0026#34;/path/on/host/to/backups\u0026#34; # Thư mục trên máy host # --- Logic Backup --- mkdir -p ${BACKUP_DIR} DATE=$(date +%Y-%m-%d_%H-%M-%S) FILE_NAME=\u0026#34;${DB_NAME}_${DATE}.sql.gz\u0026#34; BACKUP_FILE=\u0026#34;${BACKUP_DIR}/${FILE_NAME}\u0026#34; echo \u0026#34;Dang bat dau backup database từ container: ${CONTAINER_NAME}...\u0026#34; # Dùng \u0026#39;docker exec\u0026#39; để chạy pg_dump BÊN TRONG container # Output sẽ được chuyển ra máy host và nén lại docker exec ${CONTAINER_NAME} pg_dump -U ${DB_USER} -d ${DB_NAME} | gzip \u0026gt; ${BACKUP_FILE} # ...(Phần kiểm tra và xóa file cũ tương tự như script trước) ... # Xóa biến môi trường PGPASSWORD để bảo mật unset PGPASSWORD # Kiểm tra xem backup có thành công không if [ $? -eq 0 ]; then echo \u0026#34;Backup thanh cong: ${BACKUP_FILE}\u0026#34; else echo \u0026#34;Backup that bai!\u0026#34; exit 1 fi # Xóa các file backup cũ hơn 7 ngày echo \u0026#34;Xoa cac file backup cu hon 7 ngay...\u0026#34; find ${BACKUP_DIR} -type f -name \u0026#34;*.sql.gz\u0026#34; -mtime +7 -delete echo \u0026#34;Hoan tat.\u0026#34; Sau đó, bạn cũng dùng cron trên máy host để chạy script backup_docker.sh này.\nCách 2: Dùng một Sidecar Container\nĐây là một pattern nâng cao và rất phổ biến trong Kubernetes. Ý tưởng là bạn sẽ chạy một container riêng biệt chỉ để làm nhiệm vụ backup.\nTrong docker-compose.yml có thể định nghĩa một service backup:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 services: db: image: postgres:13 container_name: my_postgres_container environment: - POSTGRES_USER=your_db_user - POSTGRES_PASSWORD=your_db_password - POSTGRES_DB=your_db_name volumes: - postgres_data:/var/lib/postgresql/data # Service này không chạy liên tục, chỉ chạy khi được gọi backup: image: postgres:13 # Dùng cùng image để có sẵn pg_dump depends_on: - db volumes: - ./backups:/backups # Gắn thư mục backups của host vào container environment: - PGPASSWORD=your_db_password # Lệnh sẽ chạy khi container này được khởi động command: \u0026gt; bash -c \u0026#34; pg_dump -h db -U your_db_user -d your_db_name | gzip \u0026gt; /backups/backup_$(date +%Y-%m-%d_%H-%M-%S).sql.gz \u0026#34; volumes: postgres_data: Chạy backup\n1 docker-compose run --rm backup Bạn có thể kết hợp lệnh này với cron trên máy host để tự động hóa.\nIII. Tích hợp với Cloud (DevOps Workflow hoàn chỉnh) Một quy trình DevOps thực thụ sẽ không dừng lại ở việc lưu file backup trên cùng một server.\nWorkflow nâng cao:\nTạo file backup: Sử dụng một trong các kỹ thuật trên để tạo file .sql.gz.\nTải lên Cloud Storage: Dùng các công cụ command-line của nhà cung cấp cloud để đẩy file backup lên một nơi an toàn.\nAWS S3: aws s3 cp /path/to/backup.sql.gz s3://your-backup-bucket/\nGoogle Cloud Storage: gsutil cp /path/to/backup.sql.gz gs://your-backup-bucket/\nAzure Blob Storage: az storage blob upload \u0026ndash;file /path/to/backup.sql.gz \u0026ndash;container-name your-container \u0026ndash;name backup.sql.gz\nXóa file backup local: Sau khi đã tải lên cloud thành công, bạn có thể xóa file trên server để tiết kiệm dung lượng.\nThiết lập Lifecycle Rules: Cấu hình trên Cloud Storage để tự động xóa các bản backup cũ (ví dụ: chuyển sang lớp lưu trữ rẻ hơn sau 30 ngày và xóa hẳn sau 90 ngày).\nGiám sát và Cảnh báo (Monitoring \u0026amp; Alerting):\nSử dụng các công cụ như Prometheus, Healthchecks.io, hoặc đơn giản là gửi email/thông báo Slack khi script backup chạy thành công hoặc thất bại. Tự động hóa việc Restore: Viết script để tự động tải về bản backup mới nhất từ cloud và restore vào một môi trường staging. Chạy script này định kỳ (ví dụ: hàng tuần) để đảm bảo 100% rằng backup của bạn hoạt động.\nVí dụ script tích hợp AWS S3:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # ... (Phần tạo backup như trên) ... # Kiểm tra backup thành công if [ $? -eq 0 ]; then echo \u0026#34;Backup thanh cong: ${BACKUP_FILE}\u0026#34; # Tải lên S3 echo \u0026#34;Tai file backup len AWS S3...\u0026#34; aws s3 cp ${BACKUP_FILE} s3://your-s3-bucket/database/ if [ $? -eq 0 ]; then echo \u0026#34;Tai len S3 thanh cong. Xoa file local.\u0026#34; rm ${BACKUP_FILE} else echo \u0026#34;Tai len S3 that bai!\u0026#34; fi else echo \u0026#34;Backup failed!\u0026#34; # Gửi cảnh báo đến Slack/Email ở đây exit 1 fi # ... (Phần xóa backup cũ trên S3 có thể dùng lifecycle rules) ... ","date":"2025-10-19T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/backup-database/","title":"Kĩ thuật backup dữ liệu Database định kỳ"},{"content":" Phase 1: Server Initialization \u0026amp; Basic Configuration 1. First Connect 1 ssh root@your_server_ip 2. Create new User 1 2 3 4 5 # add user adduser your_username # sudo authorization usermod -aG sudo your_username 3. FW - Uncomplicated Firewall 1 2 3 4 5 6 7 8 # Install ufw if not available sudo apt install ufw # Allow ssh connection sudo ufw allow OpenSSH # Activate firewall sudo ufw enable 4. Update System 1 apt update \u0026amp; apt upgrade -y 5. Re-Login 1 ssh your_username@your_server_ip Phase 2: Setup Environment Docker \u0026amp; Docker Compose 1 2 3 4 5 6 7 # Install Docker curl -sSL https://get.docker.com | sh # Add user to docker group sudo usermod -aG docker $USER # Re-Login to Apply changes Kích hoạt memory cgroups trên nếu cần 1 2 3 4 5 docker info # Cần kích hoạt nếu xuất hiện logs dưới đây: WARNING: No memory limit support WARNING: No swap limit support **Mở tệp cmdline.txt **\n1 sudo nano /boot/firmware/cmdline.txt Thêm các tham số cấu hình\n1 2 # Thêm các tham số sau vào cùng một dòng với các nội dung hiện có, không xuống dòng mới cgroup_enable=memory cgroup_memory=1 Save và Reboot 1 sudo reboot Cloudflared Tunnel Workflow ","date":"2025-10-15T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/raspberry-pi-basic-server-workflow/","title":"Hướng dẫn setup môi trường server cơ bản chạy web và các dịch vụ nền cho Raspberry Pi (Debian)"},{"content":"Transmission Control Protocol (Giao thức điều khiển truyền vận), là một giao thức cốt lõi trong bộ giao thức Internet (TCP/IP)\nTCP là gì? TCP hoạt động ở tầng Giao vận (Transport Layer - Tầng 4 trong mô hình OSI. Nhiệm vụ chính của TCP là đảm bảo dữ liệu được truyền đi một cách đáng tin cậy và đúng thứ tự giữa các ứng dụng trên các thiết bị mạng khác nhau.\nHãy tưởng tượng bạn gửi một bức thư dài qua đường bưu điện. Thay vì gửi cả tập giấy dày, bạn chia nhỏ nó thành nhiều trang, đánh số thứ tự mỗi trang và gửi từng trang riêng lẻ. TCP cũng làm điều tương tự với dữ liệu của bạn. Nó chia dòng dữ liệu lớn thành các gói tin nhỏ hơn gọi là segment (phân đoạn).\nTCP thường hoạt động cùng với Giao thức IP. Trong khi IP chịu trách nhiệm tìm đường và gửi các gói tin đến đúng địa chỉ đích, TCP đảm bảo rằng tất cả các gói tin này đến nơi an toàn, không lỗi và được lắp ráp lại theo đúng thứ tự ban đầu. Sự kết hợp này được gọi là TCP/IP, là nền tảng cho hầu hết các hoạt động trên Internet ngày nay.\nCác đặc điểm chính của TCP TCP được biết đến là một giao thức \u0026ldquo;hướng kết nối\u0026rdquo; (connection-oriented) và đáng tin cậy. Điều này có nghĩa là trước khi bất kỳ dữ liệu nào được gửi đi, một kết nối ảo phải được thiết lập giữa máy gửi và máy nhận. Các đặc điểm nổi bật của TCP bao gồm:\nĐộ tin cậy cao: TCP đảm bảo dữ liệu đến đích một cách toàn vẹn. Nó sử dụng cơ chế kiểm tra lỗi (checksum), gửi lại các gói tin bị mất và loại bỏ các gói tin trùng lặp.\nĐảm bảo đúng thứ tự: Mỗi segment được gán một \u0026ldquo;số thứ tự\u0026rdquo; (sequence number). Bên nhận sẽ dựa vào số này để sắp xếp lại các segment theo đúng thứ tự ban đầu, đảm bảo dữ liệu không bị xáo trộn.\nKiểm soát luồng (Flow Control): TCP sử dụng một cơ chế gọi là \u0026ldquo;cửa sổ trượt\u0026rdquo; (sliding window) để điều chỉnh tốc độ truyền dữ liệu. Điều này giúp bên gửi không làm quá tải bên nhận bằng cách gửi dữ liệu nhanh hơn khả năng xử lý của nó.\nKiểm soát tắc nghẽn (Congestion Control): TCP có khả năng phát hiện tình trạng tắc nghẽn mạng và tự động giảm tốc độ truyền để tránh làm tình hình tệ hơn.\nTCP hoạt động như thế nào? Quy trình \u0026ldquo;Bắt tay ba bước\u0026rdquo; Hoạt động của TCP có thể được chia thành ba giai đoạn chính: thiết lập kết nối, truyền dữ liệu và kết thúc kết nối.\n1. Thiết lập kết nối: Bắt tay ba bước (Three-Way Handshake) Đây là quy trình bắt buộc để thiết lập một kết nối TCP đáng tin cậy. Quá trình này diễn ra như sau:\nBước 1 (SYN): Máy khách (Client) muốn bắt đầu kết nối sẽ gửi một gói tin có cờ SYN (Synchronize) đến máy chủ (Server). Gói tin này về cơ bản là một lời chào: \u0026ldquo;Chào Server, tôi muốn kết nối. Số thứ tự bắt đầu của tôi là X.\u0026rdquo;\nBước 2 (SYN-ACK): Server nhận được gói SYN, nếu đồng ý kết nối, nó sẽ gửi lại một gói tin có cả cờ SYN và ACK (Acknowledgement). Gói tin này có ý nghĩa: \u0026ldquo;Chào Client, tôi đã nhận được yêu cầu của bạn (ACK X+1). Tôi cũng sẵn sàng kết nối. Số thứ tự bắt đầu của tôi là Y.\u0026rdquo;\nBước 3 (ACK): Client nhận được gói SYN-ACK từ Server. Để hoàn tất quá trình, Client gửi lại một gói tin chỉ có cờ ACK. Gói tin này xác nhận: \u0026ldquo;Tôi đã nhận được gói tin của Server (ACK Y+1). Kết nối đã được thiết lập!\u0026rdquo;\nSau khi hoàn thành 3 bước này, một kết nối ổn định được tạo ra và quá trình truyền dữ liệu có thể bắt đầu.\n2. Truyền dữ liệu Khi kết nối đã được thiết lập, dữ liệu sẽ được chia thành các segment và gửi đi.\nBên gửi sẽ gửi một lượng dữ liệu (trong giới hạn của cửa sổ trượt).\nBên nhận sau khi nhận được dữ liệu sẽ gửi lại một gói tin ACK để xác nhận.\nNếu bên gửi không nhận được ACK trong một khoảng thời gian nhất định, nó sẽ tự động gửi lại segment đó.\n3. Kết thúc kết nối: Bắt tay bốn bước (Four-Way Handshake) Khi quá trình truyền dữ liệu hoàn tất, kết nối sẽ được đóng lại thông qua một quy trình \u0026ldquo;bắt tay bốn bước\u0026rdquo; để đảm bảo cả hai bên đều đồng ý chấm dứt.\nMột bên (ví dụ: Client) gửi một gói tin FIN (Finish) để thông báo muốn kết thúc.\nBên kia (Server) gửi lại một gói ACK để xác nhận đã nhận được yêu cầu.\nSau đó, Server cũng gửi một gói FIN của riêng mình.\nCuối cùng, Client gửi lại một gói ACK để xác nhận, và kết nối được đóng hoàn toàn.\nSo sánh TCP và UDP Trong tầng Giao vận, ngoài TCP còn có một giao thức quan trọng khác là UDP (User Datagram Protocol). Dưới đây là bảng so sánh nhanh giữa hai giao thức này:\nĐặc điểm TCP (Transmission Control Protocol) UDP (User Datagram Protocol) Kiểu kết nối Hướng kết nối (Connection-oriented) Không kết nối (Connectionless) Độ tin cậy Rất cao. Đảm bảo dữ liệu đến nơi, đúng thứ tự, không lỗi. Không đáng tin cậy. Không đảm bảo dữ liệu có đến đích hay không, không sắp xếp thứ tự. Tốc độ Chậm hơn do các cơ chế kiểm tra, xác nhận và thiết lập kết nối. Rất nhanh do không có các quy trình phức tạp. Kiểm soát luồng Có Không Header Lớn hơn (tối thiểu 20 bytes) do chứa nhiều thông tin điều khiển. Nhỏ hơn (8 bytes), giúp giảm thiểu dữ liệu thừa. Ứng dụng phổ biến Truy cập web (HTTP/HTTPS), gửi email (SMTP), truyền file (FTP). Streaming video/audio, game online, gọi VoIP, DNS. Khi nào nên sử dụng TCP? TCP là lựa chọn lý tưởng cho các ứng dụng đòi hỏi tính toàn vẹn và độ chính xác của dữ liệu là ưu tiên hàng đầu. Nếu việc mất một vài gói tin có thể gây ra lỗi nghiêm trọng (ví dụ như tải một tệp tin bị hỏng, email bị mất nội dung), thì TCP là giao thức bắt buộc phải sử dụng.\n","date":"2025-10-13T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/tcp/","title":"Tổng quan về TCP"},{"content":"Open Systems Interconnection - OSI là một khung khái niệm chia các chức năng truyền thông mạng thành 7 lớp hay 7 tầng riêng biệt. Được phát triển bởi Tổ chức Tiêu chuẩn hóa Quốc tế (ISO)\nCấu trúc 7 tầng của mô hình OSI Quá trình truyền dữ liệu trong mô hình OSI diễn ra theo thứ tự từ tầng ứng dụng (tầng 7) đi xuống tầng vật lý (tầng 1) ở máy gửi, và ngược lại ở máy nhận. Mỗi tầng có những chức năng cụ thể và có thêm thêm header (thông tin điều khiển) của riêng mình vào dữ liệu trước khi chuyển xuống tầng tiếp theo. Quá trình này gọi là \u0026ldquo;đóng gói dữ liệu\u0026rdquo;.\nTầng 7: Application Layer Đây là tầng gần gũi nhất với người dùng. Nó cung cấp giao diện để các ứng dụng phần mềm có thể truy cập và sử dụng các dịch vụ mạng.\nChức năng chính:\nCung cấp các dịch vụ mạng cho ứng dụng của người dùng như truy cập web, gửi/nhận email, truyền file.\nXác định các giao thức mà ứng dụng sử dụng để trao đổi dữ liệu.\nVí dụ thực tế: Khi bạn sử dụng trình duyệt web, email hoặc một phần mềm chat, bạn đang tương tác với tầng ứng dụng. Các giao thức phổ biến ở tầng này bao gồm HTTP/HTTPS (truy cập web), FTP (truyền tệp), SMTP (gửi email), và DNS (hệ thống phân giải tên miền).\nTầng 6: Presentation Layer Tầng này hoạt động như một \u0026ldquo;người phiên dịch\u0026rdquo; của mạng, đảm bảo rằng dữ liệu được gửi từ tầng ứng dụng của một hệ thống có thể được đọc và hiểu bởi tầng ứng dụng của hệ thống khác.\nChức năng chính:\nĐịnh dạng dữ liệu: Chuyển đổi dữ liệu sang một định dạng chung mà mạng có thể hiểu.\nMã hóa và giải mã: Đảm bảo tính bảo mật và bí mật của dữ liệu trong quá trình truyền.\nNén và giải nén: Giảm kích thước dữ liệu để truyền đi nhanh hơn và tiết kiệm băng thông.\nVí dụ thực tế: Mã hóa HTTPS thông qua SSL/TLS thường được coi là hoạt động ở tầng này. Các định dạng tệp hình ảnh (JPEG, GIF) và video (MPEG) cũng là ví dụ về hoạt động của tầng trình bày.\nTầng 5: Session Layer Tầng này chịu trách nhiệm thiết lập, quản lý và kết thúc các phiên giao tiếp (kết nối) giữa hai máy tính.\nChức năng chính:\nThiết lập và quản lý phiên: Tạo, duy trì và đồng bộ hóa các phiên giao tiếp giữa các ứng dụng.\nĐiều khiển đối thoại: Xác định lượt truyền dữ liệu (ai gửi, ai nhận, và trong bao lâu).\nKhôi phục phiên: Nếu một phiên bị gián đoạn, tầng này có thể giúp khôi phục lại từ một điểm kiểm tra (checkpoint), tránh việc phải truyền lại toàn bộ dữ liệu.\nVí dụ thực tế: Khi bạn thực hiện một cuộc gọi video, tầng phiên sẽ duy trì kết nối ổn định trong suốt cuộc gọi. Các giao thức như NetBIOS, RPC cũng hoạt động ở tầng này.\nTầng 4: Transport Layer Tầng vận chuyển đảm bảo việc truyền dữ liệu hoàn chỉnh và đáng tin cậy từ một tiến trình trên máy gửi đến một tiến trình trên máy nhận.\nChức năng chính:\nPhân đoạn và tái lắp ráp: Chia nhỏ dữ liệu từ tầng phiên thành các đoạn (segment) nhỏ hơn để truyền đi và tập hợp chúng lại ở phía nhận.\nKiểm soát luồng: Điều chỉnh tốc độ truyền dữ liệu để tránh làm quá tải thiết bị nhận.\nKiểm soát lỗi: Đảm bảo dữ liệu đến nơi một cách chính xác, không bị lỗi, mất mát hay trùng lặp.\nCung cấp hai loại giao thức chính:\nTCP (Transmission Control Protocol): Hướng kết nối, đảm bảo độ tin cậy cao (dữ liệu được gửi đầy đủ và đúng thứ tự). Thích hợp cho việc tải tệp, gửi email.\nUDP (User Datagram Protocol): Không kết nối, truyền dữ liệu nhanh hơn nhưng không đảm bảo độ tin cậy. Thích hợp cho streaming video, game online.\nTầng 3: Network Layer Tầng mạng chịu trách nhiệm cho việc định địa chỉ logic và định tuyến các gói tin (packet) qua các mạng khác nhau để đến đúng đích.\nChức năng chính:\nĐịnh địa chỉ logic (Logical Addressing): Gán địa chỉ IP cho các thiết bị để xác định chúng trên mạng.\nĐịnh tuyến (Routing): Xác định con đường tốt nhất để các gói tin di chuyển từ nguồn đến đích qua nhiều mạng khác nhau. Các thiết bị định tuyến (router) hoạt động ở tầng này.\nVí dụ thực tế: Khi bạn truy cập một trang web, tầng mạng sẽ xác định đường đi cho dữ liệu của bạn qua Internet để đến được máy chủ của trang web đó. Giao thức IP (Internet Protocol) là giao thức chính ở tầng này.\nTầng 2: Data Link Layer Tầng này cung cấp phương tiện truyền dữ liệu đáng tin cậy qua một liên kết vật lý trực tiếp. Nó nhận các gói tin từ tầng mạng và đóng gói chúng thành các khung (frame).\nChức năng chính:\nĐịnh địa chỉ vật lý (Physical Addressing): Thêm địa chỉ MAC (Media Access Control) của thiết bị gửi và nhận vào mỗi khung. Địa chỉ MAC là duy nhất cho mỗi card mạng.\nKiểm soát lỗi: Phát hiện và sửa lỗi có thể xảy ra ở tầng vật lý.\nKiểm soát truy cập môi trường (Media Access Control - MAC): Điều khiển việc các thiết bị trên cùng một mạng chia sẻ truy cập vào môi trường truyền.\nVí dụ thực tế: Các thiết bị chuyển mạch (switch) hoạt động ở tầng này. Giao thức Ethernet là một ví dụ điển hình.\nTầng 1: Physical Layer Đây là tầng thấp nhất, chịu trách nhiệm truyền các bit dữ liệu (0 và 1) qua môi trường truyền vật lý.\nChức năng chính:\nĐịnh nghĩa các đặc tính vật lý: Quy định về các thiết bị phần cứng như cáp mạng, đầu nối, card mạng, cũng như các đặc tính về điện, cơ và quang.\nBiểu diễn bit: Chuyển đổi các bit 0 và 1 thành các tín hiệu điện, ánh sáng hoặc sóng vô tuyến để truyền đi.\nTốc độ dữ liệu: Xác định số bit được truyền đi mỗi giây.\nVí dụ thực tế: Cáp đồng, cáp quang, sóng Wi-Fi, hub, và repeater là những ví dụ về các thành phần hoạt động ở tầng vật lý.\nƯu và nhược điểm của mô hình OSI Ưu điểm:\nChuẩn hóa: Tạo ra một tiêu chuẩn chung, giúp các nhà sản xuất khác nhau tạo ra các sản phẩm tương thích.\nGiảm độ phức tạp: Chia nhỏ quá trình truyền thông phức tạp thành các phần đơn giản, dễ quản lý và dễ hiểu hơn.\nHỗ trợ kỹ thuật module: Cho phép thay đổi hoặc phát triển công nghệ ở một tầng mà không ảnh hưởng đến các tầng khác.\nDễ dàng khắc phục sự cố: Giúp các kỹ sư mạng xác định vấn đề xảy ra ở tầng nào một cách nhanh chóng.\nNhược điểm:\nTính lý thuyết: Mô hình OSI chỉ là một mô hình tham chiếu và không được triển khai rộng rãi trong thực tế như mô hình TCP/IP.\nPhức tạp: Một số người cho rằng mô hình 7 tầng là quá phức tạp và một số tầng có chức năng không thực sự cần thiết trong nhiều ứng dụng thực tế.\n","date":"2025-10-12T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/osi/","title":"Tổng quan về mô hình OSI"},{"content":"Có một số cách để tạo USB boot Windows trên Linux. Đây là phương pháp phổ biến nhất:\nSử dụng WoeUSB-ng Cài đặt 1 2 3 4 5 6 # Ubuntu/Debian sudo apt install git p7zip-full python3-pip python3-wxgtk4.0 sudo pip3 install WoeUSB-ng # Fedora sudo dnf install WoeUSB-ng Sử dụng 1 sudo woeusb --device /đường/dẫn/tới/Windows.iso /dev/sdX (Thay /dev/sdX bằng USB của bạn, ví dụ /dev/sdb)\nCách nhận biết tên thiết bị USB trên Linux 1. Command lsblk 1 lsblk Kết quả sẽ hiển thị dạng:\n1 2 3 4 5 6 NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 238.5G 0 disk ├─sda1 8:1 0 512M 0 part /boot/efi └─sda2 8:2 0 238G 0 part / sdb 8:16 1 14.9G 0 disk \u0026lt;-- Đây là USB └─sdb1 8:17 1 14.9G 0 part /media/user/USB Nhận biết: USB thường có RM = 1 (removable), dung lượng nhỏ hơn ổ cứng chính.\n2. Command sudo fdisk -l 1 sudo fdisk -l Tìm thiết bị có nhãn như \u0026ldquo;USB\u0026rdquo; hoặc dung lượng khớp với USB của bạn.\n","date":"2025-10-04T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/usb-boot-windows-on-linux/","title":"Hướng dẫn tạo USB Boot Windows trên Linux"},{"content":"Hướng dẫn sửa lỗi authorized khi SSH vào raspberry pi\nSửa trực tiếp trên Thẻ nhớ Tắt Pi và tháo thẻ nhớ SD.\nCắm thẻ nhớ vào máy tính của bạn (bạn có thể cần một đầu đọc thẻ).\nTruy cập vào phân vùng có tên rootfs (hoặc phân vùng có dung lượng lớn hơn).\nĐi đến đường dẫn /home/nagih/.ssh/.\nKiểm tra file authorized_keys: Mở nó ra và đảm bảo nội dung của file ~/.ssh/id_ed25519.pub trên máy tính của bạn được chép chính xác vào đây, trên một dòng duy nhất.\nKiểm tra quyền (khó hơn): Việc kiểm tra và sửa quyền file trên thẻ SD từ một máy tính khác (như Windows) là không khả thi. Nếu bạn dùng Linux, bạn có thể mount thẻ nhớ và dùng chmod để sửa.\n","date":"2025-09-26T00:00:00Z","image":"https://nagih.nooblearn2code.com/image-placeholder.png","permalink":"https://nagih.nooblearn2code.com/posts/fix-authorized/","title":"Hướng dẫn sửa lỗi authorized khi SSH vào raspberry pi"},{"content":"Các vấn đề về kết nối Internet phổ biến và cách khắc phục chi tiết\nI. CHUẨN ĐOÁN VẤN ĐỀ Bước 1: Kiểm tra kết nối vật lý 1 2 3 4 5 6 7 8 # Kiểm tra card mạng có được nhận diện không lspci | grep -i network lspci | grep -i ethernet lsusb | grep -i wireless # Kiểm tra interface có tồn tại không ip link show ifconfig -a Kết quả mong đợi: Thấy các interface như eth0, wlan0, enp0s3\nBước 2: Kiểm tra trạng thái Interface 1 2 3 4 5 6 # Xem trạng thái chi tiết ip addr show nmcli device status # Kiểm tra interface có UP không ip link show eth0 # Thay eth0 bằng interface của bạn Phân tích kết quả\nUP: Interface đã bật\nDOWN: Interface bị tắt\nNO-CARRIER: Không có tín hiệu (Dây mạng rút, không có sóng Wifi)\nBước 3: Test kết nối từng lớp 1 2 3 4 5 6 7 8 9 10 11 12 13 # Layer 1-2: Kiểm tra link local ping -c 3 127.0.0.1 # Layer 3: Kiểm tra gateway ip route show # Xem default gateway ping -c 3 \u0026lt;gateway-ip\u0026gt; # Ping gateway # Layer 3: Kiểm tra DNS server ping -c 3 1.1.1.1 # Ping IP trực tiếp (Cloudflared / Google) # Layer 4: Kiểm tra phân giải tên miền nslookup google.com ping -c 3 google.com Bước 4: Kiểm tra cấu hình mạng 1 2 3 4 5 6 7 8 9 10 # Kiểm tra IP configuration ip addr show route -n # Kiểm tra DNS setting cat /etc/resolv.conf system-resolve --status # Kiểm tra DHCP sudo dhclient -v eth0 # Test DHCP renewal Bước 5: Kiểm tra service và process 1 2 3 4 5 6 7 8 9 10 11 12 # Kiểm tra network services systemctl status NetworkManager systemctl status networking systemctl status systemd-networkd # Kiểm tra Firewall sudo ufw status sudo iptables -L -n # Kiểm tra process sử dụng network ss -tuln # Listening ports netstart -rn # Routing table Bước 6: Xem Logs và Error messages 1 2 3 4 5 6 7 8 journalctl -u NetworkManager -f dmesg | grep -i network dmesg | grep -i eth dmesg | grep -i wlan # Kernal messages dmes | tail -20 tail -f var/log/syslog | grep -i network Ma trận chuẩn đoán nhanh Triệu chứng Lệnh kiểm tra Nguyên nhân có thể Không thấy interface ip link show Driver không có/sai Interface DOWN ip link show Interface bị disable Không có IP ip addr show DHCP fail, static config sai Ping localhost fail ping 127.0.0.1 Network stack broken Ping gateway fail ping \u0026lt;gateway\u0026gt; L2/L3 problem Ping IP OK, domain fail nslookup google.com DNS problem Kết nối chậm traceroute google.com Routing/bandwidth issue Scripts auto chuẩn đoán lỗi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #!/bin/bash echo \u0026#34;=== NETWORK DIAGNOSTIC REPORT ===\u0026#34; echo \u0026#34;Date: $(date)\u0026#34; echo echo \u0026#34;1. NETWORK INTERFACES:\u0026#34; ip link show echo echo \u0026#34;2. IP ADDRESSES:\u0026#34; ip addr show echo echo \u0026#34;3. ROUTING TABLE:\u0026#34; ip route show echo echo \u0026#34;4. DNS CONFIGURATION:\u0026#34; cat /etc/resolv.conf echo echo \u0026#34;5. CONNECTIVITY TESTS:\u0026#34; echo -n \u0026#34;Localhost: \u0026#34; ping -c 1 -W 2 127.0.0.1 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; GATEWAY=$(ip route | grep default | awk \u0026#39;{print $3}\u0026#39; | head -1) if [ ! -z \u0026#34;$GATEWAY\u0026#34; ]; then echo -n \u0026#34;Gateway ($GATEWAY): \u0026#34; ping -c 1 -W 2 $GATEWAY \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; fi echo -n \u0026#34;External DNS (8.8.8.8): \u0026#34; ping -c 1 -W 2 8.8.8.8 \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; echo -n \u0026#34;Domain resolution (google.com): \u0026#34; nslookup google.com \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; echo \u0026#34;OK\u0026#34; || echo \u0026#34;FAIL\u0026#34; echo echo \u0026#34;6. ACTIVE SERVICES:\u0026#34; systemctl is-active NetworkManager 2\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;NetworkManager: Active\u0026#34; || echo \u0026#34;NetworkManager: Inactive\u0026#34; systemctl is-active networking 2\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026#34;networking: Active\u0026#34; || echo \u0026#34;networking: Inactive\u0026#34; Chạy scripts\n1 2 chmod +x network-diagnostic.sh ./network-diagnostic.sh II. XỬ LÝ LỖI 1. Không kết nối được mạng Kiểm tra trạng thái mạng\n1 2 3 ip link show ip addr show nmcli device status Khắc phục\n1 2 3 4 5 # Khởi động lại network manager sudo systemctl restart NetworkManager # Hoặc khởi động lại networking service sudo systemctl restart networking 2. Lỗi DNS không phân giải được Kiểm tra DNS\n1 2 3 nslookup google.com dig google.com cat /etc/resolv.conf Khắc phục\n1 2 3 4 5 6 7 8 9 10 11 # Thay đổi DNS server sudo nano /etc/resolv.conf # Thêm các dòng sau: # Cloudflared nameserver 1.1.1.1 nameserver 1.0.0.1 # Google nameserver 8.8.8.8 nameserver 8.8.4.4 3. Lỗi drive card mạng Kiểm tra drive\n1 2 3 lspci -nnk | grep -iA2 net lsusb # cho USB WiFi adapter dmesg | grep -i network Khắc phục\n1 2 3 4 5 6 7 # Cài đặt driver thiếu sudo apt update sudo apt install linux-firmware sudo apt install firmware-iwlwifi # cho Intel WiFi # Khởi động lại sudo modprobe -r iwlwifi \u0026amp;\u0026amp; sudo modprobe iwlwifi 4. Lỗi Wifi không kết nối được 1 2 3 iwconfig nmcli dev wifi list rfkill list Khắc phục\n1 2 3 4 5 6 7 8 9 # Bật WiFi nếu bị tắt sudo rfkill unblock wifi # Kết nối WiFi nmcli dev wifi connect \u0026#34;TenWiFi\u0026#34; password \u0026#34;MatKhau\u0026#34; # Reset network settings sudo rm /var/lib/NetworkManager/NetworkManager.state sudo systemctl restart NetworkManager 5. Lỗi IP conflict hoặc không nhận được IP 1 2 ip route show dhclient -v Khắc phục\n1 2 3 4 5 6 # Renew IP address sudo dhclient -r sudo dhclient # Hoặc reset network interface sudo ifdown eth0 \u0026amp;\u0026amp; sudo ifup eth0 6. Lỗi firewall chặn kết nối Kiểm tra firewall\n1 2 sudo ufw status sudo iptables -L Khắc phục\n1 2 3 4 5 6 7 # Tạm thời tắt firewall để test sudo ufw disable # Hoặc mở port cần thiết sudo ufw allow 80 sudo ufw allow 443 sudo ufw allow ssh 7. Lỗi proxy settings Kiểm tra proxy\n1 2 3 echo $http_proxy echo $https_proxy cat /etc/environment Khắc phục\n1 2 3 4 5 6 7 8 9 # Xóa proxy settings unset http_proxy unset https_proxy unset HTTP_PROXY unset HTTPS_PROXY # Hoặc cấu hình đúng proxy export http_proxy=http://proxy-server:port export https_proxy=http://proxy-server:port 8. Lỗi MTU size Kiểm tra và fix MTU\n1 2 3 4 5 6 7 # Kiểm tra MTU hiện tại ip link show # Thay đổi MTU sudo ip link set dev eth0 mtu 1400 # Hoặc cấu hình vĩnh viễn trong /etc/network/interfaces III. RESET HOÀN TOÀN NETWORKING 1 2 3 4 5 6 7 8 9 10 11 # Backup cấu hình cũ nếu cần sudo cp -r /etc/NetworkManager /etc/NetworkManager.backup # Reset NetworkManager sudo rm -rf /etc/NetworkManager/system-connections/* sudo systemctl stop NetworkManager sudo systemctl start NetworkManager # Hoặc reinstall network packages sudo apt remove --purge network-manager sudo apt install network-manager ","date":"2025-09-16T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/internet-errors/","title":"Các vấn đề về Internet và cách khắc phục"},{"content":"Chia sẻ mẫu Documentation cho lập trình viên Backend\nE-Library Management System - Backend Documentation 📋 Table of Contents System Overview Architecture API Documentation Database Schema Authentication \u0026amp; Security Setup \u0026amp; Deployment Testing Monitoring \u0026amp; Logging 🎯 System Overview Project: E-Library Management System\nVersion: v2.1.0\nTech Stack: Node.js, Express.js, MongoDB, Redis, Docker\nPurpose: Backend API cho hệ thống quản lý thư viện sách điện tử\nCore Features User authentication \u0026amp; authorization\nBook catalog management\nBook borrowing/returning system\nSearch \u0026amp; filtering\nUser notifications\nAdmin dashboard APIs\n🏗️ Architecture High-Level Architecture 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐ │ Client Apps │─ │ Load Balancer │──│ API Gateway │ └─────────────────┘ └─────────────────┘ └─────────────────┘ │ ┌─────────────────────────────┼─────────────────────────────┐ │ │ │ ┌───────▼───────┐ ┌───────▼───────┐ ┌───────▼───────┐ │ │ │ │ Auth Service │ │ Book Service │ │ User Service │ │ │ │ └───────────────┘ └───────────────┘ └────────────────┘ │ │ │ └─────────────────────────────┼─────────────────────────────┘ │ ┌─────────────────────────────┼─────────────────────────────┐ │ │ │ ┌───────▼───────┐ ┌───────▼───────┐ ┌───────▼───────┐ │ │ │ │ MongoDB │ │ Redis │ │ File Store │ │ │ │ │ (Primary) │ │ (Caching) │ │ (Images) │ │ │ │ └───────────────┘ └───────────────┘ └───────────────┘ Service Dependencies Auth Service: JWT token validation, user roles\nBook Service: Book CRUD operations, search, categorization\nUser Service: User profile management, borrowing history\nNotification Service: Email/SMS notifications\nFile Service: Book cover uploads, PDF handling\n📡 API Documentation Base URL 1 2 3 Production: https://api.elibrary.com/v2 Staging: https://staging-api.elibrary.com/v2 Development: http://localhost:3000/v2 Authentication All protected endpoints require Bearer token:\n1 Authorization: Bearer \u0026lt;jwt_token\u0026gt; Response Format 1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Request processed successfully\u0026#34;, \u0026#34;data\u0026#34;: {}, \u0026#34;pagination\u0026#34;: { \u0026#34;page\u0026#34;: 1, \u0026#34;limit\u0026#34;: 20, \u0026#34;total\u0026#34;: 100, \u0026#34;totalPages\u0026#34;: 5 }, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } Error Response 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { \u0026#34;success\u0026#34;: false, \u0026#34;error\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;VALIDATION_ERROR\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Invalid request data\u0026#34;, \u0026#34;details\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Email format is invalid\u0026#34; } ] }, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } 🔐 Authentication Endpoints POST /auth/register Description: Đăng ký tài khoản mới\nRequest Body:\n1 2 3 4 5 6 7 { \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;SecurePass123!\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;+84901234567\u0026#34; } Response (201):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;User registered successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;isVerified\u0026#34;: false }, \u0026#34;token\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34; } } POST /auth/login Description: Đăng nhập hệ thống\nRequest Body:\n1 2 3 4 { \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;SecurePass123!\u0026#34; } Response (200):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Login successful\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;user\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;user@example.com\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34; }, \u0026#34;token\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34;, \u0026#34;refreshToken\u0026#34;: \u0026#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\u0026#34; } } 📚 Book Management Endpoints GET /books Description: Lấy danh sách sách với phân trang và filter\nQuery Parameters:\npage (integer, default: 1): Trang hiện tại limit (integer, default: 20): Số sách per page category (string): Filter theo danh mục author (string): Filter theo tác giả search (string): Tìm kiếm theo title/author available (boolean): Chỉ lấy sách còn available Example Request:\n1 GET /books?page=1\u0026amp;limit=10\u0026amp;category=fiction\u0026amp;available=true Response (200):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 { \u0026#34;success\u0026#34;: true, \u0026#34;data\u0026#34;: { \u0026#34;books\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;The Great Gatsby\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;F. Scott Fitzgerald\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-0743273565\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;fiction\u0026#34;, \u0026#34;publishYear\u0026#34;: 1925, \u0026#34;description\u0026#34;: \u0026#34;A classic American novel...\u0026#34;, \u0026#34;coverImage\u0026#34;: \u0026#34;https://cdn.elibrary.com/covers/great-gatsby.jpg\u0026#34;, \u0026#34;totalCopies\u0026#34;: 5, \u0026#34;availableCopies\u0026#34;: 3, \u0026#34;rating\u0026#34;: 4.5, \u0026#34;createdAt\u0026#34;: \u0026#34;2025-09-01T10:00:00.000Z\u0026#34;, \u0026#34;updatedAt\u0026#34;: \u0026#34;2025-09-15T14:30:00.000Z\u0026#34; } ] }, \u0026#34;pagination\u0026#34;: { \u0026#34;page\u0026#34;: 1, \u0026#34;limit\u0026#34;: 10, \u0026#34;total\u0026#34;: 156, \u0026#34;totalPages\u0026#34;: 16 } } POST /books Description: Thêm sách mới (Admin only)\nAuthentication: Required (Admin role)\nRequest Body:\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;title\u0026#34;: \u0026#34;New Book Title\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Author Name\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-1234567890\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;science\u0026#34;, \u0026#34;publishYear\u0026#34;: 2024, \u0026#34;description\u0026#34;: \u0026#34;Book description here...\u0026#34;, \u0026#34;totalCopies\u0026#34;: 3, \u0026#34;coverImage\u0026#34;: \u0026#34;base64_encoded_image_or_url\u0026#34; } Response (201):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book created successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;book\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123457\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;New Book Title\u0026#34;, \u0026#34;author\u0026#34;: \u0026#34;Author Name\u0026#34;, \u0026#34;isbn\u0026#34;: \u0026#34;978-1234567890\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;science\u0026#34;, \u0026#34;publishYear\u0026#34;: 2024, \u0026#34;description\u0026#34;: \u0026#34;Book description here...\u0026#34;, \u0026#34;totalCopies\u0026#34;: 3, \u0026#34;availableCopies\u0026#34;: 3, \u0026#34;rating\u0026#34;: 0, \u0026#34;createdAt\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34; } } } PUT /books/:bookId Description: Cập nhật thông tin sách (Admin only)\nAuthentication: Required (Admin role)\nDELETE /books/:bookId Description: Xóa sách (Admin only)\nAuthentication: Required (Admin role)\n📖 Borrowing System Endpoints POST /borrowings Description: Mượn sách\nAuthentication: Required\nRequest Body:\n1 2 3 4 { \u0026#34;bookId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;borrowDuration\u0026#34;: 14 } Response (201):\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book borrowed successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;borrowing\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123458\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;bookId\u0026#34;: \u0026#34;66e123456789abcdef123456\u0026#34;, \u0026#34;borrowDate\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34;, \u0026#34;dueDate\u0026#34;: \u0026#34;2025-09-30T10:30:00.000Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;active\u0026#34;, \u0026#34;renewalCount\u0026#34;: 0 } } } PUT /borrowings/:borrowingId/return Description: Trả sách\nAuthentication: Required\nResponse (200):\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;success\u0026#34;: true, \u0026#34;message\u0026#34;: \u0026#34;Book returned successfully\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;borrowing\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;66e123456789abcdef123458\u0026#34;, \u0026#34;returnDate\u0026#34;: \u0026#34;2025-09-16T15:45:00.000Z\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;returned\u0026#34;, \u0026#34;lateFee\u0026#34;: 0 } } } GET /borrowings/my-books Description: Lấy danh sách sách đang mượn của user\nAuthentication: Required\n🗄️ Database Schema Users Collection 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 { _id: ObjectId, email: String (unique, required), password: String (hashed, required), firstName: String (required), lastName: String (required), phoneNumber: String, role: String (enum: [\u0026#39;user\u0026#39;, \u0026#39;librarian\u0026#39;, \u0026#39;admin\u0026#39;], default: \u0026#39;user\u0026#39;), isVerified: Boolean (default: false), avatar: String, address: { street: String, city: String, zipCode: String }, preferences: { notifications: { email: Boolean (default: true), sms: Boolean (default: false) }, favoriteCategories: [String] }, createdAt: Date, updatedAt: Date } Books Collection 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 { _id: ObjectId, title: String (required, indexed), author: String (required, indexed), isbn: String (unique, required), category: String (required, indexed), publishYear: Number, publisher: String, language: String (default: \u0026#39;vietnamese\u0026#39;), description: String, coverImage: String, pdfFile: String, totalCopies: Number (required, min: 1), availableCopies: Number (required), rating: Number (default: 0), reviewCount: Number (default: 0), tags: [String], createdAt: Date, updatedAt: Date, createdBy: ObjectId (ref: \u0026#39;User\u0026#39;) } Borrowings Collection 1 2 3 4 5 6 7 8 9 10 11 12 13 14 { _id: ObjectId, userId: ObjectId (ref: \u0026#39;User\u0026#39;, required), bookId: ObjectId (ref: \u0026#39;Book\u0026#39;, required), borrowDate: Date (required), dueDate: Date (required), returnDate: Date, status: String (enum: [\u0026#39;active\u0026#39;, \u0026#39;returned\u0026#39;, \u0026#39;overdue\u0026#39;], required), renewalCount: Number (default: 0, max: 2), lateFee: Number (default: 0), notes: String, createdAt: Date, updatedAt: Date } Categories Collection 1 2 3 4 5 6 7 8 9 10 11 { _id: ObjectId, name: String (required, unique), slug: String (required, unique), description: String, parentCategory: ObjectId (ref: \u0026#39;Category\u0026#39;), isActive: Boolean (default: true), sortOrder: Number (default: 0), createdAt: Date, updatedAt: Date } 🔒 Authentication \u0026amp; Security JWT Configuration 1 2 3 4 5 6 { secret: process.env.JWT_SECRET, algorithm: \u0026#39;HS256\u0026#39;, expiresIn: \u0026#39;24h\u0026#39;, refreshTokenExpiresIn: \u0026#39;7d\u0026#39; } Password Requirements Minimum 8 characters At least 1 uppercase letter At least 1 lowercase letter At least 1 number At least 1 special character Rate Limiting 1 2 3 4 5 6 { \u0026#34;/auth/login\u0026#34;: \u0026#34;5 requests per 15 minutes per IP\u0026#34;, \u0026#34;/auth/register\u0026#34;: \u0026#34;3 requests per hour per IP\u0026#34;, \u0026#34;/books\u0026#34;: \u0026#34;100 requests per 15 minutes per user\u0026#34;, \u0026#34;/borrowings\u0026#34;: \u0026#34;20 requests per hour per user\u0026#34; } CORS Configuration 1 2 3 4 5 6 7 8 9 { origin: [ \u0026#39;https://elibrary.com\u0026#39;, \u0026#39;https://admin.elibrary.com\u0026#39;, \u0026#39;http://localhost:3000\u0026#39; // development only ], methods: [\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;, \u0026#39;PUT\u0026#39;, \u0026#39;DELETE\u0026#39;], allowedHeaders: [\u0026#39;Content-Type\u0026#39;, \u0026#39;Authorization\u0026#39;] } ⚙️ Setup \u0026amp; Deployment Environment Variables 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Database MONGODB_URI=mongodb://localhost:27017/elibrary REDIS_URL=redis://localhost:6379 # Authentication JWT_SECRET=your-super-secret-jwt-key JWT_EXPIRES_IN=24h REFRESH_TOKEN_SECRET=your-refresh-token-secret # External Services EMAIL_SERVICE_API_KEY=your-email-service-key SMS_SERVICE_API_KEY=your-sms-service-key CLOUDINARY_URL=cloudinary://your-cloudinary-url # Server PORT=3000 NODE_ENV=production Development Setup 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 1. Clone repository git clone https://github.com/company/elibrary-backend.git cd elibrary-backend # 2. Install dependencies npm install # 3. Copy environment file cp .env.example .env # 4. Start MongoDB and Redis docker-compose up -d mongo redis # 5. Run database migrations npm run migrate # 6. Start development server npm run dev Docker Deployment 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # docker-compose.prod.yml version: \u0026#39;3.8\u0026#39; services: app: build: . ports: - \u0026#34;3000:3000\u0026#34; environment: - NODE_ENV=production - MONGODB_URI=mongodb://mongo:27017/elibrary - REDIS_URL=redis://redis:6379 depends_on: - mongo - redis mongo: image: mongo:6.0 volumes: - mongo_data:/data/db environment: MONGO_INITDB_ROOT_USERNAME: admin MONGO_INITDB_ROOT_PASSWORD: password redis: image: redis:7-alpine volumes: - redis_data:/data volumes: mongo_data: redis_data: CI/CD Pipeline (GitHub Actions) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 name: Deploy to Production on: push: branches: [main] jobs: test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-node@v3 with: node-version: \u0026#39;18\u0026#39; - run: npm ci - run: npm test deploy: needs: test runs-on: ubuntu-latest steps: - name: Deploy to server run: | ssh user@server \u0026#34;cd /app \u0026amp;\u0026amp; git pull \u0026amp;\u0026amp; docker-compose up -d --build\u0026#34; 🧪 Testing Test Structure 1 2 3 4 5 6 7 8 9 10 11 tests/ ├── unit/ │ ├── controllers/ │ ├── services/ │ └── utils/ ├── integration/ │ ├── auth.test.js │ ├── books.test.js │ └── borrowings.test.js └── e2e/ └── api.test.js Running Tests 1 2 3 4 5 6 7 8 9 10 11 # Unit tests npm run test:unit # Integration tests npm run test:integration # E2E tests npm run test:e2e # All tests with coverage npm run test:coverage Test Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // tests/integration/books.test.js describe(\u0026#39;Books API\u0026#39;, () =\u0026gt; { beforeEach(async () =\u0026gt; { await Book.deleteMany({}); await User.deleteMany({}); // Create test user and admin testUser = await User.create({ email: \u0026#39;test@example.com\u0026#39;, password: \u0026#39;hashedpassword\u0026#39;, firstName: \u0026#39;Test\u0026#39;, lastName: \u0026#39;User\u0026#39; }); userToken = jwt.sign({ userId: testUser._id }, process.env.JWT_SECRET); }); describe(\u0026#39;GET /books\u0026#39;, () =\u0026gt; { it(\u0026#39;should return paginated books\u0026#39;, async () =\u0026gt; { // Create test books await Book.create([ { title: \u0026#39;Book 1\u0026#39;, author: \u0026#39;Author 1\u0026#39;, isbn: \u0026#39;1111111111\u0026#39; }, { title: \u0026#39;Book 2\u0026#39;, author: \u0026#39;Author 2\u0026#39;, isbn: \u0026#39;2222222222\u0026#39; } ]); const response = await request(app) .get(\u0026#39;/v2/books?page=1\u0026amp;limit=10\u0026#39;) .expect(200); expect(response.body.success).toBe(true); expect(response.body.data.books).toHaveLength(2); expect(response.body.pagination.total).toBe(2); }); }); }); 📊 Monitoring \u0026amp; Logging Logging Configuration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // config/logger.js const winston = require(\u0026#39;winston\u0026#39;); const logger = winston.createLogger({ level: process.env.LOG_LEVEL || \u0026#39;info\u0026#39;, format: winston.format.combine( winston.format.timestamp(), winston.format.errors({ stack: true }), winston.format.json() ), transports: [ new winston.transports.File({ filename: \u0026#39;logs/error.log\u0026#39;, level: \u0026#39;error\u0026#39; }), new winston.transports.File({ filename: \u0026#39;logs/combined.log\u0026#39; }), new winston.transports.Console({ format: winston.format.simple() }) ] }); Metrics Collection Response Time: Average API response time Request Rate: Requests per second Error Rate: 4xx/5xx error percentage Database Connection: MongoDB connection pool status Memory Usage: Node.js heap usage Active Users: Currently logged in users Health Check Endpoint 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // GET /health { \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-09-16T10:30:00.000Z\u0026#34;, \u0026#34;services\u0026#34;: { \u0026#34;database\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;redis\u0026#34;: \u0026#34;connected\u0026#34;, \u0026#34;external_apis\u0026#34;: \u0026#34;operational\u0026#34; }, \u0026#34;metrics\u0026#34;: { \u0026#34;uptime\u0026#34;: \u0026#34;72h 15m\u0026#34;, \u0026#34;memory_usage\u0026#34;: \u0026#34;245MB\u0026#34;, \u0026#34;cpu_usage\u0026#34;: \u0026#34;15%\u0026#34; } } Alerting Rules Response time \u0026gt; 2000ms for 5 minutes Error rate \u0026gt; 5% for 3 minutes Database connection lost Memory usage \u0026gt; 80% Disk space \u0026lt; 10% 📈 Error Codes Reference Code HTTP Status Description VALIDATION_ERROR 400 Request validation failed UNAUTHORIZED 401 Invalid or missing authentication FORBIDDEN 403 Insufficient permissions NOT_FOUND 404 Resource not found CONFLICT 409 Resource already exists RATE_LIMIT_EXCEEDED 429 Too many requests INTERNAL_ERROR 500 Server error SERVICE_UNAVAILABLE 503 External service unavailable 🔄 Changelog v2.1.0 (2025-09-16) Added\nBook rating and review system Advanced search with filters PDF file upload for digital books Notification system for due dates Changed\nImproved authentication with refresh tokens Enhanced error handling and logging Updated database schema for better performance Fixed\nMemory leaks in file upload Race condition in book borrowing Timezone issues in due date calculations v2.0.0 (2025-08-01) Added\nComplete API redesign Role-based access control Redis caching layer Docker containerization 📞 Support \u0026amp; Contact Development Team: backend-team@company.com DevOps Team: devops@company.com Documentation: https://docs.elibrary.com Issue Tracker: https://github.com/company/elibrary-backend/issues Last updated: September 16, 2025\n","date":"2025-09-16T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/backend-documentation/","title":"Mẫu Documentation cho Backend"},{"content":"biến SSH từ một công cụ kết nối đơn thuần thành một hệ thống quản lý danh tính hiệu quả\nGiới thiệu ~/.ssh/config File ~/.ssh/config cho phép bạn tạo các bí danh (alias) và các quy tắc kết nối cụ thể cho từng máy chủ. Thay vì phải gõ các lệnh dài dòng với các tùy chọn phức tạp, bạn có thể định nghĩa tất cả trong file này. Cấu trúc của file bao gồm các khối Host, mỗi khối chứa các chỉ thị áp dụng cho host đó.\nKịch bản: Quản lý nhiều tài khoản GitHub (Cá nhân \u0026amp; Công việc) Đây là một kịch bản rất phổ biến. Mục tiêu là có thể làm việc trên các kho lưu trữ của cả hai tài khoản trên cùng một máy tính mà không cần phải thay đổi cấu hình thủ công mỗi lần chuyển đổi.\nTạo khóa SSH thứ hai:\nHãy chắc chắn rằng bạn đã tạo 1 cặp khóa mới dành cho công việc và đặt một tên file khác biệt, ví dụ: id_ed25519_work. Sau đó, thêm khóa công khai này vào tài khoản GitHub công việc.\nCấu hình ~/.ssh/config:\nMở file ~/.ssh/config (nếu chưa có, hãy tạo nó) và thêm vào nội dung sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 # Tài khoản GitHub cá nhân Host github.com-personal HostName github.com User git IdentityFile ~/.ssh/id_ed25519_personal IdentitiesOnly yes # Tài khoản GitHub công việc Host github.com-work HostName github.com User git IdentityFile ~/.ssh/id_ed25519_work IdentitiesOnly yes Phân tích Host github.com-personal: Đây là bí danh (alias) bạn sẽ sử dụng. Khi Git hoặc SSH thấy host này, nó sẽ áp dụng các quy tắc bên dưới.\nHostName github.com: Đây là tên máy chủ thực tế mà SSH sẽ kết nối đến.\nUser git: GitHub yêu cầu tất cả các kết nối SSH sử dụng user git.\nIdentityFile ~/.ssh/id_ed25519_personal: Yêu cầu SSH sử dụng file khóa riêng tư cụ thể này để xác thực.\nIdentitiesOnly yes: Cực kỳ quan trọng. Theo mặc định, SSH client có thể thử tất cả các khóa có sẵn trong ssh-agent hoặc các file mặc định. Khi kết nối đến GitHub, nếu gửi sai khóa, kết nối có thể bị từ chối sau vài lần thử. IdentitiesOnly yes buộc SSH client chỉ sử dụng duy nhất khóa được chỉ định trong IdentityFile cho host này, loại bỏ sự mơ hồ và ngăn ngừa lỗi xác thực.\nÁp dụng cấu hình vào Git Sau khi đã cấu hình ~/.ssh/config, bạn cần cập nhật URL của các kho lưu trữ Git để chúng sử dụng các bí danh mới.\nĐối với kho lưu trữ mới (khi git clone): Thay vì sử dụng URL SSH mặc định, hãy thay thế github.com bằng bí danh bạn đã tạo.\n1 2 # Clone kho lưu trữ công việc $ git clone git@github.com-work:work-organization/project.git Đối với kho lưu trữ đã có: Sử dụng lệnh git remote set-url để cập nhật URL của remote origin.\n1 2 3 4 5 # Điều hướng đến thư mục kho lưu trữ công việc của bạn $ cd path/to/work/project # Cập nhật URL của remote $ git remote set-url origin git@github.com-work:work-organization/project.git Bạn có thể kiểm tra lại bằng lệnh git remote -v.\nVới thiết lập này, quy trình làm việc của bạn sẽ trở nên hoàn toàn tự động. Khi bạn ở trong một thư mục dự án công việc, các lệnh Git sẽ tự động sử dụng khóa công việc. Khi ở trong dự án cá nhân, chúng sẽ sử dụng khóa cá nhân.\n","date":"2025-09-10T00:00:00Z","image":"https://nagih.nooblearn2code.com/thumb/ssh","permalink":"https://nagih.nooblearn2code.com/posts/all-in-one/","title":"Hướng dẫn quản lý nhiều khóa SSH trên 1 thiết bị"},{"content":" Bước 1: Tạo Cặp Khóa SSH với ssh-keygen Thuật toán Mã hóa Ed25519 (Khuyến nghị): Đây là thuật toán hiện đại, được khuyến nghị sử dụng. Ed25519 cung cấp mức độ bảo mật rất cao với độ dài khóa ngắn hơn, giúp quá trình xác thực diễn ra nhanh hơn.\n1 ssh-keygen -t ed25519 -C \u0026#34;your_email@example.com\u0026#34; RSA (Lựa chọn thay thế): RSA là một thuật toán cũ. Nếu bạn cần hỗ trợ các hệ thống cũ không tương thích với Ed25519.\n1 ssh-keygen -t rsa -b 4096 -C \u0026#34;your_email@example.com\u0026#34; Nhập passphrase (Nếu cần)\nPassphrase này sẽ mã hóa file khóa riêng tư của bạn trên đĩa\nNgay cả khi máy tính của bạn bị đánh cắp và kẻ tấn công có được file khóa riêng tư, họ cũng không thể sử dụng nó nếu không biết passphrase.\nLưu khóa và Đặt tên file Mặc định, ssh-keygen sẽ lưu cặp khóa vào thư mục ~/.ssh/ với tên file là id_ed25519 và id_ed25519.pub (hoặc id_rsa cho RSA). Có thể đặt tên là ~/.ssh/id_ed25519_personal cho tài khoản cá nhân và ~/.ssh/id_ed25519_work cho tài khoản công việc.\nBước 2: Quản Lý Khóa với ssh-agent Khởi động ssh-agent:\nChạy lệnh sau trong terminal để khởi động agent cho phiên làm việc hiện tại.\n1 eval \u0026#34;$(ssh-agent -s)\u0026#34; Thêm khóa riêng tư vào ssh-agent:\nBạn sẽ được yêu cầu nhập passphrase nếu đã tạo.\n1 ssh-add ~/.ssh/id_ed25519 Bước 3: Thêm Public Key vào GitHub Account Copy Public Key\nmacOS:\n1 pbcopy \u0026lt; ~/.ssh/id_ed25519_personal.pub Linux/Windows (Git Bash hoặc WSL):\n1 cat ~/.ssh/id_ed25519.pub Copy public key được in ra màn hình.\nThêm khóa vào GitHub:\nTruy cập tài khoản GitHub của bạn trên Browser.\nVào Settings (Cài đặt)\nTrong thanh bên trái, chọn SSH and GPG keys (Khóa SSH và GPG).\nNhấp vào nút New SSH key (Khóa SSH mới).\nTrong trường Title, đặt một cái tên mang tính mô tả cho khóa của bạn (ví dụ: \u0026ldquo;MacBook Pro Cá Nhân\u0026rdquo;).\nTrong trường Key, dán nội dung khóa công khai bạn đã sao chép.\nNhấp vào Add SSH key (Thêm khóa SSH) để hoàn tất.\nBước 4: Kiểm Tra Kết Nối Chạy lệnh kiểm tra:\n1 ssh -T git@github.com Xác thực máy chủ (lần đầu tiên):\n1 2 3 The authenticity of host \u0026#39;github.com (IP_ADDRESS)\u0026#39; can\u0026#39;t be established. ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU. Are you sure you want to continue connecting (yes/no)? Đây là một tính năng bảo mật của SSH để chống lại các cuộc tấn công xen giữa (man-in-the-middle). Sau khi xác nhận, gõ yes và nhấn Enter.\nKết quả thành công:\n1 Hi username! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. Điều này xác nhận rằng cặp khóa SSH của bạn đã được thiết lập chính xác và GitHub đã xác thực thành công danh tính của bạn.\n","date":"2025-09-10T00:00:00Z","image":"https://nagih.nooblearn2code.com/thumb/setup-ssh.png","permalink":"https://nagih.nooblearn2code.com/posts/setup-ssh-for-github/","title":"Hướng dẫn thiết lập khóa SSH cho github"},{"content":"Ngay cả với một thiết lập cẩn thận, các vấn đề vẫn có thể phát sinh. Việc hiểu rõ cách chẩn đoán và khắc phục các lỗi SSH phổ biến là một kỹ năng quan trọng.\nChế độ Verbose Trước khi thử bất kỳ giải pháp nào, bước đầu tiên luôn là thu thập thêm thông tin. Tùy chọn -v (verbose) của lệnh ssh sẽ in ra chi tiết quá trình kết nối, cho bạn biết file cấu hình nào đang được đọc, khóa nào đang được thử, và chính xác lỗi xảy ra ở đâu.\n1 $ ssh -vT git@github.com Error 1: Permission denied (publickey) Ý nghĩa: Đây là lỗi xác thực phổ biến nhất. Nó có nghĩa là máy chủ GitHub đã từ chối tất cả các khóa SSH mà client của bạn cung cấp.\nCác bước kiểm tra và khắc phục:\nKiểm tra khóa trên GitHub: Đảm bảo rằng khóa công khai của bạn đã được thêm chính xác vào tài khoản GitHub.\nKiểm tra ssh-agent: Chạy ssh-add -l để xem các khóa hiện có trong agent. Nếu danh sách trống hoặc không chứa khóa bạn cần, hãy chạy lại ssh-add ~/.ssh/your_private_key để thêm nó vào.\nKiểm tra quyền truy cập file: SSH yêu cầu quyền truy cập rất nghiêm ngặt. Thư mục ~/.ssh phải có quyền là 700 (drwx−−−−−−), và file khóa riêng tư của bạn phải có quyền là 600 (−rw−−−−−−−). Sử dụng các lệnh sau để sửa:\n1 2 $ chmod 700 ~/.ssh $ chmod 600 ~/.ssh/your_private_key Kiểm tra ~/.ssh/config: Nếu bạn đang sử dụng file cấu hình, hãy kiểm tra kỹ lưỡng xem Host alias có khớp với URL remote của Git không, và IdentityFile có trỏ đến đúng file khóa riêng tư không.\nError 2: Host key verification failed Ý nghĩa: Dấu vân tay của máy chủ GitHub đã thay đổi so với lần cuối bạn kết nối. Đây là một cơ chế bảo mật quan trọng để cảnh báo về khả năng có một cuộc tấn công Man-in-the-Middle.\nCách khắc phục an toàn:\nKhông bao giờ bỏ qua cảnh báo này một cách mù quáng.\nTruy cập trang tài liệu chính thức của GitHub để xác minh dấu vân tay máy chủ mới nhất của họ.\nNếu dấu vân tay khớp, bạn có thể an toàn xóa khóa cũ khỏi file ~/.ssh/known_hosts bằng lệnh:\n1 $ ssh-keygen -R github.com Error 3: Agent admitted failure to sign using the key Ý nghĩa: ssh-agent đang chạy nhưng không thể sử dụng khóa để tạo chữ ký số cần thiết cho việc xác thực. Lỗi này đôi khi xảy ra trên các hệ thống Linux.\nCách khắc phục: Giải pháp thường rất đơn giản là tải lại khóa vào agent. Chạy lệnh ssh-add thường sẽ giải quyết được vấn đề này.\nError 4: Key is already in use Ý nghĩa: Bạn đang cố gắng thêm một khóa công khai vào tài khoản GitHub, nhưng khóa đó đã được sử dụng ở một nơi khác - hoặc trên một tài khoản người dùng khác, hoặc trong một kho lưu trữ khác dưới dạng \u0026ldquo;deploy key\u0026rdquo;.\nNguyên tắc: Một khóa SSH phải là định danh duy nhất cho một người dùng trên toàn bộ nền tảng GitHub. Khi được sử dụng làm deploy key, nó cũng phải là duy nhất cho mỗi kho lưu trữ.\nCách khắc phục:\nSử dụng lệnh sau để xác định tài khoản nào đang sử dụng khóa đó:\n1 $ ssh -T -ai ~/.ssh/your_key git@github.com Gỡ khóa khỏi tài khoản hoặc kho lưu trữ cũ, hoặc đơn giản là tạo một cặp khóa hoàn toàn mới cho mục đích sử dụng mới.\nError 5: Các Phương Pháp Bảo Mật Tốt Nhất (Best Practices) và Tổng Kết Làm chủ SSH không chỉ dừng lại ở việc thiết lập thành công. Việc duy trì một tư thế bảo mật vững chắc đòi hỏi sự chú ý liên tục. Các phương pháp tốt nhất có thể được tóm gọn trong một vòng đời bảo mật của khóa SSH.\nVòng Đời Bảo Mật Của Khóa SSH Tạo (Creation):\nThuật toán mạnh: Luôn ưu tiên sử dụng Ed25519 vì hiệu suất và bảo mật vượt trội.\nPassphrase mạnh: Luôn đặt một passphrase mạnh và duy nhất cho mỗi khóa. Sử dụng trình quản lý mật khẩu để lưu trữ an toàn các passphrase này.\nBảo vệ (Protection):\nQuyền truy cập file: Duy trì quyền truy cập file chính xác là điều bắt buộc: chmod 700 ~/.ssh và chmod 600 ~/.ssh/private_key.\nBí mật tuyệt đối: Không bao giờ chia sẻ, gửi qua email, hoặc lưu trữ khóa riêng tư của bạn ở bất kỳ đâu ngoài máy tính cá nhân đã được bảo vệ. Chỉ có khóa công khai là an toàn để chia sẻ.\nSử dụng (Usage):\nSử dụng ssh-agent: Tận dụng ssh-agent để giảm thiểu số lần phải nhập passphrase, qua đó giảm nguy cơ bị keylogger ghi lại.\nCấu hình timeout cho agent: Để tăng cường bảo mật, hãy đặt thời gian tồn tại cho các khóa trong agent bằng tùy chọn -t. Lệnh ssh-add -t 3600 sẽ yêu cầu agent \u0026ldquo;quên\u0026rdquo; khóa sau một giờ (3600 giây) không hoạt động. Điều này cực kỳ hữu ích để bảo vệ chống lại việc truy cập trái phép nếu máy tính của bạn bị bỏ lại mà không được khóa.\nBảo trì (Maintenance):\nKiểm tra định kỳ (Audit): Lên lịch (ví dụ: hàng quý) để truy cập trang cài đặt SSH trên GitHub và xem lại danh sách các khóa đã được cấp quyền. Xóa ngay lập tức bất kỳ khóa nào bạn không nhận ra, không còn sử dụng, hoặc thuộc về các thiết bị đã mất.\nXoay vòng khóa (Rotation): Một thực hành bảo mật nâng cao là định kỳ tạo một cặp khóa mới và thay thế các khóa cũ. Việc này giới hạn \u0026ldquo;cửa sổ cơ hội\u0026rdquo; cho một kẻ tấn công nếu một khóa cũ bị xâm phạm mà bạn không hề hay biết.\n","date":"2025-09-10T00:00:00Z","image":"https://nagih.nooblearn2code.com/thumb/ssh-error.png","permalink":"https://nagih.nooblearn2code.com/posts/error-handler/","title":"Hướng dẫn xử lý sự cố và các lỗi thường gặp khi thiết lập SSH"},{"content":"Những hạn chế của xác thực qua HTTPS và sự thay thế SSH\nTrong hệ sinh thái phát triển phần mềm hiện đại, GitHub không chỉ là một kho lưu trữ mã nguồn mà còn là trung tâm cộng tác, quản lý dự án và triển khai ứng dụng. Việc tương tác hiệu quả và an toàn với nền tảng này là một kỹ năng cơ bản đối với mọi nhà phát triển. Mặc dù HTTPS cung cấp một phương thức kết nối ban đầu đơn giản, việc chuyển sang sử dụng giao thức SSH (Secure Shell) là một bước tiến quan trọng, không chỉ nâng cao đáng kể mức độ bảo mật mà còn tối ưu hóa quy trình làm việc hàng ngày.\n1. Những Hạn Chế của Xác thực qua HTTPS Khi bắt đầu với Git và GitHub, hầu hết người dùng đều chọn HTTPS vì sự đơn giản của nó. Tuy nhiên, phương thức này có những hạn chế cố hữu. Xác thực qua HTTPS yêu cầu sử dụng Personal Access Token (PAT), một chuỗi ký tự hoạt động tương tự như mật khẩu.\nMặc dù dễ thiết lập, quy trình này bộc lộ sự bất tiện trong quá trình sử dụng lâu dài. Git sẽ thường xuyên yêu cầu người dùng nhập thông tin xác thực, làm gián đoạn luồng công việc. Mặc dù các công cụ hỗ trợ quản lý thông tin đăng nhập (credential helpers) có thể lưu trữ token, nhưng chúng lại đặt ra một vấn đề khác về mức độ an toàn của việc lưu trữ này. Quan trọng hơn, một PAT bị rò rỉ có thể cấp cho kẻ tấn công quyền truy cập không chỉ vào các kho lưu trữ mà còn có thể vào toàn bộ tài khoản GitHub, tùy thuộc vào phạm vi quyền hạn được cấp cho token đó.\nSo Sánh Nhanh: HTTPS và SSH trên GitHub Để tóm tắt những khác biệt chính, bảng dưới đây cung cấp một cái nhìn tổng quan về hai phương thức xác thực.\nTiêu chí HTTPS (với Personal Access Token) SSH Cơ chế Xác thực Dựa trên token (hoạt động như mật khẩu) Cặp khóa Public/Private (mật mã bất đối xứng) Mức độ Bảo mật Dễ bị lộ nếu token không được bảo vệ cẩn thận Rất cao; khóa riêng tư không bao giờ truyền qua mạng Sự tiện lợi Yêu cầu nhập lại token hoặc phụ thuộc vào credential helper Rất tiện lợi sau khi thiết lập, không cần nhập lại thông tin Thiết lập ban đầu Đơn giản, chỉ cần tạo token Phức tạp hơn một chút, yêu cầu tạo và quản lý cặp khóa Quản lý Truy cập Phân quyền thông qua phạm vi của token trên GitHub Có thể quản lý truy cập chi tiết qua từng khóa riêng lẻ ","date":"2025-09-10T00:00:00Z","permalink":"https://nagih.nooblearn2code.com/posts/https-ssh/","title":"SSH - Github"},{"content":"Thông thường khi cài windows, mặc định sẽ tự tạo phân vùng Boot EFI 512MB, bài viết này sẽ hướng dẫn bạn cách tùy biến size phân vùng EFI\nSử dụng Command Prompt trong quá trình cài đặt\nBước 1: Khởi động từ USB/DVD cài Windows\nKhi màn hình xuất hiện, nhấn Shift + F10 để mở Command Prompt Bước 2: Sử dụng DiskPart để tạo phân vùng\n1 2 3 4 5 diskpart list disk select disk 0 (Chọn ổ đĩa cần cài) clean convert gpt Bước 3: Tạo phân vùng EFI với size tùy chỉnh\n1 2 3 4 create partition efi size=4096 format quick fs=fat32 label=\u0026#34;System\u0026#34; assign letter=S active Thay 4096 bằng size bạn muốn (MB)\nBước 4: Tạo phân vùng MSR\n1 create partition msr size=128 Bước 5: Tạo phân vùng chính cho Windows\n1 2 3 4 5 create partition primary format quick fs=ntfs label=\u0026#34;Windows\u0026#34; assign letter=C active exit Thông thường hay xảy ra trường hợp ổ C đang được định nghĩa là USB Boot, lúc này hãy cứ thao tác bằng giao diện như bình thường\n","date":"2025-09-08T00:00:00Z","image":"https://nagih.nooblearn2code.com/images/image-placeholder.png","permalink":"https://nagih.nooblearn2code.com/posts/custom-windows-efi/","title":"Hướng dẫn tùy biến phân vùng EFI khi cài windows"},{"content":"Phân Tích về Kiến Trúc API Hiện Đại | Rest \u0026amp; gRPC\nGiới thiệu REST, với tư cách là một kiểu kiến trúc, đã định hình nên các API web trong hơn hai thập kỷ, trở thành tiêu chuẩn de facto nhờ tính linh hoạt và khả năng tiếp cận phổ quát. Mặt khác, gRPC, một framework mã nguồn mở hiệu suất cao do Google phát triển, nổi lên như một giải pháp được thiết kế đặc biệt cho kỷ nguyên microservice, nơi hiệu suất, độ trễ thấp và các hợp đồng dịch vụ nghiêm ngặt là tối quan trọng.\nREST REST không phải là một giao thức hay một tiêu chuẩn, mà là một kiểu kiến trúc (architectural style) được định nghĩa bởi Roy Fielding vào năm 2000. Một hệ thống được coi là \u0026ldquo;RESTful\u0026rdquo; khi nó tuân thủ một tập hợp các ràng buộc kiến trúc được thiết kế để tối ưu hóa cho một hệ thống phân tán quy mô lớn như World Wide Web.\nKiến trúc cốt lõi của REST Sức mạnh và sự phổ biến của REST bắt nguồn từ sáu ràng buộc sau:\nTách Biệt Client-Server (Client-Server Decoupling): Server và client chỉ tương tác thông qua một giao diện chuẩn hóa. Sự tách biệt này cho phép chúng phát triển độc lập - client không cần biết về logic nghiệp vụ của server, và server không cần biết về giao diện của client miễn là hợp đồng giao diện không thay đổi.\nVô Trạng Thái (Statelessness): Trong kiến trúc REST, mỗi yêu cầu từ client đến server phải chứa tất cả thông tin cần thiết để server hiểu và xử lý nó. Server không lưu trữ bất kỳ trạng thái phiên nào của client giữa các yêu cầu.\nGiao Diện Đồng Nhất (Uniform Interface): Được thiết kế để đơn giản hóa và tách rời kiến trúc. Nó bao gồm 4 ràng buộc con:Đ\nIdentification of resources: Mọi tài nguyên đều được định danh duy nhất thông qua một URI (Uniform Resource Identifier).\nVí dụ: https://.../osers/123 thì 123 là ID duy nhất của order đó. Manipulation of resources through representations: Client tương tác với tài nguyên thông qua các biểu diễn của chúng (ví dụ: một tài liệu JSON hoặc XML). Biểu diễn này chứa đủ thông tin để client có thể sửa đổi hoặc xóa tài nguyên trên server.\nSelf-descriptive: Mỗi thông điệp chứa đủ thông tin để mô tả cách xử lý nó. Ví dụ, một header Content-Type cho biết định dạng media của thông điệp.\nHATEOAS: Client chỉ cần biết URI khởi đầu. Sau đó, tất cả các hành động và tài nguyên trong tương lai mà client có thể truy cập đều được khám phá thông qua các siêu liên kết có trong các phản hồi từ server.\nCacheability: Cho phép client hoặc các máy chủ trung gian lưu trữ các phản hồi, giúp giảm độ trễ và tải cho server.\nLayered System: Client không thể biết liệu nó đang kết nối trực tiếp đến server cuối cùng hay một máy chủ trung gian (microservices).\nCode on Demand: Đây là ràng buộc duy nhất không bắt buộc. Nó cho phép server tạm thời mở rộng hoặc tùy chỉnh chức năng của client bằng cách truyền mã thực thi (ví dụ: JavaScript).\nTriển khai đển hình Thông thường, REST được triển khai trên HTTP/1.1. Các tài nguyên được thao tác bằng HTTP tiêu chuẩn (GET, POST, PUT, DELETE), và dữ liệu thường được trao đổi bằng định dạng JSON.\nFramework gRPC - Hiệu Suất và Gọi Thủ Tục Từ Xa gRPC (gRPC Remote Procedure Call) là một framework RPC hiện đại, được xây dựng trên nền tảng các công nghệ hiệu suất cao. Thay vì tập trung vào tài nguyên, gRPC tập trung vào các dịch vụ và các thủ tục (hàm) mà client có thể gọi từ xa. Kiến trúc của nó được xây dựng trên ba trụ cột chính: Protocol Buffers, HTTP/2, và các mô hình streaming tiên tiến.\nMô Hình RPC Cốt lõi của gRPC là mô hình Gọi Thủ Tục Từ Xa (Remote Procedure Call). Ý tưởng là cho phép một client gọi một hàm trên một server từ xa một cách minh bạch, như thể nó là một lời gọi hàm cục bộ. Framework sẽ trừu tượng hóa toàn bộ quá trình giao tiếp mạng phức tạp, bao gồm tuần tự hóa dữ liệu, kết nối và xử lý lỗi.\n1. Protocol Buffers (Protobuf) Protobuf là Ngôn ngữ Định nghĩa Giao diện (Interface Definition Language - IDL) mặc định của gRPC. Nó đóng vai trò là bản thiết kế cho cả dịch vụ và cấu trúc dữ liệu.\nDesign-first: Với gRPC, bắt đầu bằng cách định nghĩa các dịch vụ cấu trúc dữ liệu trong một tệp .proto. Tệp này hoạt động như một hợp đồng chính thức giữa client và server.\nTạo mã tự động: Trình biên dịch protoc của Protobuf sau đó sẽ đọc tệp .proto này và tự động tạo ra các client stub (phía client) và server skeleton (phía server) với kiểu dữ liệu mạnh (strongly-typed).\n2. Giao thức HTTP/2 gRPC được xây dựng nguyên bản trên HTTP/2, một bản nâng cấp lớn so với HTTP/1.1, và tận dụng triệt để các tính năng của nó để đạt được hiệu suất vượt trội.\nBinary Framing: HTTP/2 truyền dữ liệu dưới dạng các khung nhị phân, hiệu quả hơn so với định dạng văn bản của HTTP/1.1.\nFull Multiplexing: Đây là tính năng đột phá nhất. HTTP/2 cho phép gửi và nhận nhiều yêu cầu và phản hồi đồng thời trên một kết nối TCP duy nhất, loại bỏ hoàn toàn vấn đề \u0026ldquo;chặn đầu hàng\u0026rdquo; (head-of-line blocking) của HTTP/1.1.\nHeader Compression: Sử dụng thuật toán HPACK, HTTP/2 nén các header của yêu cầu và phản hồi, giảm đáng kể dữ liệu dư thừa và chi phí mạng.\nHỗ trợ streaming nguyên bản: HTTP/2 được thiết kế để hỗ trợ streaming dữ liệu, một nền tảng cơ bản cho các mô hình giao tiếp tiên tiến của gRPC.\n3. Các mô hình Streaming tiên tiến Nhờ vào nền tảng HTTP/2, gRPC hỗ trợ bốn mô hình giao tiếp, mang lại sự linh hoạt vượt trội so với mô hình yêu cầu-phản hồi đơn lẻ của REST:\nUnary RPC: Mô hình yêu cầu-phản hồi cổ điển, tương tự như một lời gọi REST. Client gửi một yêu cầu duy nhất và nhận lại một phản hồi duy nhất.\nServer Streaming RPC: Client gửi một yêu cầu và nhận lại một luồng (stream) các phản hồi từ server. Rất hữu ích cho các trường hợp như đăng ký nhận thông báo hoặc cập nhật dữ liệu trực tiếp.\nClient Streaming RPC: Client gửi một luồng các thông điệp đến server, và server sẽ phản hồi bằng một thông điệp duy nhất sau khi đã nhận tất cả. Thích hợp cho việc tải lên các tệp lớn hoặc gửi dữ liệu đo lường từ xa.\nBidirectional Streaming RPC: Cả client và server đều có thể gửi các luồng thông điệp cho nhau một cách độc lập trên cùng một kết nối. Mô hình này lý tưởng cho các ứng dụng tương tác thời gian thực như chat hoặc game nhiều người chơi.\nBảng So Sánh Tổng Quan Tiêu Chí REST gRPC Mô hình Dựa trên tài nguyên (Resource-based) Gọi thủ tục từ xa (RPC) Tiêu chuẩn hóa Không có tiêu chuẩn chính thức, là một tập hợp các nguyên tắc Được định nghĩa rõ ràng và chi tiết Giao thức vận chuyển Thường là HTTP/1.1 (có thể dùng HTTP/2) HTTP/2 Định dạng dữ liệu mặc định JSON (cũng hỗ trợ XML, text, v.v.) Protocol Buffers (Protobuf) Các chế độ dịch vụ Chỉ Unary (yêu cầu-phản hồi đơn lẻ) Unary, Client streaming, Server streaming, Bidirectional streaming Thiết kế API Thường là Code-first (mã trước) Design-first (thiết kế trước) Mức độ ghép nối Ghép nối lỏng (Loosely coupled) Ghép nối chặt (Tightly coupled) Tạo mã Yêu cầu công cụ bên thứ ba (ví dụ: OpenAPI Generator) Tích hợp sẵn (thông qua trình biên dịch protoc) Hỗ trợ trình duyệt Hỗ trợ nguyên bản và phổ quát Yêu cầu lớp proxy (gRPC-Web) Lưu cache Hỗ trợ tốt thông qua các cơ chế HTTP tiêu chuẩn Không hỗ trợ mặc định, cần tự triển khai Triết Lý và Thiết Kế Sự khác biệt cơ bản nhất giữa REST và gRPC nằm ở triết lý thiết kế của chúng: \u0026ldquo;cái gì\u0026rdquo; so với \u0026ldquo;làm gì\u0026rdquo;.\nREST: Tập trung vào việc phơi bày các thực thể hoặc tài nguyên (danh từ). Client tương tác với các tài nguyên này bằng CRUD (Create, Read, Update, Delete) và các nguyên tắc lập trình hướng đối tượng.\ngRPC: Tập trung vào việc phơi bày các hành động hoặc thủ tục (động từ). Client gọi các hàm cụ thể trên server, ví dụ CreateUser(user_details). Đây là một thiết kế hướng dịch vụ, ánh xạ trực tiếp đến logic ứng dụng.\nCó một mối quan hệ nghịch đảo giữa sự dễ dàng trong thiết lập/gỡ lỗi ban đầu và khả năng bảo trì lâu dài trong các hệ thống đa ngôn ngữ. REST rất dễ bắt đầu, nhưng có thể dẫn đến các vấn đề tích hợp sau này do thiếu một hợp đồng chính thức. gRPC đòi hỏi nhiều công sức thiết lập hơn (định nghĩa tệp .proto, tạo mã), nhưng nó cung cấp một nền tảng vững chắc, an toàn về kiểu dữ liệu giúp ngăn ngừa các lỗi tích hợp, đặc biệt là trong kiến trúc microservices với nhiều nhóm và ngôn ngữ khác nhau.\n","date":"2025-08-28T00:00:00Z","image":"https://nagih.nooblearn2code.com/image-placeholder.png","permalink":"https://nagih.nooblearn2code.com/posts/rest-grpc/","title":"REST và gRPC"},{"content":"6 Cấp Độ Trưởng Thành Từ Deploy Thủ Công Đến Vận Hành Tinh Gọn\nLevel 0: Deploy Thủ Công Công cụ và Quy trình Quy trình thủ công: Việc triển khai được thực hiện bằng cách kết nối thủ công đến máy chủ thông qua các giao thức như FTP, SCP, hoặc SSH, sau đó sao chép từng tệp.\nQuản lý mã nguồn hỗn loạn: Nếu có sử dụng Git, quy trình làm việc thường là \u0026ldquo;Centralized Workflow\u0026rdquo;, nơi mọi người đều đẩy (push) mã nguồn trực tiếp lên nhánh chính (main hoặc master), gây ra sự bất ổn định và khó theo dõi.\nRủi ro và Nỗi đau Rủi ro bảo mật: Giao thức FTP truyền thông tin đăng nhập (username, password) dưới dạng văn bản thuần (plain text), khiến chúng dễ dàng bị \u0026ldquo;bắt\u0026rdquo; bởi bất kỳ ai trên mạng. Dữ liệu truyền đi cũng không được mã hóa, có nguy cơ bị tấn công xen giữa (man-in-the-middle), nơi kẻ tấn công có thể chèn mã độc vào các tệp đang được triển khai mà không bị phát hiện.\nHệ thống cực kỳ mong manh: Quy trình này rất dễ xảy ra lỗi. Chỉ cần quên một tệp, sao chép sai thư mục, hoặc một tệp truyền bị lỗi cũng có thể làm sập toàn bộ hệ thống.\nKhông có cơ chế Rollback: Khi một lần triển khai thất bại, không có cách nào dễ dàng và tự động để quay trở lại phiên bản ổn định trước đó.\nLevel 1: Script và Quản Lý Mã Nguồn Có Cấu Trúc Công cụ và Quy trình Sự ra đời của Script: \u0026ldquo;Deployment checklist\u0026rdquo; từ level 0 được mã hóa thành một kịch bản (script) triển khai đơn giản, thường sử dụng Bash. Script này tự động hóa các bước kết nối đến máy chủ, lấy mã nguồn mới nhất từ kho chứa, và khởi động lại các dịch vụ.\nQuy trình Git có cấu trúc: Nhóm nhận ra rằng việc đẩy trực tiếp lên nhánh main là không bền vững. Họ áp dụng một chiến lược phân nhánh chính thức, phổ biến nhất là Feature Branch Workflow.\nNhánh main giờ đây được coi là \u0026ldquo;bất khả xâm phạm\u0026rdquo; và luôn ở trạng thái sẵn sàng để triển khai.\nTất cả công việc mới (tính năng, sửa lỗi) được thực hiện trên các nhánh riêng biệt.\nCác thay đổi được tích hợp trở lại vào main thông qua Pull Request (hoặc Merge Request), cho phép thực hiện quy trình đánh giá mã nguồn (code review).\nLợi ích và Những Vấn đề Còn Tồn Tại Lợi ích: Bản thân quy trình triển khai giờ đây đã đáng tin cậy và nhất quán hơn. Nhánh main ổn định hơn. Việc đánh giá mã nguồn giúp cải thiện chất lượng.\nVấn đề còn tồn tại: Script không xử lý tốt các trường hợp thất bại. Không có kiểm thử tự động, lỗi vẫn được triển khai, chỉ là một cách nhất quán hơn. Các môi trường (development, staging, production) vẫn được cấu hình thủ công và không nhất quán, dẫn đến vấn đề kinh điển \u0026ldquo;nó chạy trên máy của tôi\u0026rdquo;.\nLevel 2: CI/CD Đây là một bước nhảy vọt. Trọng tâm chuyển từ một script triển khai đơn lẻ sang một đường ống (pipeline) tự động hóa hoàn toàn, hoạt động như một \u0026ldquo;nhà máy\u0026rdquo; trung tâm cho việc phân phối phần mềm. Đây là nơi thế giới \u0026ldquo;Dev\u0026rdquo; và \u0026ldquo;Ops\u0026rdquo; thực sự bắt đầu hợp nhất.\nCốt Lõi Tích hợp Liên tục (Continuous Integration - CI): Là thực tiễn tự động hóa việc tích hợp các thay đổi mã nguồn từ nhiều nhà phát triển vào một dự án duy nhất. Mỗi lần đẩy mã nguồn lên một nhánh sẽ kích hoạt một quy trình xây dựng (build) tự động và một bộ các bài kiểm thử tự động (unit test, integration test).\nPhân phối Liên tục (Continuous Delivery - CD): Là một phần mở rộng của CI. Sau khi các giai đoạn xây dựng và kiểm thử thành công, phần mềm sẽ được đóng gói và triển khai tự động đến một hoặc nhiều môi trường phi sản xuất (như staging). Việc triển khai lên production thường là một bước thủ công, chỉ cần một cú nhấp chuột.\nTriển khai Liên tục (Continuous Deployment - cũng là CD): Là hình thức tiên tiến nhất, nơi mọi thay đổi vượt qua tất cả các bài kiểm thử tự động đều được triển khai tự động lên production mà không cần sự can thiệp của con người.\nCông cụ Việc lựa chọn một công cụ CI/CD là một quyết định quan trọng ở giai đoạn này. Bảng dưới đây so sánh các lựa chọn phổ biến nhất.\nTính năng Jenkins GitLab CI GitHub Actions Thiết lập \u0026amp; Lưu trữ Cần cài đặt thủ công, thiết lập agent, tự lưu trữ (on-premise/cloud). Tích hợp sẵn trong GitLab, không cần cài đặt riêng. Tích hợp sẵn trong GitHub, không cần cài đặt riêng. Cấu hình Jenkinsfile (viết bằng Groovy) hoặc qua giao diện người dùng (UI). Tệp YAML (.gitlab-ci.yml) trong kho mã nguồn. Tệp YAML trong thư mục .github/workflows. Hệ sinh thái \u0026amp; Mở rộng Cực kỳ mạnh mẽ với hơn 1800 plugin, tùy biến cao nhưng có thể phức tạp và dễ gặp vấn đề tương thích. Tích hợp sâu với các tính năng của GitLab. Hệ sinh thái plugin nhỏ hơn Jenkins. Thị trường (Marketplace) rộng lớn với các \u0026ldquo;Actions\u0026rdquo; tái sử dụng. Dễ dàng tạo action tùy chỉnh. Trường hợp sử dụng lý tưởng Các quy trình phức tạp, yêu cầu tùy biến sâu, môi trường on-premise hoặc các hệ thống cũ (legacy). Các nhóm đã và đang sử dụng GitLab làm nền tảng chính, muốn một giải pháp \u0026ldquo;tất cả trong một\u0026rdquo;. Các nhóm ưu tiên GitHub, dự án mã nguồn mở, startup, cần sự đơn giản và khởi đầu nhanh chóng. Lợi ích và Thách thức Mới Lợi ích: Vòng lặp phản hồi nhanh hơn đáng kể, chất lượng mã nguồn được cải thiện, giảm rủi ro triển khai và tăng năng suất của nhà phát triển.\nThách thức: Bản thân \u0026ldquo;đường ống CI/CD\u0026rdquo; trở thành một phần mềm phức tạp cần được bảo trì. Các nhóm giờ đây phải đối mặt với những vấn đề mới như các bài kiểm thử chạy chậm hoặc không ổn định (flaky tests), quản lý các phụ thuộc phức tạp, và vấn đề dai dẳng về \u0026ldquo;trôi dạt môi trường\u0026rdquo; (environment drift), nơi môi trường staging và production không giống hệt nhau.\nLevel 3: Hạ Tầng Dưới Dạng Mã (IaC) và Container Hóa Để giải quyết vấn đề trôi dạt môi trường và làm cho việc quản lý hạ tầng trở nên nghiêm ngặt như phát triển ứng dụng, các nhóm áp dụng triết lý \u0026ldquo;mọi thứ đều là mã nguồn\u0026rdquo;.\nCốt Lõi Hạ tầng dưới dạng mã (Infrastructure as Code - IaC): Là việc quản lý và cấp phát hạ tầng (máy chủ, mạng, cơ sở dữ liệu) thông qua các tệp định nghĩa mà máy có thể đọc được (mã nguồn), thay vì cấu hình thủ công. Có hai cách tiếp cận chính:\nDeclarative: Bạn định nghĩa trạng thái cuối cùng mong muốn của hạ tầng. Công cụ (ví dụ: Terraform) sẽ tự tìm cách để đạt được trạng thái đó. Đây là cách tiếp cận chủ đạo trong IaC hiện đại.\nImperative: Bạn viết các kịch bản chỉ định các bước chính xác cần thực hiện để cấu hình hạ tầng (ví dụ: Ansible, Chef, Puppet).\nContainer hóa với Docker: Là người bạn đồng hành hoàn hảo của IaC. Docker giải quyết vấn đề \u0026ldquo;nó chạy trên máy của tôi\u0026rdquo; bằng cách đóng gói một ứng dụng và tất cả các phụ thuộc của nó vào một đơn vị duy nhất, được tiêu chuẩn hóa và bị cô lập gọi là container.\nDockerfile: \u0026ldquo;Công thức\u0026rdquo; hay bản thiết kế để xây dựng một image.\nImage: Một mẫu chỉ đọc (read-only) chứa ứng dụng và môi trường của nó.\nContainer: Một thực thể đang chạy (running instance) của một image. Nó nhẹ và có tính di động cao.\nQuy trình Mới Đường ống CI/CD được nâng cấp. Nó không còn chỉ triển khai mã nguồn; nó xây dựng một Docker image (một tạo phẩm nhất quán được đảm bảo) và sử dụng các công cụ IaC như Terraform để cấp phát một môi trường giống hệt nơi container sẽ chạy.\nLợi ích và Nút thắt Cổ chai Tiếp theo Lợi ích: Vấn đề trôi dạt môi trường được loại bỏ. Các lần triển khai giờ đây có tính nhất quán và độ tin cậy cao trên các môi trường dev, staging và production. Các thay đổi về hạ tầng được quản lý phiên bản, được đánh giá và có thể kiểm tra lại.\nNút thắt cổ chai tiếp theo: Tổ chức bây giờ đã thành công và có hàng trăm hoặc hàng nghìn container. Làm thế nào để quản lý chúng? Làm thế nào để xử lý mạng, mở rộng quy mô và kiểm tra sức khỏe cho tất cả các container này? Đây là vấn đề của việc điều phối (orchestration).\nLevel 4: Điều Phối Container và Kiến Trúc Cloud-Native Trọng tâm chuyển từ việc quản lý các container riêng lẻ sang quản lý một ứng dụng phân tán bao gồm nhiều container ở quy mô lớn. Điều này đòi hỏi một \u0026ldquo;nhạc trưởng\u0026rdquo; cho \u0026ldquo;dàn nhạc\u0026rdquo; container.\nCốt Lõi: Kubernetes (K8s) Kubernetes: Là hệ thống mã nguồn mở, tiêu chuẩn de-facto của ngành công nghiệp, dùng để tự động hóa việc triển khai, mở rộng quy mô và quản lý các ứng dụng được container hóa. Nó giải quyết vấn đề chạy các hệ thống phân tán một cách linh hoạt và có khả năng phục hồi.\n**Các đối tượng Kubernetes chính:\nPod: Đơn vị triển khai nhỏ nhất, cơ bản nhất trong Kubernetes. Nó là một lớp vỏ bọc quanh một hoặc nhiều container, chia sẻ tài nguyên lưu trữ và mạng. Hãy coi nó như \u0026ldquo;nguyên tử\u0026rdquo; cơ bản của một ứng dụng K8s.\nDeployment: Một đối tượng cấp cao hơn mô tả trạng thái mong muốn cho ứng dụng của bạn. Nó nói với Kubernetes rằng \u0026ldquo;Tôi muốn có 3 bản sao (replica) của pod máy chủ web của tôi chạy mọi lúc.\u0026rdquo; Bộ điều khiển Deployment (Deployment Controller) sẽ làm việc để biến trạng thái này thành hiện thực.\nService: Một lớp trừu tượng định nghĩa một tập hợp logic các Pod và một chính sách để truy cập chúng. Nó cung cấp một địa chỉ IP và tên DNS ổn định, để các phần khác của ứng dụng (hoặc người dùng bên ngoài) có thể kết nối đến các Pod, ngay cả khi chúng được tạo ra và phá hủy.\nLợi ích và Sự Phức Tạp Mới Lợi ích: Tổ chức đạt được khả năng mở rộng quy mô thực sự, tự phục hồi (Kubernetes tự động khởi động lại các container bị lỗi), và tính sẵn sàng cao. Các bản cập nhật và quay lui (rolling updates and rollbacks) giờ đây được quản lý một cách khai báo và an toàn.\nSự phức tạp mới: Bản thân Kubernetes là một hệ thống cực kỳ phức tạp. Việc học nó rất khó khăn. Quản lý, giám sát và bảo mật một cụm Kubernetes (cluster) trở thành một công việc toàn thời gian. Thách thức mới không còn là \u0026ldquo;làm thế nào để chạy ứng dụng của chúng ta?\u0026rdquo; mà là \u0026ldquo;làm thế nào để chạy Kubernetes một cách đáng tin cậy?\u0026rdquo;\nLevel 5: Vận Hành Dựa Trên Dữ Liệu (SRE, GitOps, \u0026amp; Observability) Đây là level cao nhất. Các hoạt động vận hành không còn là bị động hay thậm chí chỉ là tự động; chúng trở nên chủ động, được điều khiển bằng dữ liệu và được xem như một ngành kỹ thuật phần mềm.\nCốt Lõi Site Reliability Engineering - SRE: Một phương pháp triển khai cụ thể của DevOps, bắt nguồn từ Google. Nó coi các vấn đề vận hành như những bài toán phần mềm.\nSLI, SLO, và Ngân sách Lỗi (Error Budgets): SRE cung cấp một khung làm việc toán học cho độ tin cậy.\nSLI (Service Level Indicator - Chỉ số Cấp độ Dịch vụ): Một thước đo định lượng về một khía cạnh nào đó của dịch vụ (ví dụ: độ trễ yêu cầu, tỷ lệ lỗi).\nSLO (Service Level Objective - Mục tiêu Cấp độ Dịch vụ): Một giá trị mục tiêu cho một SLI trong một khoảng thời gian (ví dụ: 99.9% yêu cầu được phục vụ trong \u0026lt;200ms).\nError Budget (Ngân sách Lỗi): Là phần nghịch đảo của SLO (100%−SLO). Đây là lượng \u0026ldquo;không đáng tin cậy\u0026rdquo; mà nhóm được phép \u0026ldquo;tiêu thụ\u0026rdquo;. Nếu ngân sách lỗi còn dương, nhóm có thể phát hành tính năng mới. Nếu nó cạn kiệt, mọi công việc phải chuyển sang cải thiện độ tin cậy.\nSRE và DevOps: SRE trả lời câu hỏi \u0026ldquo;làm thế nào\u0026rdquo; cho cái \u0026ldquo;gì\u0026rdquo; của DevOps.\nGitOps: Sự tiến hóa của IaC và CI/CD. Git là nguồn chân lý duy nhất (single source of truth) cho toàn bộ trạng thái hệ thống (hạ tầng và ứng dụng).\nQuy trình làm việc: Các thay đổi được thực hiện thông qua Pull Request đến một kho chứa Git. Một agent bên trong cụm Kubernetes (như Argo CD hoặc Flux) liên tục so sánh trạng thái thực tế với trạng thái được khai báo trong Git và tự động điều chỉnh bất kỳ sự khác biệt nào.\nArgo CD và Flux: Argo CD giống một nền tảng hoàn chỉnh, có giao diện người dùng, trong khi Flux là một bộ công cụ mô-đun hơn, tập trung vào dòng lệnh và thường được coi là gần gũi hơn với cách tiếp cận \u0026ldquo;thuần Kubernetes\u0026rdquo;.\nKhả năng Quan sát (Observability): Vượt ra ngoài việc giám sát đơn giản (\u0026ldquo;máy chủ có hoạt động không?\u0026rdquo;) để đạt đến sự hiểu biết sâu sắc về hệ thống (\u0026ldquo;tại sao máy chủ lại chậm đối với người dùng ở khu vực cụ thể này?\u0026rdquo;).\nBa Trụ cột của Observability:\nLogs: Các bản ghi chi tiết, có dấu thời gian về các sự kiện riêng lẻ.\nMetrics: Dữ liệu số, được tổng hợp theo thời gian (ví dụ: mức sử dụng CPU, số lượng yêu cầu).\nTraces: Cho thấy hành trình từ đầu đến cuối của một yêu cầu khi nó di chuyển qua một hệ thống phân tán.\nCông cụ: Các ngăn xếp công cụ phổ biến bao gồm Prometheus \u0026amp; Grafana để theo dõi số liệu và trực quan hóa, và ELK Stack (Elasticsearch, Logstash, Kibana) để quản lý nhật ký.\nKết luận Hành động Đánh giá Mức độ Trưởng thành: Các tổ chức nên sử dụng mô hình này để xác định vị trí hiện tại của nhóm mình.\nTập trung vào Nút thắt Cổ chai Tiếp theo: Thay vì cố gắng nhảy từ Cấp độ 0 lên Cấp độ 5, chìa khóa là xác định điểm yếu lớn nhất hiện tại và áp dụng các thực tiễn của cấp độ tiếp theo để giải quyết nó. Quá trình này nên diễn ra từ từ và có kế hoạch.\nLộ trình Kỹ năng Tóm tắt: Để phát triển cá nhân hoặc xây dựng đội ngũ, một lộ trình kỹ năng có cấu trúc là cần thiết:\nNền tảng: Ngôn ngữ lập trình (Python/Go), Linux/Shell Scripting, Git.\nDevOps Cốt lõi: Công cụ CI/CD (Jenkins, GitLab CI, GitHub Actions), IaC (Terraform), Containers (Docker).\nNâng cao/Cloud-Native: Kubernetes, Nền tảng Đám mây (AWS/GCP/Azure), Giám sát/Quan sát (Prometheus, Grafana).\nTinh hoa/SRE: Hiểu biết sâu về hệ thống phân tán, triển khai SLI/SLO, tự động hóa nâng cao.\n","date":"2025-08-17T00:00:00Z","image":"https://nagih.nooblearn2code.com/images/image-placeholder.png","permalink":"https://nagih.nooblearn2code.com/posts/6-level-deploy/","title":"6 Level Deploy"},{"content":"9 nguyên tắc cốt lõi và một số kỹ năng mở rộng khi khởi tạo bảng trong MySQL, đảm bảo ứng dụng không chỉ chạy đúng mà còn hiệu quả và dễ bảo trì\n1. Mọi Table Luôn Phải Có Các Column Mặc Định\nMột thiết kế table hoàn chỉnh cần có ít nhất 5 trường mặc định để theo dõi lịch sử và tính nhất quán của dữ liệu:\nversion: Ghi lại số lần chỉnh sửa của table, đồng thời liên quan đến các khái niệm khóa lạc quan (optimistic lock) và khóa bi quan (pessimistic lock)\ncreator_id: (Tùy chọn, tùy thuộc vào công ty) Ai là người tạo bản ghi này\nmodifier: Ai là người cuối cùng sửa đổi bản ghi, quan trọng để biết hành động cuối cùng trên table\ncreate_at: Thời gian bản ghi được tạo\nupdate_at: Thời gian bản ghi được cập nhật lần cuối\n2. Giải Thích Ngữ Nghĩa Các Column Bằng Comment\nKhi viết DDL (Data Definition Language) cho MySQL, PostgreSQL, hoặc bất kỳ hệ quản trị cơ sở dữ liệu nào, hãy luôn thêm comment giải thích ý nghĩa của từng column. Việc comment rõ ràng giúp các thành viên mới gia nhập team dễ dàng hiểu và làm quen với cấu trúc dữ liệu, tránh sự hiểu lầm về ngữ nghĩa của các trường\n3. Xóa Dữ Liệu Không Phải Xóa \u0026ldquo;Bay\u0026rdquo; (Xóa Logic)\nKhông bao giờ sử dụng lệnh DELETE để xóa vật lý dữ liệu trực tiếp trong môi trường sản phẩm. Thay vào đó, hãy sử dụng phương pháp xóa logic (soft delete) bằng cách thêm một trường để đánh dấu bản ghi đã bị xóa hay chưa, và thời gian xóa\nBan đầu có thể sử dụng hai trường: is_deleted (0: hoạt động, 1: đã xóa) và deleted_at (thời gian xóa)\nCách tối ưu hơn là chỉ sử dụng một trường deleted_at: Nếu giá trị là NULL nghĩa là bản ghi chưa bị xóa; nếu có giá trị thời gian, đó là thời gian bản ghi bị xóa\nLưu ý: Giá trị NULL có thể gây nhược điểm nghiêm trọng về hiệu suất index khi dữ liệu lớn, do đó cần cân nhắc kỹ hoặc tìm hiểu sâu hơn về NULL trong database\n4. Quy Ước Đặt Tên Với Prefix (Tiền Tố)\nCác trường (field) trong table nên có các tiền tố (prefix) để dễ dàng xác định nguồn gốc khi các bảng được join lại với nhau. Ví dụ, bảng account có thể có trường acc_number. Việc này cực kỳ quan trọng vì trong thực tế, chúng ta ít khi làm việc với dữ liệu độc lập mà thường phải join nhiều bảng (ít nhất 3 bảng là nguyên tắc làm việc). Nếu không có prefix, việc phân biệt ID hay create_at thuộc về bảng nào khi join sẽ gây ra sự hiểu nhầm và lỗi\n5. Tách Bảng Khi Có Quá Nhiều Trường (Vertical Partitioning)\nMột table không nên có quá nhiều trường (column), tối đa khoảng 20 trường. Nếu vượt quá, cần phải tách bảng dọc (vertical partition). Bảng có nhiều trường sẽ làm dữ liệu lưu trữ lớn, giảm hiệu suất truy vấn và tốn bộ nhớ\nTách bảng: Chia thành một bảng chính chứa các trường được truy cập thường xuyên và quan trọng (ví dụ: title, status, thumbnail của một bài post), và một bảng chi tiết chứa các trường ít quan trọng hơn hoặc chỉ hiển thị khi người dùng click vào (ví dụ: content, description)\nMối quan hệ giữa hai bảng này thường là 1-1, giúp việc join đơn giản và hiệu quả, không ảnh hưởng đến hiệu suất\n6. Chọn Kiểu Dữ Liệu và Độ Dài Thích Hợp\nMột hệ thống tốt không chỉ chạy đúng mà còn phải chạy hiệu quả. Việc chọn kiểu dữ liệu và độ dài phù hợp giúp:\nTiết kiệm bộ nhớ (memory) và dung lượng đĩa (disk)\nTối ưu tốc độ query\nGiảm tỷ lệ Input/Output (I/O). Ví dụ:\nTrường title không nên để VARCHAR(255) nếu độ dài thực tế chỉ khoảng 100 ký tự (như tiêu đề video YouTube/TikTok)\nTrường language chỉ cần CHAR(2) (ví dụ: \u0026ldquo;en\u0026rdquo;, \u0026ldquo;vi\u0026rdquo;) thay vì VARCHAR dài\nTrường status chỉ nên dùng TINYINT (kích thước 1 byte, lưu trữ 0-255) thay vì INT (kích thước 4 byte, lưu trữ 0-4 tỷ ID) nếu các giá trị chỉ là 1, 2, 3\n7. Nguyên Tắc Not NULL\nKhông nên cho phép giá trị NULL bừa bãi. NULL không phải là một số, một chuỗi hay một biến boolean; nó là một vùng không xác định. NULL có thể:\nLàm hỏng logic nghiệp vụ nếu quên xử lý\nGây lỗi index khi so sánh bằng NULL (ví dụ WHERE column IS NULL thường không sử dụng index hiệu quả). Các trường bắt buộc phải có giá trị (như title, status, create_at) nên được khai báo là NOT NULL. Khi không có giá trị, hãy sử dụng DEFAULT đi kèm với NOT NULL\n8. Chiến Lược Đánh Index\nIndex là chìa khóa để tối ưu hiệu suất truy vấn\nNên đánh index cho các trường ít trùng lặp và thường xuyên được sử dụng trong truy vấn, ví dụ: creator_id và create_at (quan trọng khi truy vấn theo thời gian). Luôn có prefix idx_ cho các index\nTrường deleted_at luôn cần được đánh index để tránh hiển thị các bản ghi đã bị xóa ra công khai, điều này có thể dẫn đến các vấn đề pháp lý (ví dụ: GDPR của Châu Âu)\nQUY TẮC VÀNG: Không nên đánh index cho các trường có dữ liệu lặp lại quá nhiều (ví dụ: trường status mà 90% bản ghi có cùng một giá trị). Việc đánh index trong trường hợp này thậm chí có thể làm chậm truy vấn hơn so với không đánh index, vì database sẽ quét toàn bộ table thay vì sử dụng index\nGiải pháp thay thế khi cần truy vấn các trường có nhiều giá trị trùng lặp:\nThêm trường tiền tố phạm vi thời gian: Ví dụ, kết hợp status với create_at theo phạm vi thời gian (WHERE status = 1 AND create_at BETWEEN '2025-06-15 00:00 :00' AND '2025-06-15 23:59:59') để giúp index hoạt động hiệu quả hơn\nChia table thành các phân vùng (Partition): Phù hợp với dữ liệu lớn, giúp chia nhỏ dữ liệu. Tuy nhiên, Partition không thay thế được index và có nhược điểm riêng, chỉ nên dùng khi thực sự cần và hiểu rõ\nTạo View: View có thể hoạt động rất tốt trong các truy vấn với stored procedure hoặc function, giúp truy vấn nhanh hơn khi dữ liệu được lặp lại và cảm thấy đúng đánh lặp lại\n9. Nguyên Tắc Normal Form (3NF, 4NF, 5NF)\nNormalization là một nguyên tắc cơ bản trong thiết kế database nhằm giảm thiểu sự dư thừa dữ liệu và cải thiện tính toàn vẹn dữ liệu\n3NF (Third Normal Form) là một nguyên tắc cơ bản cần nắm vững\nNgoài ra, còn có các dạng chuẩn mở rộng hơn như 4NF (Fourth Normal Form) và 5NF (Fifth Normal Form), giúp tối ưu hóa hơn nữa về sự mở rộng và tính linh hoạt của database\nViệc tìm hiểu sâu về các Normal Form này sẽ giúp bạn thiết kế database hiệu quả hơn cho các mô hình kinh doanh phức tạp\n","date":"2025-08-12T00:00:00Z","image":"https://nagih.nooblearn2code.com/images/image-placeholder.png","permalink":"https://nagih.nooblearn2code.com/posts/9-mysql-table-design-rules-skills/","title":"9 MySQL Table Design Rules \u0026 Skills"},{"content":"Chúng ta đã biết cache rất hữu ích, nhưng nó có một giới hạn cố hữu: dung lượng nhỏ. Bộ nhớ tốc độ cao (như RAM) rất đắt đỏ, vì vậy cache không thể lưu trữ mọi thứ.\nCác Chính Sách \u0026ldquo;Dọn Dẹp\u0026rdquo; Chúng ta đã biết cache rất hữu ích, nhưng nó có một giới hạn cố hữu: dung lượng nhỏ. Bộ nhớ tốc độ cao (như RAM) rất đắt đỏ, vì vậy cache không thể lưu trữ mọi thứ.\nĐiều này dẫn đến một vấn đề không thể tránh khỏi: khi cache đã đầy và một mục dữ liệu mới cần được thêm vào, hệ thống phải quyết định loại bỏ một mục dữ liệu cũ để nhường chỗ. Quá trình này được gọi là Eviction.\nThuật toán được sử dụng để quyết định mục nào sẽ bị loại bỏ được gọi là Chính sách dọn dẹp (Eviction Policy).\nCác chiến lược dọn dẹp phổ biến FIFO (First-In, First-Out - Vào trước, Ra trước):\nNguyên tắc: Nó loại bỏ mục dữ liệu cũ nhất, bất kể nó có được sử dụng thường xuyên hay không. Nó hoạt động giống như một hàng đợi (queue).\nƯu điểm: Rất dễ cài đặt và có chi phí quản lý thấp.\nNhược điểm: Thường không hiệu quả vì nó có thể loại bỏ một mục rất phổ biến chỉ vì nó được nạp vào cache từ lâu.\nLRU (Least Recently Used - Ít được sử dụng gần đây nhất):\nNguyên tắc: Loại bỏ mục dữ liệu mà đã không được truy cập trong khoảng thời gian dài nhất.\nƯu điểm: Hiệu quả hơn FIFO rất nhiều trong hầu hết các trường hợp thực tế, vì nó giữ lại những dữ liệu đang được sử dụng tích cực.\nNhược điểm: Phức tạp hơn trong việc triển khai vì nó đòi hỏi phải theo dõi thời gian truy cập của mỗi mục, gây tốn thêm một chút bộ nhớ và xử lý.\nLFU (Least Frequently Used - Ít được sử dụng thường xuyên nhất):\nNguyên tắc: Loại bỏ mục dữ liệu được truy cập với số lần ít nhất.\nƯu điểm: Rất tốt trong việc xác định và giữ lại các mục dữ liệu \u0026ldquo;hot\u0026rdquo; (phổ biến) trong một thời gian dài, ngay cả khi chúng không được truy cập gần đây.\nNhược điểm: Phức tạp để triển khai hiệu quả. (ví dụ: một mục từng rất hot nhưng giờ không còn ai dùng nữa vẫn có thể chiếm chỗ trong cache một thời gian dài). Nó cũng có thể loại bỏ một mục mới được thêm vào nhưng chưa có cơ hội tích lũy đủ số lần truy cập.\nBảng so sánh các chính sách dọn dẹp Chính sách Nguyên tắc cốt lõi Ví dụ tương tự Ưu điểm Nhược điểm Phù hợp nhất cho FIFO Loại bỏ mục vào cache sớm nhất. Xếp hàng mua vé: người đến trước được phục vụ trước. Đơn giản, chi phí thấp. Không thông minh, có thể loại bỏ dữ liệu quan trọng. Các hệ thống có mẫu truy cập tuần tự, không lặp lại. LRU Loại bỏ mục ít được dùng đến gần đây nhất. Dọn dẹp bàn làm việc: trả lại cuốn sách bạn không đụng đến lâu nhất. Hiệu quả cao trong hầu hết các trường hợp, thích ứng tốt với sự thay đổi. Phức tạp hơn, cần theo dõi thời gian truy cập. Các ứng dụng thông thường, nơi dữ liệu gần đây có khả năng được tái sử dụng cao (ví dụ: trang tin tức, mạng xã hội). LFU Loại bỏ mục có số lần truy cập ít nhất. Thư viện cho mượn sách: loại bỏ những cuốn ít người mượn nhất. Giữ lại được các mục \u0026ldquo;hot\u0026rdquo; một cách ổn định. Phức tạp, có thể giữ lại dữ liệu \u0026ldquo;hot\u0026rdquo; đã lỗi thời, không thích ứng nhanh. Các hệ thống có một số dữ liệu cực kỳ phổ biến và ổn định (ví dụ: sản phẩm bán chạy, video viral). Giữ Cho Dữ Liệu Đồng Nhất: Các Chính Sách Ghi Khi một ứng dụng thực hiện thao tác ghi (write) hoặc cập nhật (update), một vấn đề nghiêm trọng nảy sinh. Bây giờ chúng ta có hai bản sao của cùng một dữ liệu: một trong cache và một trong cơ sở dữ liệu. Nếu chúng không được cập nhật đồng bộ, cache sẽ chứa dữ liệu cũ. Việc phục vụ stale data cho người dùng có thể dẫn đến các lỗi nghiêm trọng, thông tin sai lệch và trải nghiệm tồi tệ.\nChính sách ghi (Write Policy) là quy tắc xác định cách hệ thống xử lý các thao tác ghi để giải quyết vấn đề về tính nhất quán này.\nCác chính sách ghi cốt lõi Write-Through (Ghi Xuyên)\nQuy trình: Khi ứng dụng ghi dữ liệu, nó sẽ ghi đồng thời vào cả cache và cơ sở dữ liệu. Thao tác chỉ được coi là hoàn tất khi cả hai nơi đều đã ghi xong.\nLưu đồ: Ứng dụng -\u0026gt; Ghi vào Cache -\u0026gt; Ghi vào Database -\u0026gt; Hoàn tất\nƯu điểm: Tính nhất quán dữ liệu rất cao. Cache và database luôn đồng bộ. Đơn giản để triển khai và đáng tin cậy.\nNhược điểm: Độ trễ của thao tác ghi cao, vì ứng dụng phải chờ cả hai thao tác ghi hoàn tất.\nTrường hợp sử dụng: Các ứng dụng quan trọng nơi tính nhất quán dữ liệu là tối thượng, ví dụ như hệ thống ngân hàng, quản lý kho hàng.\nWrite-Back (Ghi Sau / Write-Behind)\nQuy trình: Khi ứng dụng ghi dữ liệu, nó chỉ ghi vào cache tốc độ cao trước. Thao tác được xác nhận hoàn tất ngay lập tức. Việc ghi vào cơ sở dữ liệu sẽ được trì hoãn và thực hiện sau đó, có thể là sau một khoảng thời gian nhất định hoặc khi mục cache đó sắp bị dọn dẹp. Hệ thống thường dùng một \u0026ldquo;bit bẩn\u0026rdquo; (dirty bit) để đánh dấu các mục trong cache đã bị thay đổi và cần được ghi lại vào database.\nLưu đồ: Ứng dụng -\u0026gt; Ghi vào Cache -\u0026gt; Hoàn tất. (Background: Cache -\u0026gt; Ghi vào Database)\nƯu điểm: Độ trễ ghi cực thấp và thông lượng cao. Giảm tải cho database bằng cách gộp nhiều lần ghi vào cùng một đối tượng thành một lần ghi duy nhất (write-coalescing).\nNhược điểm: Có nguy cơ mất dữ liệu nếu cache bị lỗi trước khi dữ liệu kịp ghi vào database. Phức tạp hơn để triển khai.\nTrường hợp sử dụng: Các ứng dụng có lượng ghi lớn, nơi hiệu năng là ưu tiên hàng đầu và có thể chấp nhận một rủi ro nhỏ về mất mát dữ liệu, ví dụ như ghi log hành vi người dùng, cập nhật số lượt xem bài viết.\nWrite-Around (Ghi Vòng)\nQuy trình: Khi ứng dụng ghi dữ liệu, nó sẽ ghi trực tiếp vào cơ sở dữ liệu, hoàn toàn bỏ qua cache. Dữ liệu chỉ được nạp vào cache sau này, khi có một yêu cầu đọc bị cache miss.\nLưu đồ: Ứng dụng -\u0026gt; Ghi vào Database -\u0026gt; Hoàn tất\nƯu điểm: Tránh \u0026ldquo;làm ô nhiễm\u0026rdquo; cache bằng những dữ liệu có thể không bao giờ được đọc lại.\nNhược điểm: Một yêu cầu đọc ngay sau khi ghi sẽ luôn luôn là cache miss, dẫn đến độ trễ đọc cao cho dữ liệu vừa được ghi.\nTrường hợp sử dụng: Các ứng dụng ghi dữ liệu nhưng hiếm khi đọc lại ngay sau đó, ví dụ như các hệ thống nhập dữ liệu hàng loạt (bulk data ingestion), lưu trữ log.\nCác chính sách ghi không tồn tại một cách độc lập. Chúng liên kết chặt chẽ với cách hệ thống xử lý một write miss (khi ứng dụng muốn ghi vào một mục không có trong cache). Có hai lựa chọn:\nWrite Allocate (Fetch on Write): Khi có write miss, hệ thống sẽ tải khối dữ liệu đó từ database vào cache trước, rồi mới thực hiện thao tác ghi.\nNo-Write Allocate: Khi có write miss, hệ thống sẽ ghi thẳng vào database, không tải dữ liệu đó vào cache.\n","date":"2025-08-10T00:00:00Z","image":"https://nagih.nooblearn2code.com/image-placeholder.png","permalink":"https://nagih.nooblearn2code.com/posts/cache-hit-cache-miss/","title":"Các chính sách 'Dọn Dẹp' Cache"},{"content":"Nhiều người đã nghe về cache, có thể là \u0026ldquo;xóa cache trình duyệt\u0026rdquo; hay \u0026ldquo;cache của CPU\u0026rdquo;. Nhưng cache thực sự là gì? Nó hoạt động ra sao và tại sao nó lại quan trọng đến vậy?\nCache Là Gì? Câu chuyện về Thư viện và Chiếc bàn làm việc Hãy tưởng tượng bạn là một nhà nghiên cứu cần rất nhiều sách cho công việc của mình. Toàn bộ sách được lưu trữ trong một thư viện khổng lồ ở phía bên kia thành phố. Mỗi khi cần một thông tin, bạn phải mất công di chuyển đến thư viện, tìm đúng cuốn sách, đọc, rồi lại đi về. Quá trình này rất chậm chạp và tốn thời gian.\nBây giờ, bạn nghĩ ra một giải pháp thông minh hơn. Thay vì mỗi lần cần lại chạy đi, bạn sẽ mang những cuốn sách hay dùng nhất về đặt ngay trên chiếc bàn làm việc của mình. Chiếc bàn này tuy nhỏ, không thể chứa cả thư viện, nhưng nó ở ngay trước mặt bạn. Lần tới, khi cần thông tin từ những cuốn sách đó, bạn chỉ cần với tay là có ngay, nhanh hơn gấp trăm lần so với việc đi đến thư viện.\nThư viện khổng lồ chính là nơi lưu trữ dữ liệu chính, ví dụ như ổ cứng (HDD/SSD) hoặc Database. Nơi này có dung lượng lớn nhưng tốc độ truy cập khá chậm.\nChiếc bàn làm việc của bạn chính là Cache.\nCache là một lớp lưu trữ dữ liệu tốc độ cao, có kích thước nhỏ, dùng để chứa một tập hợp con của dữ liệu gốc. Mục đích của nó là để các yêu cầu truy xuất dữ liệu trong tương lai được phục vụ nhanh hơn rất nhiều so với việc phải lấy dữ liệu từ database. Về cơ bản, cache cho phép chúng ta tái sử dụng một cách hiệu quả những dữ liệu đã được truy xuất hoặc tính toán trước đó.\nTại sao Cache lại quan trọng ? Tăng tốc độ một cách chóng mặt (Performance): Đây là mục đích chính. Cache thường được triển khai trên các phần cứng truy cập nhanh như RAM (Bộ nhớ truy cập ngẫu nhiên). Tốc độ truy cập RAM nhanh hơn hàng trăm, thậm chí hàng nghìn lần so với ổ đĩa.\nGiảm tải cho hệ thống Backend: Thay vì mọi yêu cầu đều phải truy cập vào cơ sở dữ liệu, phần lớn các yêu cầu đọc sẽ được cache xử lý. Điều này giúp cơ sở dữ liệu không bị quá tải, đặc biệt là trong những thời điểm có lưu lượng truy cập tăng đột biến, và giữ cho toàn bộ hệ thống ổn định.\nTiết kiệm chi phí (Cost Efficiency): Ở quy mô lớn, việc phục vụ dữ liệu từ cache trong bộ nhớ (in-memory) có thể rẻ hơn đáng kể so với việc phải nâng cấp liên tục các máy chủ cơ sở dữ liệu hoặc trả chi phí cho lưu lượng mạng cao khi truy xuất dữ liệu từ các dịch vụ đám mây.\nCache Hit và Cache Miss Hoạt động của cache xoay quanh hai case chính: Cache Hit và Cache Miss. Khi một client (có thể là CPU, trình duyệt web, hoặc ứng dụng của bạn) cần dữ liệu, nó sẽ luôn hỏi cache trước tiên.\nCache Hit (Tìm thấy trong Cache): Đây là case lý tưởng. Cache sẽ ngay lập tức trả về dữ liệu này cho client. Quá trình này cực kỳ nhanh chóng.\nCache Miss (Không tìm thấy trong Cache): Đây là case không mong muốn. Khi đó, hệ thống buộc phải truy cập đến database để lấy dữ liệu. Sau khi lấy được, dữ liệu này sẽ được sao chép một bản vào cache để những lần yêu cầu sau sẽ trở thành cache hit, rồi mới được trả về cho client.\nCache không phải là một phép màu tăng tốc miễn phí. Nó đi kèm với sự đánh đổi và chi phí. Một cache miss vốn dĩ còn chậm hơn một hệ thống không có cache. Bởi vì trong một hệ thống không cache, thời gian truy xuất chỉ đơn giản là thời gian lấy dữ liệu từ nguồn chính. Còn trong một cache miss, tổng thời gian là Thời gian kiểm tra cache (và thất bại) + Thời gian lấy dữ liệu từ database.\nDo đó, mục tiêu của mọi chiến lược caching không chỉ đơn giản là \u0026ldquo;có cache\u0026rdquo;, mà là thiết kế một hệ thống nơi tổng thời gian tiết kiệm được từ vô số các cache hit phải lớn hơn rất nhiều so với tổng thời gian bị mất đi do các cache miss không thể tránh khỏi.\nTỷ lệ Cache Hit (Cache Hit Ratio) Công thức tính rất đơn giản\n1 Tỷ lệ Cache Hit= Cache Hit​ / (Cache Hit + Cache Miss) Một tỷ lệ cache hit cao (thường từ 80-95% trở lên đối với nội dung tĩnh) cho thấy cache đang hoạt động rất hiệu quả. Ngược lại, một tỷ lệ thấp cho thấy cache đang không được sử dụng tốt, có thể do cấu hình sai, chính sách dọn dẹp không phù hợp, hoặc kích thước cache quá nhỏ.\nCache Phần cứng (CPU Cache) Hệ thống phân cấp bộ nhớ (Memory Hierarchy). Đây là một mô hình tổ chức bộ nhớ trong máy tính thành nhiều cấp, giống như một kim tự tháp. Càng ở đỉnh kim tự tháp, bộ nhớ càng nhanh, càng đắt và dung lượng càng nhỏ. Càng xuống đáy, bộ nhớ càng chậm, càng rẻ và dung lượng càng lớn.\n1 2 3 4 5 6 7 (1) Register (2) L1 Cache (3) L2 Cache (4) L3 Cache (5) RAM \u0026lt;- Redis (6) SSD (7) HDD CPU cache được chia thành nhiều Level, thường là L1, L2, và L3:\nL1 Cache (Level 1): Đây là bộ nhớ cache nhỏ nhất và nhanh nhất, được tích hợp ngay trong từng nhân (core) của CPU\nL2 Cache (Level 2): Lớn hơn L1 nhưng chậm hơn một chút. L2 cache có thể nằm riêng cho từng nhân hoặc chung cho một vài nhân, tùy vào kiến trúc CPU.\nL3 Cache (Level 3): Lớn nhất và chậm nhất trong các cấp CPU cache. L3 cache thường được dùng chung cho tất cả các nhân trên một con chip. Nó giúp tăng tốc độ giao tiếp giữa các nhân và giảm thiểu việc phải truy cập ra RAM.\nCache Phần mềm Cache Trình duyệt (Browser Cache): Khi bạn truy cập một trang web, trình duyệt của bạn sẽ tự động lưu các tài nguyên tĩnh như hình ảnh, file CSS, JavaScript vào một thư mục trên ổ cứng. Lần sau khi bạn quay lại trang đó, trình duyệt sẽ tải các tài nguyên này từ ổ cứng thay vì phải tải lại từ server, giúp trang web hiển thị gần như ngay lập tức. Đây là một dạng cache phía client (client-side), riêng tư cho mỗi người dùng.\nCache Mạng Phân phối Nội dung (CDN - Content Delivery Network): Đây là một mạng lưới các máy chủ proxy được đặt ở nhiều vị trí địa lý trên toàn cầu. Các máy chủ này lưu trữ (cache) bản sao của nội dung trang web (như video, hình ảnh, file tĩnh). Ví dụ điển hình là Netflix hay YouTube. Khi bạn ở Việt Nam và xem một video, rất có thể bạn đang nhận dữ liệu từ một máy chủ CDN đặt tại Singapore hoặc Hồng Kông, chứ không phải từ máy chủ gốc ở Mỹ. Điều này giúp giảm đáng kể độ trễ và tăng tốc độ tải.\nCache Cơ sở dữ liệu (Database Cache): Hầu hết các hệ quản trị cơ sở dữ liệu như MySQL, PostgreSQL đều có một bộ đệm cache nội bộ. Nó lưu lại kết quả của các câu truy vấn (query) được thực thi thường xuyên. Khi nhận được một câu truy vấn giống hệt, thay vì phải quét lại toàn bộ bảng dữ liệu, database sẽ trả về kết quả từ cache của nó.\nCache Ứng dụng (Application Cache / In-Memory Cache): Thường sử dụng các công cụ chuyên dụng như Redis hoặc Memcached. Lớp cache này có thể lưu trữ bất cứ thứ gì. Việc này giúp ứng dụng không phải tính toán lại hoặc truy vấn lại những thông tin tốn kém trên mỗi yêu cầu.\n","date":"2025-08-10T00:00:00Z","image":"https://nagih.nooblearn2code.com/images/image-placeholder.png","permalink":"https://nagih.nooblearn2code.com/posts/introdution-to-cache/","title":"Giới thiệu về Cache"}]