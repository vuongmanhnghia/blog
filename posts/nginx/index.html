<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Nginx Overview | Nagih | Blog</title>
<meta name=keywords content="nginx"><meta name=description content="Nginx - Từ C10k Đến Containers"><meta name=author content="Nagih"><link rel=canonical href=https://blog.nagih.io.vn/posts/nginx/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.nagih.io.vn/posts/nginx/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://blog.nagih.io.vn/posts/nginx/"><meta property="og:site_name" content="Nagih | Blog"><meta property="og:title" content="Nginx Overview"><meta property="og:description" content="Nginx - Từ C10k Đến Containers"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-16T00:00:00+00:00"><meta property="article:modified_time" content="2025-08-16T00:00:00+00:00"><meta property="article:tag" content="Nginx"><meta property="og:image" content="https://blog.nagih.io.vn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.nagih.io.vn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Nginx Overview"><meta name=twitter:description content="Nginx - Từ C10k Đến Containers"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.nagih.io.vn/posts/"},{"@type":"ListItem","position":2,"name":"Nginx Overview","item":"https://blog.nagih.io.vn/posts/nginx/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Nginx Overview","name":"Nginx Overview","description":"Nginx - Từ C10k Đến Containers\n","keywords":["nginx"],"articleBody":"Nginx - Từ C10k Đến Containers\nPhần 1: Nền Tảng Hiệu Năng: “Tại Sao” và “Cái Gì” của Nginx Phần này thiết lập bối cảnh cơ bản về sự tồn tại và triết lý thiết kế cốt lõi của Nginx. Khám phá vấn đề lịch sử mà Nginx được thiết kế để giải quyết và phân tích các lựa chọn kiến trúc đã biến nó thành một nền tảng của cơ sở hạ tầng web hiện đại.\n1.1. Nguồn Gốc của Nginx: Giải Quyết Vấn Đề 10,000 Kết Nối Nginx ra đời không phải là một sự cải tiến gia tăng, mà là một sự thay đổi mô hình trong kiến trúc máy chủ web, một phản ứng trực tiếp trước những hạn chế kiến trúc cơ bản của các máy chủ tiền nhiệm, vốn không còn phù hợp với sự phát triển bùng nổ của Internet.\nVào đầu những năm 2000, khi Internet phát triển với tốc độ chóng mặt, một thách thức kỹ thuật mới đã xuất hiện, được gọi là vấn đề C10k. Thuật ngữ này, do kỹ sư Dan Kegel đặt ra vào năm 1999, mô tả bài toán xử lý 10,000 kết nối đồng thời trên một máy chủ duy nhất.1 Vấn đề này không chỉ đơn thuần là về tốc độ xử lý yêu cầu (throughput), mà là về khả năng quản lý hiệu quả một số lượng lớn các kết nối đang mở cùng một lúc. Các máy chủ web phổ biến thời bấy giờ, như Apache, với mô hình xử lý một tiến trình hoặc một luồng cho mỗi kết nối, đã gặp phải giới hạn nghiêm trọng. Mỗi kết nối tiêu tốn một lượng tài nguyên CPU và bộ nhớ đáng kể, tạo ra một rào cản về khả năng mở rộng khi số lượng người dùng tăng vọt.\nTrong bối cảnh đó, Igor Sysoev, một kỹ sư hệ thống người Nga làm việc tại Rambler, đã bắt đầu phát triển Nginx vào năm 2002. Ban đầu, ông đã cố gắng cải thiện hiệu suất của Apache thông qua các module như\nmod_accel, nhưng nhanh chóng nhận ra rằng cần một cách tiếp cận hoàn toàn mới. Nginx không được tạo ra để trở thành “một Apache nhanh hơn”, mà là để định nghĩa lại cách một máy chủ web xử lý I/O và quản lý kết nối. Phần mềm được phát hành công khai vào năm 2004 dưới dạng mã nguồn mở miễn phí, theo giấy phép BSD 2 điều khoản.\nThành công của kiến trúc mới này đã được chứng minh nhanh chóng. Đến tháng 9 năm 2008, Nginx đã phục vụ 500 triệu yêu cầu mỗi ngày cho cổng thông tin và công cụ tìm kiếm Rambler. Năm 2011, Nginx, Inc. được thành lập để cung cấp các sản phẩm thương mại và hỗ trợ (NGINX Plus), và sau đó được F5 Networks mua lại vào năm 2019.\n1.2. Kiến Trúc của Tốc Độ: Hướng Sự Kiện, I/O Bất Đồng Bộ Không Chặn Chìa khóa cho hiệu suất và khả năng mở rộng vượt trội của Nginx nằm ở kiến trúc bất đồng bộ, hướng sự kiện và I/O không chặn (asynchronous, event-driven, non-blocking I/O). Đây là yếu tố cốt lõi giúp Nginx giải quyết vấn đề C10k.\nNginx hoạt động theo mô hình master-worker. Một tiến trình\nmaster duy nhất chịu trách nhiệm cho các tác vụ quản trị: đọc và xác thực cấu hình, liên kết với các cổng mạng, và tạo ra một số lượng tiến trình worker (thường là một worker cho mỗi lõi CPU). Các tiến trình\nworker này mới là nơi xử lý các yêu cầu của client.\nMỗi tiến trình worker là đơn luồng (single-threaded) và chạy một vòng lặp sự kiện (event loop). Vòng lặp này sử dụng các cơ chế hiệu quả của hệ điều hành như epoll (trên Linux) hoặc kqueue (trên FreeBSD) để giám sát hàng ngàn kết nối cùng lúc cho các sự kiện (ví dụ: có dữ liệu mới để đọc, bộ đệm sẵn sàng để ghi). Khi một sự kiện xảy ra, một hàm gọi lại (callback) được kích hoạt để xử lý nó. Vì tất cả các hoạt động I/O đều là\nkhông chặn (non-blocking), tiến trình worker không bao giờ phải chờ đợi các hoạt động chậm chạp như đọc/ghi đĩa hoặc mạng. Thay vào đó, nó khởi tạo hoạt động và ngay lập tức chuyển sang xử lý các sự kiện khác. Khi hoạt động I/O hoàn tất, hệ điều hành sẽ thông báo cho vòng lặp sự kiện, và kết quả sẽ được xử lý.\nMô hình này mang lại hai lợi ích to lớn. Thứ nhất, nó loại bỏ hoàn toàn chi phí tạo ra một tiến trình hoặc luồng mới cho mỗi kết nối. Thứ hai, nó tránh được việc chuyển đổi ngữ cảnh (context switching) tốn kém, một vấn đề lớn của các mô hình truyền thống khi tải cao. Kết quả là Nginx có thể xử lý hàng ngàn kết nối với chi phí bộ nhớ cực thấp (chỉ khoảng 100KB đến 1MB mỗi kết nối) và đạt được thông lượng rất cao, có thể lên tới 100,000 yêu cầu mỗi giây cho mỗi worker.\nKiến trúc master-worker không chỉ mang lại hiệu suất mà còn là nền tảng cho sự ổn định vận hành và các tính năng quan trọng như cập nhật cấu hình không gián đoạn (zero-downtime reloads). Khi cần thay đổi cấu hình, một tín hiệu reload được gửi đến tiến trình master. Master sẽ xác thực cấu hình mới và tạo ra một bộ worker mới với cấu hình cập nhật. Các worker cũ sẽ được tắt một cách nhẹ nhàng: chúng ngừng chấp nhận kết nối mới nhưng tiếp tục xử lý các kết nối hiện có cho đến khi hoàn tất. Khi tất cả các kết nối cũ đã đóng, các worker cũ sẽ tự kết thúc. Toàn bộ quá trình này diễn ra mà không làm mất bất kỳ kết nối nào của client, cho phép cập nhật không thời gian chết, một yêu cầu tối quan trọng trong các hoạt động DevOps hiện đại.\nPhần 2: “Con Dao Đa Năng” của Thụy Sĩ - Các Trường Hợp Sử Dụng Cốt Lõi của Nginx Từ lý thuyết đến thực tiễn, phần này sẽ trình bày sự linh hoạt của Nginx thông qua các vai trò phổ biến nhất của nó. Mỗi tiểu mục sẽ bao gồm các ví dụ cấu hình được chú thích chi tiết.\n2.1. Máy Chủ Web Hiệu Năng Cao (cho Nội Dung Tĩnh) Nhờ kiến trúc hướng sự kiện hiệu quả, Nginx vượt trội trong việc phục vụ nội dung tĩnh như các tệp HTML, CSS, JavaScript và hình ảnh. Trong các bài kiểm tra hiệu năng, Nginx luôn cho thấy hiệu suất cao hơn đáng kể so với Apache trong lĩnh vực này.\nMột cấu hình cơ bản để phục vụ một trang web tĩnh rất đơn giản. Khối server định nghĩa một máy chủ ảo, chỉ thị listen xác định cổng lắng nghe, server_name chỉ định tên miền, root là đường dẫn đến thư mục chứa tệp của trang web, và index xác định tệp mặc định sẽ được phục vụ.\nMột mô hình triển khai phổ biến là thiết lập kết hợp, trong đó Nginx đóng vai trò là “người gác cổng” phía trước Apache. Trong mô hình này, Nginx nhận tất cả các yêu cầu, phục vụ trực tiếp các tệp tĩnh với tốc độ tối đa, và chuyển tiếp các yêu cầu nội dung động (như PHP) đến Apache để xử lý.\nVí dụ cấu hình:\nNginx\nserver { listen 80; server_name example.com www.example.com; root /var/www/html; index index.html index.htm; # Tối ưu hóa việc phục vụ file tĩnh location ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ { expires 365d; # Yêu cầu trình duyệt lưu cache tài sản tĩnh trong 1 năm add_header Cache-Control \"public\"; } } 2.2. Người Bảo Vệ: Nginx trong vai trò Reverse Proxy Reverse proxy là một máy chủ trung gian nằm giữa client và các máy chủ backend. Nó nhận yêu cầu từ client và chuyển tiếp chúng đến máy chủ phù hợp. Vai trò này mang lại nhiều lợi ích: che giấu kiến trúc của hệ thống backend, tăng cường bảo mật bằng cách tạo ra một điểm vào duy nhất, có thể chấm dứt SSL/TLS, và là nền tảng cho cân bằng tải và caching.\nChỉ thị cốt lõi cho chức năng này là proxy_pass, dùng để chỉ định địa chỉ của máy chủ backend hoặc một nhóm upstream. Một yếu tố cực kỳ quan trọng là sử dụng chỉ thị\nproxy_set_header để chuyển tiếp các thông tin quan trọng của client (như Host gốc, X-Real-IP, và X-Forwarded-For) đến máy chủ backend. Nếu không, máy chủ backend sẽ chỉ thấy địa chỉ IP của proxy, làm mất thông tin về client gốc.\nNginx cũng có cơ chế đệm phản hồi (proxy_buffering). Khi được bật (mặc định), Nginx sẽ lưu phản hồi từ máy chủ backend vào bộ đệm và chỉ gửi cho client khi đã nhận đủ. Điều này giúp tối ưu hóa hiệu suất với các client có kết nối chậm, cho phép máy chủ backend xử lý yêu cầu nhanh chóng và giải phóng tài nguyên, trong khi Nginx từ từ gửi dữ liệu về cho client.\nVí dụ cấu hình:\nNginx\nlocation /app/ { proxy_pass http://backend_server:8080; # Chuyển tiếp các header quan trọng đến backend proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } 2.3. Người Điều Phối Giao Thông: Nginx trong vai trò Load Balancer Cân bằng tải là một trong những ứng dụng phổ biến nhất của reverse proxy, giúp phân phối lưu lượng truy cập qua nhiều máy chủ backend để cải thiện hiệu suất, khả năng mở rộng và độ tin cậy của hệ thống.\nCấu hình này được thực hiện thông qua khối upstream, nơi định nghĩa một nhóm các máy chủ backend. Sau đó, chỉ thị\nproxy_pass sẽ trỏ đến tên của nhóm upstream này. Nginx mã nguồn mở hỗ trợ các thuật toán cân bằng tải sau:\nRound Robin (Mặc định): Các yêu cầu được phân phối lần lượt đến từng máy chủ trong nhóm. Có thể sử dụng tham số weight để gán trọng số, giúp các máy chủ mạnh hơn nhận được nhiều lưu lượng hơn. Least Connections (least_conn): Yêu cầu tiếp theo được gửi đến máy chủ có số lượng kết nối đang hoạt động ít nhất. Thuật toán này rất hiệu quả khi thời gian xử lý các yêu cầu không đồng đều. IP Hash (ip_hash): Máy chủ được chọn dựa trên một hàm băm từ địa chỉ IP của client. Điều này đảm bảo rằng các yêu cầu từ cùng một client sẽ luôn được chuyển đến cùng một máy chủ. Đây là một cách đơn giản để thực hiện “sticky sessions” (phiên cố định), rất quan trọng cho các ứng dụng cần duy trì trạng thái phiên. NGINX Plus cung cấp các phương pháp nâng cao hơn như least_time và các tính năng duy trì phiên phức tạp hơn như sticky cookie và sticky route.\nVí dụ cấu hình:\nNginx\nupstream backend_pool { # ip_hash; # Bỏ comment để bật sticky sessions # least_conn; # Bỏ comment để dùng thuật toán least connections server backend1.example.com weight=3; server backend2.example.com; server backend3.example.com backup; # Chỉ sử dụng khi các server khác lỗi } server { listen 80; location / { proxy_pass http://backend_pool; } } 2.4. Người Gác Cổng: Nginx trong vai trò API Gateway Trong các kiến trúc microservices hiện đại, API Gateway đóng vai trò là một điểm vào duy nhất cho tất cả các yêu cầu API. Sự phát triển của Nginx thành một API Gateway là một sự mở rộng tự nhiên từ các khả năng cốt lõi của nó như một reverse proxy hiệu năng cao. Một reverse proxy về cơ bản là chặn, kiểm tra và chuyển tiếp yêu cầu. Một API Gateway cũng làm điều tương tự nhưng thêm vào đó các logic phức tạp hơn như định tuyến dựa trên đường dẫn API, xác thực thông tin đăng nhập và thực thi các chính sách sử dụng. Các khối\nlocation mạnh mẽ của Nginx cung cấp khả năng định tuyến dựa trên URI, module limit_req cung cấp giới hạn tốc độ, và khả năng kiểm tra header cho phép xác thực. Do đó, các khối xây dựng cơ bản cho một API Gateway đã có sẵn trong Nginx.\nCác tính năng chính của một API Gateway dựa trên Nginx bao gồm:\nĐịnh tuyến (Routing): Chuyển hướng yêu cầu đến microservice backend phù hợp dựa trên URI. Xác thực (Authentication): Xác thực API key hoặc JSON Web Tokens (JWT). Giới hạn tốc độ (Rate Limiting): Áp dụng giới hạn tốc độ để ngăn chặn lạm dụng và đảm bảo sử dụng công bằng. Chấm dứt SSL/TLS (SSL/TLS Termination): Giảm tải việc mã hóa/giải mã từ các dịch vụ backend. Có nhiều cách để triển khai điều này: sử dụng các tính năng gốc của Nginx, mở rộng với Lua/OpenResty, hoặc sử dụng sản phẩm thương mại NGINX Plus API Gateway. Một dự án hiện đại đáng chú ý là NGINX Gateway Fabric, một triển khai của Gateway API dành cho Kubernetes, sử dụng Nginx làm data plane.\n2.5. Người Tăng Tốc: Caching Nâng Cao với Nginx Nginx có thể lưu trữ (cache) các phản hồi từ máy chủ backend, giúp cải thiện đáng kể hiệu suất và giảm tải cho máy chủ gốc.\nViệc cấu hình proxy_cache được thực hiện thông qua các chỉ thị chính sau:\nproxy_cache_path: Định nghĩa vị trí lưu trữ cache trên đĩa, vùng bộ nhớ chia sẻ cho các khóa (keys_zone), kích thước tối đa (max_size), và thời gian không hoạt động (inactive). proxy_cache: Kích hoạt một vùng cache cụ thể trong một khối location hoặc server. proxy_cache_valid: Thiết lập thời gian cache mặc định cho các mã trạng thái HTTP khác nhau (ví dụ: cache phản hồi 200 OK trong 60 phút, 404 Not Found trong 1 phút). proxy_cache_key: Định nghĩa chuỗi được sử dụng để tạo khóa duy nhất cho mỗi mục được cache (mặc định là $scheme$proxy_host$request_uri). Để gỡ lỗi và theo dõi, việc thêm một header tùy chỉnh (X-Cache-Status) với giá trị của biến $upstream_cache_status là vô giá. Header này sẽ cho biết một yêu cầu là HIT (tìm thấy trong cache), MISS (không tìm thấy), EXPIRED (hết hạn), BYPASS (bỏ qua cache), v.v..\nCác khái niệm nâng cao bao gồm việc phục vụ nội dung cũ khi backend gặp sự cố (proxy_cache_use_stale) và bỏ qua cache cho các yêu cầu nhất định (proxy_cache_bypass).\nVí dụ cấu hình:\nNginx\n# Trong khối http proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m; # Trong khối server server { #... location / { proxy_cache my_cache; proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; proxy_pass http://my_upstream; add_header X-Cache-Status $upstream_cache_status; } } Phần 3: Nginx trong Hệ Sinh Thái Hiện Đại - Một Phân Tích So Sánh Phần này cung cấp một so sánh cân bằng và chi tiết giữa Nginx và các đối thủ chính của nó, giúp các kỹ sư đưa ra quyết định kiến trúc sáng suốt dựa trên yêu cầu dự án cụ thể.\n3.1. Cuộc Đối Đầu Kinh Điển: Nginx vs. Apache HTTP Server Sự lựa chọn giữa Nginx và Apache không còn đơn thuần là câu hỏi “cái nào nhanh hơn”, mà là sự lựa chọn về triết lý kiến trúc. Nginx ưu tiên hiệu suất thô và hiệu quả thông qua một mô hình tập trung, cứng nhắc, trong khi Apache ưu tiên sự linh hoạt và kiểm soát phân tán, thường phải trả giá bằng hiệu suất.\nKiến trúc: Nginx sử dụng mô hình hướng sự kiện với các worker đơn luồng, trong khi Apache sử dụng mô hình hướng tiến trình/luồng (với các MPM như prefork, worker, event). Hiệu năng: Nginx nhanh hơn đáng kể khi phục vụ nội dung tĩnh và vượt trội dưới tải đồng thời cao do sử dụng ít tài nguyên hơn.12 Apache, với các module động như mod_php, có thể xử lý nội dung động hiệu quả hơn bên trong chính máy chủ, mặc dù các thiết lập hiện đại thường sử dụng PHP-FPM, làm cho sự khác biệt này ít rõ rệt hơn. Cấu hình: Nginx sử dụng một tệp cấu hình tập trung. Apache cung cấp cấu hình ở cấp thư mục thông qua các tệp .htaccess, mang lại sự linh hoạt cho người dùng trong môi trường hosting chia sẻ nhưng có thể làm giảm hiệu suất vì máy chủ phải quét hệ thống tệp cho các tệp này trên mỗi yêu cầu. Trong các môi trường DevOps hiện đại, nơi cơ sở hạ tầng thường được quản lý tập trung thông qua tự động hóa (IaC), khả năng kiểm soát phân tán của .htaccess có thể trở thành một gánh nặng hơn là một tính năng, làm cho cấu hình tập trung và có thể dự đoán của Nginx trở nên hấp dẫn hơn. Modules: Apache có một hệ sinh thái module động khổng lồ. Các module Nginx truyền thống cần được biên dịch vào tệp nhị phân, mặc dù việc tải module động đã được hỗ trợ từ năm 2016. 3.2. Chuyên Gia: Nginx vs. HAProxy Nguồn gốc \u0026 Trọng tâm: Nginx bắt đầu như một máy chủ web và phát triển thành một công cụ đa năng. HAProxy được thiết kế từ đầu như một bộ cân bằng tải và reverse proxy hiệu suất cao cho lưu lượng TCP và HTTP. Tính năng Layer 7: Cả hai đều là những bộ cân bằng tải Layer 7 (HTTP) xuất sắc. Nginx có lợi thế là một máy chủ web đầy đủ tính năng, có thể phục vụ trực tiếp các tệp tĩnh, điều mà HAProxy không thể làm. Hiệu năng \u0026 Chuyên môn hóa: HAProxy thường được coi là một chuyên gia với hiệu suất vượt trội và các tính năng nâng cao hơn dành riêng cho việc cân bằng tải, chẳng hạn như kiểm tra sức khỏe mạnh mẽ hơn và khả năng quan sát tốt hơn ngay từ đầu trong phiên bản mã nguồn mở của nó. Vận hành: HAProxy được khen ngợi vì khả năng tải lại nóng không gián đoạn (hot reloads) và mô hình vận hành đơn giản hơn cho các thay đổi trực tiếp, trong khi Nginx OSS yêu cầu tải lại hoàn toàn, có thể làm mất kết nối trong giây lát. Mô hình phổ biến: Một kiến trúc mạnh mẽ và phổ biến là sử dụng cả hai: Nginx ở biên (edge) để chấm dứt SSL và phục vụ nội dung tĩnh, sau đó chuyển tiếp lưu lượng đến một HAProxy nội bộ để cân bằng tải phức tạp qua các dịch vụ backend. 3.3. Thách Thức Mới: Nginx vs. Caddy Caddy đại diện cho một sự thay đổi triết lý hướng tới “bảo mật mặc định” và trải nghiệm của nhà phát triển. Nó đánh đổi khả năng tùy chỉnh vô hạn của Nginx để lấy các mặc định tự động, hợp lý, bao phủ phần lớn các trường hợp sử dụng, làm cho nó trở thành một sự thay thế hiện đại hấp dẫn.\nDễ dàng cấu hình: Caddy nổi tiếng với tệp cấu hình Caddyfile đơn giản, dễ đọc, thường ngắn gọn hơn nhiều so với cấu hình Nginx tương đương. HTTPS tự động: Đây là tính năng “sát thủ” của Caddy. Nó tích hợp sẵn với Let’s Encrypt để tự động cấp phát và gia hạn chứng chỉ TLS cho tất cả các trang web được cấu hình, một quá trình đòi hỏi một công cụ riêng biệt như Certbot với Nginx. Kiến trúc \u0026 Hiệu năng: Caddy được viết bằng Go và tận dụng mô hình đồng thời của Go. Nó rất hiệu quả, mặc dù Nginx vẫn có thể có lợi thế trong các kịch bản lưu lượng cực cao với các cấu hình được tinh chỉnh kỹ lưỡng. Hệ sinh thái: Nginx có một cộng đồng và hệ sinh thái module lớn hơn và trưởng thành hơn nhiều. Caddy nhỏ hơn nhưng đang phát triển nhanh chóng. 3.4. Bảng Phân Tích So Sánh Bảng dưới đây cung cấp một cái nhìn tổng quan, giúp các kỹ sư nhanh chóng so sánh các công cụ dựa trên các tiêu chí DevOps quan trọng.\nTiêu chí Nginx Apache HAProxy Caddy Kiến trúc Hướng sự kiện, bất đồng bộ Hướng tiến trình/luồng Hướng sự kiện, bất đồng bộ Hướng sự kiện, bất đồng bộ (Go) Trường hợp sử dụng chính Web server, Reverse Proxy, Cân bằng tải, API Gateway Web server, Hosting chia sẻ Cân bằng tải, Reverse Proxy (TCP/HTTP) Web server, Reverse Proxy Hiệu năng nội dung tĩnh Xuất sắc Tốt Không áp dụng Rất tốt Mô hình cấu hình Tập trung Phân tán (.htaccess) Tập trung Tập trung (Caddyfile) Xử lý SSL/TLS Thủ công (cần Certbot) Thủ công (cần Certbot) Rất hiệu quả (chấm dứt TLS) Tự động (tích hợp Let’s Encrypt) Hệ sinh thái \u0026 Mở rộng Rất lớn, trưởng thành Lớn nhất, nhiều module động Chuyên biệt, tập trung Đang phát triển Kịch bản lý tưởng Hệ thống hiệu năng cao, được quản lý tập trung Hosting chia sẻ, cần sự linh hoạt ở cấp người dùng Cân bằng tải chuyên dụng, yêu cầu độ tin cậy cao Ưu tiên sự đơn giản, HTTPS tự động, trải nghiệm nhà phát triển Phần 4: Làm Chủ Cấu Hình Nginx Phần này đi sâu vào ngôn ngữ cấu hình của Nginx, từ cấu trúc cấp cao đến logic chi tiết điều khiển quá trình xử lý yêu cầu.\n4.1. Giải Phẫu Tệp nginx.conf Tệp cấu hình chính của Nginx thường nằm ở /etc/nginx/nginx.conf. Cấu trúc của nó được tổ chức theo các khối phân cấp được gọi là\ncontext (ví dụ: main, events, http, server, location). Các chỉ thị trong một context cha sẽ được kế thừa bởi các context con nhưng có thể bị ghi đè.\nmain/Global: Định nghĩa các chỉ thị cốt lõi như user và worker_processes. events: Cấu hình các tham số xử lý kết nối, như worker_connections (số kết nối tối đa cho mỗi worker). http: Chứa các chỉ thị để xử lý lưu lượng HTTP, bao gồm các khối server và upstream. Một thực hành tốt nhất là sử dụng chỉ thị include để mô-đun hóa cấu hình, thường bằng cách bao gồm các tệp từ /etc/nginx/conf.d/*.conf và /etc/nginx/sites-enabled/*. Mặc dù điều này thúc đẩy sự tổ chức, nó cũng có thể làm cho việc gỡ lỗi trở nên phức tạp nếu không được quản lý cẩn thận. Một chỉ thị trong\nnginx.conf có thể bị ghi đè bởi một chỉ thị trong conf.d/global.conf, và sau đó lại bị ghi đè bởi một chỉ thị trong sites-enabled/mysite.conf. Do đó, một kỹ năng quan trọng đối với kỹ sư DevOps là hiểu rõ logic kế thừa và bao gồm này. Các công cụ như nginx -T trở nên cần thiết để xem cấu hình được lắp ráp đầy đủ.\n4.2. Lưu Trữ Nhiều Trang Web: Server Blocks (Virtual Hosts) Nginx sử dụng các khối server để định nghĩa các máy chủ ảo (virtual hosts), cho phép một phiên bản Nginx duy nhất lưu trữ nhiều trang web. Nginx quyết định khối\nserver nào sẽ xử lý một yêu cầu dựa trên các chỉ thị listen (IP:port) và server_name (tên miền từ header Host).\nTrên các hệ thống Debian/Ubuntu, quy trình chuẩn là:\nTạo một tệp cấu hình cho mỗi trang web trong /etc/nginx/sites-available/. Tạo một liên kết tượng trưng (symbolic link) từ tệp đó đến /etc/nginx/sites-enabled/ để kích hoạt trang web. Điều này cho phép bật hoặc tắt các trang web một cách dễ dàng mà không cần xóa tệp cấu hình. 4.3. Nghệ Thuật Định Tuyến: Logic Khớp Khối Location Khối location được sử dụng để kiểm soát cách xử lý các yêu cầu cho các URI khác nhau trong một máy chủ.36 Việc làm chủ logic khớp của nó là rất quan trọng. Thứ tự xử lý, thường là một nguồn gây nhầm lẫn, như sau:\nKhớp chính xác (=): location = /path - Nếu URI khớp chính xác, khối này được sử dụng ngay lập tức và việc tìm kiếm dừng lại. Ưu tiên cao nhất. Khớp tiền tố ưu tiên (^~): location ^~ /path - Nginx tìm kiếm tiền tố khớp dài nhất. Nếu đây là khớp dài nhất, Nginx sẽ sử dụng nó và không kiểm tra các khối regex. Đây là một cơ chế tối ưu hóa hiệu suất có chủ ý, cho phép quản trị viên bỏ qua các đánh giá regex tốn kém cho các đường dẫn phổ biến. Khớp Regex (~, ~*): location ~ \\.php$ (phân biệt chữ hoa/thường) hoặc location ~* \\.(jpg|png)$ (không phân biệt). Chúng được kiểm tra theo thứ tự xuất hiện trong tệp cấu hình. Khớp đầu tiên sẽ thắng. Khớp tiền tố dài nhất (không có modifier): location /path - Nếu không có regex nào khớp, tiền tố khớp dài nhất được tìm thấy trước đó sẽ được sử dụng. Ưu tiên thấp nhất. Điều quan trọng cần lưu ý là các khối location chỉ khớp với đường dẫn URI, không phải chuỗi truy vấn (query string). Để định tuyến dựa trên tham số truy vấn, có thể sử dụng một giải pháp thay thế bằng câu lệnh\nif và biến $args hoặc $query_string.\nPhần 5: Nginx trong Thế Giới Container với Docker Phần này cung cấp hướng dẫn thực tế, từng bước để triển khai và quản lý Nginx trong một môi trường container hiện đại.\n5.1. Bắt Đầu: Chạy Image Nginx Chính Thức Bắt đầu với những điều cơ bản về việc sử dụng image Nginx chính thức từ Docker Hub. Một container đơn giản có thể được chạy, ánh xạ cổng với\n-p 8080:80 và mount một thư mục nội dung tĩnh từ máy chủ vào thư mục gốc web mặc định của container (/usr/share/nginx/html) bằng cách sử dụng volume mount: -v /path/on/host:/usr/share/nginx/html:ro.\n5.2. Tùy Chỉnh Container Nginx của Bạn Có ba phương pháp chính để tùy chỉnh container Nginx:\nMount tệp cấu hình tùy chỉnh: Cách đơn giản nhất là mount tệp nginx.conf của riêng bạn hoặc một tệp vào /etc/nginx/conf.d/ để ghi đè lên các mặc định: -v /path/to/my.conf:/etc/nginx/conf.d/default.conf:ro.\nXây dựng Image tùy chỉnh với Dockerfile: Đối với các tùy chỉnh phức tạp hơn, có thể tạo một Dockerfile bắt đầu bằng FROM nginx:latest và sử dụng COPY để thêm các tệp cấu hình và nội dung tĩnh trực tiếp vào image. Lệnh\nCMD cần bao gồm -g 'daemon off;' để giữ Nginx chạy ở nền trước, cho phép Docker quản lý tiến trình.\nSử dụng biến môi trường và template: Image Nginx chính thức hỗ trợ một cơ chế templating. Các tệp có đuôi .template trong /etc/nginx/templates/ sẽ được thay thế các biến môi trường (như ${NGINX_HOST}) trước khi được ghi vào /etc/nginx/conf.d/. Đây là một mẫu mạnh mẽ cho cấu hình động trong các đường ống CI/CD.\n5.3. Điều Phối với Docker Compose: Một Ví Dụ Reverse Proxy Thực Tế Docker Compose là công cụ tiêu chuẩn để định nghĩa và chạy các ứng dụng Docker đa container. Một ví dụ\ndocker-compose.yaml hoàn chỉnh sẽ định nghĩa hai dịch vụ: một ứng dụng backend node và một dịch vụ nginx hoạt động như một reverse proxy.\nSự kỳ diệu làm cho mô hình reverse proxy Nginx hoạt động liền mạch trong môi trường container chính là mạng Docker. Docker Compose tạo ra một mạng tùy chỉnh cho các dịch vụ được định nghĩa trong tệp. Docker cung cấp một dịch vụ DNS nội bộ trên mạng này. Mỗi container có thể được truy cập bởi các container khác trên cùng một mạng bằng tên dịch vụ của nó (ví dụ:\nnode). Do đó, cấu hình Nginx có thể sử dụng\nproxy_pass http://node:8181; mà không cần biết địa chỉ IP thực tế của container backend. Điều này cho phép tạo ra một ngăn xếp ứng dụng di động, tự chứa và linh hoạt, có thể được triển khai ở bất cứ đâu có Docker.\nVí dụ docker-compose.yaml:\nYAML\nversion: \"3.8\" services: node: build: context:./api target: dev volumes: -./api/index.js:/src/index.js nginx: restart: always image: nginx:1-alpine ports: - \"8089:80\" volumes: -./nginx/default.conf:/etc/nginx/conf.d/default.conf depends_on: - node Phần 6: Bảo Mật Máy Chủ Nginx - Danh Sách Kiểm Tra Cứng Hóa Phần này cung cấp một danh sách kiểm tra toàn diện các thực hành bảo mật tốt nhất, biến một cài đặt Nginx mặc định thành một máy chủ được cứng hóa, sẵn sàng cho môi trường sản xuất.\n6.1. Mã Hóa Mọi Thứ: SSL/TLS với Let’s Encrypt HTTPS là điều không thể thiếu cho các ứng dụng web hiện đại. Let’s Encrypt cung cấp chứng chỉ TLS miễn phí và đáng tin cậy. Hướng dẫn từng bước sử dụng client\nCertbot và plugin Nginx của nó (python3-certbot-nginx) sẽ được cung cấp. Chạy certbot --nginx sẽ tự động lấy và cài đặt chứng chỉ, sửa đổi khối server liên quan để bật SSL và thiết lập chuyển hướng từ HTTP sang HTTPS. Việc thiết lập cronjob tự động gia hạn mà Certbot tạo ra là rất quan trọng.\n6.2. Điều Tiết Lưu Lượng: Giới Hạn Tốc Độ Nâng Cao Giới hạn tốc độ là một biện pháp phòng thủ quan trọng chống lại các cuộc tấn công brute-force, DDoS và lạm dụng API Nginx sử dụng thuật toán\nleaky bucket (xô rò rỉ). Cấu hình được thực hiện với hai chỉ thị:\nlimit_req_zone: Được định nghĩa trong context http, nó thiết lập vùng bộ nhớ chia sẻ. Các tham số chính là key (ví dụ: $binary_remote_addr để giới hạn theo IP), tên và kích thước zone, và rate (ví dụ: 10r/s). limit_req: Được sử dụng trong một khối location để áp dụng giới hạn của một vùng cụ thể. Các tham số quan trọng burst và nodelay cũng cần được giải thích. burst=20 cho phép một loạt 20 yêu cầu được xếp hàng và xử lý theo tốc độ đã định. nodelay cho phép loạt yêu cầu đó được xử lý ngay lập tức mà không bị điều tiết, nhưng các yêu cầu tiếp theo sẽ bị từ chối nếu tốc độ vẫn bị vượt quá.\n6.3. Các Header Bảo Mật Thiết Yếu Các HTTP Security Header hướng dẫn trình duyệt kích hoạt các tính năng bảo mật, cung cấp một lớp phòng thủ bổ sung. Chúng có thể được triển khai bằng chỉ thị\nadd_header:\nStrict-Transport-Security (HSTS): add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always; - Buộc trình duyệt sử dụng HTTPS. X-Frame-Options: add_header X-Frame-Options \"SAMEORIGIN\"; - Ngăn chặn clickjacking. X-Content-Type-Options: add_header X-Content-Type-Options \"nosniff\"; - Ngăn chặn các cuộc tấn công MIME-sniffing. X-XSS-Protection: add_header X-XSS-Protection \"1; mode=block\"; - Kích hoạt bộ lọc XSS tích hợp của trình duyệt. 6.4. Lớp WAF: ModSecurity và các Lựa Chọn Thay Thế Một Tường lửa Ứng dụng Web (WAF) bảo vệ chống lại các cuộc tấn công lớp ứng dụng phổ biến như SQL injection và XSS.\nModSecurity từ lâu đã là WAF mã nguồn mở tiêu chuẩn, có sẵn dưới dạng module Nginx.56\nTuy nhiên, một thông tin quan trọng là F5 đã thông báo Kết thúc vòng đời (End-of-Life) cho module NGINX ModSecurity WAF vào ngày 31 tháng 3 năm 2024.57 Điều này đánh dấu một bước ngoặt quan trọng trong bối cảnh bảo mật Nginx, buộc cộng đồng phải đánh giá và áp dụng các công nghệ WAF mới hơn.\nCác lựa chọn thay thế hiện đại bao gồm:\nNAXSI (Nginx Anti XSS \u0026 SQL Injection): Một WAF nhẹ, dành riêng cho Nginx, sử dụng hệ thống tính điểm đơn giản thay vì các quy tắc regex phức tạp. Nó nhanh hơn và dễ bảo trì hơn nhưng kém linh hoạt hơn ModSecurity. open-appsec: Một WAF hiện đại dựa trên AI/ML, hoàn toàn tương thích với Nginx. Nó tập trung vào việc phát hiện mối đe dọa một cách chủ động mà không dựa vào các chữ ký truyền thống, làm cho nó trở thành một ứng cử viên sáng giá để thay thế ModSecurity. 6.5. Danh Sách Kiểm Tra Cứng Hóa Chung Một danh sách kiểm tra cuối cùng các kỹ thuật cứng hóa thiết yếu bao gồm:\nẨn phiên bản Nginx: Sử dụng server_tokens off; để ngăn rò rỉ thông tin. Vô hiệu hóa các phương thức HTTP không cần thiết: Sử dụng limit_except GET POST HEAD { deny all; } để chỉ cho phép các phương thức cần thiết. Hạn chế truy cập vào các tệp nhạy cảm: Sử dụng khối location để từ chối truy cập vào các tệp như .git, .env. Ngăn chặn DoS với Timeouts: Cấu hình thời gian chờ client hợp lý (client_body_timeout, client_header_timeout) để ngăn chặn các cuộc tấn công kiểu Slowloris. Cấu hình bộ mã hóa SSL/TLS mạnh: Cung cấp một bộ mã hóa hiện đại, an toàn. Chạy với người dùng không phải root: Đảm bảo chỉ thị user trong nginx.conf được đặt thành một người dùng không có đặc quyền. Phần 7: Vượt Ra Ngoài những Điều Cơ Bản - Mở Rộng Nginx Phần cuối cùng này sẽ đề cập ngắn gọn đến sức mạnh của hệ sinh thái module của Nginx, cung cấp một ví dụ thực tế về một module của bên thứ ba có giá trị.\n7.1. Sức Mạnh của Modules: Nén Brotli Chức năng của Nginx có thể được mở rộng thông qua các module, có thể được biên dịch tĩnh hoặc tải động.\nBrotli là một thuật toán nén hiện đại do Google phát triển, cung cấp tỷ lệ nén tốt hơn Gzip, giúp trang web tải nhanh hơn.\nModule ngx_brotli có thể được thêm vào bằng cách biên dịch Nginx từ nguồn hoặc, trên nhiều hệ thống, bằng cách cài đặt một gói module động đã được biên dịch sẵn (ví dụ: nginx-module-brotli).\nVí dụ cấu hình:\nNginx\n# Trong context chính (cho module động) load_module modules/ngx_http_brotli_filter_module.so; load_module modules/ngx_http_brotli_static_module.so; # Trong context http, server, hoặc location brotli on; brotli_comp_level 6; brotli_types text/plain text/css application/json...; brotli_static on; # Phục vụ các tệp.br nếu tồn tại Nếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","wordCount":"5765","inLanguage":"en","image":"https://blog.nagih.io.vn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-08-16T00:00:00Z","dateModified":"2025-08-16T00:00:00Z","author":{"@type":"Person","name":"Nagih"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.nagih.io.vn/posts/nginx/"},"publisher":{"@type":"Organization","name":"Nagih | Blog","logo":{"@type":"ImageObject","url":"https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.nagih.io.vn/ accesskey=h title="Home (Alt + H)"><img src=https://blog.nagih.io.vn/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.nagih.io.vn/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://blog.nagih.io.vn/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.nagih.io.vn/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://blog.nagih.io.vn/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://nagih.io.vn title=Home><span>Home</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.nagih.io.vn/>Home</a>&nbsp;»&nbsp;<a href=https://blog.nagih.io.vn/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Nginx Overview</h1><div class=post-meta><span title='2025-08-16 00:00:00 +0000 UTC'>August 16, 2025</span>&nbsp;·&nbsp;28 min&nbsp;·&nbsp;5765 words&nbsp;·&nbsp;Nagih&nbsp;|&nbsp;<a href=https://github.com/vuongmanhnghia/posts/content/posts/deploy/Nginx.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#phần-1-nền-tảng-hiệu-năng-tại-sao-và-cái-gì-của-nginx>Phần 1: Nền Tảng Hiệu Năng: &ldquo;Tại Sao&rdquo; và &ldquo;Cái Gì&rdquo; của Nginx</a><ul><li><a href=#11-nguồn-gốc-của-nginx-giải-quyết-vấn-đề-10000-kết-nối>1.1. Nguồn Gốc của Nginx: Giải Quyết Vấn Đề 10,000 Kết Nối</a></li><li><a href=#12-kiến-trúc-của-tốc-độ-hướng-sự-kiện-io-bất-đồng-bộ-không-chặn>1.2. Kiến Trúc của Tốc Độ: Hướng Sự Kiện, I/O Bất Đồng Bộ Không Chặn</a></li></ul></li><li><a href=#phần-2-con-dao-đa-năng-của-thụy-sĩ---các-trường-hợp-sử-dụng-cốt-lõi-của-nginx>Phần 2: &ldquo;Con Dao Đa Năng&rdquo; của Thụy Sĩ - Các Trường Hợp Sử Dụng Cốt Lõi của Nginx</a><ul><li><a href=#21-máy-chủ-web-hiệu-năng-cao-cho-nội-dung-tĩnh>2.1. Máy Chủ Web Hiệu Năng Cao (cho Nội Dung Tĩnh)</a></li><li><a href=#22-người-bảo-vệ-nginx-trong-vai-trò-reverse-proxy>2.2. Người Bảo Vệ: Nginx trong vai trò Reverse Proxy</a></li><li><a href=#23-người-điều-phối-giao-thông-nginx-trong-vai-trò-load-balancer>2.3. Người Điều Phối Giao Thông: Nginx trong vai trò Load Balancer</a></li><li><a href=#24-người-gác-cổng-nginx-trong-vai-trò-api-gateway>2.4. Người Gác Cổng: Nginx trong vai trò API Gateway</a></li><li><a href=#25-người-tăng-tốc-caching-nâng-cao-với-nginx>2.5. Người Tăng Tốc: Caching Nâng Cao với Nginx</a></li></ul></li><li><a href=#phần-3-nginx-trong-hệ-sinh-thái-hiện-đại---một-phân-tích-so-sánh>Phần 3: Nginx trong Hệ Sinh Thái Hiện Đại - Một Phân Tích So Sánh</a><ul><li><a href=#31-cuộc-đối-đầu-kinh-điển-nginx-vs-apache-http-server>3.1. Cuộc Đối Đầu Kinh Điển: Nginx vs. Apache HTTP Server</a></li><li><a href=#32-chuyên-gia-nginx-vs-haproxy>3.2. Chuyên Gia: Nginx vs. HAProxy</a></li><li><a href=#33-thách-thức-mới-nginx-vs-caddy>3.3. Thách Thức Mới: Nginx vs. Caddy</a></li><li><a href=#34-bảng-phân-tích-so-sánh>3.4. Bảng Phân Tích So Sánh</a></li></ul></li><li><a href=#phần-4-làm-chủ-cấu-hình-nginx>Phần 4: Làm Chủ Cấu Hình Nginx</a><ul><li><a href=#41-giải-phẫu-tệp-nginxconf>4.1. Giải Phẫu Tệp <code>nginx.conf</code></a></li><li><a href=#42-lưu-trữ-nhiều-trang-web-server-blocks-virtual-hosts>4.2. Lưu Trữ Nhiều Trang Web: Server Blocks (Virtual Hosts)</a></li><li><a href=#43-nghệ-thuật-định-tuyến-logic-khớp-khối-location>4.3. Nghệ Thuật Định Tuyến: Logic Khớp Khối Location</a></li></ul></li><li><a href=#phần-5-nginx-trong-thế-giới-container-với-docker>Phần 5: Nginx trong Thế Giới Container với Docker</a><ul><li><a href=#51-bắt-đầu-chạy-image-nginx-chính-thức>5.1. Bắt Đầu: Chạy Image Nginx Chính Thức</a></li><li><a href=#52-tùy-chỉnh-container-nginx-của-bạn>5.2. Tùy Chỉnh Container Nginx của Bạn</a></li><li><a href=#53-điều-phối-với-docker-compose-một-ví-dụ-reverse-proxy-thực-tế>5.3. Điều Phối với Docker Compose: Một Ví Dụ Reverse Proxy Thực Tế</a></li></ul></li><li><a href=#phần-6-bảo-mật-máy-chủ-nginx---danh-sách-kiểm-tra-cứng-hóa>Phần 6: Bảo Mật Máy Chủ Nginx - Danh Sách Kiểm Tra Cứng Hóa</a><ul><li><a href=#61-mã-hóa-mọi-thứ-ssltls-với-lets-encrypt>6.1. Mã Hóa Mọi Thứ: SSL/TLS với Let&rsquo;s Encrypt</a></li><li><a href=#62-điều-tiết-lưu-lượng-giới-hạn-tốc-độ-nâng-cao>6.2. Điều Tiết Lưu Lượng: Giới Hạn Tốc Độ Nâng Cao</a></li><li><a href=#63-các-header-bảo-mật-thiết-yếu>6.3. Các Header Bảo Mật Thiết Yếu</a></li><li><a href=#64-lớp-waf-modsecurity-và-các-lựa-chọn-thay-thế>6.4. Lớp WAF: ModSecurity và các Lựa Chọn Thay Thế</a></li><li><a href=#65-danh-sách-kiểm-tra-cứng-hóa-chung>6.5. Danh Sách Kiểm Tra Cứng Hóa Chung</a></li></ul></li><li><a href=#phần-7-vượt-ra-ngoài-những-điều-cơ-bản---mở-rộng-nginx>Phần 7: Vượt Ra Ngoài những Điều Cơ Bản - Mở Rộng Nginx</a><ul><li><a href=#71-sức-mạnh-của-modules-nén-brotli>7.1. Sức Mạnh của Modules: Nén Brotli</a></li></ul></li></ul></nav></div></details></div><div class=post-content><p>Nginx - Từ C10k Đến Containers</p><h2 id=phần-1-nền-tảng-hiệu-năng-tại-sao-và-cái-gì-của-nginx>Phần 1: Nền Tảng Hiệu Năng: &ldquo;Tại Sao&rdquo; và &ldquo;Cái Gì&rdquo; của Nginx<a hidden class=anchor aria-hidden=true href=#phần-1-nền-tảng-hiệu-năng-tại-sao-và-cái-gì-của-nginx>#</a></h2><p>Phần này thiết lập bối cảnh cơ bản về sự tồn tại và triết lý thiết kế cốt lõi của Nginx. Khám phá vấn đề lịch sử mà Nginx được thiết kế để giải quyết và phân tích các lựa chọn kiến trúc đã biến nó thành một nền tảng của cơ sở hạ tầng web hiện đại.</p><h3 id=11-nguồn-gốc-của-nginx-giải-quyết-vấn-đề-10000-kết-nối>1.1. Nguồn Gốc của Nginx: Giải Quyết Vấn Đề 10,000 Kết Nối<a hidden class=anchor aria-hidden=true href=#11-nguồn-gốc-của-nginx-giải-quyết-vấn-đề-10000-kết-nối>#</a></h3><p>Nginx ra đời không phải là một sự cải tiến gia tăng, mà là một sự thay đổi mô hình trong kiến trúc máy chủ web, một phản ứng trực tiếp trước những hạn chế kiến trúc cơ bản của các máy chủ tiền nhiệm, vốn không còn phù hợp với sự phát triển bùng nổ của Internet.</p><p>Vào đầu những năm 2000, khi Internet phát triển với tốc độ chóng mặt, một thách thức kỹ thuật mới đã xuất hiện, được gọi là <strong>vấn đề C10k</strong>. Thuật ngữ này, do kỹ sư Dan Kegel đặt ra vào năm 1999, mô tả bài toán xử lý 10,000 kết nối đồng thời trên một máy chủ duy nhất.1 Vấn đề này không chỉ đơn thuần là về tốc độ xử lý yêu cầu (throughput), mà là về khả năng quản lý hiệu quả một số lượng lớn các kết nối đang mở cùng một lúc. Các máy chủ web phổ biến thời bấy giờ, như Apache, với mô hình xử lý một tiến trình hoặc một luồng cho mỗi kết nối, đã gặp phải giới hạn nghiêm trọng. Mỗi kết nối tiêu tốn một lượng tài nguyên CPU và bộ nhớ đáng kể, tạo ra một rào cản về khả năng mở rộng khi số lượng người dùng tăng vọt.</p><p>Trong bối cảnh đó, Igor Sysoev, một kỹ sư hệ thống người Nga làm việc tại Rambler, đã bắt đầu phát triển Nginx vào năm 2002. Ban đầu, ông đã cố gắng cải thiện hiệu suất của Apache thông qua các module như</p><p><code>mod_accel</code>, nhưng nhanh chóng nhận ra rằng cần một cách tiếp cận hoàn toàn mới. Nginx không được tạo ra để trở thành &ldquo;một Apache nhanh hơn&rdquo;, mà là để định nghĩa lại cách một máy chủ web xử lý I/O và quản lý kết nối. Phần mềm được phát hành công khai vào năm 2004 dưới dạng mã nguồn mở miễn phí, theo giấy phép BSD 2 điều khoản.</p><p>Thành công của kiến trúc mới này đã được chứng minh nhanh chóng. Đến tháng 9 năm 2008, Nginx đã phục vụ 500 triệu yêu cầu mỗi ngày cho cổng thông tin và công cụ tìm kiếm Rambler. Năm 2011, Nginx, Inc. được thành lập để cung cấp các sản phẩm thương mại và hỗ trợ (NGINX Plus), và sau đó được F5 Networks mua lại vào năm 2019.</p><h3 id=12-kiến-trúc-của-tốc-độ-hướng-sự-kiện-io-bất-đồng-bộ-không-chặn>1.2. Kiến Trúc của Tốc Độ: Hướng Sự Kiện, I/O Bất Đồng Bộ Không Chặn<a hidden class=anchor aria-hidden=true href=#12-kiến-trúc-của-tốc-độ-hướng-sự-kiện-io-bất-đồng-bộ-không-chặn>#</a></h3><p>Chìa khóa cho hiệu suất và khả năng mở rộng vượt trội của Nginx nằm ở kiến trúc <strong>bất đồng bộ, hướng sự kiện và I/O không chặn</strong> (asynchronous, event-driven, non-blocking I/O). Đây là yếu tố cốt lõi giúp Nginx giải quyết vấn đề C10k.</p><p>Nginx hoạt động theo mô hình <strong>master-worker</strong>. Một tiến trình</p><p><code>master</code> duy nhất chịu trách nhiệm cho các tác vụ quản trị: đọc và xác thực cấu hình, liên kết với các cổng mạng, và tạo ra một số lượng tiến trình <code>worker</code> (thường là một worker cho mỗi lõi CPU). Các tiến trình</p><p><code>worker</code> này mới là nơi xử lý các yêu cầu của client.</p><p>Mỗi tiến trình <code>worker</code> là <strong>đơn luồng</strong> (single-threaded) và chạy một <strong>vòng lặp sự kiện</strong> (event loop). Vòng lặp này sử dụng các cơ chế hiệu quả của hệ điều hành như <code>epoll</code> (trên Linux) hoặc <code>kqueue</code> (trên FreeBSD) để giám sát hàng ngàn kết nối cùng lúc cho các sự kiện (ví dụ: có dữ liệu mới để đọc, bộ đệm sẵn sàng để ghi). Khi một sự kiện xảy ra, một hàm gọi lại (callback) được kích hoạt để xử lý nó. Vì tất cả các hoạt động I/O đều là</p><p><strong>không chặn</strong> (non-blocking), tiến trình worker không bao giờ phải chờ đợi các hoạt động chậm chạp như đọc/ghi đĩa hoặc mạng. Thay vào đó, nó khởi tạo hoạt động và ngay lập tức chuyển sang xử lý các sự kiện khác. Khi hoạt động I/O hoàn tất, hệ điều hành sẽ thông báo cho vòng lặp sự kiện, và kết quả sẽ được xử lý.</p><p>Mô hình này mang lại hai lợi ích to lớn. Thứ nhất, nó loại bỏ hoàn toàn chi phí tạo ra một tiến trình hoặc luồng mới cho mỗi kết nối. Thứ hai, nó tránh được việc <strong>chuyển đổi ngữ cảnh</strong> (context switching) tốn kém, một vấn đề lớn của các mô hình truyền thống khi tải cao. Kết quả là Nginx có thể xử lý hàng ngàn kết nối với chi phí bộ nhớ cực thấp (chỉ khoảng 100KB đến 1MB mỗi kết nối) và đạt được thông lượng rất cao, có thể lên tới 100,000 yêu cầu mỗi giây cho mỗi worker.</p><p>Kiến trúc master-worker không chỉ mang lại hiệu suất mà còn là nền tảng cho sự ổn định vận hành và các tính năng quan trọng như cập nhật cấu hình không gián đoạn (zero-downtime reloads). Khi cần thay đổi cấu hình, một tín hiệu <code>reload</code> được gửi đến tiến trình master. Master sẽ xác thực cấu hình mới và tạo ra một <em>bộ worker mới</em> với cấu hình cập nhật. Các worker cũ sẽ được tắt một cách nhẹ nhàng: chúng ngừng chấp nhận kết nối mới nhưng tiếp tục xử lý các kết nối hiện có cho đến khi hoàn tất. Khi tất cả các kết nối cũ đã đóng, các worker cũ sẽ tự kết thúc. Toàn bộ quá trình này diễn ra mà không làm mất bất kỳ kết nối nào của client, cho phép <strong>cập nhật không thời gian chết</strong>, một yêu cầu tối quan trọng trong các hoạt động DevOps hiện đại.</p><hr><h2 id=phần-2-con-dao-đa-năng-của-thụy-sĩ---các-trường-hợp-sử-dụng-cốt-lõi-của-nginx>Phần 2: &ldquo;Con Dao Đa Năng&rdquo; của Thụy Sĩ - Các Trường Hợp Sử Dụng Cốt Lõi của Nginx<a hidden class=anchor aria-hidden=true href=#phần-2-con-dao-đa-năng-của-thụy-sĩ---các-trường-hợp-sử-dụng-cốt-lõi-của-nginx>#</a></h2><p>Từ lý thuyết đến thực tiễn, phần này sẽ trình bày sự linh hoạt của Nginx thông qua các vai trò phổ biến nhất của nó. Mỗi tiểu mục sẽ bao gồm các ví dụ cấu hình được chú thích chi tiết.</p><h3 id=21-máy-chủ-web-hiệu-năng-cao-cho-nội-dung-tĩnh>2.1. Máy Chủ Web Hiệu Năng Cao (cho Nội Dung Tĩnh)<a hidden class=anchor aria-hidden=true href=#21-máy-chủ-web-hiệu-năng-cao-cho-nội-dung-tĩnh>#</a></h3><p>Nhờ kiến trúc hướng sự kiện hiệu quả, Nginx vượt trội trong việc phục vụ nội dung tĩnh như các tệp HTML, CSS, JavaScript và hình ảnh. Trong các bài kiểm tra hiệu năng, Nginx luôn cho thấy hiệu suất cao hơn đáng kể so với Apache trong lĩnh vực này.</p><p>Một cấu hình cơ bản để phục vụ một trang web tĩnh rất đơn giản. Khối <code>server</code> định nghĩa một máy chủ ảo, chỉ thị <code>listen</code> xác định cổng lắng nghe, <code>server_name</code> chỉ định tên miền, <code>root</code> là đường dẫn đến thư mục chứa tệp của trang web, và <code>index</code> xác định tệp mặc định sẽ được phục vụ.</p><p>Một mô hình triển khai phổ biến là thiết lập kết hợp, trong đó Nginx đóng vai trò là &ldquo;người gác cổng&rdquo; phía trước Apache. Trong mô hình này, Nginx nhận tất cả các yêu cầu, phục vụ trực tiếp các tệp tĩnh với tốc độ tối đa, và chuyển tiếp các yêu cầu nội dung động (như PHP) đến Apache để xử lý.</p><p><strong>Ví dụ cấu hình:</strong></p><p>Nginx</p><pre tabindex=0><code>server {
    listen 80;
    server_name example.com www.example.com;
    root /var/www/html;
    index index.html index.htm;

    # Tối ưu hóa việc phục vụ file tĩnh
    location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
        expires 365d; # Yêu cầu trình duyệt lưu cache tài sản tĩnh trong 1 năm
        add_header Cache-Control &#34;public&#34;;
    }
}
</code></pre><h3 id=22-người-bảo-vệ-nginx-trong-vai-trò-reverse-proxy>2.2. Người Bảo Vệ: Nginx trong vai trò Reverse Proxy<a hidden class=anchor aria-hidden=true href=#22-người-bảo-vệ-nginx-trong-vai-trò-reverse-proxy>#</a></h3><p>Reverse proxy là một máy chủ trung gian nằm giữa client và các máy chủ backend. Nó nhận yêu cầu từ client và chuyển tiếp chúng đến máy chủ phù hợp. Vai trò này mang lại nhiều lợi ích: che giấu kiến trúc của hệ thống backend, tăng cường bảo mật bằng cách tạo ra một điểm vào duy nhất, có thể chấm dứt SSL/TLS, và là nền tảng cho cân bằng tải và caching.</p><p>Chỉ thị cốt lõi cho chức năng này là <code>proxy_pass</code>, dùng để chỉ định địa chỉ của máy chủ backend hoặc một nhóm <code>upstream</code>. Một yếu tố cực kỳ quan trọng là sử dụng chỉ thị</p><p><code>proxy_set_header</code> để chuyển tiếp các thông tin quan trọng của client (như <code>Host</code> gốc, <code>X-Real-IP</code>, và <code>X-Forwarded-For</code>) đến máy chủ backend. Nếu không, máy chủ backend sẽ chỉ thấy địa chỉ IP của proxy, làm mất thông tin về client gốc.</p><p>Nginx cũng có cơ chế đệm phản hồi (<code>proxy_buffering</code>). Khi được bật (mặc định), Nginx sẽ lưu phản hồi từ máy chủ backend vào bộ đệm và chỉ gửi cho client khi đã nhận đủ. Điều này giúp tối ưu hóa hiệu suất với các client có kết nối chậm, cho phép máy chủ backend xử lý yêu cầu nhanh chóng và giải phóng tài nguyên, trong khi Nginx từ từ gửi dữ liệu về cho client.</p><p><strong>Ví dụ cấu hình:</strong></p><p>Nginx</p><pre tabindex=0><code>location /app/ {
    proxy_pass http://backend_server:8080;

    # Chuyển tiếp các header quan trọng đến backend
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
}
</code></pre><h3 id=23-người-điều-phối-giao-thông-nginx-trong-vai-trò-load-balancer>2.3. Người Điều Phối Giao Thông: Nginx trong vai trò Load Balancer<a hidden class=anchor aria-hidden=true href=#23-người-điều-phối-giao-thông-nginx-trong-vai-trò-load-balancer>#</a></h3><p>Cân bằng tải là một trong những ứng dụng phổ biến nhất của reverse proxy, giúp phân phối lưu lượng truy cập qua nhiều máy chủ backend để cải thiện hiệu suất, khả năng mở rộng và độ tin cậy của hệ thống.</p><p>Cấu hình này được thực hiện thông qua khối <code>upstream</code>, nơi định nghĩa một nhóm các máy chủ backend. Sau đó, chỉ thị</p><p><code>proxy_pass</code> sẽ trỏ đến tên của nhóm <code>upstream</code> này. Nginx mã nguồn mở hỗ trợ các thuật toán cân bằng tải sau:</p><ul><li><strong>Round Robin (Mặc định):</strong> Các yêu cầu được phân phối lần lượt đến từng máy chủ trong nhóm. Có thể sử dụng tham số <code>weight</code> để gán trọng số, giúp các máy chủ mạnh hơn nhận được nhiều lưu lượng hơn.</li><li><strong>Least Connections (<code>least_conn</code>):</strong> Yêu cầu tiếp theo được gửi đến máy chủ có số lượng kết nối đang hoạt động ít nhất. Thuật toán này rất hiệu quả khi thời gian xử lý các yêu cầu không đồng đều.</li><li><strong>IP Hash (<code>ip_hash</code>):</strong> Máy chủ được chọn dựa trên một hàm băm từ địa chỉ IP của client. Điều này đảm bảo rằng các yêu cầu từ cùng một client sẽ luôn được chuyển đến cùng một máy chủ. Đây là một cách đơn giản để thực hiện &ldquo;sticky sessions&rdquo; (phiên cố định), rất quan trọng cho các ứng dụng cần duy trì trạng thái phiên.</li></ul><p>NGINX Plus cung cấp các phương pháp nâng cao hơn như <code>least_time</code> và các tính năng duy trì phiên phức tạp hơn như <code>sticky cookie</code> và <code>sticky route</code>.</p><p><strong>Ví dụ cấu hình:</strong></p><p>Nginx</p><pre tabindex=0><code>upstream backend_pool {
    # ip_hash; # Bỏ comment để bật sticky sessions
    # least_conn; # Bỏ comment để dùng thuật toán least connections
    server backend1.example.com weight=3;
    server backend2.example.com;
    server backend3.example.com backup; # Chỉ sử dụng khi các server khác lỗi
}

server {
    listen 80;
    location / {
        proxy_pass http://backend_pool;
    }
}
</code></pre><h3 id=24-người-gác-cổng-nginx-trong-vai-trò-api-gateway>2.4. Người Gác Cổng: Nginx trong vai trò API Gateway<a hidden class=anchor aria-hidden=true href=#24-người-gác-cổng-nginx-trong-vai-trò-api-gateway>#</a></h3><p>Trong các kiến trúc microservices hiện đại, API Gateway đóng vai trò là một điểm vào duy nhất cho tất cả các yêu cầu API. Sự phát triển của Nginx thành một API Gateway là một sự mở rộng tự nhiên từ các khả năng cốt lõi của nó như một reverse proxy hiệu năng cao. Một reverse proxy về cơ bản là chặn, kiểm tra và chuyển tiếp yêu cầu. Một API Gateway cũng làm điều tương tự nhưng thêm vào đó các logic phức tạp hơn như định tuyến dựa trên đường dẫn API, xác thực thông tin đăng nhập và thực thi các chính sách sử dụng. Các khối</p><p><code>location</code> mạnh mẽ của Nginx cung cấp khả năng định tuyến dựa trên URI, module <code>limit_req</code> cung cấp giới hạn tốc độ, và khả năng kiểm tra header cho phép xác thực. Do đó, các khối xây dựng cơ bản cho một API Gateway đã có sẵn trong Nginx.</p><p>Các tính năng chính của một API Gateway dựa trên Nginx bao gồm:</p><ul><li><strong>Định tuyến (Routing):</strong> Chuyển hướng yêu cầu đến microservice backend phù hợp dựa trên URI.</li><li><strong>Xác thực (Authentication):</strong> Xác thực API key hoặc JSON Web Tokens (JWT).</li><li><strong>Giới hạn tốc độ (Rate Limiting):</strong> Áp dụng giới hạn tốc độ để ngăn chặn lạm dụng và đảm bảo sử dụng công bằng.</li><li><strong>Chấm dứt SSL/TLS (SSL/TLS Termination):</strong> Giảm tải việc mã hóa/giải mã từ các dịch vụ backend.</li></ul><p>Có nhiều cách để triển khai điều này: sử dụng các tính năng gốc của Nginx, mở rộng với Lua/OpenResty, hoặc sử dụng sản phẩm thương mại NGINX Plus API Gateway. Một dự án hiện đại đáng chú ý là NGINX Gateway Fabric, một triển khai của Gateway API dành cho Kubernetes, sử dụng Nginx làm data plane.</p><h3 id=25-người-tăng-tốc-caching-nâng-cao-với-nginx>2.5. Người Tăng Tốc: Caching Nâng Cao với Nginx<a hidden class=anchor aria-hidden=true href=#25-người-tăng-tốc-caching-nâng-cao-với-nginx>#</a></h3><p>Nginx có thể lưu trữ (cache) các phản hồi từ máy chủ backend, giúp cải thiện đáng kể hiệu suất và giảm tải cho máy chủ gốc.</p><p>Việc cấu hình <code>proxy_cache</code> được thực hiện thông qua các chỉ thị chính sau:</p><ul><li><code>proxy_cache_path</code>: Định nghĩa vị trí lưu trữ cache trên đĩa, vùng bộ nhớ chia sẻ cho các khóa (<code>keys_zone</code>), kích thước tối đa (<code>max_size</code>), và thời gian không hoạt động (<code>inactive</code>).</li><li><code>proxy_cache</code>: Kích hoạt một vùng cache cụ thể trong một khối <code>location</code> hoặc <code>server</code>.</li><li><code>proxy_cache_valid</code>: Thiết lập thời gian cache mặc định cho các mã trạng thái HTTP khác nhau (ví dụ: cache phản hồi <code>200 OK</code> trong 60 phút, <code>404 Not Found</code> trong 1 phút).</li><li><code>proxy_cache_key</code>: Định nghĩa chuỗi được sử dụng để tạo khóa duy nhất cho mỗi mục được cache (mặc định là <code>$scheme$proxy_host$request_uri</code>).</li></ul><p>Để gỡ lỗi và theo dõi, việc thêm một header tùy chỉnh (<code>X-Cache-Status</code>) với giá trị của biến <code>$upstream_cache_status</code> là vô giá. Header này sẽ cho biết một yêu cầu là <code>HIT</code> (tìm thấy trong cache), <code>MISS</code> (không tìm thấy), <code>EXPIRED</code> (hết hạn), <code>BYPASS</code> (bỏ qua cache), v.v..</p><p>Các khái niệm nâng cao bao gồm việc phục vụ nội dung cũ khi backend gặp sự cố (<code>proxy_cache_use_stale</code>) và bỏ qua cache cho các yêu cầu nhất định (<code>proxy_cache_bypass</code>).</p><p><strong>Ví dụ cấu hình:</strong></p><p>Nginx</p><pre tabindex=0><code># Trong khối http
proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m;

# Trong khối server
server {
    #...
    location / {
        proxy_cache my_cache;
        proxy_cache_valid 200 302 10m;
        proxy_cache_valid 404 1m;
        proxy_pass http://my_upstream;

        add_header X-Cache-Status $upstream_cache_status;
    }
}
</code></pre><hr><h2 id=phần-3-nginx-trong-hệ-sinh-thái-hiện-đại---một-phân-tích-so-sánh>Phần 3: Nginx trong Hệ Sinh Thái Hiện Đại - Một Phân Tích So Sánh<a hidden class=anchor aria-hidden=true href=#phần-3-nginx-trong-hệ-sinh-thái-hiện-đại---một-phân-tích-so-sánh>#</a></h2><p>Phần này cung cấp một so sánh cân bằng và chi tiết giữa Nginx và các đối thủ chính của nó, giúp các kỹ sư đưa ra quyết định kiến trúc sáng suốt dựa trên yêu cầu dự án cụ thể.</p><h3 id=31-cuộc-đối-đầu-kinh-điển-nginx-vs-apache-http-server>3.1. Cuộc Đối Đầu Kinh Điển: Nginx vs. Apache HTTP Server<a hidden class=anchor aria-hidden=true href=#31-cuộc-đối-đầu-kinh-điển-nginx-vs-apache-http-server>#</a></h3><p>Sự lựa chọn giữa Nginx và Apache không còn đơn thuần là câu hỏi &ldquo;cái nào nhanh hơn&rdquo;, mà là sự lựa chọn về triết lý kiến trúc. Nginx ưu tiên hiệu suất thô và hiệu quả thông qua một mô hình tập trung, cứng nhắc, trong khi Apache ưu tiên sự linh hoạt và kiểm soát phân tán, thường phải trả giá bằng hiệu suất.</p><ul><li><strong>Kiến trúc:</strong> Nginx sử dụng mô hình hướng sự kiện với các worker đơn luồng, trong khi Apache sử dụng mô hình hướng tiến trình/luồng (với các MPM như <code>prefork</code>, <code>worker</code>, <code>event</code>).</li><li><strong>Hiệu năng:</strong> Nginx nhanh hơn đáng kể khi phục vụ nội dung tĩnh và vượt trội dưới tải đồng thời cao do sử dụng ít tài nguyên hơn.12 Apache, với các module động như
<code>mod_php</code>, có thể xử lý nội dung động hiệu quả hơn <em>bên trong chính máy chủ</em>, mặc dù các thiết lập hiện đại thường sử dụng PHP-FPM, làm cho sự khác biệt này ít rõ rệt hơn.</li><li><strong>Cấu hình:</strong> Nginx sử dụng một tệp cấu hình tập trung. Apache cung cấp cấu hình ở cấp thư mục thông qua các tệp <code>.htaccess</code>, mang lại sự linh hoạt cho người dùng trong môi trường hosting chia sẻ nhưng có thể làm giảm hiệu suất vì máy chủ phải quét hệ thống tệp cho các tệp này trên mỗi yêu cầu. Trong các môi trường DevOps hiện đại, nơi cơ sở hạ tầng thường được quản lý tập trung thông qua tự động hóa (IaC), khả năng kiểm soát phân tán của
<code>.htaccess</code> có thể trở thành một gánh nặng hơn là một tính năng, làm cho cấu hình tập trung và có thể dự đoán của Nginx trở nên hấp dẫn hơn.</li><li><strong>Modules:</strong> Apache có một hệ sinh thái module động khổng lồ. Các module Nginx truyền thống cần được biên dịch vào tệp nhị phân, mặc dù việc tải module động đã được hỗ trợ từ năm 2016.</li></ul><h3 id=32-chuyên-gia-nginx-vs-haproxy>3.2. Chuyên Gia: Nginx vs. HAProxy<a hidden class=anchor aria-hidden=true href=#32-chuyên-gia-nginx-vs-haproxy>#</a></h3><ul><li><strong>Nguồn gốc & Trọng tâm:</strong> Nginx bắt đầu như một máy chủ web và phát triển thành một công cụ đa năng. HAProxy được thiết kế từ đầu như một bộ cân bằng tải và reverse proxy hiệu suất cao cho lưu lượng TCP và HTTP.</li><li><strong>Tính năng Layer 7:</strong> Cả hai đều là những bộ cân bằng tải Layer 7 (HTTP) xuất sắc. Nginx có lợi thế là một máy chủ web đầy đủ tính năng, có thể phục vụ trực tiếp các tệp tĩnh, điều mà HAProxy không thể làm.</li><li><strong>Hiệu năng & Chuyên môn hóa:</strong> HAProxy thường được coi là một chuyên gia với hiệu suất vượt trội và các tính năng nâng cao hơn dành riêng cho việc cân bằng tải, chẳng hạn như kiểm tra sức khỏe mạnh mẽ hơn và khả năng quan sát tốt hơn ngay từ đầu trong phiên bản mã nguồn mở của nó.</li><li><strong>Vận hành:</strong> HAProxy được khen ngợi vì khả năng tải lại nóng không gián đoạn (hot reloads) và mô hình vận hành đơn giản hơn cho các thay đổi trực tiếp, trong khi Nginx OSS yêu cầu tải lại hoàn toàn, có thể làm mất kết nối trong giây lát.</li><li><strong>Mô hình phổ biến:</strong> Một kiến trúc mạnh mẽ và phổ biến là sử dụng cả hai: Nginx ở biên (edge) để chấm dứt SSL và phục vụ nội dung tĩnh, sau đó chuyển tiếp lưu lượng đến một HAProxy nội bộ để cân bằng tải phức tạp qua các dịch vụ backend.</li></ul><h3 id=33-thách-thức-mới-nginx-vs-caddy>3.3. Thách Thức Mới: Nginx vs. Caddy<a hidden class=anchor aria-hidden=true href=#33-thách-thức-mới-nginx-vs-caddy>#</a></h3><p>Caddy đại diện cho một sự thay đổi triết lý hướng tới &ldquo;bảo mật mặc định&rdquo; và trải nghiệm của nhà phát triển. Nó đánh đổi khả năng tùy chỉnh vô hạn của Nginx để lấy các mặc định tự động, hợp lý, bao phủ phần lớn các trường hợp sử dụng, làm cho nó trở thành một sự thay thế hiện đại hấp dẫn.</p><ul><li><strong>Dễ dàng cấu hình:</strong> Caddy nổi tiếng với tệp cấu hình <code>Caddyfile</code> đơn giản, dễ đọc, thường ngắn gọn hơn nhiều so với cấu hình Nginx tương đương.</li><li><strong>HTTPS tự động:</strong> Đây là tính năng &ldquo;sát thủ&rdquo; của Caddy. Nó tích hợp sẵn với Let&rsquo;s Encrypt để tự động cấp phát và gia hạn chứng chỉ TLS cho tất cả các trang web được cấu hình, một quá trình đòi hỏi một công cụ riêng biệt như Certbot với Nginx.</li><li><strong>Kiến trúc & Hiệu năng:</strong> Caddy được viết bằng Go và tận dụng mô hình đồng thời của Go. Nó rất hiệu quả, mặc dù Nginx vẫn có thể có lợi thế trong các kịch bản lưu lượng cực cao với các cấu hình được tinh chỉnh kỹ lưỡng.</li><li><strong>Hệ sinh thái:</strong> Nginx có một cộng đồng và hệ sinh thái module lớn hơn và trưởng thành hơn nhiều. Caddy nhỏ hơn nhưng đang phát triển nhanh chóng.</li></ul><h3 id=34-bảng-phân-tích-so-sánh>3.4. Bảng Phân Tích So Sánh<a hidden class=anchor aria-hidden=true href=#34-bảng-phân-tích-so-sánh>#</a></h3><p>Bảng dưới đây cung cấp một cái nhìn tổng quan, giúp các kỹ sư nhanh chóng so sánh các công cụ dựa trên các tiêu chí DevOps quan trọng.</p><table><thead><tr><th>Tiêu chí</th><th>Nginx</th><th>Apache</th><th>HAProxy</th><th>Caddy</th></tr></thead><tbody><tr><td><strong>Kiến trúc</strong></td><td>Hướng sự kiện, bất đồng bộ</td><td>Hướng tiến trình/luồng</td><td>Hướng sự kiện, bất đồng bộ</td><td>Hướng sự kiện, bất đồng bộ (Go)</td></tr><tr><td><strong>Trường hợp sử dụng chính</strong></td><td>Web server, Reverse Proxy, Cân bằng tải, API Gateway</td><td>Web server, Hosting chia sẻ</td><td>Cân bằng tải, Reverse Proxy (TCP/HTTP)</td><td>Web server, Reverse Proxy</td></tr><tr><td><strong>Hiệu năng nội dung tĩnh</strong></td><td>Xuất sắc</td><td>Tốt</td><td>Không áp dụng</td><td>Rất tốt</td></tr><tr><td><strong>Mô hình cấu hình</strong></td><td>Tập trung</td><td>Phân tán (<code>.htaccess</code>)</td><td>Tập trung</td><td>Tập trung (Caddyfile)</td></tr><tr><td><strong>Xử lý SSL/TLS</strong></td><td>Thủ công (cần Certbot)</td><td>Thủ công (cần Certbot)</td><td>Rất hiệu quả (chấm dứt TLS)</td><td>Tự động (tích hợp Let&rsquo;s Encrypt)</td></tr><tr><td><strong>Hệ sinh thái & Mở rộng</strong></td><td>Rất lớn, trưởng thành</td><td>Lớn nhất, nhiều module động</td><td>Chuyên biệt, tập trung</td><td>Đang phát triển</td></tr><tr><td><strong>Kịch bản lý tưởng</strong></td><td>Hệ thống hiệu năng cao, được quản lý tập trung</td><td>Hosting chia sẻ, cần sự linh hoạt ở cấp người dùng</td><td>Cân bằng tải chuyên dụng, yêu cầu độ tin cậy cao</td><td>Ưu tiên sự đơn giản, HTTPS tự động, trải nghiệm nhà phát triển</td></tr></tbody></table><hr><h2 id=phần-4-làm-chủ-cấu-hình-nginx>Phần 4: Làm Chủ Cấu Hình Nginx<a hidden class=anchor aria-hidden=true href=#phần-4-làm-chủ-cấu-hình-nginx>#</a></h2><p>Phần này đi sâu vào ngôn ngữ cấu hình của Nginx, từ cấu trúc cấp cao đến logic chi tiết điều khiển quá trình xử lý yêu cầu.</p><h3 id=41-giải-phẫu-tệp-nginxconf>4.1. Giải Phẫu Tệp <code>nginx.conf</code><a hidden class=anchor aria-hidden=true href=#41-giải-phẫu-tệp-nginxconf>#</a></h3><p>Tệp cấu hình chính của Nginx thường nằm ở <code>/etc/nginx/nginx.conf</code>. Cấu trúc của nó được tổ chức theo các khối phân cấp được gọi là</p><p><strong>context</strong> (ví dụ: <code>main</code>, <code>events</code>, <code>http</code>, <code>server</code>, <code>location</code>). Các chỉ thị trong một context cha sẽ được kế thừa bởi các context con nhưng có thể bị ghi đè.</p><ul><li><strong><code>main</code>/Global:</strong> Định nghĩa các chỉ thị cốt lõi như <code>user</code> và <code>worker_processes</code>.</li><li><strong><code>events</code>:</strong> Cấu hình các tham số xử lý kết nối, như <code>worker_connections</code> (số kết nối tối đa cho mỗi worker).</li><li><strong><code>http</code>:</strong> Chứa các chỉ thị để xử lý lưu lượng HTTP, bao gồm các khối <code>server</code> và <code>upstream</code>.</li></ul><p>Một thực hành tốt nhất là sử dụng chỉ thị <code>include</code> để mô-đun hóa cấu hình, thường bằng cách bao gồm các tệp từ <code>/etc/nginx/conf.d/*.conf</code> và <code>/etc/nginx/sites-enabled/*</code>. Mặc dù điều này thúc đẩy sự tổ chức, nó cũng có thể làm cho việc gỡ lỗi trở nên phức tạp nếu không được quản lý cẩn thận. Một chỉ thị trong</p><p><code>nginx.conf</code> có thể bị ghi đè bởi một chỉ thị trong <code>conf.d/global.conf</code>, và sau đó lại bị ghi đè bởi một chỉ thị trong <code>sites-enabled/mysite.conf</code>. Do đó, một kỹ năng quan trọng đối với kỹ sư DevOps là hiểu rõ logic kế thừa và bao gồm này. Các công cụ như <code>nginx -T</code> trở nên cần thiết để xem cấu hình được lắp ráp đầy đủ.</p><h3 id=42-lưu-trữ-nhiều-trang-web-server-blocks-virtual-hosts>4.2. Lưu Trữ Nhiều Trang Web: Server Blocks (Virtual Hosts)<a hidden class=anchor aria-hidden=true href=#42-lưu-trữ-nhiều-trang-web-server-blocks-virtual-hosts>#</a></h3><p>Nginx sử dụng các khối <code>server</code> để định nghĩa các máy chủ ảo (virtual hosts), cho phép một phiên bản Nginx duy nhất lưu trữ nhiều trang web. Nginx quyết định khối</p><p><code>server</code> nào sẽ xử lý một yêu cầu dựa trên các chỉ thị <code>listen</code> (IP:port) và <code>server_name</code> (tên miền từ header <code>Host</code>).</p><p>Trên các hệ thống Debian/Ubuntu, quy trình chuẩn là:</p><ol><li>Tạo một tệp cấu hình cho mỗi trang web trong <code>/etc/nginx/sites-available/</code>.</li><li>Tạo một liên kết tượng trưng (symbolic link) từ tệp đó đến <code>/etc/nginx/sites-enabled/</code> để kích hoạt trang web. Điều này cho phép bật hoặc tắt các trang web một cách dễ dàng mà không cần xóa tệp cấu hình.</li></ol><h3 id=43-nghệ-thuật-định-tuyến-logic-khớp-khối-location>4.3. Nghệ Thuật Định Tuyến: Logic Khớp Khối Location<a hidden class=anchor aria-hidden=true href=#43-nghệ-thuật-định-tuyến-logic-khớp-khối-location>#</a></h3><p>Khối <code>location</code> được sử dụng để kiểm soát cách xử lý các yêu cầu cho các URI khác nhau trong một máy chủ.36 Việc làm chủ logic khớp của nó là rất quan trọng. Thứ tự xử lý, thường là một nguồn gây nhầm lẫn, như sau:</p><ol><li><strong>Khớp chính xác (<code>=</code>):</strong> <code>location = /path</code> - Nếu URI khớp chính xác, khối này được sử dụng ngay lập tức và việc tìm kiếm dừng lại. Ưu tiên cao nhất.</li><li><strong>Khớp tiền tố ưu tiên (<code>^~</code>):</strong> <code>location ^~ /path</code> - Nginx tìm kiếm tiền tố khớp dài nhất. Nếu đây là khớp dài nhất, Nginx sẽ sử dụng nó và <em>không</em> kiểm tra các khối regex. Đây là một cơ chế tối ưu hóa hiệu suất có chủ ý, cho phép quản trị viên bỏ qua các đánh giá regex tốn kém cho các đường dẫn phổ biến.</li><li><strong>Khớp Regex (<code>~</code>, <code>~*</code>):</strong> <code>location ~ \.php$</code> (phân biệt chữ hoa/thường) hoặc <code>location ~* \.(jpg|png)$</code> (không phân biệt). Chúng được kiểm tra theo thứ tự xuất hiện trong tệp cấu hình. Khớp đầu tiên sẽ thắng.</li><li><strong>Khớp tiền tố dài nhất (không có modifier):</strong> <code>location /path</code> - Nếu không có regex nào khớp, tiền tố khớp dài nhất được tìm thấy trước đó sẽ được sử dụng. Ưu tiên thấp nhất.</li></ol><p>Điều quan trọng cần lưu ý là các khối <code>location</code> chỉ khớp với đường dẫn URI, không phải chuỗi truy vấn (query string). Để định tuyến dựa trên tham số truy vấn, có thể sử dụng một giải pháp thay thế bằng câu lệnh</p><p><code>if</code> và biến <code>$args</code> hoặc <code>$query_string</code>.</p><hr><h2 id=phần-5-nginx-trong-thế-giới-container-với-docker>Phần 5: Nginx trong Thế Giới Container với Docker<a hidden class=anchor aria-hidden=true href=#phần-5-nginx-trong-thế-giới-container-với-docker>#</a></h2><p>Phần này cung cấp hướng dẫn thực tế, từng bước để triển khai và quản lý Nginx trong một môi trường container hiện đại.</p><h3 id=51-bắt-đầu-chạy-image-nginx-chính-thức>5.1. Bắt Đầu: Chạy Image Nginx Chính Thức<a hidden class=anchor aria-hidden=true href=#51-bắt-đầu-chạy-image-nginx-chính-thức>#</a></h3><p>Bắt đầu với những điều cơ bản về việc sử dụng image Nginx chính thức từ Docker Hub. Một container đơn giản có thể được chạy, ánh xạ cổng với</p><p><code>-p 8080:80</code> và mount một thư mục nội dung tĩnh từ máy chủ vào thư mục gốc web mặc định của container (<code>/usr/share/nginx/html</code>) bằng cách sử dụng volume mount: <code>-v /path/on/host:/usr/share/nginx/html:ro</code>.</p><h3 id=52-tùy-chỉnh-container-nginx-của-bạn>5.2. Tùy Chỉnh Container Nginx của Bạn<a hidden class=anchor aria-hidden=true href=#52-tùy-chỉnh-container-nginx-của-bạn>#</a></h3><p>Có ba phương pháp chính để tùy chỉnh container Nginx:</p><ol><li><p><strong>Mount tệp cấu hình tùy chỉnh:</strong> Cách đơn giản nhất là mount tệp <code>nginx.conf</code> của riêng bạn hoặc một tệp vào <code>/etc/nginx/conf.d/</code> để ghi đè lên các mặc định: <code>-v /path/to/my.conf:/etc/nginx/conf.d/default.conf:ro</code>.</p></li><li><p><strong>Xây dựng Image tùy chỉnh với <code>Dockerfile</code>:</strong> Đối với các tùy chỉnh phức tạp hơn, có thể tạo một <code>Dockerfile</code> bắt đầu bằng <code>FROM nginx:latest</code> và sử dụng <code>COPY</code> để thêm các tệp cấu hình và nội dung tĩnh trực tiếp vào image. Lệnh</p><p><code>CMD</code> cần bao gồm <code>-g 'daemon off;'</code> để giữ Nginx chạy ở nền trước, cho phép Docker quản lý tiến trình.</p></li><li><p><strong>Sử dụng biến môi trường và template:</strong> Image Nginx chính thức hỗ trợ một cơ chế templating. Các tệp có đuôi <code>.template</code> trong <code>/etc/nginx/templates/</code> sẽ được thay thế các biến môi trường (như <code>${NGINX_HOST}</code>) trước khi được ghi vào <code>/etc/nginx/conf.d/</code>. Đây là một mẫu mạnh mẽ cho cấu hình động trong các đường ống CI/CD.</p></li></ol><h3 id=53-điều-phối-với-docker-compose-một-ví-dụ-reverse-proxy-thực-tế>5.3. Điều Phối với Docker Compose: Một Ví Dụ Reverse Proxy Thực Tế<a hidden class=anchor aria-hidden=true href=#53-điều-phối-với-docker-compose-một-ví-dụ-reverse-proxy-thực-tế>#</a></h3><p>Docker Compose là công cụ tiêu chuẩn để định nghĩa và chạy các ứng dụng Docker đa container. Một ví dụ</p><p><code>docker-compose.yaml</code> hoàn chỉnh sẽ định nghĩa hai dịch vụ: một ứng dụng backend <code>node</code> và một dịch vụ <code>nginx</code> hoạt động như một reverse proxy.</p><p>Sự kỳ diệu làm cho mô hình reverse proxy Nginx hoạt động liền mạch trong môi trường container chính là mạng Docker. Docker Compose tạo ra một mạng tùy chỉnh cho các dịch vụ được định nghĩa trong tệp. Docker cung cấp một dịch vụ DNS nội bộ trên mạng này. Mỗi container có thể được truy cập bởi các container khác trên cùng một mạng bằng tên dịch vụ của nó (ví dụ:</p><p><code>node</code>). Do đó, cấu hình Nginx có thể sử dụng</p><p><code>proxy_pass http://node:8181;</code> mà không cần biết địa chỉ IP thực tế của container backend. Điều này cho phép tạo ra một ngăn xếp ứng dụng di động, tự chứa và linh hoạt, có thể được triển khai ở bất cứ đâu có Docker.</p><p><strong>Ví dụ <code>docker-compose.yaml</code>:</strong></p><p>YAML</p><pre tabindex=0><code>version: &#34;3.8&#34;
services:
  node:
    build:
      context:./api
      target: dev
    volumes:
      -./api/index.js:/src/index.js
  nginx:
    restart: always
    image: nginx:1-alpine
    ports:
      - &#34;8089:80&#34;
    volumes:
      -./nginx/default.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - node
</code></pre><hr><h2 id=phần-6-bảo-mật-máy-chủ-nginx---danh-sách-kiểm-tra-cứng-hóa>Phần 6: Bảo Mật Máy Chủ Nginx - Danh Sách Kiểm Tra Cứng Hóa<a hidden class=anchor aria-hidden=true href=#phần-6-bảo-mật-máy-chủ-nginx---danh-sách-kiểm-tra-cứng-hóa>#</a></h2><p>Phần này cung cấp một danh sách kiểm tra toàn diện các thực hành bảo mật tốt nhất, biến một cài đặt Nginx mặc định thành một máy chủ được cứng hóa, sẵn sàng cho môi trường sản xuất.</p><h3 id=61-mã-hóa-mọi-thứ-ssltls-với-lets-encrypt>6.1. Mã Hóa Mọi Thứ: SSL/TLS với Let&rsquo;s Encrypt<a hidden class=anchor aria-hidden=true href=#61-mã-hóa-mọi-thứ-ssltls-với-lets-encrypt>#</a></h3><p>HTTPS là điều không thể thiếu cho các ứng dụng web hiện đại. Let&rsquo;s Encrypt cung cấp chứng chỉ TLS miễn phí và đáng tin cậy. Hướng dẫn từng bước sử dụng client</p><p><strong>Certbot</strong> và plugin Nginx của nó (<code>python3-certbot-nginx</code>) sẽ được cung cấp. Chạy <code>certbot --nginx</code> sẽ tự động lấy và cài đặt chứng chỉ, sửa đổi khối <code>server</code> liên quan để bật SSL và thiết lập chuyển hướng từ HTTP sang HTTPS. Việc thiết lập cronjob tự động gia hạn mà Certbot tạo ra là rất quan trọng.</p><h3 id=62-điều-tiết-lưu-lượng-giới-hạn-tốc-độ-nâng-cao>6.2. Điều Tiết Lưu Lượng: Giới Hạn Tốc Độ Nâng Cao<a hidden class=anchor aria-hidden=true href=#62-điều-tiết-lưu-lượng-giới-hạn-tốc-độ-nâng-cao>#</a></h3><p>Giới hạn tốc độ là một biện pháp phòng thủ quan trọng chống lại các cuộc tấn công brute-force, DDoS và lạm dụng API Nginx sử dụng thuật toán</p><p><strong>leaky bucket</strong> (xô rò rỉ). Cấu hình được thực hiện với hai chỉ thị:</p><ul><li><code>limit_req_zone</code>: Được định nghĩa trong context <code>http</code>, nó thiết lập vùng bộ nhớ chia sẻ. Các tham số chính là <code>key</code> (ví dụ: <code>$binary_remote_addr</code> để giới hạn theo IP), tên và kích thước <code>zone</code>, và <code>rate</code> (ví dụ: <code>10r/s</code>).</li><li><code>limit_req</code>: Được sử dụng trong một khối <code>location</code> để áp dụng giới hạn của một vùng cụ thể.</li></ul><p>Các tham số quan trọng <code>burst</code> và <code>nodelay</code> cũng cần được giải thích. <code>burst=20</code> cho phép một loạt 20 yêu cầu được xếp hàng và xử lý theo tốc độ đã định. <code>nodelay</code> cho phép loạt yêu cầu đó được xử lý ngay lập tức mà không bị điều tiết, nhưng các yêu cầu tiếp theo sẽ bị từ chối nếu tốc độ vẫn bị vượt quá.</p><h3 id=63-các-header-bảo-mật-thiết-yếu>6.3. Các Header Bảo Mật Thiết Yếu<a hidden class=anchor aria-hidden=true href=#63-các-header-bảo-mật-thiết-yếu>#</a></h3><p>Các HTTP Security Header hướng dẫn trình duyệt kích hoạt các tính năng bảo mật, cung cấp một lớp phòng thủ bổ sung. Chúng có thể được triển khai bằng chỉ thị</p><p><code>add_header</code>:</p><ul><li><strong><code>Strict-Transport-Security (HSTS)</code>:</strong> <code>add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;</code> - Buộc trình duyệt sử dụng HTTPS.</li><li><strong><code>X-Frame-Options</code>:</strong> <code>add_header X-Frame-Options "SAMEORIGIN";</code> - Ngăn chặn clickjacking.</li><li><strong><code>X-Content-Type-Options</code>:</strong> <code>add_header X-Content-Type-Options "nosniff";</code> - Ngăn chặn các cuộc tấn công MIME-sniffing.</li><li><strong><code>X-XSS-Protection</code>:</strong> <code>add_header X-XSS-Protection "1; mode=block";</code> - Kích hoạt bộ lọc XSS tích hợp của trình duyệt.</li></ul><h3 id=64-lớp-waf-modsecurity-và-các-lựa-chọn-thay-thế>6.4. Lớp WAF: ModSecurity và các Lựa Chọn Thay Thế<a hidden class=anchor aria-hidden=true href=#64-lớp-waf-modsecurity-và-các-lựa-chọn-thay-thế>#</a></h3><p>Một Tường lửa Ứng dụng Web (WAF) bảo vệ chống lại các cuộc tấn công lớp ứng dụng phổ biến như SQL injection và XSS.</p><p><strong>ModSecurity</strong> từ lâu đã là WAF mã nguồn mở tiêu chuẩn, có sẵn dưới dạng module Nginx.56</p><p>Tuy nhiên, một thông tin quan trọng là F5 đã thông báo <strong>Kết thúc vòng đời (End-of-Life) cho module NGINX ModSecurity WAF vào ngày 31 tháng 3 năm 2024</strong>.57 Điều này đánh dấu một bước ngoặt quan trọng trong bối cảnh bảo mật Nginx, buộc cộng đồng phải đánh giá và áp dụng các công nghệ WAF mới hơn.</p><p>Các lựa chọn thay thế hiện đại bao gồm:</p><ul><li><strong>NAXSI (Nginx Anti XSS & SQL Injection):</strong> Một WAF nhẹ, dành riêng cho Nginx, sử dụng hệ thống tính điểm đơn giản thay vì các quy tắc regex phức tạp. Nó nhanh hơn và dễ bảo trì hơn nhưng kém linh hoạt hơn ModSecurity.</li><li><strong>open-appsec:</strong> Một WAF hiện đại dựa trên AI/ML, hoàn toàn tương thích với Nginx. Nó tập trung vào việc phát hiện mối đe dọa một cách chủ động mà không dựa vào các chữ ký truyền thống, làm cho nó trở thành một ứng cử viên sáng giá để thay thế ModSecurity.</li></ul><h3 id=65-danh-sách-kiểm-tra-cứng-hóa-chung>6.5. Danh Sách Kiểm Tra Cứng Hóa Chung<a hidden class=anchor aria-hidden=true href=#65-danh-sách-kiểm-tra-cứng-hóa-chung>#</a></h3><p>Một danh sách kiểm tra cuối cùng các kỹ thuật cứng hóa thiết yếu bao gồm:</p><ul><li><strong>Ẩn phiên bản Nginx:</strong> Sử dụng <code>server_tokens off;</code> để ngăn rò rỉ thông tin.</li><li><strong>Vô hiệu hóa các phương thức HTTP không cần thiết:</strong> Sử dụng <code>limit_except GET POST HEAD { deny all; }</code> để chỉ cho phép các phương thức cần thiết.</li><li><strong>Hạn chế truy cập vào các tệp nhạy cảm:</strong> Sử dụng khối <code>location</code> để từ chối truy cập vào các tệp như <code>.git</code>, <code>.env</code>.</li><li><strong>Ngăn chặn DoS với Timeouts:</strong> Cấu hình thời gian chờ client hợp lý (<code>client_body_timeout</code>, <code>client_header_timeout</code>) để ngăn chặn các cuộc tấn công kiểu Slowloris.</li><li><strong>Cấu hình bộ mã hóa SSL/TLS mạnh:</strong> Cung cấp một bộ mã hóa hiện đại, an toàn.</li><li><strong>Chạy với người dùng không phải root:</strong> Đảm bảo chỉ thị <code>user</code> trong <code>nginx.conf</code> được đặt thành một người dùng không có đặc quyền.</li></ul><hr><h2 id=phần-7-vượt-ra-ngoài-những-điều-cơ-bản---mở-rộng-nginx>Phần 7: Vượt Ra Ngoài những Điều Cơ Bản - Mở Rộng Nginx<a hidden class=anchor aria-hidden=true href=#phần-7-vượt-ra-ngoài-những-điều-cơ-bản---mở-rộng-nginx>#</a></h2><p>Phần cuối cùng này sẽ đề cập ngắn gọn đến sức mạnh của hệ sinh thái module của Nginx, cung cấp một ví dụ thực tế về một module của bên thứ ba có giá trị.</p><h3 id=71-sức-mạnh-của-modules-nén-brotli>7.1. Sức Mạnh của Modules: Nén Brotli<a hidden class=anchor aria-hidden=true href=#71-sức-mạnh-của-modules-nén-brotli>#</a></h3><p>Chức năng của Nginx có thể được mở rộng thông qua các module, có thể được biên dịch tĩnh hoặc tải động.</p><p><strong>Brotli</strong> là một thuật toán nén hiện đại do Google phát triển, cung cấp tỷ lệ nén tốt hơn Gzip, giúp trang web tải nhanh hơn.</p><p>Module <code>ngx_brotli</code> có thể được thêm vào bằng cách biên dịch Nginx từ nguồn hoặc, trên nhiều hệ thống, bằng cách cài đặt một gói module động đã được biên dịch sẵn (ví dụ: <code>nginx-module-brotli</code>).</p><p><strong>Ví dụ cấu hình:</strong></p><p>Nginx</p><pre tabindex=0><code># Trong context chính (cho module động)
load_module modules/ngx_http_brotli_filter_module.so;
load_module modules/ngx_http_brotli_static_module.so;

# Trong context http, server, hoặc location
brotli on;
brotli_comp_level 6;
brotli_types text/plain text/css application/json...;
brotli_static on; # Phục vụ các tệp.br nếu tồn tại
</code></pre><hr><p><em>Nếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!</em></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.nagih.io.vn/tags/nginx/>Nginx</a></li></ul><nav class=paginav><a class=prev href=https://blog.nagih.io.vn/posts/6-level-deploy/><span class=title>« Prev</span><br><span>6 Level Deploy</span>
</a><a class=next href=https://blog.nagih.io.vn/posts/docker-best-practice-for-production/><span class=title>Next »</span><br><span>Docker Best Practice for Production</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Nginx Overview on x" href="https://x.com/intent/tweet/?text=Nginx%20Overview&amp;url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f&amp;hashtags=nginx"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Nginx Overview on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f&amp;title=Nginx%20Overview&amp;summary=Nginx%20Overview&amp;source=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Nginx Overview on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f&title=Nginx%20Overview"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Nginx Overview on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Nginx Overview on whatsapp" href="https://api.whatsapp.com/send?text=Nginx%20Overview%20-%20https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Nginx Overview on telegram" href="https://telegram.me/share/url?text=Nginx%20Overview&amp;url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Nginx Overview on ycombinator" href="https://news.ycombinator.com/submitlink?t=Nginx%20Overview&u=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fnginx%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.nagih.io.vn/>Nagih | Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>