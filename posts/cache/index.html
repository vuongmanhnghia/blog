<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cache | Nagih | Blog</title>
<meta name=keywords content="cache"><meta name=description content="Overview of Cache"><meta name=author content="Nagih"><link rel=canonical href=https://blog.nagih.io.vn/posts/cache/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=https://blog.nagih.io.vn/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.nagih.io.vn/posts/cache/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://blog.nagih.io.vn/posts/cache/"><meta property="og:site_name" content="Nagih | Blog"><meta property="og:title" content="Cache"><meta property="og:description" content="Overview of Cache"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-08-10T00:00:00+00:00"><meta property="article:tag" content="Cache"><meta property="og:image" content="https://blog.nagih.io.vn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.nagih.io.vn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Cache"><meta name=twitter:description content="Overview of Cache"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.nagih.io.vn/posts/"},{"@type":"ListItem","position":2,"name":"Cache","item":"https://blog.nagih.io.vn/posts/cache/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Cache","name":"Cache","description":"Overview of Cache\n","keywords":["cache"],"articleBody":"Overview of Cache\nTrong thế giới phát triển phần mềm, chúng ta luôn bị ám ảnh bởi một từ khóa: hiệu năng. Làm thế nào để ứng dụng chạy nhanh hơn? Làm sao để trang web tải trong chớp mắt? Làm sao để hệ thống chịu được hàng triệu lượt truy cập mà không sụp đổ? Giữa vô vàn câu trả lời, có một khái niệm nền tảng, một kỹ thuật được áp dụng ở mọi quy mô, từ con chip nhỏ trong CPU đến các hệ thống phân tán toàn cầu. Đó chính là Cache.\nNhiều người đã nghe về cache, có thể là “xóa cache trình duyệt” hay “cache của CPU”. Nhưng cache thực sự là gì? Nó hoạt động ra sao và tại sao nó lại quan trọng đến vậy?\nBài viết này sẽ đưa bạn đi từ những khái niệm cơ bản nhất đến các chiến lược chuyên sâu trong thiết kế hệ thống. Hy vọng rằng sau khi đọc xong, bạn sẽ có một cái nhìn rõ ràng và sâu sắc về “vũ khí bí mật” mang tên cache.\nHãy cùng bắt đầu!\nCache Là Gì? Để hiểu về cache, hãy bắt đầu bằng một câu chuyện đơn giản.\nCâu chuyện về Thư viện và Chiếc bàn làm việc Hãy tưởng tượng bạn là một nhà nghiên cứu cần rất nhiều sách cho công việc của mình. Toàn bộ sách được lưu trữ trong một thư viện khổng lồ ở phía bên kia thành phố. Mỗi khi cần một thông tin, bạn phải mất công di chuyển đến thư viện, tìm đúng cuốn sách, đọc, rồi lại đi về. Quá trình này rất chậm chạp và tốn thời gian.\nBây giờ, bạn nghĩ ra một giải pháp thông minh hơn. Thay vì mỗi lần cần lại chạy đi, bạn sẽ mang những cuốn sách hay dùng nhất về đặt ngay trên chiếc bàn làm việc của mình. Chiếc bàn này tuy nhỏ, không thể chứa cả thư viện, nhưng nó ở ngay trước mặt bạn. Lần tới, khi cần thông tin từ những cuốn sách đó, bạn chỉ cần với tay là có ngay, nhanh hơn gấp trăm lần so với việc đi đến thư viện.\nTrong thế giới máy tính, câu chuyện này diễn ra liên tục.\nThư viện khổng lồ chính là nơi lưu trữ dữ liệu chính, ví dụ như ổ cứng (HDD/SSD) hoặc Database. Nơi này có dung lượng lớn nhưng tốc độ truy cập khá chậm. Chiếc bàn làm việc của bạn chính là Cache. Cache là một lớp lưu trữ dữ liệu tốc độ cao, có kích thước nhỏ, dùng để chứa một tập hợp con của dữ liệu gốc. Mục đích của nó là để các yêu cầu truy xuất dữ liệu trong tương lai được phục vụ nhanh hơn rất nhiều so với việc phải lấy dữ liệu từ database. Về cơ bản, cache cho phép chúng ta tái sử dụng một cách hiệu quả những dữ liệu đã được truy xuất hoặc tính toán trước đó.\nTại sao Cache lại quan trọng đến vậy? Sử dụng cache mang lại 3 lợi ích cốt lõi, biến nó trở thành một kỹ thuật không thể thiếu trong hầu hết mọi hệ thống máy tính hiện đại.\nTăng tốc độ một cách chóng mặt (Performance): Đây là mục đích chính. Cache thường được triển khai trên các phần cứng truy cập nhanh như RAM (Bộ nhớ truy cập ngẫu nhiên). Tốc độ truy cập RAM nhanh hơn hàng trăm, thậm chí hàng nghìn lần so với ổ đĩa. Việc phục vụ dữ liệu từ cache giúp giảm độ trễ (latency) và tăng số lượng thao tác I/O mỗi giây (IOPS) một cách đáng kể, làm cho ứng dụng trở nên mượt mà và phản hồi nhanh hơn. Giảm tải cho hệ thống Backend: Cache hoạt động như một tấm khiên, che chắn cho cơ sở dữ liệu hoặc các dịch vụ API. Thay vì mọi yêu cầu đều phải truy cập vào cơ sở dữ liệu, phần lớn các yêu cầu đọc sẽ được cache xử lý. Điều này giúp cơ sở dữ liệu không bị quá tải, đặc biệt là trong những thời điểm có lưu lượng truy cập tăng đột biến, và giữ cho toàn bộ hệ thống ổn định. Tiết kiệm chi phí (Cost Efficiency): Ở quy mô lớn, việc phục vụ dữ liệu từ cache trong bộ nhớ (in-memory) có thể rẻ hơn đáng kể so với việc phải nâng cấp liên tục các máy chủ cơ sở dữ liệu hoặc trả chi phí cho lưu lượng mạng cao khi truy xuất dữ liệu từ các dịch vụ đám mây. Cache Hit và Cache Miss Hoạt động của cache xoay quanh hai kịch bản chính: Cache Hit và Cache Miss. Khi một client (có thể là CPU, trình duyệt web, hoặc ứng dụng của bạn) cần dữ liệu, nó sẽ luôn hỏi cache trước tiên.\nCache Hit (Tìm thấy trong Cache): Đây là kịch bản lý tưởng. Dữ liệu được yêu cầu có tồn tại trong cache. Cache sẽ ngay lập tức trả về dữ liệu này cho client. Quá trình này cực kỳ nhanh chóng. Cache Miss (Không tìm thấy trong Cache): Đây là kịch bản không mong muốn. Dữ liệu được yêu cầu không có trong cache. Khi đó, hệ thống buộc phải truy cập đến database để lấy dữ liệu. Sau khi lấy được, dữ liệu này sẽ được sao chép một bản vào cache để những lần yêu cầu sau sẽ trở thành cache hit, rồi mới được trả về cho client. Một điểm cực kỳ quan trọng cần nhận thức ở đây là sự tồn tại của “Cache Miss” cho thấy một sự thật nền tảng: cache không phải là một phép màu tăng tốc miễn phí. Nó đi kèm với sự đánh đổi và chi phí. Một cache miss vốn dĩ còn chậm hơn một hệ thống không có cache. Bởi vì trong một hệ thống không cache, thời gian truy xuất chỉ đơn giản là thời gian lấy dữ liệu từ nguồn chính. Còn trong một cache miss, tổng thời gian là Thời gian kiểm tra cache (và thất bại) + Thời gian lấy dữ liệu từ database.\nDo đó, mục tiêu của mọi chiến lược caching không chỉ đơn giản là “có cache”, mà là thiết kế một hệ thống nơi tổng thời gian tiết kiệm được từ vô số các cache hit phải lớn hơn rất nhiều so với tổng thời gian bị mất đi do các cache miss không thể tránh khỏi. Điều này biến caching từ một công cụ đơn thuần thành một bài toán tối ưu hóa chiến lược.\nTỷ lệ Cache Hit (Cache Hit Ratio) Để biết cache của chúng ta có hoạt động hiệu quả hay không, chúng ta cần một thước đo. Thước đo quan trọng nhất chính là Tỷ lệ Cache Hit (Cache Hit Ratio).\nCông thức tính rất đơn giản\nTỷ lệ Cache Hit= Cache Hit​ / (Cache Hit + Cache Miss)\nTỷ lệ này, thường được biểu diễn dưới dạng phần trăm, cho biết có bao nhiêu phần trăm yêu cầu được phục vụ nhanh chóng từ cache. Một tỷ lệ cache hit cao (thường từ 80-95% trở lên đối với nội dung tĩnh) cho thấy cache đang hoạt động rất hiệu quả. Ngược lại, một tỷ lệ thấp cho thấy cache đang không được sử dụng tốt, có thể do cấu hình sai, chính sách dọn dẹp không phù hợp, hoặc kích thước cache quá nhỏ.\nCache Phần cứng (CPU Cache) Loại cache nhanh nhất, cơ bản nhất nằm ở cấp độ phần cứng, được tích hợp trực tiếp CPU. Mục đích của nó là để bắc một cây cầu qua “vực thẳm” tốc độ giữa một CPU siêu nhanh và RAM chậm hơn nhiều.\nĐể hiểu điều này, chúng ta cần biết về Hệ thống phân cấp bộ nhớ (Memory Hierarchy). Đây là một mô hình tổ chức bộ nhớ trong máy tính thành nhiều cấp, giống như một kim tự tháp. Càng ở đỉnh kim tự tháp, bộ nhớ càng nhanh, càng đắt và dung lượng càng nhỏ. Càng xuống đáy, bộ nhớ càng chậm, càng rẻ và dung lượng càng lớn.\nCode snippet\n(1) Register (2) L1 Cache (3) L2 Cache (4) L3 Cache (5) RAM \u003c- Redis (6) SSD (7) HDD CPU cache được chia thành nhiều cấp (Level), thường là L1, L2, và L3:\nL1 Cache (Level 1): Đây là bộ nhớ cache nhỏ nhất và nhanh nhất, được tích hợp ngay trong từng nhân (core) của CPU L2 Cache (Level 2): Lớn hơn L1 nhưng chậm hơn một chút. L2 cache có thể nằm riêng cho từng nhân hoặc chung cho một vài nhân, tùy vào kiến trúc CPU. L3 Cache (Level 3): Lớn nhất và chậm nhất trong các cấp CPU cache. L3 cache thường được dùng chung cho tất cả các nhân trên một con chip. Nó giúp tăng tốc độ giao tiếp giữa các nhân và giảm thiểu việc phải truy cập ra RAM. Cache Phần mềm Ngoài phần cứng, caching là một kỹ thuật được quản lý bởi phần mềm ở nhiều lớp khác nhau trong một ứng dụng. Đây là những loại cache mà các lập trình viên chúng ta thường xuyên tương tác và thiết kế.\nCache Trình duyệt (Browser Cache): Khi bạn truy cập một trang web, trình duyệt của bạn sẽ tự động lưu các tài nguyên tĩnh như hình ảnh, file CSS, JavaScript vào một thư mục trên ổ cứng. Lần sau khi bạn quay lại trang đó, trình duyệt sẽ tải các tài nguyên này từ ổ cứng thay vì phải tải lại từ server, giúp trang web hiển thị gần như ngay lập tức. Đây là một dạng cache phía client (client-side), riêng tư cho mỗi người dùng. Cache Mạng Phân phối Nội dung (CDN - Content Delivery Network): Đây là một mạng lưới các máy chủ proxy được đặt ở nhiều vị trí địa lý trên toàn cầu. Các máy chủ này lưu trữ (cache) bản sao của nội dung trang web (như video, hình ảnh, file tĩnh). Ví dụ điển hình là Netflix hay YouTube. Khi bạn ở Việt Nam và xem một video, rất có thể bạn đang nhận dữ liệu từ một máy chủ CDN đặt tại Singapore hoặc Hồng Kông, chứ không phải từ máy chủ gốc ở Mỹ. Điều này giúp giảm đáng kể độ trễ và tăng tốc độ tải. Cache Cơ sở dữ liệu (Database Cache): Hầu hết các hệ quản trị cơ sở dữ liệu như MySQL, PostgreSQL đều có một bộ đệm cache nội bộ. Nó lưu lại kết quả của các câu truy vấn (query) được thực thi thường xuyên. Khi nhận được một câu truy vấn giống hệt, thay vì phải quét lại toàn bộ bảng dữ liệu, database sẽ trả về kết quả từ cache của nó. Cache Ứng dụng (Application Cache / In-Memory Cache): Đây là lớp cache mà các lập trình viên chủ động thêm vào kiến trúc ứng dụng của mình, thường sử dụng các công cụ chuyên dụng như Redis hoặc Memcached. Lớp cache này có thể lưu trữ bất cứ thứ gì: kết quả của các phép tính toán phức tạp, phản hồi từ các API, các đối tượng dữ liệu đã được định dạng sẵn… Việc này giúp ứng dụng không phải tính toán lại hoặc truy vấn lại những thông tin tốn kém trên mỗi yêu cầu. Hãy xem xét cấu trúc: Client -\u003e Cache -\u003e Nguồn.\nVới CPU: Client là nhân xử lý, Cache là L1, Nguồn là RAM. Với Web: Client là công cụ render, Cache là ổ cứng cục bộ, Nguồn là web server. Với CDN: Client là trình duyệt, Cache là máy chủ biên (edge server), Nguồn là máy chủ gốc (origin server). Với App: Client là logic nghiệp vụ, Cache là Redis/Memcached, Nguồn là Database. Khi Cache Bị Đầy: Các Chính Sách “Dọn Dẹp” Chúng ta đã biết cache rất hữu ích, nhưng nó có một giới hạn cố hữu: dung lượng nhỏ. Bộ nhớ tốc độ cao (như RAM) rất đắt đỏ, vì vậy cache không thể lưu trữ mọi thứ.\nĐiều này dẫn đến một vấn đề không thể tránh khỏi: khi cache đã đầy và một mục dữ liệu mới cần được thêm vào, hệ thống phải quyết định loại bỏ một mục dữ liệu cũ để nhường chỗ. Quá trình này được gọi là Eviction (dọn dẹp/loại bỏ).\nThuật toán được sử dụng để quyết định mục nào sẽ bị loại bỏ được gọi là Chính sách dọn dẹp (Eviction Policy). Quay lại với câu chuyện thư viện, khi bàn làm việc của bạn đã chật kín sách, bạn sẽ phải chọn một cuốn để trả lại thư viện trước khi mang cuốn mới về. Bạn chọn cuốn nào? Sự lựa chọn của bạn chính là một chính sách dọn dẹp.\nDưới đây là các chiến lược dọn dẹp phổ biến nhất.\nCác chiến lược dọn dẹp phổ biến FIFO (First-In, First-Out - Vào trước, Ra trước): Nguyên tắc: Đây là chính sách đơn giản nhất. Nó loại bỏ mục dữ liệu cũ nhất, tức là mục đã nằm trong cache lâu nhất, bất kể nó có được sử dụng thường xuyên hay không. Nó hoạt động giống như một hàng đợi (queue). Ưu điểm: Rất dễ cài đặt và có chi phí quản lý thấp. Nhược điểm: Thường không hiệu quả vì nó có thể loại bỏ một mục rất phổ biến chỉ vì nó được nạp vào cache từ lâu. LRU (Least Recently Used - Ít được sử dụng gần đây nhất): Nguyên tắc: Chính sách này loại bỏ mục dữ liệu mà đã không được truy cập trong khoảng thời gian dài nhất. Nó hoạt động dựa trên nguyên tắc tính cục bộ về thời gian (temporal locality) Ưu điểm: Hiệu quả hơn FIFO rất nhiều trong hầu hết các trường hợp thực tế, vì nó giữ lại những dữ liệu đang được sử dụng tích cực. Nhược điểm: Phức tạp hơn trong việc triển khai vì nó đòi hỏi phải theo dõi thời gian truy cập của mỗi mục, gây tốn thêm một chút bộ nhớ và xử lý. LFU (Least Frequently Used - Ít được sử dụng thường xuyên nhất): Nguyên tắc: Chính sách này loại bỏ mục dữ liệu được truy cập với số lần ít nhất. Nó dựa trên nguyên tắc tính cục bộ về tần suất (frequency locality) – ý tưởng rằng có một số dữ liệu vốn dĩ đã phổ biến hơn những dữ liệu khác. Ưu điểm: Rất tốt trong việc xác định và giữ lại các mục dữ liệu “hot” (phổ biến) trong một thời gian dài, ngay cả khi chúng không được truy cập gần đây. Nhược điểm: Phức tạp để triển khai hiệu quả. Nó có thể không thích ứng nhanh với các mẫu truy cập thay đổi (ví dụ: một mục từng rất hot nhưng giờ không còn ai dùng nữa vẫn có thể chiếm chỗ trong cache một thời gian dài). Nó cũng có thể loại bỏ một mục mới được thêm vào nhưng chưa có cơ hội tích lũy đủ số lần truy cập. Bảng so sánh các chính sách dọn dẹp Để giúp bạn dễ dàng lựa chọn, đây là bảng so sánh các chính sách phổ biến:\nChính sách Nguyên tắc cốt lõi Ví dụ tương tự Ưu điểm Nhược điểm Phù hợp nhất cho FIFO Loại bỏ mục vào cache sớm nhất. Xếp hàng mua vé: người đến trước được phục vụ trước. Đơn giản, chi phí thấp. Không thông minh, có thể loại bỏ dữ liệu quan trọng. Các hệ thống có mẫu truy cập tuần tự, không lặp lại. LRU Loại bỏ mục ít được dùng đến gần đây nhất. Dọn dẹp bàn làm việc: trả lại cuốn sách bạn không đụng đến lâu nhất. Hiệu quả cao trong hầu hết các trường hợp, thích ứng tốt với sự thay đổi. Phức tạp hơn, cần theo dõi thời gian truy cập. Các ứng dụng thông thường, nơi dữ liệu gần đây có khả năng được tái sử dụng cao (ví dụ: trang tin tức, mạng xã hội). LFU Loại bỏ mục có số lần truy cập ít nhất. Thư viện cho mượn sách: loại bỏ những cuốn ít người mượn nhất. Giữ lại được các mục “hot” một cách ổn định. Phức tạp, có thể giữ lại dữ liệu “hot” đã lỗi thời, không thích ứng nhanh. Các hệ thống có một số dữ liệu cực kỳ phổ biến và ổn định (ví dụ: sản phẩm bán chạy, video viral). Giữ Cho Dữ Liệu Đồng Nhất: Các Chính Sách Ghi Khi một ứng dụng thực hiện thao tác ghi (write) hoặc cập nhật (update), một vấn đề nghiêm trọng nảy sinh. Bây giờ chúng ta có hai bản sao của cùng một dữ liệu: một trong cache và một trong cơ sở dữ liệu. Nếu chúng không được cập nhật đồng bộ, cache sẽ chứa dữ liệu cũ. Việc phục vụ stale data cho người dùng có thể dẫn đến các lỗi nghiêm trọng, thông tin sai lệch và trải nghiệm tồi tệ.\nChính sách ghi (Write Policy) là quy tắc xác định cách hệ thống xử lý các thao tác ghi để giải quyết vấn đề về tính nhất quán này.\nCác chính sách ghi cốt lõi Write-Through (Ghi Xuyên) Quy trình: Khi ứng dụng ghi dữ liệu, nó sẽ ghi đồng thời vào cả cache và cơ sở dữ liệu. Thao tác chỉ được coi là hoàn tất khi cả hai nơi đều đã ghi xong. Lưu đồ: Ứng dụng -\u003e Ghi vào Cache -\u003e Ghi vào Database -\u003e Hoàn tất Ưu điểm: Tính nhất quán dữ liệu rất cao. Cache và database luôn đồng bộ. Đơn giản để triển khai và đáng tin cậy. Nhược điểm: Độ trễ của thao tác ghi cao, vì ứng dụng phải chờ cả hai thao tác ghi hoàn tất. Trường hợp sử dụng: Các ứng dụng quan trọng nơi tính nhất quán dữ liệu là tối thượng, ví dụ như hệ thống ngân hàng, quản lý kho hàng. Write-Back (Ghi Sau / Write-Behind) Quy trình: Khi ứng dụng ghi dữ liệu, nó chỉ ghi vào cache tốc độ cao trước. Thao tác được xác nhận hoàn tất ngay lập tức. Việc ghi vào cơ sở dữ liệu sẽ được trì hoãn và thực hiện sau đó, có thể là sau một khoảng thời gian nhất định hoặc khi mục cache đó sắp bị dọn dẹp. Hệ thống thường dùng một “bit bẩn” (dirty bit) để đánh dấu các mục trong cache đã bị thay đổi và cần được ghi lại vào database. Lưu đồ: Ứng dụng -\u003e Ghi vào Cache -\u003e Hoàn tất. (Background: Cache -\u003e Ghi vào Database) Ưu điểm: Độ trễ ghi cực thấp và thông lượng cao. Giảm tải cho database bằng cách gộp nhiều lần ghi vào cùng một đối tượng thành một lần ghi duy nhất (write-coalescing). Nhược điểm: Có nguy cơ mất dữ liệu nếu cache bị lỗi trước khi dữ liệu kịp ghi vào database. Phức tạp hơn để triển khai. Trường hợp sử dụng: Các ứng dụng có lượng ghi lớn, nơi hiệu năng là ưu tiên hàng đầu và có thể chấp nhận một rủi ro nhỏ về mất mát dữ liệu, ví dụ như ghi log hành vi người dùng, cập nhật số lượt xem bài viết. Write-Around (Ghi Vòng) Quy trình: Khi ứng dụng ghi dữ liệu, nó sẽ ghi trực tiếp vào cơ sở dữ liệu, hoàn toàn bỏ qua cache. Dữ liệu chỉ được nạp vào cache sau này, khi có một yêu cầu đọc bị cache miss. Lưu đồ: Ứng dụng -\u003e Ghi vào Database -\u003e Hoàn tất Ưu điểm: Tránh “làm ô nhiễm” cache bằng những dữ liệu có thể không bao giờ được đọc lại. Nhược điểm: Một yêu cầu đọc ngay sau khi ghi sẽ luôn luôn là cache miss, dẫn đến độ trễ đọc cao cho dữ liệu vừa được ghi. Trường hợp sử dụng: Các ứng dụng ghi dữ liệu nhưng hiếm khi đọc lại ngay sau đó, ví dụ như các hệ thống nhập dữ liệu hàng loạt (bulk data ingestion), lưu trữ log. Các chính sách ghi không tồn tại một cách độc lập. Chúng liên kết chặt chẽ với cách hệ thống xử lý một write miss (khi ứng dụng muốn ghi vào một mục không có trong cache). Có hai lựa chọn:\nWrite Allocate (Fetch on Write): Khi có write miss, hệ thống sẽ tải khối dữ liệu đó từ database vào cache trước, rồi mới thực hiện thao tác ghi. No-Write Allocate: Khi có write miss, hệ thống sẽ ghi thẳng vào database, không tải dữ liệu đó vào cache. Sự kết hợp giữa chính sách ghi và chính sách write miss tạo ra các chiến lược hoàn chỉnh. Ví dụ, một hệ thống Write-Back thường đi kèm với Write Allocate. Triết lý của Write-Back là hấp thụ các thao tác ghi để tăng hiệu năng, với giả định rằng dữ liệu đó sẽ sớm được truy cập lại. Vì vậy, khi có write miss, việc tải dữ liệu vào cache trước là hợp lý để các thao tác sau đó có thể hưởng lợi từ cache. Ngược lại, một hệ thống Write-Through thường sử dụng No-Write Allocate (chính là chiến lược Write-Around). Triết lý của Write-Through là an toàn dữ liệu. Nếu có write miss, việc tải dữ liệu vào cache chỉ để ghi nó ngay lập tức ra database là không hiệu quả. Sẽ đơn giản hơn nếu ghi thẳng vào database và tránh làm ô nhiễm cache.\nHiểu được mối liên kết nhân quả này giúp các nhà phát triển đưa ra quyết định kiến trúc mạch lạc và tối ưu hơn, thay vì chọn hai chính sách một cách ngẫu nhiên.\nXây Dựng Hệ Thống Với Cache: Các Mẫu Thiết Kế Mẫu 1: Cache-Aside (Lazy Loading) Đây là mẫu thiết kế phổ biến và trực quan nhất. Trong mẫu này, logic của ứng dụng chịu trách nhiệm hoàn toàn cho việc quản lý cache.\nQuy trình:\nỨng dụng cần đọc dữ liệu, nó sẽ kiểm tra cache trước. Nếu có (cache hit), dữ liệu được trả về. Nếu không có (cache miss), ứng dụng sẽ đọc dữ liệu từ database. Sau đó, ứng dụng sẽ ghi dữ liệu vừa đọc được vào cache. Khi ghi dữ liệu, ứng dụng thường sẽ cập nhật database trước, sau đó vô hiệu hóa (invalidate) mục tương ứng trong cache. Ưu điểm: Ứng dụng có toàn quyền kiểm soát. Cache chỉ lưu những dữ liệu thực sự được yêu cầu, giúp tiết kiệm không gian. Hệ thống có khả năng chống chịu lỗi cache tốt (nếu cache sập, ứng dụng có thể đọc trực tiếp từ database).\nNhược điểm: Yêu cầu đầu tiên cho bất kỳ dữ liệu nào cũng sẽ là cache miss. Code của ứng dụng phức tạp hơn vì phải chứa logic quản lý cache.\nMẫu 2: Read-Through Mẫu này trừu tượng hóa database khỏi ứng dụng. Ứng dụng chỉ cần “nói chuyện” với cache.\nQuy trình: Ứng dụng yêu cầu dữ liệu từ cache. Nếu cache có, nó sẽ trả về. Nếu cache không có, chính cache sẽ chịu trách nhiệm đi lấy dữ liệu từ database, lưu lại rồi trả về cho ứng dụng. Ưu điểm: Đơn giản hóa code ứng dụng vì logic caching được đóng gói trong cache provider. Nhược điểm: Kém linh hoạt hơn. Cache provider phải hỗ trợ mẫu này. Mẫu 3 \u0026 4: Write-Through và Write-Behind (Write-Back) Đây là các mẫu tập trung vào việc ghi, thường đi đôi với Read-Through.\nWrite-Through: Ứng dụng ghi dữ liệu vào cache, và cache sẽ chịu trách nhiệm ghi đồng bộ dữ liệu đó vào database. Điều này đảm bảo tính nhất quán cao. Write-Behind: Ứng dụng ghi dữ liệu vào cache, và cache sẽ ghi dữ liệu đó vào database một cách bất đồng bộ (trong nền). Điều này cho hiệu năng ghi rất cao. Sự lựa chọn giữa Cache-Aside và các mẫu Read/Write-Through không chỉ là chi tiết kỹ thuật, mà là một quyết định kiến trúc nền tảng về sự phân tách trách nhiệm (separation of concerns).\nCache-Aside đặt trách nhiệm điều phối dữ liệu lên vai ứng dụng. Ứng dụng “biết” cả về cache và database. Read/Write-Through coi cache như một lớp mặt tiền (facade) cho database. Ứng dụng chỉ cần biết “lấy dữ liệu” hoặc “ghi dữ liệu” tại một điểm duy nhất là cache. Mô hình Read-Through thúc đẩy sự phân tách trách nhiệm sạch sẽ hơn, dẫn đến code ứng dụng đơn giản và dễ bảo trì hơn. Tuy nhiên, nó lại ràng buộc chặt chẽ cache với database, khiến việc thay đổi database hoặc sử dụng cache cho các nguồn dữ liệu khác trở nên khó khăn. Ngược lại, Cache-Aside linh hoạt hơn – cache có thể chứa dữ liệu từ nhiều nguồn (database, API, file,…) – nhưng phải trả giá bằng sự phức tạp tăng lên trong code ứng dụng. Đây là một sự đánh đổi kinh điển giữa đơn giản/đóng gói và linh hoạt/kiểm soát.\nThách Thức Lớn Nhất: Dữ Liệu Cũ và Vô Hiệu Hóa Cache Vấn đề cốt lõi vẫn là stale data. Khi dữ liệu trong nguồn chính bị thay đổi bởi một tiến trình khác mà cache không hề hay biết, cache sẽ trở nên lỗi thời. Phục vụ dữ liệu lỗi thời này có thể gây ra những hậu quả tai hại.\nCache Invalidation là quá trình đánh dấu hoặc loại bỏ dữ liệu trong cache để nó không còn hợp lệ nữa.\nCác chiến lược vô hiệu hóa cache Time-To-Live (TTL) Expiration (Hết hạn theo thời gian): Quy trình: Đây là chiến lược đơn giản nhất. Khi dữ liệu được lưu vào cache, nó được gán một “tuổi thọ”, ví dụ 5 phút. Sau 5 phút, dữ liệu này tự động bị coi là không hợp lệ và sẽ bị xóa hoặc bỏ qua trong lần truy cập tiếp theo, buộc hệ thống phải lấy lại dữ liệu mới từ database. Ưu điểm: Dễ triển khai, đảm bảo dữ liệu cuối cùng sẽ nhất quán. Nhược điểm: Dữ liệu có thể bị lỗi thời trong suốt khoảng thời gian TTL. Việc chọn TTL phù hợp là một nghệ thuật cân bằng khó khăn: TTL quá ngắn sẽ làm giảm tỷ lệ cache hit, TTL quá dài sẽ tăng nguy cơ stale data. Event-Driven Invalidation (Active Deletion - Xóa chủ động): Quy trình: Một cách tiếp cận chủ động hơn. Khi dữ liệu trong database được cập nhật (ví dụ, người dùng đổi ảnh đại diện), ứng dụng sẽ gửi một lệnh DELETE hoặc INVALIDATE rõ ràng đến cache để xóa mục tương ứng. Ưu điểm: Đảm bảo dữ liệu được vô hiệu hóa gần như ngay lập tức, mang lại tính nhất quán cao hơn nhiều so với TTL. Nhược điểm: Phức tạp hơn để triển khai. Nó đòi hỏi sự liên kết chặt chẽ giữa code ghi vào database và cache. Trong một hệ thống phân tán, nó rất dễ gặp phải các vấn đề về race condition (tranh chấp) hoặc lỗi mạng. Vấn đề “khó” của cache invalidation không chỉ nằm ở việc khi nào cần vô hiệu hóa, mà là làm thế nào để đảm bảo việc vô hiệu hóa đó là chính xác và nguyên tử trong một môi trường có nhiều tiến trình chạy đồng thời. Đây là lúc chúng ta đối mặt với một vấn đề kinh điển về race condition.\nHãy xem xét kịch bản sau trong mẫu Cache-Aside:\nTiến trình A đọc dữ liệu X. Bị cache miss. Tiến trình A đi đến database để đọc dữ liệu X (phiên bản cũ). Trong lúc đó, tiến trình B cập nhật dữ liệu X trong database và ngay lập tức gửi lệnh vô hiệu hóa cache cho X. Tiến trình A, sau khi đọc xong dữ liệu X (phiên bản cũ) từ database, giờ đây lại ghi nó vào cache. Kết quả: Cache bây giờ chứa dữ liệu X đã lỗi thời, và lệnh vô hiệu hóa của tiến trình B trở nên vô nghĩa. Dữ liệu lỗi thời này sẽ tồn tại trong cache cho đến khi TTL hết hạn. Đây không phải là lỗi của một công cụ cụ thể, mà là một lỗ hổng cơ bản trong việc định thời của các hoạt động phân tán. Các giải pháp cho vấn đề này, như sử dụng phiên bản (versioning) cho dữ liệu hoặc cơ chế cho thuê (lease), không còn là các kỹ thuật vô hiệu hóa đơn giản nữa. Chúng là các cơ chế kiểm soát tương tranh (concurrency control) phức tạp. Ví dụ, với cơ chế lease mà Facebook sử dụng, chỉ tiến trình nào nhận được “hợp đồng thuê” khi bị cache miss mới có quyền ghi lại vào cache. Nếu một lệnh vô hiệu hóa xảy ra trong thời gian đó, “hợp đồng thuê” sẽ bị thu hồi, và thao tác ghi dữ liệu cũ của tiến trình A sẽ bị từ chối.\nKết luận: Cache - Sự Đánh Đổi Thông Minh Nếu có một điều cần đọng lại, đó là: Cache không phải là một viên đạn bạc, mà là một kỹ thuật mạnh mẽ đòi hỏi sự đánh đổi thông minh.\nMỗi quyết định bạn đưa ra – chọn loại cache nào, chính sách dọn dẹp ra sao, chính sách ghi nào, mẫu thiết kế nào – đều là một sự cân bằng giữa các yếu tố:\nHiệu năng và Chi phí Độ phức tạp và Tính đơn giản Tính nhất quán dữ liệu và Độ trễ Mô hình tối ưu nhất mà tôi biết Không có câu trả lời nào là đúng cho mọi trường hợp. Một hệ thống yêu cầu tính nhất quán tuyệt đối sẽ phải hy sinh một phần hiệu năng ghi (sử dụng Write-Through). Một hệ thống cần hiệu năng ghi tối đa có thể phải chấp nhận rủi ro về dữ liệu (sử dụng Write-Back).\nHiểu rõ các khái niệm và chiến lược này không phải để tìm ra một “công thức hoàn hảo”, mà là để trang bị cho bạn một bộ công cụ mạnh mẽ. Với bộ công cụ này, bạn có thể phân tích yêu cầu của ứng dụng, dự đoán các mẫu truy cập, và đưa ra những quyết định kiến trúc sáng suốt, phù hợp nhất với bài toán cụ thể của mình.\nChúc bạn thành công trên con đường xây dựng những hệ thống nhanh hơn, mạnh hơn và hiệu quả hơn!\nNếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!\n","wordCount":"5203","inLanguage":"en","image":"https://blog.nagih.io.vn/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-08-10T00:00:00Z","dateModified":"2025-08-10T00:00:00Z","author":{"@type":"Person","name":"Nagih"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.nagih.io.vn/posts/cache/"},"publisher":{"@type":"Organization","name":"Nagih | Blog","logo":{"@type":"ImageObject","url":"https://blog.nagih.io.vn/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.nagih.io.vn/ accesskey=h title="Home (Alt + H)"><img src=https://blog.nagih.io.vn/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.nagih.io.vn/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://blog.nagih.io.vn/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.nagih.io.vn/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://blog.nagih.io.vn/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://nagih.io.vn title=Home><span>Home</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.nagih.io.vn/>Home</a>&nbsp;»&nbsp;<a href=https://blog.nagih.io.vn/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Cache</h1><div class=post-meta><span title='2025-08-10 00:00:00 +0000 UTC'>August 10, 2025</span>&nbsp;·&nbsp;25 min&nbsp;·&nbsp;5203 words&nbsp;·&nbsp;Nagih&nbsp;|&nbsp;<a href=https://github.com/vuongmanhnghia/posts/content/posts/system/Cache.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#cache-là-gì>Cache Là Gì?</a><ul><li><a href=#câu-chuyện-về-thư-viện-và-chiếc-bàn-làm-việc>Câu chuyện về Thư viện và Chiếc bàn làm việc</a></li><li><a href=#tại-sao-cache-lại-quan-trọng-đến-vậy>Tại sao Cache lại quan trọng đến vậy?</a></li><li><a href=#cache-hit-và-cache-miss>Cache Hit và Cache Miss</a></li><li><a href=#tỷ-lệ-cache-hit-cache-hit-ratio>Tỷ lệ Cache Hit (Cache Hit Ratio)</a></li><li><a href=#cache-phần-cứng-cpu-cache>Cache Phần cứng (CPU Cache)</a></li><li><a href=#cache-phần-mềm>Cache Phần mềm</a></li></ul></li><li><a href=#khi-cache-bị-đầy-các-chính-sách-dọn-dẹp>Khi Cache Bị Đầy: Các Chính Sách &ldquo;Dọn Dẹp&rdquo;</a><ul><li><a href=#các-chiến-lược-dọn-dẹp-phổ-biến>Các chiến lược dọn dẹp phổ biến</a></li><li><a href=#bảng-so-sánh-các-chính-sách-dọn-dẹp>Bảng so sánh các chính sách dọn dẹp</a></li></ul></li><li><a href=#giữ-cho-dữ-liệu-đồng-nhất-các-chính-sách-ghi>Giữ Cho Dữ Liệu Đồng Nhất: Các Chính Sách Ghi</a><ul><li><a href=#các-chính-sách-ghi-cốt-lõi>Các chính sách ghi cốt lõi</a></li></ul></li><li><a href=#xây-dựng-hệ-thống-với-cache-các-mẫu-thiết-kế>Xây Dựng Hệ Thống Với Cache: Các Mẫu Thiết Kế</a><ul><li><a href=#mẫu-1-cache-aside-lazy-loading>Mẫu 1: Cache-Aside (Lazy Loading)</a></li><li><a href=#mẫu-2-read-through>Mẫu 2: Read-Through</a></li><li><a href=#mẫu-3--4-write-through-và-write-behind-write-back>Mẫu 3 & 4: Write-Through và Write-Behind (Write-Back)</a></li></ul></li><li><a href=#thách-thức-lớn-nhất-dữ-liệu-cũ-và-vô-hiệu-hóa-cache>Thách Thức Lớn Nhất: Dữ Liệu Cũ và Vô Hiệu Hóa Cache</a><ul><li><a href=#các-chiến-lược-vô-hiệu-hóa-cache>Các chiến lược vô hiệu hóa cache</a></li></ul></li><li><a href=#kết-luận-cache---sự-đánh-đổi-thông-minh>Kết luận: Cache - Sự Đánh Đổi Thông Minh</a></li></ul></nav></div></details></div><div class=post-content><p>Overview of Cache</p><p>Trong thế giới phát triển phần mềm, chúng ta luôn bị ám ảnh bởi một từ khóa: <strong>hiệu năng</strong>. Làm thế nào để ứng dụng chạy nhanh hơn? Làm sao để trang web tải trong chớp mắt? Làm sao để hệ thống chịu được hàng triệu lượt truy cập mà không sụp đổ? Giữa vô vàn câu trả lời, có một khái niệm nền tảng, một kỹ thuật được áp dụng ở mọi quy mô, từ con chip nhỏ trong CPU đến các hệ thống phân tán toàn cầu. Đó chính là <strong>Cache</strong>.</p><p>Nhiều người đã nghe về cache, có thể là &ldquo;xóa cache trình duyệt&rdquo; hay &ldquo;cache của CPU&rdquo;. Nhưng cache thực sự là gì? Nó hoạt động ra sao và tại sao nó lại quan trọng đến vậy?</p><p>Bài viết này sẽ đưa bạn đi từ những khái niệm cơ bản nhất đến các chiến lược chuyên sâu trong thiết kế hệ thống. Hy vọng rằng sau khi đọc xong, bạn sẽ có một cái nhìn rõ ràng và sâu sắc về &ldquo;vũ khí bí mật&rdquo; mang tên cache.</p><p>Hãy cùng bắt đầu!</p><h2 id=cache-là-gì>Cache Là Gì?<a hidden class=anchor aria-hidden=true href=#cache-là-gì>#</a></h2><p>Để hiểu về cache, hãy bắt đầu bằng một câu chuyện đơn giản.</p><h3 id=câu-chuyện-về-thư-viện-và-chiếc-bàn-làm-việc>Câu chuyện về Thư viện và Chiếc bàn làm việc<a hidden class=anchor aria-hidden=true href=#câu-chuyện-về-thư-viện-và-chiếc-bàn-làm-việc>#</a></h3><p>Hãy tưởng tượng bạn là một nhà nghiên cứu cần rất nhiều sách cho công việc của mình. Toàn bộ sách được lưu trữ trong một thư viện khổng lồ ở phía bên kia thành phố. Mỗi khi cần một thông tin, bạn phải mất công di chuyển đến thư viện, tìm đúng cuốn sách, đọc, rồi lại đi về. Quá trình này rất chậm chạp và tốn thời gian.</p><p>Bây giờ, bạn nghĩ ra một giải pháp thông minh hơn. Thay vì mỗi lần cần lại chạy đi, bạn sẽ mang những cuốn sách hay dùng nhất về đặt ngay trên chiếc bàn làm việc của mình. Chiếc bàn này tuy nhỏ, không thể chứa cả thư viện, nhưng nó ở ngay trước mặt bạn. Lần tới, khi cần thông tin từ những cuốn sách đó, bạn chỉ cần với tay là có ngay, nhanh hơn gấp trăm lần so với việc đi đến thư viện.</p><p>Trong thế giới máy tính, câu chuyện này diễn ra liên tục.</p><ul><li><strong>Thư viện khổng lồ</strong> chính là nơi lưu trữ dữ liệu chính, ví dụ như ổ cứng (HDD/SSD) hoặc Database. Nơi này có dung lượng lớn nhưng tốc độ truy cập khá chậm.</li><li><strong>Chiếc bàn làm việc</strong> của bạn chính là <strong>Cache</strong>.</li></ul><p><strong>Cache</strong> là một lớp lưu trữ dữ liệu tốc độ cao, có kích thước nhỏ, dùng để chứa một tập hợp con của dữ liệu gốc. Mục đích của nó là để các yêu cầu truy xuất dữ liệu trong tương lai được phục vụ nhanh hơn rất nhiều so với việc phải lấy dữ liệu từ database. Về cơ bản, cache cho phép chúng ta tái sử dụng một cách hiệu quả những dữ liệu đã được truy xuất hoặc tính toán trước đó.</p><h3 id=tại-sao-cache-lại-quan-trọng-đến-vậy>Tại sao Cache lại quan trọng đến vậy?<a hidden class=anchor aria-hidden=true href=#tại-sao-cache-lại-quan-trọng-đến-vậy>#</a></h3><p>Sử dụng cache mang lại 3 lợi ích cốt lõi, biến nó trở thành một kỹ thuật không thể thiếu trong hầu hết mọi hệ thống máy tính hiện đại.</p><ol><li><strong>Tăng tốc độ một cách chóng mặt (Performance):</strong> Đây là mục đích chính. Cache thường được triển khai trên các phần cứng truy cập nhanh như RAM (Bộ nhớ truy cập ngẫu nhiên). Tốc độ truy cập RAM nhanh hơn hàng trăm, thậm chí hàng nghìn lần so với ổ đĩa. Việc phục vụ dữ liệu từ cache giúp giảm độ trễ (latency) và tăng số lượng thao tác I/O mỗi giây (IOPS) một cách đáng kể, làm cho ứng dụng trở nên mượt mà và phản hồi nhanh hơn.</li><li><strong>Giảm tải cho hệ thống Backend:</strong> Cache hoạt động như một tấm khiên, che chắn cho cơ sở dữ liệu hoặc các dịch vụ API. Thay vì mọi yêu cầu đều phải truy cập vào cơ sở dữ liệu, phần lớn các yêu cầu đọc sẽ được cache xử lý. Điều này giúp cơ sở dữ liệu không bị quá tải, đặc biệt là trong những thời điểm có lưu lượng truy cập tăng đột biến, và giữ cho toàn bộ hệ thống ổn định.</li><li><strong>Tiết kiệm chi phí (Cost Efficiency):</strong> Ở quy mô lớn, việc phục vụ dữ liệu từ cache trong bộ nhớ (in-memory) có thể rẻ hơn đáng kể so với việc phải nâng cấp liên tục các máy chủ cơ sở dữ liệu hoặc trả chi phí cho lưu lượng mạng cao khi truy xuất dữ liệu từ các dịch vụ đám mây.</li></ol><h3 id=cache-hit-và-cache-miss>Cache Hit và Cache Miss<a hidden class=anchor aria-hidden=true href=#cache-hit-và-cache-miss>#</a></h3><p>Hoạt động của cache xoay quanh hai kịch bản chính: <strong>Cache Hit</strong> và <strong>Cache Miss</strong>. Khi một client (có thể là CPU, trình duyệt web, hoặc ứng dụng của bạn) cần dữ liệu, nó sẽ luôn hỏi cache trước tiên.</p><ul><li><strong>Cache Hit (Tìm thấy trong Cache):</strong> Đây là kịch bản lý tưởng. Dữ liệu được yêu cầu có tồn tại trong cache. Cache sẽ ngay lập tức trả về dữ liệu này cho client. Quá trình này cực kỳ nhanh chóng.</li><li><strong>Cache Miss (Không tìm thấy trong Cache):</strong> Đây là kịch bản không mong muốn. Dữ liệu được yêu cầu không có trong cache. Khi đó, hệ thống buộc phải truy cập đến database để lấy dữ liệu. Sau khi lấy được, dữ liệu này sẽ được sao chép một bản vào cache để những lần yêu cầu sau sẽ trở thành cache hit, rồi mới được trả về cho client.</li></ul><p>Một điểm cực kỳ quan trọng cần nhận thức ở đây là sự tồn tại của &ldquo;Cache Miss&rdquo; cho thấy một sự thật nền tảng: cache không phải là một phép màu tăng tốc miễn phí. Nó đi kèm với sự đánh đổi và chi phí. Một cache miss vốn dĩ còn <strong>chậm hơn</strong> một hệ thống không có cache. Bởi vì trong một hệ thống không cache, thời gian truy xuất chỉ đơn giản là thời gian lấy dữ liệu từ nguồn chính. Còn trong một cache miss, tổng thời gian là <code>Thời gian kiểm tra cache (và thất bại)</code> + <code>Thời gian lấy dữ liệu từ database</code>.</p><p>Do đó, mục tiêu của mọi chiến lược caching không chỉ đơn giản là &ldquo;có cache&rdquo;, mà là thiết kế một hệ thống nơi tổng thời gian tiết kiệm được từ vô số các cache hit phải lớn hơn rất nhiều so với tổng thời gian bị mất đi do các cache miss không thể tránh khỏi. Điều này biến caching từ một công cụ đơn thuần thành một bài toán tối ưu hóa chiến lược.</p><h3 id=tỷ-lệ-cache-hit-cache-hit-ratio>Tỷ lệ Cache Hit (Cache Hit Ratio)<a hidden class=anchor aria-hidden=true href=#tỷ-lệ-cache-hit-cache-hit-ratio>#</a></h3><p>Để biết cache của chúng ta có hoạt động hiệu quả hay không, chúng ta cần một thước đo. Thước đo quan trọng nhất chính là <strong>Tỷ lệ Cache Hit (Cache Hit Ratio)</strong>.</p><p>Công thức tính rất đơn giản</p><p>Tỷ lệ Cache Hit= Cache Hit​ / (Cache Hit + Cache Miss)</p><p>Tỷ lệ này, thường được biểu diễn dưới dạng phần trăm, cho biết có bao nhiêu phần trăm yêu cầu được phục vụ nhanh chóng từ cache. Một tỷ lệ cache hit cao (thường từ 80-95% trở lên đối với nội dung tĩnh) cho thấy cache đang hoạt động rất hiệu quả. Ngược lại, một tỷ lệ thấp cho thấy cache đang không được sử dụng tốt, có thể do cấu hình sai, chính sách dọn dẹp không phù hợp, hoặc kích thước cache quá nhỏ.</p><h3 id=cache-phần-cứng-cpu-cache>Cache Phần cứng (CPU Cache)<a hidden class=anchor aria-hidden=true href=#cache-phần-cứng-cpu-cache>#</a></h3><p>Loại cache nhanh nhất, cơ bản nhất nằm ở cấp độ phần cứng, được tích hợp trực tiếp CPU. Mục đích của nó là để bắc một cây cầu qua &ldquo;vực thẳm&rdquo; tốc độ giữa một CPU siêu nhanh và RAM chậm hơn nhiều.</p><p>Để hiểu điều này, chúng ta cần biết về <strong>Hệ thống phân cấp bộ nhớ (Memory Hierarchy)</strong>. Đây là một mô hình tổ chức bộ nhớ trong máy tính thành nhiều cấp, giống như một kim tự tháp. Càng ở đỉnh kim tự tháp, bộ nhớ càng nhanh, càng đắt và dung lượng càng nhỏ. Càng xuống đáy, bộ nhớ càng chậm, càng rẻ và dung lượng càng lớn.</p><p>Code snippet</p><pre tabindex=0><code>(1) Register
(2) L1 Cache
(3) L2 Cache
(4) L3 Cache
(5) RAM &lt;- Redis
(6) SSD
(7) HDD
</code></pre><p>CPU cache được chia thành nhiều cấp (Level), thường là L1, L2, và L3:</p><ul><li><strong>L1 Cache (Level 1):</strong> Đây là bộ nhớ cache nhỏ nhất và nhanh nhất, được tích hợp ngay trong từng nhân (core) của CPU</li><li><strong>L2 Cache (Level 2):</strong> Lớn hơn L1 nhưng chậm hơn một chút. L2 cache có thể nằm riêng cho từng nhân hoặc chung cho một vài nhân, tùy vào kiến trúc CPU.</li><li><strong>L3 Cache (Level 3):</strong> Lớn nhất và chậm nhất trong các cấp CPU cache. L3 cache thường được dùng chung cho tất cả các nhân trên một con chip. Nó giúp tăng tốc độ giao tiếp giữa các nhân và giảm thiểu việc phải truy cập ra RAM.</li></ul><h3 id=cache-phần-mềm>Cache Phần mềm<a hidden class=anchor aria-hidden=true href=#cache-phần-mềm>#</a></h3><p>Ngoài phần cứng, caching là một kỹ thuật được quản lý bởi phần mềm ở nhiều lớp khác nhau trong một ứng dụng. Đây là những loại cache mà các lập trình viên chúng ta thường xuyên tương tác và thiết kế.</p><ul><li><strong>Cache Trình duyệt (Browser Cache):</strong> Khi bạn truy cập một trang web, trình duyệt của bạn sẽ tự động lưu các tài nguyên tĩnh như hình ảnh, file CSS, JavaScript vào một thư mục trên ổ cứng. Lần sau khi bạn quay lại trang đó, trình duyệt sẽ tải các tài nguyên này từ ổ cứng thay vì phải tải lại từ server, giúp trang web hiển thị gần như ngay lập tức. Đây là một dạng cache phía client (client-side), riêng tư cho mỗi người dùng.</li><li><strong>Cache Mạng Phân phối Nội dung (CDN - Content Delivery Network):</strong> Đây là một mạng lưới các máy chủ proxy được đặt ở nhiều vị trí địa lý trên toàn cầu. Các máy chủ này lưu trữ (cache) bản sao của nội dung trang web (như video, hình ảnh, file tĩnh). Ví dụ điển hình là Netflix hay YouTube. Khi bạn ở Việt Nam và xem một video, rất có thể bạn đang nhận dữ liệu từ một máy chủ CDN đặt tại Singapore hoặc Hồng Kông, chứ không phải từ máy chủ gốc ở Mỹ. Điều này giúp giảm đáng kể độ trễ và tăng tốc độ tải.</li><li><strong>Cache Cơ sở dữ liệu (Database Cache):</strong> Hầu hết các hệ quản trị cơ sở dữ liệu như MySQL, PostgreSQL đều có một bộ đệm cache nội bộ. Nó lưu lại kết quả của các câu truy vấn (query) được thực thi thường xuyên. Khi nhận được một câu truy vấn giống hệt, thay vì phải quét lại toàn bộ bảng dữ liệu, database sẽ trả về kết quả từ cache của nó.</li><li><strong>Cache Ứng dụng (Application Cache / In-Memory Cache):</strong> Đây là lớp cache mà các lập trình viên chủ động thêm vào kiến trúc ứng dụng của mình, thường sử dụng các công cụ chuyên dụng như <strong>Redis</strong> hoặc <strong>Memcached</strong>. Lớp cache này có thể lưu trữ bất cứ thứ gì: kết quả của các phép tính toán phức tạp, phản hồi từ các API, các đối tượng dữ liệu đã được định dạng sẵn&mldr; Việc này giúp ứng dụng không phải tính toán lại hoặc truy vấn lại những thông tin tốn kém trên mỗi yêu cầu.</li></ul><p>Hãy xem xét cấu trúc: <code>Client -> Cache -> Nguồn</code>.</p><ul><li>Với CPU: Client là nhân xử lý, Cache là L1, Nguồn là RAM.</li><li>Với Web: Client là công cụ render, Cache là ổ cứng cục bộ, Nguồn là web server.</li><li>Với CDN: Client là trình duyệt, Cache là máy chủ biên (edge server), Nguồn là máy chủ gốc (origin server).</li><li>Với App: Client là logic nghiệp vụ, Cache là Redis/Memcached, Nguồn là Database.</li></ul><h2 id=khi-cache-bị-đầy-các-chính-sách-dọn-dẹp>Khi Cache Bị Đầy: Các Chính Sách &ldquo;Dọn Dẹp&rdquo;<a hidden class=anchor aria-hidden=true href=#khi-cache-bị-đầy-các-chính-sách-dọn-dẹp>#</a></h2><p>Chúng ta đã biết cache rất hữu ích, nhưng nó có một giới hạn cố hữu: dung lượng nhỏ. Bộ nhớ tốc độ cao (như RAM) rất đắt đỏ, vì vậy cache không thể lưu trữ mọi thứ.</p><p>Điều này dẫn đến một vấn đề không thể tránh khỏi: khi cache đã đầy và một mục dữ liệu mới cần được thêm vào, hệ thống phải quyết định loại bỏ một mục dữ liệu cũ để nhường chỗ. Quá trình này được gọi là <strong>Eviction</strong> (dọn dẹp/loại bỏ).</p><p>Thuật toán được sử dụng để quyết định <em>mục nào</em> sẽ bị loại bỏ được gọi là <strong>Chính sách dọn dẹp (Eviction Policy)</strong>. Quay lại với câu chuyện thư viện, khi bàn làm việc của bạn đã chật kín sách, bạn sẽ phải chọn một cuốn để trả lại thư viện trước khi mang cuốn mới về. Bạn chọn cuốn nào? Sự lựa chọn của bạn chính là một chính sách dọn dẹp.</p><p>Dưới đây là các chiến lược dọn dẹp phổ biến nhất.</p><h3 id=các-chiến-lược-dọn-dẹp-phổ-biến>Các chiến lược dọn dẹp phổ biến<a hidden class=anchor aria-hidden=true href=#các-chiến-lược-dọn-dẹp-phổ-biến>#</a></h3><ul><li><strong>FIFO (First-In, First-Out - Vào trước, Ra trước):</strong><ul><li><strong>Nguyên tắc:</strong> Đây là chính sách đơn giản nhất. Nó loại bỏ mục dữ liệu cũ nhất, tức là mục đã nằm trong cache lâu nhất, bất kể nó có được sử dụng thường xuyên hay không. Nó hoạt động giống như một hàng đợi (queue).</li><li><strong>Ưu điểm:</strong> Rất dễ cài đặt và có chi phí quản lý thấp.</li><li><strong>Nhược điểm:</strong> Thường không hiệu quả vì nó có thể loại bỏ một mục rất phổ biến chỉ vì nó được nạp vào cache từ lâu.</li></ul></li><li><strong>LRU (Least Recently Used - Ít được sử dụng gần đây nhất):</strong><ul><li><strong>Nguyên tắc:</strong> Chính sách này loại bỏ mục dữ liệu mà đã không được truy cập trong khoảng thời gian dài nhất. Nó hoạt động dựa trên nguyên tắc <strong>tính cục bộ về thời gian (temporal locality)</strong></li><li><strong>Ưu điểm:</strong> Hiệu quả hơn FIFO rất nhiều trong hầu hết các trường hợp thực tế, vì nó giữ lại những dữ liệu đang được sử dụng tích cực.</li><li><strong>Nhược điểm:</strong> Phức tạp hơn trong việc triển khai vì nó đòi hỏi phải theo dõi thời gian truy cập của mỗi mục, gây tốn thêm một chút bộ nhớ và xử lý.</li></ul></li><li><strong>LFU (Least Frequently Used - Ít được sử dụng thường xuyên nhất):</strong><ul><li><strong>Nguyên tắc:</strong> Chính sách này loại bỏ mục dữ liệu được truy cập với số lần ít nhất. Nó dựa trên nguyên tắc <strong>tính cục bộ về tần suất (frequency locality)</strong> – ý tưởng rằng có một số dữ liệu vốn dĩ đã phổ biến hơn những dữ liệu khác.</li><li><strong>Ưu điểm:</strong> Rất tốt trong việc xác định và giữ lại các mục dữ liệu &ldquo;hot&rdquo; (phổ biến) trong một thời gian dài, ngay cả khi chúng không được truy cập gần đây.</li><li><strong>Nhược điểm:</strong> Phức tạp để triển khai hiệu quả. Nó có thể không thích ứng nhanh với các mẫu truy cập thay đổi (ví dụ: một mục từng rất hot nhưng giờ không còn ai dùng nữa vẫn có thể chiếm chỗ trong cache một thời gian dài). Nó cũng có thể loại bỏ một mục mới được thêm vào nhưng chưa có cơ hội tích lũy đủ số lần truy cập.</li></ul></li></ul><h3 id=bảng-so-sánh-các-chính-sách-dọn-dẹp>Bảng so sánh các chính sách dọn dẹp<a hidden class=anchor aria-hidden=true href=#bảng-so-sánh-các-chính-sách-dọn-dẹp>#</a></h3><p>Để giúp bạn dễ dàng lựa chọn, đây là bảng so sánh các chính sách phổ biến:</p><table><thead><tr><th>Chính sách</th><th>Nguyên tắc cốt lõi</th><th>Ví dụ tương tự</th><th>Ưu điểm</th><th>Nhược điểm</th><th>Phù hợp nhất cho</th></tr></thead><tbody><tr><td><strong>FIFO</strong></td><td>Loại bỏ mục vào cache sớm nhất.</td><td>Xếp hàng mua vé: người đến trước được phục vụ trước.</td><td>Đơn giản, chi phí thấp.</td><td>Không thông minh, có thể loại bỏ dữ liệu quan trọng.</td><td>Các hệ thống có mẫu truy cập tuần tự, không lặp lại.</td></tr><tr><td><strong>LRU</strong></td><td>Loại bỏ mục ít được dùng đến gần đây nhất.</td><td>Dọn dẹp bàn làm việc: trả lại cuốn sách bạn không đụng đến lâu nhất.</td><td>Hiệu quả cao trong hầu hết các trường hợp, thích ứng tốt với sự thay đổi.</td><td>Phức tạp hơn, cần theo dõi thời gian truy cập.</td><td>Các ứng dụng thông thường, nơi dữ liệu gần đây có khả năng được tái sử dụng cao (ví dụ: trang tin tức, mạng xã hội).</td></tr><tr><td><strong>LFU</strong></td><td>Loại bỏ mục có số lần truy cập ít nhất.</td><td>Thư viện cho mượn sách: loại bỏ những cuốn ít người mượn nhất.</td><td>Giữ lại được các mục &ldquo;hot&rdquo; một cách ổn định.</td><td>Phức tạp, có thể giữ lại dữ liệu &ldquo;hot&rdquo; đã lỗi thời, không thích ứng nhanh.</td><td>Các hệ thống có một số dữ liệu cực kỳ phổ biến và ổn định (ví dụ: sản phẩm bán chạy, video viral).</td></tr></tbody></table><h2 id=giữ-cho-dữ-liệu-đồng-nhất-các-chính-sách-ghi>Giữ Cho Dữ Liệu Đồng Nhất: Các Chính Sách Ghi<a hidden class=anchor aria-hidden=true href=#giữ-cho-dữ-liệu-đồng-nhất-các-chính-sách-ghi>#</a></h2><p>Khi một ứng dụng thực hiện thao tác ghi (write) hoặc cập nhật (update), một vấn đề nghiêm trọng nảy sinh. Bây giờ chúng ta có hai bản sao của cùng một dữ liệu: một trong cache và một trong cơ sở dữ liệu. Nếu chúng không được cập nhật đồng bộ, cache sẽ chứa dữ liệu cũ. Việc phục vụ stale data cho người dùng có thể dẫn đến các lỗi nghiêm trọng, thông tin sai lệch và trải nghiệm tồi tệ.</p><p><strong>Chính sách ghi (Write Policy)</strong> là quy tắc xác định cách hệ thống xử lý các thao tác ghi để giải quyết vấn đề về tính nhất quán này.</p><h3 id=các-chính-sách-ghi-cốt-lõi>Các chính sách ghi cốt lõi<a hidden class=anchor aria-hidden=true href=#các-chính-sách-ghi-cốt-lõi>#</a></h3><ul><li><strong>Write-Through (Ghi Xuyên)</strong><ul><li><strong>Quy trình:</strong> Khi ứng dụng ghi dữ liệu, nó sẽ ghi <strong>đồng thời</strong> vào cả cache và cơ sở dữ liệu. Thao tác chỉ được coi là hoàn tất khi cả hai nơi đều đã ghi xong.</li><li><strong>Lưu đồ:</strong> <code>Ứng dụng -> Ghi vào Cache -> Ghi vào Database -> Hoàn tất</code></li><li><strong>Ưu điểm:</strong> Tính nhất quán dữ liệu rất cao. Cache và database luôn đồng bộ. Đơn giản để triển khai và đáng tin cậy.</li><li><strong>Nhược điểm:</strong> Độ trễ của thao tác ghi cao, vì ứng dụng phải chờ cả hai thao tác ghi hoàn tất.</li><li><strong>Trường hợp sử dụng:</strong> Các ứng dụng quan trọng nơi tính nhất quán dữ liệu là tối thượng, ví dụ như hệ thống ngân hàng, quản lý kho hàng.</li></ul></li><li><strong>Write-Back (Ghi Sau / Write-Behind)</strong><ul><li><strong>Quy trình:</strong> Khi ứng dụng ghi dữ liệu, nó chỉ ghi vào cache tốc độ cao trước. Thao tác được xác nhận hoàn tất ngay lập tức. Việc ghi vào cơ sở dữ liệu sẽ được trì hoãn và thực hiện sau đó, có thể là sau một khoảng thời gian nhất định hoặc khi mục cache đó sắp bị dọn dẹp. Hệ thống thường dùng một &ldquo;bit bẩn&rdquo; (dirty bit) để đánh dấu các mục trong cache đã bị thay đổi và cần được ghi lại vào database.</li><li><strong>Lưu đồ:</strong> <code>Ứng dụng -> Ghi vào Cache -> Hoàn tất. (Background: Cache -> Ghi vào Database)</code></li><li><strong>Ưu điểm:</strong> Độ trễ ghi cực thấp và thông lượng cao. Giảm tải cho database bằng cách gộp nhiều lần ghi vào cùng một đối tượng thành một lần ghi duy nhất (write-coalescing).</li><li><strong>Nhược điểm:</strong> Có nguy cơ mất dữ liệu nếu cache bị lỗi trước khi dữ liệu kịp ghi vào database. Phức tạp hơn để triển khai.</li><li><strong>Trường hợp sử dụng:</strong> Các ứng dụng có lượng ghi lớn, nơi hiệu năng là ưu tiên hàng đầu và có thể chấp nhận một rủi ro nhỏ về mất mát dữ liệu, ví dụ như ghi log hành vi người dùng, cập nhật số lượt xem bài viết.</li></ul></li><li><strong>Write-Around (Ghi Vòng)</strong><ul><li><strong>Quy trình:</strong> Khi ứng dụng ghi dữ liệu, nó sẽ ghi <strong>trực tiếp</strong> vào cơ sở dữ liệu, hoàn toàn bỏ qua cache. Dữ liệu chỉ được nạp vào cache sau này, khi có một yêu cầu đọc bị cache miss.</li><li><strong>Lưu đồ:</strong> <code>Ứng dụng -> Ghi vào Database -> Hoàn tất</code></li><li><strong>Ưu điểm:</strong> Tránh &ldquo;làm ô nhiễm&rdquo; cache bằng những dữ liệu có thể không bao giờ được đọc lại.</li><li><strong>Nhược điểm:</strong> Một yêu cầu đọc ngay sau khi ghi sẽ luôn luôn là cache miss, dẫn đến độ trễ đọc cao cho dữ liệu vừa được ghi.</li><li><strong>Trường hợp sử dụng:</strong> Các ứng dụng ghi dữ liệu nhưng hiếm khi đọc lại ngay sau đó, ví dụ như các hệ thống nhập dữ liệu hàng loạt (bulk data ingestion), lưu trữ log.</li></ul></li></ul><p>Các chính sách ghi không tồn tại một cách độc lập. Chúng liên kết chặt chẽ với cách hệ thống xử lý một <strong>write miss</strong> (khi ứng dụng muốn ghi vào một mục không có trong cache). Có hai lựa chọn:</p><ol><li><strong>Write Allocate (Fetch on Write):</strong> Khi có write miss, hệ thống sẽ tải khối dữ liệu đó từ database vào cache trước, rồi mới thực hiện thao tác ghi.</li><li><strong>No-Write Allocate:</strong> Khi có write miss, hệ thống sẽ ghi thẳng vào database, không tải dữ liệu đó vào cache.</li></ol><p>Sự kết hợp giữa chính sách ghi và chính sách write miss tạo ra các chiến lược hoàn chỉnh. Ví dụ, một hệ thống <strong>Write-Back</strong> thường đi kèm với <strong>Write Allocate</strong>. Triết lý của Write-Back là hấp thụ các thao tác ghi để tăng hiệu năng, với giả định rằng dữ liệu đó sẽ sớm được truy cập lại. Vì vậy, khi có write miss, việc tải dữ liệu vào cache trước là hợp lý để các thao tác sau đó có thể hưởng lợi từ cache. Ngược lại, một hệ thống <strong>Write-Through</strong> thường sử dụng <strong>No-Write Allocate</strong> (chính là chiến lược Write-Around). Triết lý của Write-Through là an toàn dữ liệu. Nếu có write miss, việc tải dữ liệu vào cache chỉ để ghi nó ngay lập tức ra database là không hiệu quả. Sẽ đơn giản hơn nếu ghi thẳng vào database và tránh làm ô nhiễm cache.</p><p>Hiểu được mối liên kết nhân quả này giúp các nhà phát triển đưa ra quyết định kiến trúc mạch lạc và tối ưu hơn, thay vì chọn hai chính sách một cách ngẫu nhiên.</p><h2 id=xây-dựng-hệ-thống-với-cache-các-mẫu-thiết-kế>Xây Dựng Hệ Thống Với Cache: Các Mẫu Thiết Kế<a hidden class=anchor aria-hidden=true href=#xây-dựng-hệ-thống-với-cache-các-mẫu-thiết-kế>#</a></h2><h3 id=mẫu-1-cache-aside-lazy-loading>Mẫu 1: Cache-Aside (Lazy Loading)<a hidden class=anchor aria-hidden=true href=#mẫu-1-cache-aside-lazy-loading>#</a></h3><p>Đây là mẫu thiết kế phổ biến và trực quan nhất. Trong mẫu này, logic của ứng dụng chịu trách nhiệm hoàn toàn cho việc quản lý cache.</p><ul><li><p><strong>Quy trình:</strong></p><ul><li>Ứng dụng cần đọc dữ liệu, nó sẽ kiểm tra cache trước.</li><li>Nếu có (cache hit), dữ liệu được trả về.</li><li>Nếu không có (cache miss), <strong>ứng dụng</strong> sẽ đọc dữ liệu từ database.</li><li>Sau đó, <strong>ứng dụng</strong> sẽ ghi dữ liệu vừa đọc được vào cache.</li><li>Khi ghi dữ liệu, ứng dụng thường sẽ cập nhật database trước, sau đó <strong>vô hiệu hóa (invalidate)</strong> mục tương ứng trong cache.</li></ul><p><img alt="Image Description" loading=lazy src=posts/imagespasted-image-20250810134139png/></p></li><li><p><strong>Ưu điểm:</strong> Ứng dụng có toàn quyền kiểm soát. Cache chỉ lưu những dữ liệu thực sự được yêu cầu, giúp tiết kiệm không gian. Hệ thống có khả năng chống chịu lỗi cache tốt (nếu cache sập, ứng dụng có thể đọc trực tiếp từ database).</p></li><li><p><strong>Nhược điểm:</strong> Yêu cầu đầu tiên cho bất kỳ dữ liệu nào cũng sẽ là cache miss. Code của ứng dụng phức tạp hơn vì phải chứa logic quản lý cache.</p></li></ul><h3 id=mẫu-2-read-through>Mẫu 2: Read-Through<a hidden class=anchor aria-hidden=true href=#mẫu-2-read-through>#</a></h3><p>Mẫu này trừu tượng hóa database khỏi ứng dụng. Ứng dụng chỉ cần &ldquo;nói chuyện&rdquo; với cache.</p><ul><li><strong>Quy trình:</strong><ul><li>Ứng dụng yêu cầu dữ liệu từ cache.</li><li>Nếu cache có, nó sẽ trả về.</li><li>Nếu cache không có, <strong>chính cache</strong> sẽ chịu trách nhiệm đi lấy dữ liệu từ database, lưu lại rồi trả về cho ứng dụng.</li></ul></li><li><strong>Ưu điểm:</strong> Đơn giản hóa code ứng dụng vì logic caching được đóng gói trong cache provider.</li><li><strong>Nhược điểm:</strong> Kém linh hoạt hơn. Cache provider phải hỗ trợ mẫu này.</li></ul><h3 id=mẫu-3--4-write-through-và-write-behind-write-back>Mẫu 3 & 4: Write-Through và Write-Behind (Write-Back)<a hidden class=anchor aria-hidden=true href=#mẫu-3--4-write-through-và-write-behind-write-back>#</a></h3><p>Đây là các mẫu tập trung vào việc ghi, thường đi đôi với Read-Through.</p><ul><li><strong>Write-Through:</strong> Ứng dụng ghi dữ liệu vào cache, và <strong>cache</strong> sẽ chịu trách nhiệm ghi đồng bộ dữ liệu đó vào database. Điều này đảm bảo tính nhất quán cao.</li><li><strong>Write-Behind:</strong> Ứng dụng ghi dữ liệu vào cache, và <strong>cache</strong> sẽ ghi dữ liệu đó vào database một cách bất đồng bộ (trong nền). Điều này cho hiệu năng ghi rất cao.</li></ul><p>Sự lựa chọn giữa Cache-Aside và các mẫu Read/Write-Through không chỉ là chi tiết kỹ thuật, mà là một quyết định kiến trúc nền tảng về <strong>sự phân tách trách nhiệm (separation of concerns)</strong>.</p><ul><li><strong>Cache-Aside</strong> đặt trách nhiệm điều phối dữ liệu lên vai ứng dụng. Ứng dụng &ldquo;biết&rdquo; cả về cache và database.</li><li><strong>Read/Write-Through</strong> coi cache như một lớp mặt tiền (facade) cho database. Ứng dụng chỉ cần biết &ldquo;lấy dữ liệu&rdquo; hoặc &ldquo;ghi dữ liệu&rdquo; tại một điểm duy nhất là cache.</li></ul><p>Mô hình Read-Through thúc đẩy sự phân tách trách nhiệm sạch sẽ hơn, dẫn đến code ứng dụng đơn giản và dễ bảo trì hơn. Tuy nhiên, nó lại ràng buộc chặt chẽ cache với database, khiến việc thay đổi database hoặc sử dụng cache cho các nguồn dữ liệu khác trở nên khó khăn. Ngược lại, Cache-Aside linh hoạt hơn – cache có thể chứa dữ liệu từ nhiều nguồn (database, API, file,&mldr;) – nhưng phải trả giá bằng sự phức tạp tăng lên trong code ứng dụng. Đây là một sự đánh đổi kinh điển giữa đơn giản/đóng gói và linh hoạt/kiểm soát.</p><h2 id=thách-thức-lớn-nhất-dữ-liệu-cũ-và-vô-hiệu-hóa-cache>Thách Thức Lớn Nhất: Dữ Liệu Cũ và Vô Hiệu Hóa Cache<a hidden class=anchor aria-hidden=true href=#thách-thức-lớn-nhất-dữ-liệu-cũ-và-vô-hiệu-hóa-cache>#</a></h2><p>Vấn đề cốt lõi vẫn là <strong>stale data</strong>. Khi dữ liệu trong nguồn chính bị thay đổi bởi một tiến trình khác mà cache không hề hay biết, cache sẽ trở nên lỗi thời. Phục vụ dữ liệu lỗi thời này có thể gây ra những hậu quả tai hại.</p><p><strong>Cache Invalidation</strong> là quá trình đánh dấu hoặc loại bỏ dữ liệu trong cache để nó không còn hợp lệ nữa.</p><h3 id=các-chiến-lược-vô-hiệu-hóa-cache>Các chiến lược vô hiệu hóa cache<a hidden class=anchor aria-hidden=true href=#các-chiến-lược-vô-hiệu-hóa-cache>#</a></h3><ul><li><strong>Time-To-Live (TTL) Expiration (Hết hạn theo thời gian):</strong><ul><li><strong>Quy trình:</strong> Đây là chiến lược đơn giản nhất. Khi dữ liệu được lưu vào cache, nó được gán một &ldquo;tuổi thọ&rdquo;, ví dụ 5 phút. Sau 5 phút, dữ liệu này tự động bị coi là không hợp lệ và sẽ bị xóa hoặc bỏ qua trong lần truy cập tiếp theo, buộc hệ thống phải lấy lại dữ liệu mới từ database.</li><li><strong>Ưu điểm:</strong> Dễ triển khai, đảm bảo dữ liệu cuối cùng sẽ nhất quán.</li><li><strong>Nhược điểm:</strong> Dữ liệu có thể bị lỗi thời trong suốt khoảng thời gian TTL. Việc chọn TTL phù hợp là một nghệ thuật cân bằng khó khăn: TTL quá ngắn sẽ làm giảm tỷ lệ cache hit, TTL quá dài sẽ tăng nguy cơ stale data.</li></ul></li><li><strong>Event-Driven Invalidation (Active Deletion - Xóa chủ động):</strong><ul><li><strong>Quy trình:</strong> Một cách tiếp cận chủ động hơn. Khi dữ liệu trong database được cập nhật (ví dụ, người dùng đổi ảnh đại diện), ứng dụng sẽ gửi một lệnh <code>DELETE</code> hoặc <code>INVALIDATE</code> rõ ràng đến cache để xóa mục tương ứng.</li><li><strong>Ưu điểm:</strong> Đảm bảo dữ liệu được vô hiệu hóa gần như ngay lập tức, mang lại tính nhất quán cao hơn nhiều so với TTL.</li><li><strong>Nhược điểm:</strong> Phức tạp hơn để triển khai. Nó đòi hỏi sự liên kết chặt chẽ giữa code ghi vào database và cache. Trong một hệ thống phân tán, nó rất dễ gặp phải các vấn đề về <strong>race condition</strong> (tranh chấp) hoặc lỗi mạng.</li></ul></li></ul><p>Vấn đề &ldquo;khó&rdquo; của cache invalidation không chỉ nằm ở việc <em>khi nào</em> cần vô hiệu hóa, mà là làm thế nào để đảm bảo việc vô hiệu hóa đó là <em>chính xác</em> và <em>nguyên tử</em> trong một môi trường có nhiều tiến trình chạy đồng thời. Đây là lúc chúng ta đối mặt với một vấn đề kinh điển về race condition.</p><p>Hãy xem xét kịch bản sau trong mẫu Cache-Aside:</p><ol><li>Tiến trình A đọc dữ liệu X. Bị cache miss.</li><li>Tiến trình A đi đến database để đọc dữ liệu X (phiên bản cũ).</li><li>Trong lúc đó, tiến trình B cập nhật dữ liệu X trong database và ngay lập tức gửi lệnh vô hiệu hóa cache cho X.</li><li>Tiến trình A, sau khi đọc xong dữ liệu X (phiên bản cũ) từ database, giờ đây lại ghi nó vào cache.</li><li><strong>Kết quả:</strong> Cache bây giờ chứa dữ liệu X đã lỗi thời, và lệnh vô hiệu hóa của tiến trình B trở nên vô nghĩa. Dữ liệu lỗi thời này sẽ tồn tại trong cache cho đến khi TTL hết hạn.
<img alt="Image Description" loading=lazy src=posts/imagespasted-image-20250810134758png/></li></ol><p>Đây không phải là lỗi của một công cụ cụ thể, mà là một lỗ hổng cơ bản trong việc định thời của các hoạt động phân tán. Các giải pháp cho vấn đề này, như sử dụng <strong>phiên bản (versioning)</strong> cho dữ liệu hoặc <strong>cơ chế cho thuê (lease)</strong>, không còn là các kỹ thuật vô hiệu hóa đơn giản nữa. Chúng là các cơ chế kiểm soát tương tranh (concurrency control) phức tạp. Ví dụ, với cơ chế lease mà Facebook sử dụng, chỉ tiến trình nào nhận được &ldquo;hợp đồng thuê&rdquo; khi bị cache miss mới có quyền ghi lại vào cache. Nếu một lệnh vô hiệu hóa xảy ra trong thời gian đó, &ldquo;hợp đồng thuê&rdquo; sẽ bị thu hồi, và thao tác ghi dữ liệu cũ của tiến trình A sẽ bị từ chối.</p><h2 id=kết-luận-cache---sự-đánh-đổi-thông-minh>Kết luận: Cache - Sự Đánh Đổi Thông Minh<a hidden class=anchor aria-hidden=true href=#kết-luận-cache---sự-đánh-đổi-thông-minh>#</a></h2><p>Nếu có một điều cần đọng lại, đó là: <strong>Cache không phải là một viên đạn bạc, mà là một kỹ thuật mạnh mẽ đòi hỏi sự đánh đổi thông minh.</strong></p><p>Mỗi quyết định bạn đưa ra – chọn loại cache nào, chính sách dọn dẹp ra sao, chính sách ghi nào, mẫu thiết kế nào – đều là một sự cân bằng giữa các yếu tố:</p><ul><li><strong>Hiệu năng</strong> và <strong>Chi phí</strong></li><li><strong>Độ phức tạp</strong> và <strong>Tính đơn giản</strong></li><li><strong>Tính nhất quán dữ liệu</strong> và <strong>Độ trễ</strong></li><li><strong>Mô hình tối ưu nhất mà tôi biết</strong>
<img alt="Image Description" loading=lazy src=posts/imagespasted-image-20250810135418png/></li></ul><p>Không có câu trả lời nào là đúng cho mọi trường hợp. Một hệ thống yêu cầu tính nhất quán tuyệt đối sẽ phải hy sinh một phần hiệu năng ghi (sử dụng Write-Through). Một hệ thống cần hiệu năng ghi tối đa có thể phải chấp nhận rủi ro về dữ liệu (sử dụng Write-Back).</p><p>Hiểu rõ các khái niệm và chiến lược này không phải để tìm ra một &ldquo;công thức hoàn hảo&rdquo;, mà là để trang bị cho bạn một bộ công cụ mạnh mẽ. Với bộ công cụ này, bạn có thể phân tích yêu cầu của ứng dụng, dự đoán các mẫu truy cập, và đưa ra những quyết định kiến trúc sáng suốt, phù hợp nhất với bài toán cụ thể của mình.</p><p>Chúc bạn thành công trên con đường xây dựng những hệ thống nhanh hơn, mạnh hơn và hiệu quả hơn!</p><hr><p><em>Nếu thấy hay, hãy để lại cho mình 1 comment xuống phía dưới để mình có động lực viết các blog chất lượng tiếp theo nhé!</em></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.nagih.io.vn/tags/cache/>Cache</a></li></ul><nav class=paginav><a class=prev href=https://blog.nagih.io.vn/posts/sql-overview/><span class=title>« Prev</span><br><span>SQL Overview</span>
</a><a class=next href=https://blog.nagih.io.vn/posts/kafka/><span class=title>Next »</span><br><span>Kafka</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Cache on x" href="https://x.com/intent/tweet/?text=Cache&amp;url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f&amp;hashtags=cache"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Cache on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f&amp;title=Cache&amp;summary=Cache&amp;source=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Cache on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f&title=Cache"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Cache on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Cache on whatsapp" href="https://api.whatsapp.com/send?text=Cache%20-%20https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Cache on telegram" href="https://telegram.me/share/url?text=Cache&amp;url=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Cache on ycombinator" href="https://news.ycombinator.com/submitlink?t=Cache&u=https%3a%2f%2fblog.nagih.io.vn%2fposts%2fcache%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.nagih.io.vn/>Nagih | Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>